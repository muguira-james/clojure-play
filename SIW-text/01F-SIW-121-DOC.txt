The Role of Dynamic Modeling in Simulation-Based Acquisition	Jerome B. Soller, Ph.D.	Steffanie MooreMike JonesCogniTech Corporation1060 East 100 South Suite, #202Salt Lake City, Utah  84102801-322-0101soller@cognitech-ut.comJoel B. DuBow, Ph.D.Janez JerajUniversity of UtahDept. of Materials Science and Engineering122 South Central Campus Dr. Room 304Salt Lake City, Utah 84112801-581-8388joel.dubow@m.cc.utah.eduKeywords:Modeling, Simulation, Acquisition, VPG, Sensors, Detectors, Chemical, Uncertainty, Distributed, TestABSTRACT: Military detectors and other systems that gather information on the state of  the battlefield operate in highly dynamic environments. This results in highly stochastic inputs to the sensing, control, and decision support systems that dominate modern military operations. Because C4I and other battlefield decision support systems rely on data from detection systems, the probability of mission success is highly dependent on the accuracy and response time of the detection systems. Optimizing the performance of detection and data fusion systems requires a sophisticated understanding and mathematical representation of the time dependent behavior of the detection systems in realistic environments.  Furthermore, these accurate representations require dynamic models of both the natural environment and related military systems. The integration of these representations is often denoted as a system of systems representing the battlespace environment.The effective use of these models and simulations requires a software architecture that supports standard data representations; allows simulations and decision support systems to communicate; supports common performance metrics; and facilitates the evaluation of simulations, equipment configurations, and decision support systems. This paper presents a framework for dynamic testing, an architecture that supports such testing in a collaborative environment, and a methodology to integrate test results and simulations to support acquisition decisions.  A hypothetical application  is presented  for a Simulation-Based Acquisition (SBA) of  an Improved Chemical Agent Monitor (ICAM). This application demonstrates the inherent strengths of the architecture and methodology in the context of dynamic modeling.1. IntroductionMilitary detectors and other systems that gather information on the state of the battlefield operate in highly dynamic environments. This results in highly stochastic inputs to the sensing, control, and decision support systems that dominate modern military operations. Because C4I and other battlefield decision support systems rely on data from detection systems, the probability of mission success is highly dependent on the accuracy and response time of these systems. Simulations need to accurately report on the environment and the actors in the environment. Simulations are derived from models of sensors and systems in the battlespace, in which time is a critical dimension. Therefore, these models need to represent the real-world time variation exhibited by the environment and detection systems over their mission profile.  The purpose of the sensors and detection systems is to provide accurate information for decision-making to maximize the likelihood of mission success.  Battlefield and acquisition decision-makers need to leverage the same sensor data and models of the sensors to make the best decisions.  If the acquisition process utilizes data and models that are different than those used in decision support, the success of the acquisition process may not produce useful information for decision support.   This information must represent ground truth reality and must use common representations and semantics.  Otherwise, the systems acquired will not meet expectations in the field and the resulting decisions will be suboptimal.  The requirements for decision support systems for field commanders need to be incorporated as an integral part of the acquisition process for sensors and detection systems. This paper focuses on an architecture for sensor models for chemical and biological defense that span the entire anticipated mission space and the integration of these models with environmental simulations, acquisition and decision support systems. The proposed architecture and associated methodology will enable meaningful and effective design, development, validation and analysis of models and the resulting software implementations.  The methodology for accurately modeling and simulating sensor data improve the acquisition, decision support, training, war gaming, and test and evaluation processes.2. Background2.1 Significance of Chemical and Biological Sensor ModelingFigure 1 [1] shows common sources of sensor data in a chem./bio defense scenario and the integration of that data into decision support systems. Decision support systems for Chemical and Biological Defense (CBD) rely heavily on both raw and transformed sensor data.  Examples of sensor instruments in this domain include long-range sensors (e.g., LIDAR, FTIR, radar) and short-range point detectors (e.g., Ion Mobility Spectrometers, Surface Acoustic Wave). Figure 1. Sensors and Decision Support in Battlefield C4I using a Chem./Bio Scenario [1] 2.3 CBW Modeling and Simulation ApproachesHistorically, chemical and biological instrumentation was modeled using Chemometric (multivariate statistics) techniques of considerable sophistication [2]. However, these techniques failed when applied to dynamic battlespace situations such as the Gulf war, where the steady state or slowly varying steady state assumptions caused the failure of the chemical agent detectors in the field.  Many soldiers reported disposing of their detectors in the field because of repeated false alarms and other malfunctions.   Professor Dubow, other researchers at the University of Utah, and Gary Bodily of Dugway PG recognized that inputs to the detectors in a dynamic battlefield situation were different from steady state conditions obtained in the laboratory or in most environmental applications [2]. This led to the development of a dynamic test system for detectors. This system yielded data that enabled the construction of dynamic models. The resulting models and simulations were applied to problems of the US Army Dugway Proving Ground, which supported the university efforts as part of their Virtual Proving Ground program.  The simulations discussed in this paper are derived by CogniTech and the University of Utah from those original university models.Dr. Janet Jensen of Aberdeen Proving Ground developed meaningful chemical sensor simulations for Surface Acoustic Wave (SAW) detectors.  Professor Meuzelaar and Neil Arnold of the University of Utah are continuing to develop test hardware and novel sensor configurations. 2.4 Collaborative Environments for Modeling and SimulationSeveral programs have developed software environments to support integration of sensor/detector models, environmental models, detection algorithms, and other systems.  These programs include TEAMS, CEE, and TENA.The Naval Surface Warfare Center's Testing Evaluation Assessment Modeling and Simulation (TEAMS) [3] facility simulates war fighting systems, the interfaces with adjunct systems and environments in a synthetic environment, while interfacing with actual fielded hardware.  It also supports 3-dimensional visualization of sensor performance.  TEAMS current sensor assets include: the Air Defense Alerting Device (ADAD), Acoustic Target Acquisition System (ATAS), Forward Observer/Forward Air Controller (FO/FAC), Man Portable Acoustic Sensor (MPAS), and Passive Sensor for Air Defense (PSAD).  The Air Force Research Laboratory Sensors and Information Directorates are partnering to apply the Collaborative Engineering Environment (CEE) [4] to simulation-based acquisition in a laboratory environment for the development and demonstration of information and sensor technologies. The CEE concept involves applying simulation and information technology to current business practices.  As the hub of an AFRL framework, it will tie together other major Air Force assets including the Aeronautical Systems Center's Simulation and Analysis Facility, high performance computers in the Major Shared Resource Center, and the Electronic System Center's Command and Control Unified Battlespace Environment.  The Test and Training ENabling Architecture (TENA) [5] is a software architecture for test and evaluation developed under the Secretary of Defense Central Test and Evaluation Investment Program Foundation Initiative 2010 [6].  It is implemented in the Java Programming language and prototypes are being tested at the White Sands Missile Range and the Naval Air Warfare Center. 3.  A Comprehensive Sensor Simulation ArchitectureCogniTech and the University of Utah share a vision of a comprehensive simulation architecture for sensors and detectors.  This architecture will support simulation based acquisition and decision support using common data, models, and methodologies.  This architecture was developed based on common requirements of stakeholders that use sensor models, simulations, and data.   Figure 2. Sensor Simulation ArchitectureFigure 2 demonstrates how a fully developed sensor simulation environment would be utilized.  Simulation developers would develop their simulations in a consistent format and test their simulations against standardized performance measures and public test data, which are stored in databases and generated by collecting field, test chamber, or laboratory data or by running simulations.  Upon completion of the simulation development process, the simulation developers will submit their simulations for verification, validation, and accreditation, which may include additional validation data sets not used to train the model parameters.  The framework will support Java, CORBA, HLA, and web services software interfaces operating in a secure fashion.  The framework should also integrate with hardware test devices, such as chemical stimulators (a chemical signal generator) and scene generators (a system that accurately produces the spectrum produced by the agent cloud), and high performance computing environments.  The data generated by the sensor simulations will serve as input into detection algorithms and battlefield C4I decision support systems (e.g., JWARN), as well as testing and simulation environments (e.g., TEAMS).  Simulation-based acquisition systems will rely on the availability of test data and models to simulate the performance of proposed detectors in their operational environment.The sensor architecture and methodology can support the acquisition process.  The following sections describe a scenario for the application of the architecture in a procurement using simulation-based acquisition.  The hypothetical procurement will be for a new chemical agent detector.  The detector evaluated for procurement will be the Ion Mobility Spectrometer (IMS), the core component of the Improved Chemical Agent Monitor (ICAM).  This example demonstrates how the application of SBA technologies and processes would have improved the procurement, had they been available at the time.  Specifically, CogniTech's architecture and methodology, in conjunction with the University of Utah dynamic sensor models, would have provided critical information to the program manager to reduce cost, improve performance, and accelerate the acquisition of the ICAM.4. Application to SBA for an IMS4.1 Ion Mobility SpectrometerFigure 3. Typical IMS Spectra for TDI [7]The Ion Mobility Spectrometer (IMS) [7] is the core component of the Improved Chemical Agent Monitor (ICAM).  Thousands of ICAMs have been purchased by the Army for use in the field.  Procurement of the ICAM started in the 1980s and a major upgrade program was implemented in the early 1990s.  During the initial IMS procurement, the capability to evaluate IMS performance under real-world conditions or to simulate how ICAM architecture changes would impact this performance was not yet available.   The purpose of the IMS is to identify the presence and estimate the concentration of target chemicals.  The output of an IMS is a spectrum of the type shown in figure 3.The models in this paper predict one point on the drift time axis (which is one spectrum) throughout the entire experiment (the elapsed time). This one point is chosen to provide the best estimate of the concentration target chemical as a function of time. In figure 3, this point would be the toluene diisocynate (TDI) peak. This peak would be used to estimate the concentration of TDI.The following scenario shows how SBA would be applied, had it been available at the time the ICAM was procured.  The ICAM prototype would be tested in a dynamic test system. The data collected by the dynamic test process would be used to build empirical models of the detector that accurately predict its performance over the mission profile.  The physics and chemistry of the detector and environmental conditions would constrain the model and its parameters.  The results of these models would be applied to identify and quantify deviations between detector performance and requirements.  These deviations would be used by the program manager to work with the testers and developers in a collaborative engineering environment to improve the detector to meet battlefield requirements.  This will identify performance issues early enough in the process to allow program modifications to be applied in a cost-effective way. The experimental section of this paper describes real test results on an individual ICAM that serves as a surrogate for the prototype.  These test results will lead to specific recommendations4.2. Experimental AssumptionsThe individual ICAM used in the experiments spent many years in the University of Utah laboratory.  The physical characteristics of this individual ICAM does not necessarily represent the characteristics of the whole space of ICAMs, but serve as a vehicle for showing how simulation can support acquisition.The testers are aware that an agent will not present itself to the detector as a steady state concentration. Test results in the field show that the input to a detector exhibits fluctuation. Figure 5 illustrates the type of inlet pressure fluctuations observed in the field. This waveform spans the concentration range of the detectors mission profile. Using the output of the ICAM for this input, along with the output for other representative inputs, a systems model is developed. In this case the model is a static nonlinearity followed by an AutoRegressive Integrated Moving Average (ARIMA) systems model. Furthermore, operational requirements of the instrument in the field require that the influence of noise, shock, and turbulence need to be evaluated. The software architecture described in this paper was integrated with simulations derived from the University of Utah models. The investigators configured the inputs with a wide range of values and noise models. The result of these test and modeling efforts produced a database. In the hypothetical example, the distributed database and simulations would be available to participants in this collaborative detector engineering effort. This effort automatically brings performance information and potential technical issues to participants at the earliest possible time. It also ensures the concurrent engineering needed to speed the transition from development to deployment and minimize technical risk.5. Simulation and Experimental ResultsThis section compares different models of the IMS given a variety of inputs designed to stimulate the detector over its complete operating envelope5.1 Detector TestFigure 4. Dynamic Test SetupModels in this study were tested over a data set containing the response of an ICAM IMS to a time varying input concentration of dimethyl methylphosphate (DMMP) produced by a chemical signal generator (stimulator) from the University of Utah. Within the IMS, DMMP ions react with themselves to form a dimer.  The development of accurate dynamic models of a chemical sensor requires a chemical signal generator that can stimulate the detector under test with pseudo-random continuous inputs or pulse trains. Figure 4 [8] shows a block diagram of this signal generator, which, to our knowledge, is the first instrument of its type. The peak of the dimer of DMMP is an indicator of the inlet concentration of that chemical. The models tested simulate the amplitude of the dimer peak over time. Reference input concentrations, measured independently by a Flame Photoionization Detector (FPD), were used as input to the models.  Figure 5 shows the input waveform to the ICAM.Figure 5. DMMP Reference Input Concentration5.2 Model ValidationThe validation of sensor simulations must incorporate metrics that combine ground truth, evolution over time, and representations of uncertainty.The model is validated comparing the model outputs with corresponding measurements from the actual IMS output. The models were tested for their response to time-varying input, uncertainty in input measurement, and various noise disturbances.  The performance measure for model validation is the mean square error (MSE) comparing a model output to an instrument output. The MSE is represented as: EMBED Equation.3   5.3. Models5.3.1 Static Nonlinear ModelModels of chemical detectors and analytical instruments are generally static mappings of the input to the output response over the operational range of the instrument. These models are often lookup tables or equations derived from experimental observations. The ICAM response was found to be sublinear at concentrations exceeding 750ppb. The parameters of this nonlinearity were fit to the data, developed at the University of Utah, plotting the peak output versus the magnitude of the input concentration. Although a static model for the instrument is sufficient to describe its behavior in a controlled constant concentration environment, such a model does not adequately describe an instrument's response to a time-varying input.5.3.2 ARIMA ModelA dynamic model captures the response to time varying inputs.  The initial dynamic model simulated is a combination of the static, non-linear model described above followed by an ARIMA model. A detailed analysis of the models shows that the ARIMA model exhibits a instability embodied as a numerator zero falling outside the unit circle.Figure 6. ICAM Output for Input of Figure 5 Moreover, the data fit approximated the time variation but didn't account for drift and the relatively high level of noise in the detector output. This model fit the time varying inputs well but didn't account for noise or perturbations well. A model that explicitly represents noise and adapts its noise terms to minimize error can better fit the data.5.3.3 Kalman FilterThe Kalman filter [9] is especially useful for noise and error analysis. It was used here to improve the ARIMA fit by estimating the response of the ICAM to noise and perturbation. Details of this modeling work will be reported elsewhere since this presentation focuses on SBA, the architecture and methodology.5.4. Significance of the ResultsMore significantly, the models and the data generated results that would have motivated meaningful improvements to the prototype ICAM program described in this example, had they been available in this framework at the time.Need for StabilityThis prototype ICAM exhibited instability for inverting the data. This means that it isn’t always possible to accurately estimate the input from the output spectra. While this is a correctable defect, this correction would need to be made before significant further development of the identification algorithm.Need to Minimize NoiseThis ICAM adds significant noise to the input signal. The sources of this noise need to be identified and compensated for in order to reliably use the ICAM at low concentration levels.Software Architecture ModificationThe architecture of the decision support systems and simulation environments using ICAM simulations and data must incorporate time and noise in a consistent representation and semantics.   6. ConclusionThese results, derived from the dynamic tests contained within the SBA architecture and methodology, would have identified potential problems early in the acquisition process. Moreover, the collaborative environment supported by the architecture would have permitted all stakeholders to review the results and make suggestions. A cost benefit analysis would prioritize the technical issues to address. The process would continue during the entire development cycle and beyond.  It would guide upgrades, deployment tactics, training and adaptation in the field.  At present, it is generally acknowledged that the offense leads the defense in the chemical and biological area.  Therefore, this type of dynamic modeling methodology and architecture should be incorporated into all ongoing and future procurements of chemical and biological detectors.In addition, the dynamic modeling methodology can provide techniques to evaluate the effect of changing hardware or software components on detector system performance.  It also provides means of calculating the effect of additional detectors or alterations of geographic detector deployment on agent detection probability, attack warning time, and end of attack indications.  7. AcknowledgmentsThis research was supported by the Office of Naval Research contract N00014-01-M-0131 to CogniTech Corporation and the U.S. Army Dugway Proving Ground contract DAAD09-00-P-0038 to the University of Utah. The ICAM data used to train the empirical sensor models were obtained at the University of Utah Center for Microanalysis and Reaction Chemistry, directed by Professor Henk Meuzelaar.  The authors also acknowledge the useful feedback and discussions with Dr. William Dement, Technical Director of the U.S. Army Dugway Proving Ground and Dr. Thomas Holland, TEAMS Director of the U.S. Naval Surface Warfare Center Dahlgren Division. 8. References[1]  US Department of Defense: "J.Chemical and        Biological Agent Detection, Joint Warfighting        Science and Technology Plan", 1997          http://www.fas.org/spp/military/docops/defense/       jwsp/jw04j.htm [2]  J. Dubow, J. Jarez, E. Kholmovski, J. Mathews,          G. Bodily, T. Evans, R. Liebert: "Dynamic Systems        Models of Ion Mobility Spectrometers" SPIE                                       conference proceedings, Vol. 4036, Spring 2001.[3]  Naval Surface Warfare Center:  "Testing,        Experimentation, Modeling, and Simulation",       http://www.nswc.navy.mil/teams/teams.html [4]  AFRL Sensors Directorate: "Overview of the Sensors        Directorate" Reference document SN-00-07.       http://www.afrl.af.mil/techconn/index.htm. [5]  R.A. McDonald: "The Case for Establishing System                      Engineering Guidelines that Address Entity       Observable Enhancers", SISO Simulation              Interoperability Workshop, 01S-SIW-115, Spring        2001.[6]  Col. K . Konwin: "Simulation Based Acquisition:        From Motivation to Implementation", SISO SIW        Proceedings, 01S-SIW-092, Spring 2001.[7]  G. Eiceman, Z. Karpas: Ion Mobility Spectrometry,        CRC Press, Boca Raton, 1994.[8]  N. Arnold, J. Dubow, I. Symmach,and H. Meuzelaar,       ITEA: "Chemical Signal Generators for Advanced      Point  Detection Models", Las Cruces, NM, June      1999.[9]  R. G. Brown and P. Y.C. Hwang: Introduction to            Random Signals and Applied Kalman Filtering, 2nd        ed., John Wiley, NY 1992. Author BiographiesJEROME B. SOLLER, PH.D. is the President of CogniTech Corporation.  He currently is the principal investigator of a contract to develop a web portal for the AFRL sensors directorate and a contract to develop a chemical sensor simulation environment for the Navy. He has previously held research positions at the University of Utah, the U.S. Department of Veterans Affairs, and industry.  His research focuses on statistical pattern recognition, simulations, expert systems, data mining, and software architecture. He received his Ph.D. in Computer Science from the University of Utah and his B.S. in Electrical Engineering from the Johns Hopkins University.JOEL B. DUBOW, PH.D. is a pioneer in the dynamic testing and model development of chemical detectors.  He is presently a professor of materials science at the University of Utah and has over 25 years experience as a researcher in sensors, actuators and their system representations. He is currently principal investigator on  a contract to model chemical detectors and test fixtures for the US Army Dugway Proving Ground. STEFFANIE MOORE is a software developer at CogniTech Corporation working with simulation framework development and tool development for distributed algorithm evaluation.  She received a bachelor's degree in physics and mathematics at the University of Utah, with thesis research involving the development of statistical models of photo-multiplier tubes and a calibration system for ultra high energy cosmic ray detectors with the High Resolution Fly's Eye Research Group.MIKE JONES attended the University of Utah in Chemical and Fuels Engineering.  He has worked as an analytical chemist in environmental and industrial chemical analysis, a process engineer and chemist in solvent refining of precious metals, and as a software developer in B2B web development, enterprise e-marketing / e-procurement, and messaging frameworks.  He is presently employed at CogniTech Corporation as a software developer where he works with simulations and simulation framework development.JANEZ JERAJ is pursuing a Ph.D. in Electrical Engineering at the University of Utah.  His research focuses upon adaptive, nonlinear models of detection systems and signal processing for interpreting detector data.Copyright 2001, SISO, Inc. Permission is hereby granted to SISO members and sponsors to quote any of the material herein, or to make copies thereof, for personal or internal organizational purposes, as long as proper attribution is made and this copyright notice is included. All other uses, including resale and/or redistribution for commercial purposes, are prohibited without written permission from SISO, Inc. PAGE  8PAGE  8 EMBED Visio.Drawing.5   EMBED Word.Picture.8   EMBED Visio.Drawing.5  