Developing a Flexible and Adaptable Tool for HLA ImplementationKevin MullallyAcuSoft, Inc.12249 Science DriveOrlando, FL 32826407-658-9888mullally@acusoft.comRodney LongTom VerscharenSTRICOM12249 Science DriveOrlando, FL 32826407-384-3928,407-380-4114Rodney_Long@stricom.army.mil, Tom_Verscharen@stricom.army.milKeywords:HLA, FOM, SOM, DIFABSTRACT: Developing tools for HLA requires consideration of the many different Object Model instances, SOMs and FOMs, that are implemented within the HLA domain.  As the interpretation of simulation data is dependent upon Object Model design, defining a problem space to apply solutions that are useful for all HLA implementations becomes difficult.  To be widely beneficial, HLA tools must afford a degree of flexibility for different Object Model data syntax and semantics and provide means to adapt to various simulation environments.The Federation Test System (FTS) was designed to provide a testing environment that can be applied universally to HLA implementations.  This paper will describe design considerations that allow the FTS to be flexible and adaptable within the HLA domain.  Problems that arose during FTS development will be discussed and implementation use cases will be presented.IntroductionMaturing HLA technology presents new and interesting challenges in simulation development.  As developers migrate to HLA, they will be introduced to the many facets of the HLA environment.  Support tools will be needed during this time to pave the way through the challenges of an unfamiliar, emerging technology. Under sponsorship from the US Army Simulation, Training, and Instrumentation Command (STRICOM), the Federation Test System (FTS) has been developed to support testing activities associated with the HLA Federation Development and Execution Process (FEDEP) [1], including application, integration, functional, and scenario testing.[2]  (Note that HLA Compliance Testing is a separate testing activity, which is facilitated by the DMSO.) Developing a successful tool for application within HLA requires special consideration.Problem SpaceIn his briefing to the USDA(A&T), Captain Hollenbach of the Defense Modeling & Simulation Office (DMSO) explained the need for the HLA:[3]User needs, and hence simulation representations, are diverse.Need flexibility to reuse simulations, individually or in combinations, building new only when existing ones cannot satisfy requirements.Must also be able to flexibly link simulations to live systems for testing, training, COA analysis, mission rehearsal, etc.DoD therefore needs a flexible, composable approach to constructing simulation environments. As a result, the HLA is an open architecture that allows a large degree of flexibility in implementation in order to support a wide range of modeling and simulation communities.  Disparity in HLA implementations is mainly created from the open specification of Object Models, which define the syntax and semantics of the data to be exchanged between simulations.   Each federation and simulation is responsible for creating its own Object Model in accordance with the HLA Object Model Template (HLA OMT).[4]  The number of Federation Object Models (FOMs) and Simulation Object Models (SOMs) implemented within HLA is unconstrained.   This flexibility does not come without cost.  To be cost effective and commercially viable, tools must be usable by a broad customer base; however, tools are also needed to satisfy the unique needs of individual federations.  In this context, tool developers carry the burden of bridging developers’ needs with solutions that can be tailored for each federation within the HLA environment. Federation Test SystemThe FTS is intended for use with any HLA federation, and has followed the basic software engineering methodology of black box testing.[5]  This method assumes the “Tester” cannot access the internal workings of the Federate Under Test (FUT).  Using the FTS, the Tester can send known data values through the Runtime Infrastructure (RTI) [6] to see how the FUT reacts.  The FUT may react by changing its human-machine interface (displays, audio, etc.), or may respond by sending data back through the RTI.  In the latter case, the FTS can be used to capture and analyze the resulting output.  This type of testing can be used to determine if the FUT has properly implemented the syntax and semantics of FOM/SOM data. The black box testing approach described above is a generic process that can be used throughout the different levels of the test process.FTS ApproachThere are many factors in the HLA federation environment that affect the testing process and test procedure development:Federation ObjectivesFOM DesignData Syntax and SemanticsSpecial Algorithms (i.e. Dead Reckoning)Local ArchitecturesNetwork ArchitecturesSynthetic Environment Issues (i.e. Terrain)This requires the FTS to be flexible and adaptable to various simulation environments.  Some of the HLA elements used to capture federation specific information are described below.Object Model DesignTo be useful, current and applicable to the needs of HLA developers, HLA tools such as the FTS must support the many Object Model instances, FOMs and SOMs, represented within the HLA domain.  An HLA OMT Data Interchange Format (OMT-DIF) has been defined that allows HLA implementers to openly share Object Model data.  Using the OMT-DIF, an HLA tool such as the FTS can import data definitions for the Objects and Interactions supported by an Object Model and interpret the  associated data syntax and semantics.Federation Execution Planner’s WorkbookHLA also supports numerous and varied simulation environments. The Federation Execution Planning Workbook (FEPW) [7] is used by a federation to capture the defining characteristics of the federation environment.   A FEPW Editor as well as a Data Interchange Format (FEPW-DIF) are currently being developed which will facilitate the use of this data by HLA tools. Some of these characteristics used by test tools include the objects and attributes, RTI services, and time management schemes supported by each individual federate.FTS ToolsThis section describes the tools that comprise the FTS.  Each tool is described by the functions provided, the means by which variations in the HLA federation environment are compensated, and the tools usage with other elements in the testing environment.Test FederateFunctions Provided by the Test FederateTest Stimulation: In order to test simulation interactions, objects may need to be provided in the test environment to stimulate the Federate Under Test (FUT).EXAMPLE: Testing weapons fire interactions;To demonstrate the FUT’s weapons fire capabilities, the FUT may need an object in the environment to behave as a target.To test the FUT’s susceptibility to weapons fire, the FUT may require an object in the environment to behave as an opponent and fire weapons upon the FUT.HLA Federation EnvironmentTo compensate for the many Object Model instances, FOMs and SOMs, represented within the HLA domain, the Test Federate is implemented as a scripted federate. Particular attention was taken in designing a scripting language that incorporates input from the OMT-DIF and HLA services calls for the RTI.A Federate Scripting Tool was developed as a user-friendly interface for creating Test Federate Scripts.  The Federate Scripting Tool provides a format for organizing functions to be executed during script runtime.  A function editor is utilized to create functions such as RTI service calls. The function editor collects necessary function parameters and inserts the functions into a script.  For function parameters that require object model input, a FOM navigator is used that presents FOM data, in a ready fashion, and allows the user to select desired data from the interface for input into a function.  In this manner, the user can simply point and click, creating Test Federate Scripts, quickly and easily, without the need for a programmer.The scripting language is defined in an ASCII text format.  For execution, the scripting language text is run through an interpreter that generates C++ source code.  The source code is then compiled into an executable.  When the script executable is run, it establishes a connection with the Test Federate, which performs RTI communications dictated by the script.Using a GUI interface for generating complex algorithms, such as Dead Reckoning, is impractical.  Therefore, special algorithms can simply be cut and pasted into a script’s C++ source code and compiled for execution.UsageWhen a Test Federate Script is executed, a connection is made between the script and the Test Federate to communicate functions defined in the script.  The Test Federate will then execute functions communicated by the script.  For RTI Service functions, a connection is made between the Test Federate and the RTI.  Appropriate RTI Service calls are then made by the Test Federate.Analysis FederateFunctions Provided by the Analysis FederateData Collection: Testing in a distributed simulation environment requires a mechanism to collect simulation data for analysis and review.   Data must be captured from the distributed environment and stored for later use.  For HLA Testing, an RTI interface is needed to access simulation data.Data Analysis: After simulation data has been collected, analysis routines are performed to test if the data is valid.  Analysis metrics will vary, based on expected output and the applied test methodology.Results Reporting: After simulation data has been collected and analyzed, analysis results need to be reported to the tester.  Effective results reporting should provide a detailed account of the determination of an analysis result.  The data analyzed, a statement of expected data, and a statement of the applied metrics should all be presented in a results report.HLA Federation EnvironmentTo compensate for the many Object Model instances, FOMs and SOMs, represented within the HLA domain, the Analysis Federate is implemented as a scripted federate in the same way as the Test Federate.  The Federate Scripting Tool is used to create Analysis Scripts, employing the scripting language with some additional analysis and reporting functions.  The scripting language text is then run through an interpreter, which generates C++ source code.  Special algorithms can be input into an Analysis Script’s C++ source code in the same way as Test Federate Scripts. UsageThe Analysis Federate will behave in the same way as the Test Federate, with the exception that when an Analysis Script is executed, the Analysis Federate will perform scripted analysis and reporting functions and generate a Test Report file.  Reporting functions are then displayed in real-time and saved for later review in the Test Report file.Test ManagerFunctions Provided by the Test ManagerFormal Testing Control: There are many different methods for testing distributed simulation.   The applied test method will vary depending on the purpose of the test and the metrics used.   One test method would be Unit Testing, where a developer would test a component of their system for proper performance and valid output in an isolated test. More formal test methods could be applied where Test Procedures are defined for specific requirements of a federate or federation.  Formal Testing requires that elements of the testing environment be controlled to ensure that testing events occur in proper order.HLA Federation EnvironmentTo accommodate a formal testing environment, the Test Manager is established as a controlling mechanism for the Test Federate and Analysis Federate during Test Procedure execution. To develop Test Procedures, the Test Procedure Generator tool is used.  Test Procedures are captured and organized in a Test Procedure Set.  The Test Procedure Set employs a format similar to the OMT-DIF to exchange Test Procedure data.  Each Test Procedure in a Test Procedure Set contains the following information:Initial Conditions: Testing environment conditions that need to be satisfied before the Test Procedure is performed.Scenario: A textual description of the Test Procedure, its events and how it is to be performed.Criteria: A detailed description of the metrics used to determine if the FUT will pass or fail the Test Procedure.Requirements: The Federation requirements (Federation Agreements, Interaction Protocols, FOM Lexicon) that pertain to the Test Procedure.Capabilities: The FUT capabilities that are being tested by the Test Procedure.Also included in the Test Procedure Set are instructions that walk the Federate Under Test (FUT) through the test scenario.  Test Federate Scripts and Analysis Scripts are synchronized by the issuance of instructions.  This ensures that testing events occur in proper order between the Test Federate, Analysis Federate and the FUT.UsageFor Unit Testing the Test Federate and Analysis Federate can be run in a standalone mode.  For Formal Testing, the Test Session Manager is used to orchestrate the execution of Test Procedures created by the Test Procedure Generator.  During a Test Session the Test Session Manager will:Provide a selection of Test Procedures to be performed.Provide instructions for the FUT operator, walking them through the Test Procedure scenario.Cue the Test Federate to execute Test Federate Scripts.Cue the Analysis Federate to execute Analysis Scripts.FTS Development ProblemsSince the inception of the FTS program over a year ago, many difficulties have been encountered in our efforts to develop a flexible and adaptable HLA tool for federation testing.  In the beginning, our biggest task was to identify what needed to be tested.  Since that time a number of components of the HLA development environment have come to light, such as the FEDEP, the OMT-DIF and the FEPW.  These components have been essential in defining testing requirements for HLA federation testing.  Further development is required in the areas of Conceptual Model development and the creation of a FEPW data interchange format.Data marshaling continues to be a problem that inhibits FTS development.  The HLA Interface Specification only requires that the RTI pass data between federates.  It is the responsibility of federates and federations to determine how data is to be communicated with regards to data types, byte ordering and other data marshaling issues.  The HLA OMT does specify basic data types, however there seems to be confusion within the HLA community on how to consistently handle the complex, any, and enumerated data types.  This confusion is evident by the amount of discussion on the SISO reflectors dedicated to this subject.  At this time, the FEPW seems to be the place at which some developers are pointing to collect information about how data is to be handled.  In order for the FTS and other HLA tools to be flexible in the handling of data, more work needs to be done to identify consistent mechanisms for data marshaling.ConclusionFlexibility and adaptability have been described necessary characteristics of a successful HLA tool.  The Federation Test System has been presented as a federation independent HLA tool that is useful, current and applicable to the needs of HLA developers.  Work will continue with the FTS to make use of the FEPW and other emerging HLA technologies, maximizing reuse and paving the way for HLA developers.References[1] Department of Defense High Level Architecture Federation Development and Execution Process (FEDEP) Model. Draft Version 1.2, 26 May 1998.[2] D. W. Roberts, M. M. Horst and J. A. Old, “Federation Testing Process and Tools: Federation Test and Management Integration Support and Study Final Results Report,” Georgia Tech Research Institute, Final Report on Contract N61339-97-K-0001, April 30, 1998.[3] Captain Jim Hollenbach, USN; Defense Modeling and Simulation Office “HLA Transition Report to USD(A&T) Decision Briefing to the EXCIMS”, April 2, 1998.[4] Department of Defense High Level Architecture Object Model Template Version 1.3, 5 February 1998.[5] Loper, Margaret; McLean, Thom: “The High Level Architecture Federate Compliance Testing Process”. 1997 Spring Simulation Interoperability Workshop Conference Papers, March 3-7, 1997[6] Department of Defense High Level Architecture Interface Specification Version 1.3 DRAFT 1, 20 April 1998[7] Department of Defense High Level Architecture Federation Execution Planners Workbook (FEPW), Version 1.3 Draft 7, 10 June 1998.[8] Dahmann, Judith Dr.; Lutz, Robert; Sheehan, Jack H.: “Planning for the Evolution of Automated Tools in HLA”. 1997 Spring Simulation Interoperability Workshop Conference Papers, March 3-7, 1997.Author BiographiesKevin Mullally is a Project Manager for AcuSoft, Inc., Orlando, FL.  Mr. Mullally holds a bachelor’s degree in Electrical Engineering from the University of Central Florida and has worked within the distributed simulation industry for over six years.  With a focus on distributed simulation testing, he has been involved with the development of testing software for DIS and HLA.  Mr. Mullally currently serves as the chair for the SISO SIW Testing Forum.Rodney Long is a Computer Engineer for the U.S. Army Simulation, Training, and Instrumentation Command.  Mr. Long holds a B.S.E in Computer Engineering from the University of South Carolina and has 11 years of experience in modeling and simulation for the training community.  Tom Verscharen is a Project Director for the U.S. Army STRICOM.  Mr.Verscharen holds a master's degree from Penn State University in Industrial Engineering and Operations Research and has been with the Government in training systems and simulation for fifteen years.  He has worked in the areas of ASW, aircraft, and battle force simulation and has spent 9 years in research and technology development, with the last two years concentrating on the development of testing software for DIS and HLA.