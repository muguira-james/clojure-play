Optimum Dynamic Load-Balancing Algorithm for Synchronous Parallel SimulationXue-hui Wang Bao-hong LiuJian HuangKe-di Huang School of Mechatronics Engineering and AutomationNational University of Defense TechnologyChangsha, Hunan province, P.R. China  +86-731-4574672,yzmailbox2003@163.com, zlmailbox2000@163.com, findzhanglei@hotmail.com Keywords:  Synchronous Parallel Simulation(SPS), optimistic synchronization algorithm,  load-balancing, dynamic algorithmABSTRACT: Parallel simulation is used to study the behaviors of complex systems. These systems often exhibit irregular load characteristics that change over time and are difficult to predict accurately. Most parallel simulation systems employ user-defined static partitioning. However, static partitioning requires in-depth domain knowledge of the specific simulation model in study. Contrarily dynamic load-balancing allows the simulation system to automatically balance the load of different simulation models without user’s input. This paper presents an optimum dynamic load-balancing algorithm for synchronous parallel simulation. This algorithm dynamically balances the load on processors in order to reduce the time of simulation, and thus increase the total simulation speed. Also the simulation processes are allowed to migrate according to the load of the processors.IntroductionLarge complex system simulation in various fields of science and engineering requires tremendous computational resources; however sequential execution algorithms badly limited its performance. So recently there has been a great deal of interest in parallel and distributed simulation, which runs on multiple processors to accelerate simulation. It facilitates the research of large-scale complex dynamic systems, even to explore far-ranging application spaces. Parallel simulation is used to study the behaviors of complex systems. These systems often exhibit irregular load characteristics that change over time and are difficult to predict accurately. Partitioning plays an important role in achieving good performance when simulating these systems. It enables simulation load to be evenly distributed among the processors.As well known, the performance of a parallel simulation depends very much on partitioning simulation load evenly among the set of processors to ensure load-balance between processors. Most parallel simulation systems rely on users to define the required partition. However, defining good partition for a complex simulation model often requires in-depth domain knowledge. The dynamic behaviors of the model also means that a good static partition at the start of a simulation run may become less effective over time. So it is not effective if the load of a simulation model could not be quantified accurately or changes over time during a simulation run. Therefore we would rather adopt more flexible means of the dynamic balance load. Dynamic load-balancing algorithm (DLBA) offers the ability to balance the load of the simulation system as the simulation progresses. This can achieve consistent performance given any arbitrary simulation model with unpredictable load characteristics.Synchronization MechanismsTime management is concerned with ensuring that the execution of the PDS is properly synchronized, which is particularly important for developer and user. Because the synchronization not only ensures that events are processed in a correct order in logic, but also helps to ensure that repeated executions of a simulation with the same inputs produce exactly the same results. In other words, the goal of the synchronization mechanism is to make all LP processed events accord with the local causality constraint (LCC) or else doubtless results in causality violations.A parallel simulation consists of a number of Logical Processes (LP) that communicate by exchanging time-stamp messages or events, typically each one running on a separate processor. The simulation progress is ensured by the processor scheduling new events to be executed in the future, and executing these events in the time-stamp order. A process can schedule an event for itself, locally thus (self-initiation), or remotely, for another process. In the latter case, a message is sent via the network to the remote process. Each process maintains a separate time clock, called the Local Virtual Time [1]. Synchronization algorithms can be classified as being either conservative or optimistic. In brief, conservative algorithms take precautions to avoid the possibility of processing events out of time stamp order, i.e., the execution mechanism avoids synchronization errors. For another, optimistic algorithms use a detection and recovery approach. Events are allowed to be processed out of time stamp order, however, a rollback mechanism is provided to recover from such errors. 2.1 Conservative ProtocolThe principal task of any conservative protocol is to determine when it is “safe” to process an event. An event is said to be safe indication that no event containing a smaller time stamp will be later received by this LP. Namely conservative approaches do not allow an LP to process an event until it has been guaranteed to be safe. At the heart of most conservative synchronization algorithms is for each LP to compute a Lower Bound the Time Stamp (LBTS) of future messages that may later be received by that LP. This allows the mechanism to determine which events are safe to process.Conservative protocols require each logical process to broadcast to its neighbors, in the form of null messages, a LBTS of events it will send to other logical processes, or Earliest Output Time (EOT).  By listening to the null messages from all neighbors, each logical process can determine the lowest timestamp of any events it will receive, or called Earliest Input Time (EIT). If the EIT is larger than the timestamp of the earliest event in its local event list, the logical process is certain that this earliest event can be processed without violating the causality constraint [2]. Otherwise, the logical process has to block until the earliest local event is safe to be processed.2.2 Optimistic ProtocolIn contrast to conservative approaches that avoid violations of the local causality constraint, optimistic methods allow violations to occur, but are able to detect and recover from them. In any optimistic protocols, a logical process is allowed to aggressively process local events, and to send to other logical processes new messages generated by the event execution. However, when an event arrives with a timestamp smaller than the local simulation time, which is called a straggler, a causality error is triggered.For example, the Time Warp mechanism is well known optimistic method. [2] When an LP receives an event with timestamp smaller than one or more events has already processed, it rolls back and reprocesses events in timestamp order. Rolling back an event involves restoring the state of the LP to that which existed prior processing the event. Time Warp are sent optimistically, i.e., aggressively, or with risk. All processed local events later than the straggler must be undone, and anti-messages must be sent to other logical processes to cancel messages sent during the execution of these events.Optimistic Synchronization Algorithm on SPS3.1 Synchronous Parallel Simulation ModelSynchronous Parallel Simulation (SPS) model has features such as simple programming interfaces, scalable performance and a simplified cost model for performance prediction. The SPS model allows the separation of concerns between the computation cost, synchronization cost and communication cost when designing a parallel algorithm. A SPS programming model consists of P processors linked by an interconnecting network and each with its own pool of memory. The SPS processors communicate with one another by exchanging messages using the inter-connect network.3.2 The Event HorizonThe event horizon is a concept that can first be understood without referring to parallel processing. Imagine first that all pending events are mapped into a single event queue. As each event is processed, it may generate zero or more new events with arbitrary time stamps.To maintain complete generality, it is assumed that the simulation engine has no way to predict what each event will do until it is processed. All newly generated events are maintained in a special auxiliary event queue. At some point in time, the next event to be processed will be in the auxiliary event queue. This point in time is called the event horizon [3].One of the key features of the event horizon is that, by definition, events in a given cycle are not disturbed by other events generated in the same cycle. If the events were distributed to multiple processors and if the event horizon was known before hand, it would be possible to process events in parallel without ever receiving a straggler message. The event horizon is not determined, however, until the events in the current cycle are actually processed [4]. EMBED Visio.Drawing.6  Figure 1 event horizon and event queueFigure 1 illustrates the relationship of event horizon and event queue. Here, three event horizon cycles are shown. Each cycle processes its pending events while collecting newly generated events in an auxiliary event queue. When the next event to be processed is in the auxiliary event queue, the auxiliary event queue is sorted, merged into the primary event queue, and then the next cycle begins. Cycle 3 shows that even when an event schedules a new event for the same time as itself, the event horizon algorithm always processes at least one event. Thus, there is no way for a deadlock situation to occur when processing events in cycles defined by the event horizon.3.3 Optimistic Synchronization AlgorithmThe optimistic synchronization algorithm for the SPS time management is simply shown as below. Each processor manages a group of logical processes (LPs) in the system. In this algorithm, LPs in the same processor share a common event-list. And when come into the outer while loop a series of integrated-step are executed by each processor and the SPS_sync() statement at the end of the loop[5].SPS begin();Initial()While   (GVT < SimEndTime)   doReceiveExternalEvents(); RB_DEFINE_TREE();     // ProcessRollback; ComputeGVT();         // Compute new GVT FossilCollection(); // perform fossil collection            Ne=ComputeEventHorizon();  //compute new event limit Ne every N integratedstep;ExecuteNeEvents;SPS_sync();endwhileSPS end();The algorithm provides an automatic means of limiting the number of events by event horizon, Ne being simulated per integrated-step based on statistics from fossil collected events. The aim of the algorithm is to complete the simulation in the least number of integrated-step possible.3.4 Global Virtual TimeFor all the high performance demonstrated on shared memory architecture, the cost of state saving and restoration still excessive. During forward execution the logging cost is the most part of the overheads. It can explore the parallelism in a system by allowing out of order event execution [6].  Some of these event executions may not be correct and need to be cancelled. When an event with time stamp t arrives in a process and the process already executed an event with a time stamp greater than or equal to t, the current logical process needs to be recovered to the state before time stamp t to be able to correctly execute the new event.So there are still two problems remain to be solved. For one thing, certain computations, e.g., I/O operations, cannot be rolled back. For another thing, the computation will continually consume more and more memory resources because a history must be retained, even if no rollbacks occur; some mechanism is required to reclaim the memory used for this history information. Both problems are solved by global virtual time (GVT).GVT is defined as the minimum time stamp of all events in transit or in the input queues of all logical processes. No new event generated can have a smaller time stamp than GVT. Therefore all states except that has smaller time stamp than GVT can be discarded safely. GVT is computed by observing that rollbacks are caused by messages arriving "in the past." Therefore, the smallest timestamp among unprocessed and partially processed messages gives a value for GVT. Once GVT has been computed, I/O operations occurring at simulated times older than GVT can be committed, and storage older than GVT (except one state vector for each LP) can be reclaimed. EMBED Visio.Drawing.6  Figure 1 The computation of the GVTThe computation of the GVT is shown in Figure 1. The Global Virtual Time (GVT) gives a lower bound on the timestamp of the earliest unprocessed event in the simulation. Any event processed with simulation time earlier than the GVT is committed, in the sense that it will never be rolled back.The global virtual time (GVT) shows the advance of a parallel simulation run. The GVT computation is performed after every n integrated-step; n is also known as the GVT update interval. Memories for events or states in an LP with time-stamps smaller than GVT are reclaimed after each GVT computation. The body of the loop is executed till the processor’s GVT value is greater than the simulation end time.Dynamic Load-balancing AlgorithmIn this section, a new dynamic load-balancing algorithm that balances both computation and communication workload among the processors is presented.4.1 The Cost Modeling of SPSIt is evident that the performance of the optimistic synchronization algorithm relies on three factors: a) computation balance; b) communication balance; and c) the total number of integrated-step N. We adopt C1, C2 and C3 to respectively represent the computation cost, the communication costs and the synchronization costs. For easy to analysis, we define the variables and expressions as below:N:  the total number of integrated-step;F(i): the computation cost for integrated-step i;S(i): the maximum number of messages sent respectively by any processor in integrated-step i;R(i): the maximum number of messages received respectively by any processor in integrated-step i;    D: the architecture dependent parameters D represent the communication cost;    L: the architecture dependent parameters L represent the synchronization cost;Then the SPS cost model with optimistic synchronization algorithm can be expressed as: EMBED Equation.3                    …… (1)and that EMBED Equation.3    …… (2) EMBED Equation.3               …… (3) EMBED Equation.3     …… (4)Using (2) (3) (4), the equation (1) may now be transformed into: EMBED Equation.3     …… (5)4.2 Load-Balancing for ComputationThe parameter ( determines if the simulation system is suffering from computation or communication load-imbalance. Computation load-balancing is only activated when the computation load-imbalance, F(i) exceeds the threshold value (. Where (Pi,work) is the total computation workload for processor Pi since the last migration point. The functions  EMBED Equation.3   give the maximum computation workload across all processors. And  EMBED Equation.3   give the average computation workload across all processors. Then F(i) is defined as follows: EMBED Equation.3         … (6)The pseudo code for the procedure balance computation is presented as below:pid := sps_pid();while F(i) > ( do AverageW:=(Pmax.work+Pmin.work)*1/2;loadMigrate := Pmax.work - AverageW;if  pid = max  thensend workLoad(loadMigrate,Pmin);endifPmax. work := AverageW;Pmin. work := AverageW;Compute F(i);EndwhileWhere Pmax is the processor with the max computation workload; Pmin is the processor with the min computation workload. The procedure send_workload() migrates the required amount of computation workload to the destination processor. The selection of simulation objects to migrate gives preference to those with higher computation workload so that fewer simulation objects are migrated. The procedure terminates when F(i) falls below the threshold set by (.4.3 Load-Balancing for CommunicationCommunication load-balancing is only activated when the communication load-imbalance, M(i)=S(i)+R(i) exceeds the threshold value (. (Pi, com) is the total communication for processor Pi since the last migration point. The functions  EMBED Equation.3   give the maximum communication across all processors. And  EMBED Equation.3   give the average communication across all processors. Then M(i) is defined as follows: EMBED Equation.3           …… (7)The pseudo code for the procedure balance communication is presented as below:pid=sps_pid();while M(i) > ( do EMBED Equation.3  ;if pid = max then  send workLoad(a,Pmin) endifif pid = min then send workLoad(a,Pmax) endifAverageC:=(Pmax.com+Pmin.com)*1/2;Pmax:com := AverageC;Pmin:com := AverageC;compute M(i);endwhileThe procedure uses exchange of computation workload to balance the communication workload between two processors so as to preserve computation balance. The estimated amount of workload, a, to be exchanged between the processors having the maximum and minimum communication workload is computed using the equation shown in the algorithm. Both processors then proceed to send the same amount of computation workload to each other. The procedure terminates when M(i) falls below the threshold (.ConclusionPast studies of dynamical load balancing algorithm for optimistic parallel simulation protocols have typically focused on which metrics to use to measure the actual workload of the system. Different metrics have been proposed, Most of these metrics try to balance load between processors by making them progress in simulation time at about the same rate, with respect to real time. In this paper, the metrics used are the computation and communication workload. The rate of progress in simulation time between integrated-steps for each processor in SPS is automatically controlled by the adaptive event limit set for each integrated-step.In order to speedup the synchronous parallel simulation on a heterogeneous non-dedicated multiprocessor system, using the cost model for SPS, a new dynamical load balancing algorithm is proposed. This algorithm dynamically balances the load on processors in order to reduce the total execution time, which is shown to be able to achieve consistently better performance over the original SPS optimistic protocol by balancing both computation and communication workload, Our simulation experiment result indicate that this algorithm provide better performance when the difference between processor’s speed and/or the variation of workload is large. Further work is needed to improve the computation and communication load-balancing modules to take into account lookaheads between processors when selecting simulation objects for migration.References[1] Kamil Iskra, Parallel Discrete Event Simulation Issues with Wide Area Distribution, ASCI course a9, March 7, 2003[2] C.D. Carothers, and R.M. Fujimoto, Efficient Execution of Time Warp Programs on Heterogeneous, NOWPlatforms, IEEE Transactions on Parallel and Distributed Systems, vol. 11, no. 3, pp. 299–317, March 2000.[3] Metron, Inc., SPEEDES User’s Guide, http://www.speedes.com, 2004[4] Steinman, J. Breathing Time Warp, in Proc. of the 7th Workshop on Parallel and Distributed Simulation. 1993.San Diego. p.109--118.[5] Malcolm Yoke Hean Low. Dynamic Load-Balancing for BSP Time Warp. Proceedings of the 35th Annual Simulation Symposium (SS’02), 2002 IEEE Computer Society.[6] Jenny Ulriksson, et al., A Web-based Environment for building Distributed Simulations, 02S-SIW-036, Simulation Interoperability Workshop, 2002Author BiographiesWANG XUE-HUI: She is a Ph.D. candidate in School of Mechatronics Engineering and Automation at National University of Defense Technology. She received her B.S. and M.S. degrees in Control Engineering and Science from National University of Defense Technology in 2000 and 2002. Her primary field of research includes High Level Architecture (HLA), distributed interactive simulation, theory, arithmetic, architecture of Parallel Discrete Event Simulation etc. Her e-mail address is < HYPERLINK "mailto:yzmailbox2003@163.com" yzmailbox2003@163.com>HUANG KE-DI: He is a Professor specialized in system simulation, virtual reality, simulator, theory and arithmetic of simulation. He has been an active propeller and researcher in the simulation technology and application. In addition, He has an honor of the vice director of the Chinese Association for System Simulation.