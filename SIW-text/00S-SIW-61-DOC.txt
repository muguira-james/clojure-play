Using H-Anim to Represent Human Figures in HLA-Compliant SimulationsJohn W. ShockleySRI International333 Ravenswood Ave.Menlo Park, CA 94025650-859-4165john_shockley@sri.comMark MorgenthalerLionhearth Technologies, Inc.25401 Spanish Ranch RoadLos Gatos, CA 95030408-357-5536mark_Morgenthaler@lionhearth.comKeywords:Human Figure Representation, Federation Development ProcessABSTRACT: The "H-Anim" standard was created by the Humanoid Animation Working Group of the Web3D Consortium to create representations of human figures, i.e., virtual humans, using VRML 97.  H-Anim was developed to enable avatar designers to create such figures using web-based avatar tools.The advantages of H-Anim are its broad acceptability, not only in the general web-based community, but also in other commercial environments. It is the basis for representation of avatars in the MPEG-4 standard and has been accepted by the Society of Automotive Engineers (SAE) as a standard for human representation in simulations.  It has also been developed as an interchange format for the representation of virtual humans developed from a variety of 3-D tools and motion capture devices.   In support of the development of the HLA Virtual Command Post, Lionhearth and SRI have investigated the feasibility of this standard as a mechanism for representing VCP commander avatars as HLA Federates. At the Fall 1999 SIW, we presented a demonstration of the capabilities of H-Anim and how we envisioned to incorporate this standard into the HLA VCP. This paper reports on the progress we have made to date refining the H-Anim based SOM for the HLA VCP. We believe that, as an already recognized international standard for human representation, H-Anim forms an excellent basis for a reference FOM-let for HLA compliant simulations. For background, the paper also includes a description of the H-Anim standard and how we have applied it to representing instrumented participants as commander avatars in the HLA VCP.1.	IntroductionLionhearth and SRI have been in the process of developing an HLA-compliant Virtual Command Post (VCP) distributed simulation.  To date, efforts on the HLA VCP have driven us to examine the performance of the HLA run-time infrastructure (RTI) in its ability to handle high-volume audio and video data.1, 2 While we are still engaged in examining these issues, we are also looking at the incorporation of commercial standards into HLA-compliant simulations.  The original VCP was developed as the result of a Small Business Innovative Research (SBIR) contract and was, therefore, developed for dual use applications.  The philosophy of dual use of the HLA VCP is not only an outgrowth of this project but is central to Lionhearth and SRI's strategy in marketing VCP and its technologies.  We envision a number of military applications including command post and Command, Control, Communications, Computers, and Intelligence (C4I) simulations, virtual collaborative work environments, and after action review (AAR) and display systems.  In the civil and commercial area, we envision applications in crisis management, collaborative virtual environments, and electronic commerce.  Because of this dual use orientation, we see the need for the HLA VCP to satisfy not only DoD standards but also commercial standards.  The flexibility of the HLA enables commercial standards to be incorporated within the framework of the HLA requirements.  Such a mechanism, we believe, will be a benefit to both communities.  For the HLA VCP, then, we are examining a number of commercial standards for their use within an HLA-compliant simulation.  Already, the HLA VCP is being developed around Microsoft Windows-based platforms.  For high-volume video data, we envision using the Moving Picture Coding Experts Group (MPEG) standards.  This paper describes this philosophy applied to the avatars representing real human commanders participating in the VCP.  In this case, we are using the Virtual Reality Model Language (VRML) standard H-Anim to represent these avatars.  This paper describes how H-Anim can be used as a basis for a human representation FOM.  In this paper, Section 2 provides some background on the HLA VCP, while Section 3 provides some background on H-Anim.  Section 4 describes an example of a human FOM based on the H-Anim suggested Level of Articulation Two (LOA 1).  Section 5 outlines how this is being applied in the HLA VCP, while Section 6 provides a Summary and conclusions.2.	The HLA Virtual Command PostThe Virtual Command Post (VCP) is an early experiment in the use of distributed simulation and virtual conferencing technologies to provide a ‚Äúyou are there‚Äù collaborative C4I environment. Developed by Lionhearth Technologies for the US Army Communications and Electronics Command (CECOM) under a Phase II SBIR contract, commanders and war fighters in geographically dispersed locations can use the VCP to view battlefield information on portable or man wearable devices including laptops, PDAs, or HMDs.  The VCP captures each commander‚Äôs ‚Äúpresence‚Äù in the form of compressed voice, line-of-sight, and body position and can transmit his voice and animated iconic representation over a 9600 baud radio network, leaving bandwidth available for maintenance of a distributed battlefield management database. This database is updated locally and converted at each node into 3D-battlefield visualization with interactive planning, "what-if", and data drill-down capabilities. In parallel, satellite broadcasts or video-teleconferences can be captured and displayed in the VCP on video walls.  Figure 1 depicts an initial system block diagram of the virtual command post.EMBED Word.Picture.8Figure 1: Original HLA VCP System The current HLA VCP architecture defines the following separate elements as federates: (1) commander or avatar, (2) audio object, (3) video or 2D object, and (4) the VCP room itself.  In addition we are examining the feasibility of including a generic 3D object or viewer as a separate federate.  This division was based on how the original VCP was designed and what we saw as a reasonable division of functional modules that could be separate HLA federates.  We envision that each of these could be separate functional entities that are part of an HLA federation other than the VCP.  Figure 2 describes the currently envisioned architecture for the HLA VCP.Figure 2: Current HLA VCP Architecture Because of the definition of a commander federate, there is a need to develop a representation of this federate that will be HLA-compliant.  At the same time, in order to satisfy our goals to use commercial standards, we need to have the description of this federate meet the requirements of such a standard.  For these reasons, we have examined the applicability of the H-Anim standard for the representation of human figures.  We believe that this standard will not only satisfy our requirements for the VCP but may also be of value as a reference FOM for human representation. 3.	H-AnimThe "H-Anim" standard was created by the Humanoid Animation Working Group of the Web3D Consortium to create representations of human figures, i.e., virtual humans, using VRML 97.  H-Anim was developed to enable avatar designers to create such figures using web-based avatar tools. The primary goal of the H-Anim standard is to specify a way of defining interchangeable humanoids and animations in standard VRML 97 without extensions.  This will allow people to author humanoids and animations independently. To achieve this goal it is necessary to specify a standard set of joint names (and the geometry, or segments, corresponding to those joints) as well as a minimal set of modeling conventions. There are 94 joints in the complete set of H-Anim joint names, and this is believed to be sufficient to model the most anatomically correct virtual human model possible.3  Users of the H-Anim standard are free to use any subset of the 94 standard joints. It is also possible to add joints to the H-Anim hierarchy, as long as no non-H-Anim joint is added between two H-Anim joints. Geometry is represented by segments in H-Anim, and there is a segment corresponding to each of the 94 joints in the standard hierarchy.Figure 3 illustrates the 94 joints defined for the H-Anim Level of Articulation 3 (LOA-3), the most detailed H-Anim representation.  In this diagram, the joints are simple dots connected as a stick figure in order to illustrate their location and relevance to real human joints. Figure 3: The 94 Joints of H-Anim LOA-3 The advantages of H-Anim are its broad acceptability, not only in the general web-based community, but also in other commercial environments.  It has also been developed as an interchange format for the representation of virtual humans developed from a variety of 3-D tools and motion capture devices.  Furthermore, it is the basis for representation of avatars in the MPEG-4 standard.  Outside of the web community, H-Anim has been selected as the standard representation for human models by the Society of Automotive Engineers (SAE).4.	A Human Representation FOM Based on H-AnimIn order to retain both the HLA standard and H-Anim for the representation of avatars in the HLA VCP, we had to see if the H-Anim standard could be represented as an HLA Federaton Object Model (FOM).  Fortunately, the flexibility provided by HLA enables a fairly straightforward mapping of the H-Anim standard into HLA OM format.  Figure 4 contains a graphical depiction of the Object Class Structure, while Figure 5 contains a similar graphical depiction of the Interaction Class Structure.  These structures reflect H-Anim LOA-1 and simply map the H-Anim defined objects, Joint, Effector, Displacer, into HLA object classes.  The interaction classes reflect the types of motion, Displace, Rotate, and Translate that can be applied to Joints, Effectors, and Displacers.  The presence of both DisplaceAction and Translate interactions are indicative of the difference between movement of Displacers and that of Joints and Effectors.In these figures, the attributes of the object classes are indicated in the boxes of each object subclass, while the parameters of the interactions are similarly listed under each interaction.  More detailed Attribute, Parameter, and Complex Datatype tables (Tables I, II, and III, respectively) are included in the appendix.Figure 4 Object Class StructureFigure 5 Interaction Class Structure5.	Applicability of H-AnimH-Anim provides a useful basis for avatars in the VCP primarily through run-time animation reuse.  In addition, H-Anim offers an improved ‚Äúproduction pipeline‚Äù - the process whereby avatars are authored in off-the-shelf authoring tools, e.g. Kinetics‚Äô Character Studio‚Ñ¢, and then brought into the run-time VCP. Run-time animation reuse is possible through H-Anim‚Äôs use of a standard set of joints, along with specific modeling conventions. At Lionhearth, we utilize LOA-1 (Level of Articulation 1) H-Anim avatars. In order to utilize animation reuse, it is desirable (and necessary in Lionhearth‚Äôs current system) for all avatars in the system to utilize the exact same joint hierarchy.  LOA-1 is the joint hierarchy that we have chosen as being most appropriate for real-time VR applications, such as the VCP.  Figure 6 illustrates an LOA-1 avatar used by the HLA VCP, while Figure 7 illustrates a continuous mesh avatar model.  This second avatar demonstrates how LOA-1 can be extended to depict more realistic looking people.Figure 6: HLA VCP Army Commander Avatar Using H-Anim LOA-1 Figure 7: Continuous Mesh Avatar, ‚ÄúAndrea,‚Äù Using H-Anim LOA-1After authoring an animated avatar, we process the animation file to split off animation data off from the avatar geometry data. The animation data will be relative to each joint in the hierarchy, and since we know that all our avatars will utilize the same hierarchy, this data can be applied to any LOA-1 avatar. In order for this data to be applied meaningfully, we also need to have met the H-Anim requirement that the avatar is modeled in the H-Anim neutral position, and that animation data is authored relative to that neutral position. From this point, we can then load a set of animation files, separately from the geometry for the animation files. In the VCP, at load time, we can then load a set of H-Anim avatars, as needed, and separately, a set of animation files that will be loaded into an animation table. Then, at run-time, any avatar can access any of the animations in the table, as needed, and the ‚Äúper avatar‚Äù memory requirement of each animation is eliminated.For the HLA VCP, the importance of an H-Anim-based SOM is clear.  Since we have already adopted the H-Anim standard into the simulation and we need to be HLA compliant as well, the ability to map the two standards in a complimentary fashion will enable us to satisfy both of our standards compliance goals.  For the broader Simulation Interoperability Standards Organization (SISO) community, the importance of an H-Anim-based HLA-compliant Object Model may be even more important.  The presence of the Human Behavior Representation Forum is a clear indicator of the need to include the representations of humanoids in simulation interoperability issues.  H-Anim is an already internationally recognized simulation standard for humanoid representation.  As our effort has shown, there is a relatively straightforward mapping for LOA-1 H-Anim figures into HLA.   We believe that more or less detailed representations will be similarly straightforward.  For these reasons, we propose that an H-Anim be the basis for a Reference FOM (or FOM-let) for humanoid representation within the HLA community.  Such a Reference FOM would satisfy a number of goals for some level of standardization of representation.  Also, by the very nature of a Reference FOM, it would serve as a useful starting point for model developers without being a mandatory standard.   6.	Summary and ConclusionsIn this paper, we have outlined the HLA VCP and our goals for satisfying both commercial (H-Anim) and military (HLA) standards simultaneously.  We have attempted to do this with a translation of the H-Anim LOA-1 representation into a SOM for the HLA VCP.  Our efforts have been encouraging in that this translation seemed relatively straightforward.  Because the translation from H-Anim to HLA was straightforward, and H-Anim is an already internationally recognized standard for the representation of human figures, we propose that it form the basis of a Reference FOM or FOM-let for human representation.  7.	References[1]	M. Morgenthaler and J. Shockley, Performance in Sending High Volume Data, 98F-SIW-214, Simulation Interoperability Workshop, September 1998, Orlando FL.[2]	M. Morgenthaler and J. Shockley, Performance in Sending High Volume Data: An Update--The Development of an RTI VTC Capability, 99S-SIW-102, Simulation Interoperability Workshop, March 1999, Orlando FL.[3]	Humanoid Animation Working Group, Specification for a Standard VRML Humanoid, Ver. 1.0, December 1997 [Note: Ver. 1.1 was released August 1999.][4]	Lionhearth Technologies, Inc., The HLA Virtual Command Post, response to OSD97-006 Solicitation: Commercialization of Components C4I Interface to Simulation using HLA, April 23, 1998.[5]	M. Morgenthaler and G. Steiner, Phase II SBIR Final Report for the Dispersed Virtual Command Post Program, Lionhearth Technologies, March 23, 1998.Author BiographiesJOHN SHOCKLEY is a Senior Research Engineer at SRI International.  Over the past 15 years, he has worked at SRI on a broad variety of projects--primarily in the areas of test and training range instrumentation systems for the Army, Navy, and Air Force.  He began working on modeling and simulation aspects of these systems and has since participated in DIS/HLA standards development activities for the past nine years, concentrating on integrating live and virtual systems.  MARK MORGENTHALER is the founder and President of Lionhearth Technologies. At Lionhearth, he has developed a team of technical, administrative and marketing professionals to develop virtual environments and sensor technologies to enhance collaboration.  Prior to forming Lionhearth, he served as President of Crystal River Engineering.  During his tenure, he revitalized this virtual reality company, resulting in the development of a 3D sound API--subsequently incorporated into Windows 95.  In 1993, he joined Trimble Navigation and founded the Avionics Division, responsible for developing differential GPS landing systems.   Prior to his work at Trimble, Mr. Morgenthaler had 14 years of experience at Hewlett-Packard as an engineering manager, working on a variety of graphics, multimedia, and RISC architecture projects.AcknowledgmentsThe authors would like to thank Mr. Kirk Parsons of Lionhearth who provided critical understanding of the H-Anim standard and Mr. Alexey Vaiman of Lionhearth who is instrumental in the development of the HLA VCP and helped shape the current architecture. In addition, the authors wish to thank Dr. Andreas Kemkes of Perceptronics who shared his experience in initial use of an HLA-compliant FOM based on H-Anim as part of the Intergame Program presented at the June 10, 1999 HLA Architecture Management Group Technical Exchange.Table I : HLA FOM Attributes for Avatar Using H-Anim LOA-1PRIVATEAttribute TableObjectAttributeDatatypeCardinalityUnitsResolutionAccuracyAccuracy ConditionUpdate TypeUpdate ConditionT/AU/RRouting SpaceEffectorr_hand_tiph-anim_position_structN/AN/AN/AN/AN/AN/AN/ANURN/Al_hand_tiph-anim_position_structN/AN/AN/AN/AN/AN/AN/ANURN/Askull_tiph-anim_position_structN/AN/AN/AN/AN/AN/AN/ANURN/Ar_middistal_tiph-anim_position_structN/AN/AN/AN/AN/AN/AN/ANURN/Al_middistal_tiph-anim_position_structN/AN/AN/AN/AN/AN/AN/ANURN/AJointl_ankleh-anim_position_structN/AN/AN/AN/AN/AN/AN/ANURN/Al_elbowh-anim_position_structN/AN/AN/AN/AN/AN/AN/ANURN/Al_hiph-anim_position_structN/AN/AN/AN/AN/AN/AN/ANURN/Al_kneeh-anim_position_structN/AN/AN/AN/AN/AN/AN/ANURN/Al_midtarsalh-anim_position_structN/AN/AN/AN/AN/AN/AN/ANURN/Al_shoulderh-anim_position_structN/AN/AN/AN/AN/AN/AN/ANURN/Al_wristh-anim_position_structN/AN/AN/AN/AN/AN/AN/ANURN/Ar_ankleh-anim_position_structN/AN/AN/AN/AN/AN/AN/ANURN/Ar_elbowh-anim_position_structN/AN/AN/AN/AN/AN/AN/ANURN/Ar_hiph-anim_position_structN/AN/AN/AN/AN/AN/AN/ANURN/Ar_kneeh-anim_position_structN/AN/AN/AN/AN/AN/AN/ANURN/Ar_midtarsalh-anim_position_structN/AN/AN/AN/AN/AN/AN/ANURN/Ar_shoulderh-anim_position_structN/AN/AN/AN/AN/AN/AN/ANURN/Ar_wristh-anim_position_structN/AN/AN/AN/AN/AN/AN/ANURN/ASkullbaseh-anim_position_structN/AN/AN/AN/AN/AN/AN/ANURN/Av15h-anim_position_structN/AN/AN/AN/AN/AN/AN/ANURN/ATable II : HLA FOM Parameters for Avatar Using H-Anim LOA-1PRIVATEParameter TableInteractionParameterDatatypeCardinalityUnitsResolutionAccuracyAccuracy ConditionRouting SpaceRotateRotationMagnitudeRotationN/AN/AN/AN/AN/AN/AEffectorh-anim_position_struct1meter0.1mmperfectalwaysJointh-anim_position_struct1meter0.1mmperfectalwaysDisplaceSegmentstringN/AN/AN/AN/AN/AN/AActionMovementDisplacementN/AN/AN/AN/AN/AN/ASegmentPortionCoordIndexN/AN/AN/AN/AN/ATable III : HLA FOM Complex Datatypes for Avatar Using H-Anim LOA-1PRIVATEComplex Datatype TableComplex DatatypeField NameDatatypeCardinalityUnitsResolutionAccuracyAccuracy ConditionRotationZRotationfloat1degrees0.01perfectalwaysYRotationfloat1degrees0.01perfectalwaysXRotationfloat1degrees0.01perfectalwaysRotationCenterh-anim_position_structN/AN/AN/AN/AN/ATranslationDeltaZFloat1meter0.01mmperfectalwaysDeltaYFloat1meter0.01mmperfectalwaysDeltaX11meter0.01mmperfectalwaysDisplacementPoint4DisplaceFloat1meter0.01mmperfectalwaysPoint3DisplaceFloat1meter0.01mmperfectalwaysDisplaceDirectionh-anim_position_structN/AN/AN/AN/AN/APoint1Displacefloat1meter0.01mmperfectalwaysPoint2Displace11meter0.01mmperfectalwaysCoordIndexPoint4float1Index point1perfectalwaysPoint3float1Index point1perfectalwaysPoint2float1Index point1perfectalwasPoint1float1Index point1perfectalwaysh-anim_position_structYfloat1meter0.1mmperfectalwaysZfloat1meter0.1mmperfectalwaysXfloat1meter0.1mmperfectalwaysPAGE  7