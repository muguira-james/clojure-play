Joint Modeling and Simulation System (JMASS)What it implies,… and What that means…!Robert J. MeyerASC/AAJ (JMASS JPO)2145 Monahan Way, Building 28Wright Patterson AFB, OH 45433-7017937-255-3969, ext 3818Bob.Meyer@wpafb.af.milKeywords:Modeling, Simulation, Collaboration, Reuse, Distributed DevelopmentABSTRACT:  In a previous paper, the author dared to dispel the myth and misunderstanding concerning how this engagement/engineering level Modeling and Simulation (M&S) system breaks new ground in the realm of Object-Oriented (OO) digital constructive simulation.  Building on that foundation, in this paper the author discusses in depth the implications of this new way of doing M&S business.  The "some user assembly required" nature of JMASS-based simulations raises the question of who builds the piece parts (and how) that must ultimately come together to form a simulation – in essence introducing a true distributed development paradigm. The interface-based nature of JMASS is both extremely flexible and challenging, yielding the freedom to define virtually any simulation-based problem while burdening the definer with assembling and configuring the appropriate piece parts to build that simulation.  And finally, the promise of model/component reuse inherent in the JMASS approach is just as elusive as other software promises of reuse – and begs for process and/or infrastructure support to realize this potential.  From these implications of JMASS, the author gleans a key theme – collaboration in the distributed development and reuse of authoritative digital software representations – and reveals how this theme highlights the intimate, complementary and synergistic relationship between JMASS and this current workshop's focus, Simulation Based Acquisition (SBA).1.  A Brief PrologueIn a previous paper [Ref 1], the argument was proffered and (hopefully) consummated that JMASS, in particular its emphasis on architectural interface standards for M&S, really does reflect a new way of doing business in the modeling and simulation world.  The modern moniker for such is "paradigm shift," and this previous paper concluded with the anticipatory tag line that the promise of JMASS "is limited only by the imagination and determination of those who would use it."  This paper is about "imagining" and "determining" this promise into a new (set of) process(es) for DoD M&S applications at the engagement level, and (perhaps) elsewhere.As any competent purveyor of "paradigm shifting" will point out, it is in the processes (and not the products) where most change will manifest itself.  It became rather transparent in the previous paper's discussion that the process of building an engagement-level simulation using the JMASS approach was considerably different than that used for the so-called "legacy" simulations.  In fact, a notional illustration of the JMASS taxonomy of a Radio Frequency (RF) Surface-to-Air Missile (SAM) simulation was included in the previous paper, and that same illustration is repeated in this paper as Figure 1.1.The previous paper spent the majority of its space and time stating and illustrating, via a "toy assembly" analogy and liberal use of the illustration in Figure 1.1, five basic "truths" of JMASS.  For reference, these "truths" are very briefly repeated in the following subparagraphs.JMASS is not a simulation.What gets delivered on the JMASS CD is an architecture and associated tool set, which supports the building of models, the combination of models into a simulation, the execution of simulations, and the post-processing (i.e., examination) of the results (i.e., output data) of executions of simulations.  No models or simulations, other than very simple tutorial examples, are delivered on the distribution CD, i.e., you cannot usefully "run" any analysis with the software on the delivery CD.Figure 1.1All JMASS action is player-based.Nothing happens in a JMASS-based simulation without the intent to make something happen by at least one model (or player) in that simulation.  For the example depicted in Figure 1.1, the calculation of miss distance at the point of closest approach for a missile intercept of a target must be done by one of the models (players) in the simulation, or another player must be added specifically to accomplish this task.JMASS is interface ignorant.The JMASS architecture is unaware of the content, intent or extent of model-to-model communication before, during or after simulation execution.  The architecture's "port" mechanism supports data exchange among models – in Figure 1.1 perhaps a structure for passing essential radar data among the Acq(uisition) Radar, Aircraft and RF Env(ironment) players.  The JMASS architecture is not however "cognizant" of the values, volume or validity of the data flowing among those models during execution.Compliant is NOT interoperable.A model which is found to be JMASS-compliant is not guaranteed to be meaningfully interoperable with other compliant models in a JMASS simulation.  While true that compliance generally guarantees executability (e.g., the Figure 1.1 simulation will execute), interpretation of model-to-model interfaces (e.g., radar data structure) is outside the purview of JMASS compliance and must be consistent among models (e.g., Acq Radar, Aircraft and RF Env players) for them to be considered interoperable.JMASS is NOT "plug and play."All executable software in a JMASS simulation (players, components, simulation engine, associated services, etc.) must be run through the code generation process to effect the JMASS interface standard.  Once built in this fashion, JMASS players (e.g., Acq Radar, Aircraft, etc.) and their components can be combined into simulations as if they were truly "plug and play," but the overall process is more accurately described as "plug and build and play." JMASS is distributed development.Perhaps the most visible, obvious and straightforward implication of these basic "truths" of JMASS is that the various models (players) in any JMASS-based simulation can (and thus arguably could/would/should) be developed and maintained by different agencies or organizations.  This (virtually) independent and separable model (player) paradigm is made possible and eminently fostered by the interface-based nature of JMASS– both for interactions among the models themselves, but more importantly between each model and the simulation engine.From its inception, JMASS has been about distributed development.  Building of the (many – a separate paper in itself) early JMASS prototypes as well as recent models has featured development by those agencies/organizations who have the authority and/or expertise to represent those types or "classes" of systems/phenomena.  Threat system representations have been defined by the various Defense Intelligence Agency (DIA) production centers, while the "blue system models" are envisioned for definition by the appropriate system program offices.  While now done by the JMASS Joint Program Office (JPO), management of the various environment models is planned for transition to appropriate subject matter expert working groups.Two immediate, further implications of this JMASS (or any) distributed development paradigm are the need for coordination among model developers and the need to identify and secure start up resources to prime and direct the distributed development process.  Experiences during the eight years as an Air Force program and the two years thus far as a joint program have served to reinforce quite emphatically these considerations.  Put in more proactive terms, a well-populated and well-managed collection of JMASS-compliant system/phenomena models is essential to the utility and effectiveness of the JMASS approach.One of (if not) the most important consideration in any distributed development implementation is the definition of requirements for the various models (players) which might make up any particular simulation (application).  The matrix shown in Figure 2.1 may help illustrate this notion of defining model requirements for a simulation.  The rows of the matrix reflect a typical partitioning (primarily by shooter and target domain) of engagement-level applications, while the columns reflect a typical partitioning ("class"-based in the Object-Oriented sense) of architecture/model software development.  Notionally, any application row (e.g., surface-to-air) would have need for software/models from most/all of the "class" columns, as depicted by the X's at the row/column intersectionsFigure 2.1Another very essential implementation consideration in any distributed development is the assignment/acceptance of "ownership" for the various "classes" (or columns in the Figure 2.1 matrix) of development.  Experience has shown that, without both assignment and acceptance of this software ownership, distributed development at first stagnates and eventually fractionates into irrelevance.  The notion of ownership is also key to ensuring effective reuse and interoperability – some discussion of this aspect can be found later in paragraph 4.0 of this paper.  But perhaps the most direct consequence of distributed model development is the need to connect these models into an application, i.e., simulation integration.JMASS is simulation integration.As first pointed out in Figure 1.1, simulation integration has typically not been an identifiable, separate activity in the legacy world of DoD M&S.  This is the case primarily because most legacy M&S development has occurred at the simulation (vice the model) level and thus integration of models into a simulation application happened sort of "automatically."  But the JMASS paradigm shift, with its emphasis on distributed development, inserts simulation integration as an essential activity in the building and maintaining of useful JMASS-based M&S applications.A logical and potentially troubling question might very well arise at this juncture.  With JMASS simulations being based on interface standards, both model-to-model and model-to-simulation, why would there be any need for a specific simulation integration activity?  Asked more simply, if all the pieces are built to fit together, why do we need an integrator – someone to make the pieces fit?The answer to this question is paradoxically both simple and complex.  At the simple level, simulation integration was described earlier as applying to the "building and maintaining of useful JMASS-based M&S applications."  [italics added]  The building of a simulation, as the first part of simulation integration, includes as its first step the decomposition (partitioning) of the analysis problem into those model requirements for players/components which provide the functionality to solve that analysis problem.Referencing both Figures 1.1 and 2.1, a threat RF SAM analysis problem in the Surface-to-Air arena (row one of Figure 2.1) might be decomposed into the players shown in Figure 1.1.  Those players would have to meet specific requirements to provide the functionality needed to solve the analysis problem, and/or other players may need to be added to provide the desired functionality (e.g., metrics like point of closest approach).  The simple point is that the process of simulation integration begins with this analysis problem decomposition, not with the assembly of "pre-formed," standardized piece-parts.At a complex level, this decomposition-into-requirements process typically results in players which are tailored for the specific analysis problem being addressed.  Thus, the "Aircraft" player that an analyst intends to "integrate" in a JMASS-based simulation for one analysis problem may have been designed/built for another entirely (or even minimally) different analysis problem.  Thus, not only does simulation integration include the relatively simple aspects of simulation decomposition/design, but the more complex nuances of recognizing and adapting ("reusing") existing players/models for use in different (than originally intended) analysis applications.Perhaps a(nother) toy analogy might be useful to further highlight this simulation integration aspect.  Children of the current era, and consequently their [grand]parents, are familiar with the LEGO and K'NEX sets of connectable, interface-based piece-parts.  (Their [grand]parents may be more familiar with Lincoln Logs, Tinker Toys and Erector Sets, but the analogy holds in either case!)While it seems that one can build almost anything with LEGOs or K'NEX, there are limits in both sturdiness and appearance, and arguably other aspects.  The reusability ("plug and play") of these "systems" was targeted at quite a low level, and aggregate fidelity (how closely an aircraft made of LEGOs or K'NEX looks or behaves like a real aircraft) was not the primary design goal.  In fact, neither LEGOs or K'NEX were built with aircraft representation in mind – they were simply built to fit together easily.In contrast, reusability in JMASS is targeted at the player level (at least initially –paragraph 4.0 expands on this discussion), and how well a JMASS-based aircraft model looks or behaves like a real aircraft is of palpable importance to the analysis problem it is meant to address.  Moreover, the focus of JMASS-based simulations is to capture the interaction of systems/phenomena to answer analysis problems, not on how easily or simply the players in that simulation fit together.Said more succinctly, the piece-part (LEGO or K'NEX) approach asks what can be "integrated" from the piece-parts on hand, while the JMASS approach asks what piece-parts are needed to "integrate" (build and maintain) the simulation needed to address a particular analysis problem.  The two approaches come from very different perspectives, and it is this analysis-problem perspective which subtends the unique (and necessary) simulation integration nature of the JMASS approach.While this perspective might seem to abandon or at least diminish the whole notion of software reusability, just the opposite turns out to be true.  In very real terms, reuse is where the JMASS paradigm shift shows its most promise and as already hinted at, perhaps its biggest challenge.JMASS is reuse (and interoperability).The computer software arena, although less than half a century old, has arguably had a more profound effect on technology and society than any development to date.  Alas, for all of its wonders and worthiness, the computer software world has failed miserably in perhaps its most exciting promise – software reuse.  It was long thought that once all useful algorithms had been captured in computer software, new applications would simply reuse what had already been done and the need for further computer science development would largely evaporate.The fact that such reuse has arguably not occurred (at least not to the extent once envisioned) could perhaps be attributed to a vested interest of those folks capable and positioned to make it occur (i.e., computer scientists) in maintaining a certain level of job security!  But closer analysis suggests another, perhaps more pervasive reason – the lack of a process and/or infrastructure to promote, support, or even make such reuse possible.Enter JMASS, with its promise of software reuse, and an immediate question arises – what can be expected of JMASS in light of the relatively spotty history of software reuse in general?  As the ensuing discussion will address, the answer for JMASS is tied closely to the willingness and ability of the DoD to instigate and support a process and/or infrastructure to promote such reuse.It may be illuminating to provide context for a discussion of reuse (and interoperability) by noting that reuse can and will (and probably should) occur at virtually all levels of M&S software development.  Certainly, one promising benefit of the High Level Architecture (HLA) has been the notion that, by HLA compliance, existing simulations could be "reused" in many different federations merely by undergoing a Federate Object Model (FOM) process to resolve syntactic/semantic differences among the various participating federates (the venerable "FOMerama").Within the Object-Oriented (OO) software development world the debate continues about what level of object classification is best for reuse – some argue the lowest level, some the highest, while most practitioners of OO technology settle on somewhere in the middle.  In any event, software reuse in the OO M&S area encompasses everything from simulation reuse in the HLA case down to "primitives" (gates, switches, etc.) reused many times to build even simple models of electronic circuits.As mentioned earlier, reuse in JMASS is initially targeted at the player level, e.g., the "Aircraft" player in the RF SAM example (Figure 1.1) would be a JMASS reuse success story if that same player could be used in other engagement-level applications (e.g., Air-to-Air).While the initial focus may be on reuse of JMASS system models at the player level, in actuality reuse can (and currently does) occur at the "simulation level" when more than one analysis problem and/or application area makes use of the JMASS simulation engine, tools and services.  Regardless of whether any environment or system models are shared/reused in these applications, the architecture standards and GUIs (first two columns in Figure 2.1) are effectively "reused" by any application area (row in the Figure 2.1 matrix) that chooses to use JMASS as the basis for their simulation solutions.Adding to this architecture reuse is the case where one or more of the application areas makes use of one or more of the environment models as players in their simulation solution.  Note that with the choice of an environment model comes also the interface definition for transmission of signals in that portion of the electromagnetic spectrum.  Thus system models which transmit/receive/reflect those types of signals are made easier to reuse, since the model-to-model interfaces for those models have been defined.Experience with building threat models for JMASS has shown that reuse even down at the component level is also quite possible with JMASS.  In particular, models of some threat systems have been able to share (reuse) components, while others have had to employ unique sub-components to ensure correct representation.All in all, JMASS has exhibited a relatively facile ability to support software reuse from the simulation core down to the sub-component level.  What has not occurred nearly to the extent which the JMASS software allows and supports is the actual reuse of (system) players and components, for the exact reason cited earlier – lack of a process and/or infrastructure to promote this reuse.In the case of the architecture, tools and services (and environment players), both a process (Joint Operational Requirements Document – the JORD – and the necessary methods to change it) and a funded infrastructure (the JMASS JPO) exist.  This has fostered reuse (in the form of use across the application areas) because of the stability associated with this JPO "ownership" of the architecture and environment players as mentioned earlier in the discussion on distributed development.The implication is fairly clear – "ownership" in the sense of informed and funded management of the classes of system models shown in Figure 2.1 is essential to making the JMASS promise of reusability actually blossom and bear fruit.  This "ownership" notion appears to solve the requirements definition (process) and organizational (infrastructure) needs associated with the JMASS paradigm shift to the simulation integration and reuse of models coming from a distributed development approach.The parenthetic inclusion of interoperability as part of the reuse aspects of JMASS recognizes how important it is to DoD in general and yet how tangential it is to JMASS in particular.  The term itself (interoperability) derives from hardware considerations wherein fielded systems have to either work properly in concert with each other when so intended (e.g., Army ground radios with Air Force airborne radios) or not interfere with each other when not intended to operate together.  The term has been expanded to include situations where M&S software has to function properly and directly with fielded system (typically C4ISR) hardware in sort of a hybrid situation.JMASS can (and has), with proper model definition and construction, support(ed) interoperability as explained above, although that is not the current focus of most JMASS model (and simulation) development.  Most applications of JMASS to analysis problems associated with interoperability also involve reuse issues as well, and the same essentials are necessary for those applications as well – someone (infrastructure) or something (process) to manage the reuse of the specialized models associated with the hardware involved in solving these problems.The meaning of what JMASS is/implies.Making software reuse work at all levels in JMASS is very closely tied to managing aspects of the simulation integration and distributed development sides of what JMASS is/implies.  Figure 2.1 notionally suggests one approach to managing the development of system (and environment) representations by model class "ownership."  This approach yields a sterling opportunity to manage and/or mitigate the paradigm shift that JMASS embodies, by providing a stable, reusable, well-managed set of models to support engineering- and engagement-level analysis for all DoD functional and/or service interests.It would be a mistake to argue for (or against) such an approach without considering some of the other M&S systems and battlespace depictions currently underway or under development within the DoD.  As it turns out, there may be a great potential synergy among all these efforts when it comes to models – representation of systems and phenomena – and their management.Relationship to JSIMS/JWARSThe Joint Simulation System (JSIMS) and the Joint Warfare Simulation (JWARS), are DoD-sponsored M&S programs being developed to support training and campaign-level analysis needs, respectively.  Both JSIMS and JWARS share the need with the JMASS system to represent systems and phenomena in an OO M&S context, but there the similarity basically ends.Typically, both JSIMS and JWARS require and/or use much more aggregate representations of system behavior and characteristics and environment effects/characteristics than do the engagement-level analysis problems which JMASS is targeted to help solve.  These more aggregate representations require some knowledge base of effects derived from less aggregate, more detailed interactions of systems and environment, and that effects base is usually provided by engagement-level simulations such as ones built using JMASS.Thus, at the very least some synergism exists between the JSIMS and JWARS efforts and JMASS with regard to providing support for system and environment effects in these aggregated representations.  In future scenarios, the potential exists for direct JMASS use in JSIMS and JWARS, to the extent that: 1) such use contributes to more meaningful employment of these simulation tools, and 2) JMASS models can provide the appropriate level of detail such use would require.Relationship to JVB/JSBThese two programs, the Joint Virtual Battlespace (JVB) and the Joint Synthetic Battlespace (JSB) are Army and Air Force led efforts, respectively, which focus on the requirement to immerse the warfighter in as realistic a combat situation as possible, for either acquisition insight or training purposes or conceivably both.  Said another way, the notion with both JVB and JSB is to put the warfighter and proposed or existing combat system(s) of interest into a battlespace context, populated with other combat systems so as to gain feedback on the proposed system(s) and/or effect training on existing system(s).While there certainly may be other aspects to these two efforts, both JVB and JSB by their very nature require the existence of a fairly robust collection of system and phenomena representations (models!) to support their immersion of the warfighter in this realistic-as-possible combat environment.  It is this JVB/JSB need for a collection of system and environment models that strikes a familiar chord with this paper's discussion of what (use of) JMASS implies and what that means.The Essential Implication/MeaningThe JMASS paradigm shift from legacy simulations to the new processes of distributed development, simulation integration and software reuse requires a stable, well-managed, interface-based set of system and environment models to support simulation-based solutions to DoD's engineering- and engagement-level analysis problems.  Absent this model set in some usable form, JMASS cannot meet its promise of improved M&S support to the analyst community and ultimately to the decision-makers.As noted earlier, a stable, well-managed, interface-based set of models is also important to both the JSIMS and JWARS simulation programs, and absolutely essential to the fielding and success of the warfighter immersion aspects of the JVB and JSB efforts.  In essence, a strong case can be made that all the DoD's major current and planned M&S initiatives depend on a common element – a stable, well-managed, consistent, interface-based set of system and environment models.The addition of the adjective "consistent" to the central need of DoD M&S initiatives is neither accidental nor inconsequential.  While the various M&S initiatives may (and probably do) differ a little or a lot in their detail or fidelity requirements of this common model set, any resulting different (in detail/fidelity) models of like systems or environments should be consistent with each other to the maximum extent possible.  To not require this characteristic of model consistency could compromise the integrity and utility of any and all resulting analyses.Has Anyone Addressed This?One DoD official who has wrestled with how best to tame the M&S beast is Mr Jim O'Bryon, deputy director for Live Fire Test (LFT) in the OSD/DOT&E office.  He suggested in a recent M&S workshop presentation [Ref 2] that a consortium of subject matter experts might be the best way to manage M&S in support of DoD programs.  His exact words were, "Program Managers would initially describe their .. M&S requirements to a consortium which would then .. make the decisions as to which M&S tools best suit the PM’s needs and [subsequently] .. upgrade extant models where available and originate M&S only when absolutely necessary."Mr. O'Bryon's suggestion correlates well with the notional approach depicted in Figure 2.1 for managing JMASS model and architecture development.  The consortium he advocates could manage the model classes (columns in Figure 2.1), thereby providing the stable, well-managed, consistent, interface-based set of system and environment models necessary for a successful JMASS (and arguably JSIMS, JWARS, JVB, JSB, and other programs as well).Relationship to SBATo the extent that Simulation Based Acquisition (SBA) both depends on and in some ways encompasses the joint M&S programs (JMASS, JSIMS, JWARS) and also the joint battlespace initiatives (JVB, JSB), it inherits their dependence on this stable, well-managed, consistent, interface-based set of system and environment models.More importantly, the three primary precepts of SBA – collaborative environments, data interchange formats, and distributed product descriptions – match almost exactly, solution to challenge, the implications of JMASS – distributed development, simulation integration, and software reuse.  Thus, the paradigm shift that is JMASS could be considered as a microcosmic insight into the promises and challenges that SBA portends for the future.RecommendationsBased on the information and observations contained in this paper, the following recommendations are offered:	DoD carefully consider and examine establishing a consortium-based approach to satisfy the JMASS, JSIMS, JWARS, JVB, JSB, and consequently SBA dependence on a stable, well-managed, consistent, interface-based set of system/environment models.	DoD leverage and support the JMASS program as a pilot project for implementation of a consortium-based approach to manage M&S resources in support of DoD engagement-level analysis applications.References[1]	Robert J. Meyer: "Joint Modeling And Simulation System, What it does,…and What it doesn't," Paper 01S-SIW-117, Simulation Interoperability Standards Organization (SISO), Simulation Interoperability Workshop (SIW); Orlando, FL, 25-30 March 2001.[2]	James F. O'Bryon: "Mastering M&S in Support of Combat Survivability and Lethality," Presentation, Joint Accreditation Support Activity Workshop on "Assuring M&S Credibility for Defense Acquisition and T&E"; Reno, NV, 12-15 February 2001.Author BiographyROBERT J. MEYER is the Navy Senior Engineer at the JMASS Joint Program Office (JPO), located at Wright Patterson AFB, OH.  He is on long term loan from his home office at the Naval Air Warfare Center, Weapons Division (NAWCWD), China Lake, CA.  His more than decade-long association with JMASS has mostly been as a member of the Joint Technical Coordinating Group on Aircraft Survivability (JTCG/AS) engagement-level analysis community, looking for ways to ensure that JMASS meets their needs.  His current role at the JMASS JPO includes representation of this same community, with the same goal of a JMASS-based simulation capability for engagement-level analysis. EMBED Word.Picture.8  