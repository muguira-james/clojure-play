Measures of IO Effects Using the Joint Staff Analysis ModelDr. Patrick D. AllenGeneral Dynamics Advanced Information Systems7025 Harbour View Blvd., Suite 101Suffolk, VA  23435757-673-2429pat.allen@gd-ais.comKeywords:Information Operations, Experimentation, Measures of Effectiveness, Organizational ProcessesABSTRACT: The Joint Staff Analysis Model (JSAM) was developed for the US Army Battle Command Battle Lab to analyze command post performance.  JSAM has been selected as the Army’s J/AWE tool to support Millennium Challenge 02.  One application of JSAM is to develop some measures of the effects of selected information operations on Blue or Red organizations.  Since JSAM already models the performance of an organization without IO, including IO effects will provide quantitative measures of IO on organizational performance.  Measures include times to complete tasks, resource utilization over time, quality of information products, effects on coordination, and other measures already represented in JSAM.  Note that these are not all of the measures possible for IO, nor do they represent measures of all types of IO.  However, this set of measures is a useful starting point for developing more objective measures of a wide range of offensive and defensive IO.  We present a proposed approach for incorporating a JSAM-based IO analysis as part of a limited objective experiment for Millennium Challenge 02.1.  BackgroundMeasuring the effects of information operations is fairly difficult for several reasons.  First, there are many different types of information operations, and many different types of desired effects for each type of attack.  Since IO is so broad, selecting the subset of IO methods and effects in an event takes time.  Second, ensuring that each of the selected types of attack can actually be represented in the event can require substantial resources.  Third, the effects of IO defensive actions tend to be best measured when shown in combination with the type of attacks they can defend against.  Fourth, the combinations of offensive and defensive IO actions must also be adequately represented in the event.  As a result, we can generally describe measures of information operations to be, at best, situation dependent.This does not mean, however, that we need to give up on defining useful IO measures of effectiveness (MOEs).  Instead, we recommend that all measures of IO for the situation be defined so that the situation dependencies are well understood.  This paper will give one example of how we propose to define the context of IO measures in an upcoming large-scale experiment, Millennium Challenge ’02 (MC02).Although experiments are not the same as exercises, experiments and exercises share a common concern.  The concern is that when dealing with a single large-scale event with multiple objectives, one cannot afford to have one aspect of the event dominate the results because it could preclude meeting all of the desired objectives.  For example, large-scale exercises tend to avoid playing completely realistic logistics because real logistics constraints severely reduce the pace of operations.  With a reduced pace of activities, the opportunity to achieve all of the training objectives may be precluded due to the fixed time-limit on large-scale exercises.  To prevent this problem from occurring, The White Cell or Control Cell use “magic moves” and “magic resupply” to keep the exercise moving, thereby giving the training audience a chance to achieve most of its training objectives.In a similar manner, large-scale experiments such as MC02 need to provide the opportunity to test a wide range of hypotheses across a large number of functional areas.  Since large-scale events such as MC02 occur at most once per year or once every two years, the Joint Experimentation Center cannot afford to have the event derailed by one aspect of the event.  Unfortunately for proponents of information operations, IO has the capability to “shut down” or derail an experiment.  (If everything goes according to one side’s IO plan, the other side becomes completely incapacitated.)  Although this is a desirable effect in the real world, it can derail an experiment and prevent the rest of the hypotheses from being tested.  Thus, some other way of measuring the effects of IO in an experiment needs to be created to allow all hypotheses, including IO hypotheses, to be adequately evaluated in a single event.  This paper presents a way to more realistically play IO in a large-scale event, without risking the disruption of the entire event.According to Joint Forces Command’s (JFCOM’s) latest IO Concept paper [1] the focus of IO attacks is against the mind, or the human aspects, of the enemy, eventually affecting his will.  The human aspects can be attacked in a variety of ways, including through the machines used to exchange information among the various targeted minds.  (See Figure 1.)  The context or situation we propose to examine in MC02 is the direct effect of attacks on the machine portion and the subsequent effects on the human or “mind” portion.  Figure 1:  Six Information Effects Categories Specifically, we propose to run a model of the command and staff decision processes of a target organization, and compare the difference in the process without an IO attack to a variety of cases with IO attacks (and defensive actions).  The staff processes will be represented by the Joint Staff Analysis Model (JSAM), which will be calibrated to replicate the targeted organization.  The targeted organization will be either Blue, or Red, or one of each, depending on the experiment’s objectives and affordability.  The second section of this paper will describe what the JSAM model is and does.  The third section will describe the IO measures we will attempt to measure.  The fourth section shows how this approach could be applied in MC02.  The final section summarizes the approach and its benefits.2.  JSAM Purpose and CapabilitiesThe JSAM model started life as the Organizational Sand Table (OST) model developed under the ACT II BAA for the US Army Battle Command Battle Lab - Leavenworth.  The purpose of the model was to develop a tool to analyze various candidate organizational structures for new command post (CP) designs, such as the Brigade Combat Team (BCT) CP.  Using OST, the analyst would be able to perform information-focused force structure evaluation, screen various design options for the best candidates, document the rationale and decision for why certain designs were selected for further analysis, and provide mechanisms to capture CP Measures of performance (MOPs) and MOEs.  OST allows the analyst to vary the resources assigned to a CP or to sub-elements within the CP, the resource allocation schemes used to employ these resources, and the factors considered in a variety of available output measures.  After the OST model was selected as the Army’s candidate model for MC02 under the Joint Army Warfighting Experiment (J/AWE), additional features were added to the model to include selected joint tasks and information flows.  In addition, the model was modified to read the organization databases available at the Joint Experimentation Center (JEC) and the Joint Training and Analysis Simulation Center (JTASC) to facilitate the automated populating of the required input database.  The new model is called the joint Staff Analysis Model (JSAM).Inherent in the model design is the tradeoff between cost, timeliness, and quality.  The cost is represented by the number and type of resources required to perform all of the tasks in a task list, such as to prepare a plan.  The time required to complete the task is a function of the resources available and externally imposed deadlines (which are optional).  The quality of the interim and final information products prepared during completion of each component task is a function of the time, resources, and quality of input information available to each task.  For example, using a less-appropriate but more available alternate resource to perform a task may take longer to complete and/or result in a lower-quality interim information product.  Additional quality assurance tasks can be added into the task sequence, but this also takes specific skilled resources and additional time to improve the quality.  One of the JSAM automated outputs is the Program Evaluation and Risk Technique (PERT) chart and the critical paths calculated for that task sequence.  The model automatically evaluates the precedence of tasks, determines the critical paths and the near-critical paths, and displays them for the analyst.  In our example, over 540 tasks are represented, and the critical path is identified by the red path.  (See Figure 2.)  The model allows the analyst to zoom in to the individual task level to “drill down” and obtain additional information on any task, and to “jump” to detailed information about that task by simply clicking on it.  (See Figure 3.)  The critical path provides a list of the tasks that have no slack time in their completion, and generally become the focus of analytic attention.  Changes in the task sequence or completion time due to changes in resource allocation or time deadlines will likely cause changes in the critical path, which can then be recalculated, automatically producing a new PERT chart and critical path for the new case.As another example, JSAM tracks the number and name of tasks waiting for resources by specific resource.  This allows the analyst to see a specific resource causing bottlenecks, and how much of an impact this is having on the rest of the task completion times.  Figure 4 shows the number of tasks waiting for a specific resource through the sequence of tasks being performed.  The horizontal axis is the timeline for the tasks.  The vertical axis is the number of tasks waiting on that specific resource.  The red lines are the number of tasks that are waiting for this resource and this resource alone.  The blue lines stacked on top of the red lines (not superimposed) are the number of tasks waiting for this and other resources at this time period.  The analyst can identify which tasks are waiting in each category for this resource at any time step, as shown in the pop-up tables in Figure 4.Coordination requirements are also tracked as a function of proximity.  Tasks that need to “hand-off” their outputs to the next task are first checked for proximity.  If located in the same CP cell, there is neither a delay nor a communications requirement.   If the next task requires resources that are not nearby, then the model checks for whether the required communications are available, and adds appropriate delay times as soon as that communications system is available.  When an analyst shuffles resources among cells, the model automatically tracks proximity to determine the new demands on communications caused by physically dispersing resources that need to collaborate on a specific task.JSAM also tracks the quality of the interim and final information products.  Quality can be degraded from the standard in three ways.  First, degradation of quality occurs when less than fully qualified personnel resources are used to complete a task.  The lower the skill level, the greater the degradation in quality with the rate of degradation increasing with a decrease in quality.  Second, degradation occurs when externally imposed deadlines reduce the amount of time available to complete the task.  The shorter the deadline, the greater the degradation.  Third, degradation in quality occurs when the input products are not of sufficient quality.  This reflects the principle of “garbage in, garbage out.”  Figure 5 is an example of the displays when quality has been degraded, and gives the analyst the ability to trace the cause of the quality degradation. Overall, JSAM provides the opportunity to analyze organization processes, including task sequences, resourcing levels, resource allocation schemes, and the tradeoffs between cost, timeliness and quality.  In addition to organizational designs, it can be used to analyze concepts of operation and the information flows between the various component elements.  Of particular interest to MC02, JSAM can be used to represent the activities of the Red or Blue cell that will be targeted by information operations, and provide the basis for measuring the effects of such attacks, and corresponding defensive actions, in the performance of that target organization.  [2]3.  Selected Measures of IO EffectsTo adequately measure the effects of IO, you must first be able to measure how well the system performs without IO effects being present.  Using JSAM, the analyst can measure the performance of the target organization under “benign” conditions to act as the base case (or set of base cases).  For example, assume that the target organization has a set of tasks it undertakes as part of its planning process.  The sequence of tasks is defined, and the organization assigns its available resources to complete the tasks.  Tasks are completed in a combination of sequential and parallel steps, depending on task precedence, the required input information being available from preceding tasks, and the available resources.  At each step, the quality of the interim information products passed is defined, as well as the time each interim product is available.  The last information product (the output plan in our example) has both a quality and a time stamp, which are two of its output measures.  The question then becomes, “What are the effects of IO on this process?” As described in the End Run Conceptual Model,  there are four things the IO attackerFigure 2:  Automated JSAM PERT Diagram with Critical Path Shown in Red  Figure 3:  Zoom-in of Figure 2 with Individual Tasks ShownFigure 4:  JSAM Display of Number of Tasks Waiting by Time per Resource Figure 5: JSAM Measures of Quality Based on Three Factorscan do to the defender’s information once it is in the targeted information system:  destroy, delay, read, and manipulate.  [3]  Destroyed information is deleted, delayed information is precluded from arriving at its intended destination for some time period, read information is compromised by the enemy, and manipulated information is altered.   All four of these types of effects on information can be performed covertly or overtly.  In covert attacks, the attacker takes steps to not let the defender discover the effect has taken place.  In overt attacks, the attacker wants to let the defender know the effects have occurred in order to demoralize the defender and to cause the defenders to lose confidence in their information systems.  Moreover, there are two types of IO actions—actions taken by the attacking side and actions taken by the defending side.  Steps taken by the defender to preclude IO attack effects frequently produce their own undesirable effects that reduce the performance of the defender’s information system.  For example, cutting off a communications node makes the network more secure, but also reduces the overall information system performance.  In a similar manner, applying encryption creates its own overhead requirements, which will also reduce the system’s data rate available for normal information flow even while providing increased security.All of these effects can be represented in JSAM.  For example, a node in the targeted information network can be selected for compromise.  Just how the compromising takes place is not represented in the model, which is a desirable feature given the level of classification frequently associated with Special Technical Operations.  All JSAM represents is what happens to the organization’s performance when the compromise occurs.In addition to defining which node or nodes are compromised, the attacker’s desired effect on the information flowing through that node needs to be determined.  Depending on the type of penetration achieved, the node may allow the attacker to covertly read the information flowing through that node, delay its arrival at the next node, or change some of the content, such as swapping digits on map coordinates.  JSAM can then track the flow of the information throughout the task sequence after it leaves that node, and the subsequent effects that might have.For example, delaying the completion time or flow of information from that node may have a cascade effect on the completion of the rest of the tasks.  If the node is on the critical path, or a near-critical path (i.e., a path with very little slack time), then the effects of the delay can be substantial on the overall completion time.  This is particularly true if the compromised information node is used by many tasks to complete the whole task sequence.  This type of IO effect affects the timeliness MOP of the organization in completing the task list.In addition, if the IO attacker may chose to manipulate some of the data, then subsequent products will be affected by the lower quality of the modified interim product.  If the changes remain undetected throughout the rest of the tasks, then the quality of the final product is reduced.In a similar manner, if the IO attacker has read the information flowing through that node, then the attacker has additional knowledge about the enemy’s plans and activities.  Even if the compromised node only gets access to a portion of the planning information, it may be enough to infer much of the larger picture.  The amount of information read by the IO attacker via the compromised node can be used as a measure of reduced security for the upcoming plan.Whether the IO defender detects covert attacks (such as those described above) can be represented stochastically, or scripted to ensure the rest of the experiment’s objectives are met.  Whether or not the types of IO effects could be detected again gets into the realm of STO, and is avoided for purposes of keeping this portion of the experiment unclassified.  In general, whether or not any of these intrusions can be detected is a function of the type and magnitude of the intrusion, the magnitude of any changes, and the IO defensive actions in place during the intrusion.  Each of these can be used to determine a probability of detection, which can also be represented stochastically or scripted to better support the experiment’s objectives.This section has shown how JSAM can be used to represent the effects of IO on the processes and measures of performance for a targeted organization and its information systems.  The three general categories of measures are timeliness, quality, and security.  Note that these are not all of the measures possible for IO, nor do they represent measures of all types of IO.  However, this set of measures is a useful starting point for developing more objective measures of a wide range of offensive and defensive IO.4.  Application to MC02MC02 will be held in September 2002.  Over 165 models are expected to participate in the event, though many will be simply “hung off” of one of the primary participating models rather than communicate with every other model.  A number of hypotheses will be tested in this large event.During preparation for the experiment, the IO hypotheses to be evaluated will be refined, such as those related to the Blue IO targeting process.  The decision as to whether to represent Blue IO attacks upon a Red target organization or to represent Red IO attacks against a Blue target organization will also be determined.  Once the target organizations have been  selected, the types of task sequences performed by each organization will be defined.  For example, the Red planning process would include our best guess of how the Red cell will perform during the event to replicate the planning process of the hypothesized enemy. In addition to the tasks, the resources available and the resource allocations schemes will be determined and placed in input files.Once the organization, task, list, resources and resource allocation schemes have been defined, pre-event excursions of JSAM can be run to identify interesting combinations of penetrated nodes, information flows, and IO effects.  Prior to the event, we want to identify a set of penetrations and effects that will provide a useful and challenging set of IO capabilities that do not overwhelm the opponent.  This will provide the Blue IO targeting cell a set of options and tradeoff decisions to perform, while not incapacitating the targeted Red organization until late in the event, if at all.  A similar analysis will be performed for any Blue cells attacked by Red IO actions.  Combinations of penetrations that would completely collapse the defense, or are useless to the attacker, will be identified for further analysis, but will not be included in the set recommended for use in MC02.During the actual event, the first few days of the event will be used to calibrate the Joint Staff Analysis Model to the targeted cell to ensure the validity of the task list, resource allocation schemes, task completion times, and information flows used in the targeted cell.  Observers and automated systems will be used to record when information is passed from one cell element to another.  This data will be used to calibrate JSAM to ensure that the representation in the model matches the organization being replicated.  Note that it is our intent to replicate the organization and actions of the targeted cell, not necessarily the organization and actions of a real-world opponent.  JSAM needs to represent the organization we can measure and personnel we can interview to ensure a valid calibration.  This will help validate the measures of IO applied to the organization being examined.A few days into the event, JSAM will be run in parallel to the main event to examine the effects of various IO attack combinations on the targeted organization.  Outcomes of interest from the model will be provided to the White Cell, which will determine which of these effects might be useful but not dominating for purposes of insertion into the event.  For example, a portion of the Red logistics plan may be leaked to the Blue cell to represent success in one of the Blue IO attacks.  If selected effects are played in the main event, the effect on the targeted organization in terms of timeliness, quality, and security can be measured and compared to the predictions provided by JSAM.Even if the JSAM results are not included in the flow of MC02, the participants on each side can be surveyed during and/or after the event for their reactions to JSAM results.  For example, the attacking side can be surveyed for follow-on actions in light of initial successes, while the defending side can be surveyed for reactions to detected penetrations.  These reactions are placed back into the parallel event supported by JSAM for further analysis.After MC02, further analysis and excursions can be performed.  At least one, and hopefully more, calibrated data sets will be available for analyzing additional aspects of offensive and defensive IO.  A more complete response surface of IO attack effects, and combinations of IO attack and IO defense effects, can be provided for future reference.5.  SummaryThis paper describes a potential use of the JSAM model to support measuring the effects of IO on a target organization during the upcoming MC02 large-scale experiment.  These measures are based on comparing the target organization’s performance both with and without IO effects as the basis of comparison.  A wide range of IO effects can be represented, while the three primary output measures are the timeliness, quality, and security of the final information product.The proposed approach for applying JSAM in MC02 is to run it in parallel to the actual event so that the effects represented in the model can be selectively included or excluded from the main event.  Selected outcomes may be injected into the experiment to show the attacking side what it found out (in this case) about the opposing side’s plan.  Conversely, this information may be withheld to ensure the experiment continues unaffected by IO events that would dominate the flow of the experiment.The JSAM tool can be used to perform a range of “what if” excursions before, during, and after the experiment.  This allows the “response surface” of various types of attacks and defender actions to be calculated and displayed.  Overall, JSAM allows quantitative measures of IO effects to be calculated based on task performance calibrated to the participants in a live experiment.  6.  References[1] 	Gregory, Paul, “A Concept Paper for Information Operations, Version 5.0,” Joint Futures Lab, January, 2002.[2]	Harkins, Ed, et al., “Concept Development, Experimentation, and Force Structure Readiness:  the Joint Staff Analysis Model to Analyze Command Post Performance,” Proceedings of the Multinational Experimentation Pre-Symposium Workshop, Sponsored by Chief of Defence, Norway, the Supreme Allied Commander, Atlantic, and US Joint Forces Command, 5 September 2000. [3] 	Demchak, Chris C., and Patrick D. Allen, “End Run: A Simulation Architecture For Information Warfare Report,” DARPA SBIR 991-012, Final Report, December 1999.Author BiographyPatrick Allen is a Senior Manager for Technology at General Dynamics Advanced Information Systems in Suffolk, VA.  He was the lead designer for the End Run Conceptual Model and the Joint Staff Analysis Model. Pat is assisting the Joint Experimentation Center in Collective Assessment, IO Concept Development, and strategic planning for technical support to experiments.  He is also a Colonel in the Army Reserves and a graduate of both Army War College and Air War College. 