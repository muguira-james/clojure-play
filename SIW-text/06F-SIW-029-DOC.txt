Engineering a Common Operating Environment for the ArmyEngin Z. AltanJennifer LewisScience Applications International CorporationHeathrow, FL407-687-9656, 407-247-2320 HYPERLINK "mailto:engin.z.altan@saic.com" engin.z.altan@saic.com, jennifer.e.lewis@saic.comKeywords:Distributed Simulation, Systems Engineering, 3CEABSTRACT: In March 2003, the Army Modeling and Simulation Executive Council formally recognized the need for a common operating environment to allow cohesive design, development, integration and testing of the Army’s capabilities, systems and prototypes. As a result, representatives from each of the three Army commands and the Future Combat Systems (FCS) Lead Systems Integrator (LSI) formed the Cross Command Collaboration Effort (3CE). Each 3CE participant brings to the table a special set of expectations, ranging from the overall purpose of the experiments to the underlying communications architectures involved. This paper discusses the systems engineering objectives and methodologies used to create a consistent Army environment that will be relevant today and into the future. It also discusses specific products the systems engineering and technical development groups will produce to support this environment, including object models, model gap analysis and plans for configuration management (CM) and verification and validation (V&V). Written from US Army Training and Doctrine Command’s (TRADOC) perspective, the paper also discusses issues unique to TRADOC’s participation in the common environment. 1.  IntroductionIn July 2003, a 2-star level Memorandum of Understanding (MOU) formally documented the need for a common operating environment to support distributed modeling and simulation (M&S) in the Army. As a result, the Deputy Under-Secretary of the Army for Operations Research tasked the PM UA M&S Management Office to ensure compatibility between the three commands and the LSI. In December 2004, representatives from the Army Test and Evaluation Command (ATEC), Research, Development and Experimentation Command (RDECOM), Training and Doctrine Command (TRADOC), and the LSI signed the 3CE Memorandum of Agreement (MOA), agreeing to support, develop and use a cross-command, collaborative approach to sharing modeling, simulation and instrumentation capabilities, tools, services and interfaces. Each 3CE participant brings to the table a special set of expectations, ranging from the overall purpose of the experiments to the underlying communications architectures involved. This paper discusses the interoperability objectives and methodologies used to create a consistent Army environment that will be relevant today and into the future. Written from TRADOC’s perspective, the paper also discusses issues unique to TRADOC’s participation in the common environment.2.  3CE OverviewTo ensure the common operating environment is usable in the near-term, the 3CE must focus on event execution and capability development. Event execution will use existing capabilities found in ATEC’s Distributed Training Environment (DTE), RDECOM’s Modeling Architecture for Technology, Requirements, and Experimentation (MATREX), and TRADOC’s Battle Lab Collaborative Simulation Environment (BLCSE). Capability development involves a collaborative approach to identify, develop, and maintain a core set of M&S tools, data and business processes that provide interoperable connectivity to link participating organizations. The technology and desire to implement 3CE is available. However, resolving the differences in various organizations’ cultures, methodologies and agendas is not easy. But in doing so, 3CE will create a new realm of expertise for the Army to leverage. 3CE will enforce coordinated and formalized M&S throughout the Army. Organizations will have a better understanding of component usage in other command’s environments and a greater confidence in producing consistent results. 3CE will also reduce anomalies in the Army’s M&S results by using consistently demonstrated, non-redundant, full-spectrum battlefield representations. In addition, the common operating environment is the perfect place to assess FCS-equipped Enhanced Brigade Combat Team (EBCT) and the effects between individual EBCT systems of systems.2.1  3CE Organization3CE is organized to allow participants to focus in certain areas while ensuring the overall program maintains sufficient requirements traceability and configuration management. The 3CE work breakdown structure specifies six areas of interest, each of which corresponds to a specific task group (see Figure 1 [1]). 3CE Program Management coordinates with the Requirements Determination task group to identify and prioritize analytical and other requirements. The Systems Engineering (SE) task group then defines which of these requirements are related to M&S. From these M&S requirements, the SE group identifies any capability and maturity level gaps, refines their capability development road map, and updates the Knowledge Repository. Also known as the 3CE Capabilities Toolbox, this repository provides an accessible, configuration-controlled location for 3CE participants to find effectual information about 3CE models and simulations, V&V and CM processes, test and evaluation results, and program management. The SE group then sends a prioritized list of M&S capability gaps to the Technical Development (TD) task group, which designs and implements the solution to the problem. Once implemented, the Infrastructure, Integration and Verification task group performs V&V, integrates the solution, and handles CM of the new capability (see Figure 2 [2]). Although they have evaluated certain V&V and CM processes and packages from those currently used among the 3CE participants, the group has not yet selected the most suitable ones.Recently, the advisory council combined the SE and TD task groups because their tasks were heavily inter-dependent on one another. Section 3 will discuss the objectives and accomplishments of this combined task group, which is currently focused on the analysis and testing of 3CE’s interoperability capabilities.Figure 1. 3CE Organizational Structure SHAPE  \* MERGEFORMAT 3.  3CE InteroperabilityThe main objective for the 3CE Interoperability task group is to provide a common technical perspective across all three commands and the LSI. In doing so, the group will create products and adopt processes to be used in the execution of the common operating environment. Each of the technical products and processes is assessed with specific regard to the interoperability of all live, virtual and constructive simulations. To achieve 3CE Interoperability, the technical products must be demonstrated in a Simulation Environment Characterization Assessment (SECA) and evaluated against the capability metrics derived from the 3CE System Requirements Specification (SRS). After each SECA, the 3CE Interoperability group will generate a report focusing on the interoperability aspects of the applications, tools and utilities. The metrics of interest include time to integrate, scalability, composability, and cost of the event. The report provides 3CE management with a current capability assessment and will be an important tool to demonstrate technical progress.  The first interoperability assessment is planned during October 2006. Known as the 3CE FY06 Interoperability SECA, it will test capabilities from ATEC, RDECOM and TRADOC. The 3CE Interoperability task group selected the Integrated Operational Use Case (IOUC) which best complied with the 3CE SRS for the SECA. After discussion, the group chose a common scenario for FCS missions known as the IOUC2 test case, which is a thread of IP-03.3.1 M&S AnalysisRepresentatives from each 3CE organization offered their most suitable simulation in hand for each step of the IOUC2 use case. The 3CE Interoperability task group then selected which simulation models and capabilities would be used to execute the SECA. The process included identifying the requirement for which the system was designed to satisfy, the systems capabilities and limitations, and redundant capabilities between systems [3]. It also allowed a collaborative approach to choosing the most suitable simulation between redundant systems.Figure 2. 3CE Development ProcessIn the end, the list of models to be used in the SECA came evenly from all three commands. The group used the same process to identify which tools to utilize during test execution, including data loggers, data repositories, scenario controllers, exercise managers, network performance measuring tools and playback tools.Gap Analysis In addition to providing the necessary simulation models and tools for the test execution, this process helps identify the capabilities for which the 3CE has no suitable simulation model. In the case of the 3CE FY06 Interoperability SECA, the group realized there was no simulation model readily available in any organization that could provide the necessary movement and sensor output to play an Unmanned Air Vehicle (UAV). The group decided the ATEC Tactical Unattended Ground Sensor (T-UGS) model could play the UAV. It will produce video feeds and, with the exception of movement, will be able to replicate the IOUC2 needs for the UAV. The group agreed the T-UGS would have greater interoperability value than a simulation model that could move but lacked sensor capability. The UAV gap and any gaps discovered during the execution of the SECA will be reported to the Requirements Determination task group for further evaluation and consideration.  Architectural DifferencesDuring the M&S analysis process, the 3CE Interoperability group also recognized major differences in the Semi-Automated Force (SAF) simulations used in the MATREX and BLCSE federations. Although the SAF developed from the same product line, the PM OneSAF Testbed (OTB) used in the MATREX federation implements a High Level Architecture (HLA) interface to MATREX’s Command, Control and Communications (C3) Grid to support communications effects and situational awareness. The Object Force OTB (OFOTB) used in the BLCSE federation implements a Distributed Interactive Simulation (DIS) interface to an OFOTB-variant known as the Situational Awareness Server to handle the same issues. This is a major architectural difference in the two federations, which the 3CE Interoperability group must resolve before the 3CE FY06 Interoperability SECA. However, as of this writing, no resolution has been reached.3.4  Object Model DevelopmentArguably the most critical component to interoperability is the object model defining the communications between the distributed simulations. This task is of particular importance to 3CE because each of the three commands implements different communication architectures:  ATEC uses the Training Enabling Architecture (TENA), RDECOM uses HLA, and TRADOC is transitioning from DIS to HLA (see Section 4). The 3CE Interoperability group began preliminary work to develop a common object model to represent each organization’s data elements. As of this writing, 13 objects, ranging from platforms to tactical messages to communications effects, have been identified as critical data elements to each organization. The group will discuss specific attributes associated with each data element and map those attributes among the architectures and object models used in the IOUC2 use case. Although no definitive object model yet exists, object model development activities will become more prominent in the scope of 3CE as testing and coordination progress.4.  TRADOC’s Role in 3CEAs with the other commands, 3CE will leverage the most appropriate capabilities of TRADOC’s simulation environment, including TRADOC scenarios and tactics, techniques and procedures (TTPs) to provide an overall context for emerging technology evaluation and testing. TRADOC also offers specific objectives related to key doctrine, organization and training (DOT) maturation as well as experienced personnel trained in Evaluation BCT. For its effort in 3CE, TRADOC will gain the ability to develop and mature complementary system products in a constructive and virtual M&S environment and will produce verified and validated prototypes of FCS LSI systems.TRADOC plays a unique role in the 3CE in that BLCSE incorporates almost twice as many distributed sites as any of the other 3CE participants Figure 3. 3CE Site Map SHAPE  \* MERGEFORMAT (see Figure 3 [1]). TRADOC also began its move to a common environment before the other commands. In February 2004, TRADOC decided to transition its BLCSE federation from using a DIS network interface to the HLA. Although this decision was originally intended to support improved BLCSE interoperability, the 3CE mandate added importance to the transition. Ultimately, the transition decision positioned TRADOC at the forefront of the 3CE engineering effort, as its engineers had already revisited important architectural and design decisions before the 3CE task groups formed.From 2004 to 2006, TRADOC implemented the transition. Although DIS applications can be made to use HLA easily through a variety of COTS and GOTS products, TRADOC chose a more sophisticated approach to facilitate a smooth transition into the 3CE, no matter what type of common environment was eventually created. TRADOC developed a multi-layer middleware library, which is linked into each federate application via shared objects or dynamic link libraries. The architecture of the library is extremely flexible and provides incremental incorporation of legacy simulation clients. Multiple plug-ins make it platform independent and adaptable to any communications library, including HLA 1.3, IEEE 1516, TENA, or any future communications architecture. The two main conceptual layers of the library are the traditional middleware, which abstracts and simplifies the Run-Time Infrastructure (RTI) application program interface (API), and the DIS Adapter, which acts as a front-end to the traditional middleware for DIS-centric applications [4].TRADOC also chose to base the BLCSE Federation Object Model (FOM) on the current MATREX FOM, which is being used as the preliminary FOM for the 3CE. After the BLCSE FOM stabilized during middleware integration testing, TRADOC submitted a series of change requests to the MATREX FOM management group, which would incorporate all BLCSE-specific data into the current MATREX FOM. This simple step allowed two of the Army commands to create a common object model, effectively eliminating one piece of the 3CE puzzle before 3CE object model development work began. This preliminary common object model also allows BLCSE federates to take active roles in upcoming 3CE events. As of this writing, TRADOC is preparing for two BLCSE-specific test events to finalize its HLA transition. After these events, TRADOC will participate in the 3CE FY06 Interoperability SECA as an HLA compatible federation.Originally, 3CE planned to execute the SECA two months earlier in August 2006. It would have included three separate architectures and their corresponding object models:  BLCSE using DIS, MATREX using HLA, and ATEC using TENA. To interoperate effectively, this original SECA would have required two separate gateways to communicate among the applications. However, once TRADOC finalized its HLA transition schedule, the 3CE Interoperability group decided to postpone the SECA, effectively eliminating half of the complications in the planned environment’s architecture.  5.  Summary While the idea of supporting a common operating environment has existed in the Army for more than three years, the planning and execution of the 3CE is still far from complete. Individual task groups, comprised of representatives from all three Army commands and the FCS LSI, are establishing the process and procedures necessary to create an environment that is functional today and relevant into the future. The most critical of these processes, from a systems engineering point of view, is the process to ensure interoperability among the 3CE organizations. Differences and gaps must be systematically identified and resolved using a collaborative approach. 3CE engineers are already dealing with major differences in both simulation model and network communication architectures between the commands. Only further testing through the use of SECAs will reveal if the implemented resolution of these differences is sufficient. To ensure the 3CE continues to mature into a relevant Army environment, each 3CE organization must be willing to adjust to the simulation model, data collection process, or business logic the group identifies as the most appropriate. Having recently transitioned from DIS to HLA, TRADOC engineers are in a position to be especially adaptable to the technical compromises that are necessary in creating a common operating environment. 3CE must continue to base its engineering decisions on solid analytical results that will come from iterative testing and continued collaboration.  Through their efforts, each organization and the Army as a whole, will reap the benefits of consistent, non-redundant simulation techniques and models. 6.  References[1] Kleinhample, LTC B. and V. Sullivan:  “Cross Command Collaborative Effort (3CE) Breakout Session” Army Modeling and Simulation Conference, May 2006. [2] 3CE Systems Engineering and Technology Development Face-to-Face Planning Conference – Overview, 3CE SE Branch, 15 February 2006 [3] Doescher, C., E. Johnson, and W. Hamm:  “Battle Command System Analysis Methodology in the Cross Command Collaborative Effort (3CE) Environment” Proceedings of the 2006 CCRTS, Paper 116. [4]	Rieger, L. and J. Lewis:  “Integrated Middleware for Flexible DIS and HLA Interoperability” Proceedings of the 2006 I/ITSEC, Paper 2701.Author BiographiesENGIN Z. ALTAN is leading TRADOC’s BLCSE federation transition from a DIS to an HLA environment. She also has an active role in the 3CE LVC Interoperability task for Object Model development. She holds a MS in Electrical Engineering with an emphasis in Meteorology from Technical University of Istanbul, Turkey.JENNIFER LEWIS is a software engineer for TRADOC’s BLCSE. She holds a MS in Computer Science with an emphasis in Telecommunications and Networking from the University of Texas at Dallas. She has designed and implemented network protocols for the telecommunications and defense industries for the past six years.FY06M&S SolutionsCenter, MANATICK SoldierBoeing-Houston,TXSAIC-Vienna, VARDECOMMATREX/DVLFt Dugway, UTWDTCWhite Sands, NMWSMR/IRCC/DTCCYuma, AZYPGATECATINALRedstone Arsenal,Event Requirements•(WBS 2.0)Leverage 3CE Toolkit•CertificationFacilitate Accreditation & •AssuranceConduct Quality •Facilitate Event Execution•Facilitate Event Planning•Execution/UserCapability DevelopmentProcessOutputsInputsLegendStandards•Business Processes•Technical Capabilities•RTTCList of Configuration Managed •SolutionsIntegrated for efficiencyManagementExecutionDevelopmentInfrastructure,Integration,& VerificationWBS 6.0RequirementsDeterminationWBS 5.0WBS 4.0ExecutionWBS 2.0TechnicalDevelopment(TD)SystemsEngineering(SE)WBS 3.0WBS 1.0ProgramManagementSenior Executive PanelAdvisoryCouncil(WBS 6.0)Manage Current Capabilities•SolutionsFt. Huachuca, AZEPGFt. Lewis, WAEPGAPG,MDATCBAE-Minneapolis, MNBoeing -Seattle,WABAE-Santa Clara, CAHuntington Beach, CARedstone Arsenal, ALAMRDECFY06Picatinny Arsenal, NJARDECWarren, MITARDECAPG, MDARLFY06Orlando, FLSTTCFt Belvoir,VACERDEC/BAlexandria, VAM-ITFY06Ft. Monmoth,NJCERDEC/MHuntington Beach, CALSI / BoeingFt. Gordon, GAFt. Bragg, NCFt. Lee, VAConfiguration Manage •Integrate M&S Solutions•SolutionsValidate and Verify •VerificationInfrastructure, Integration, & (WBS 5.0)SolutionsDevelop Technical •Develop M&S Solutions•Design M&S Solutions•CapabilitiesIdentify Current •Technical DevelopmentCapability GapsPrioritized List of M&S Other•Analytical•Requirements:Prioritized Capability GapsList of M&S (WBS 4.0)RepositoryUpdate Knowledge •Development Road MapRefine Capabilities •“gaps”maturity levels and Identify M&S Capability •RequirementsAssess and define M&S •System Engineering(WBS 1.0)3CE Program Management(WBS 3.0)Refine•Decompose•Prioritize•Verify•Archive•Consolidate•Identify Requirements•Analysis/EvaluationCommandsAcross •BasisAnalytical •High Level•Requirements:Source of RequirementsPM Requirements•Command Requirements•Research Requirements•etc…C, -V-SIMEX, LUT, LPM/MAT DEV, DTE, M&S Community,,FACTsFCS SSP, Ft. Huachuca, AZSMDCWSMR, NMFt. Bliss, TXFt. Monroe, DCFt. Wood, MOFt. Benning, GAVLFt. Leavenworth,KSBattle LabFt. Benning, GAJCATFt. Sill, OKFt. Knox, KYUAMBLFt. Leavenworth, KSTRACFt. Rucker, ALTRADOCBLCSEFt. Belvoir, VANVSDFt. Monmouth, NJC4ISR ITWhite Sands, NMBoeing-STL, MOBoeing-Philadelphia,PADRENGD-Sterling Hts, MIFCS