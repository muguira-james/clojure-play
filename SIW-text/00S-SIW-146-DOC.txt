Developing an HLA Federation-Independent Playback ApplicationRobert V. HeadPaul PerkinsonMichael ThomaAnnette L. WilsonVirtual Technology Corporation5400 Shawnee Road, Suite 203Alexandria, VA 22312-2300703-658-7050rhead@virtc.com, pperk@virtc.commthoma@virtc.com, awilson@virtc.comKeywords:HLA, data collection, playback, FEDEPABSTRACT: As the use of HLA federations replaces that of standalone simulations, the demand for tools that support operating in this distributed environment continues to grow.  One important capability that has not been well addressed by the tools available to date is the ability to playback the data exchanged during an execution.  HLA federation playback serves very useful demonstration and analysis purposes, including training scenario review and evaluation. This paper looks at the uses for playback, the requirements derived from those uses, the technical issues involved in meeting the requirements, and the implementation of a federation independent playback application. Pitfalls for federation developers to avoid to effectively design, develop, and execute a federation using playback will be described. Lessons learned are drawn from data collection, analysis, and playback experience with specific federations.1. IntroductionTo date, playback tools to support HLA federations have been limited and generally tied to a specific Federation Object Model (FOM) or a particular set of simulations. This paper discusses the requirements for and technical challenges involved with developing a federation-independent playback system.  Experience is drawn from the development of hlaResults, a commerical data collection, analysis, and playback tool; supporting use of the tool with the Tasmanian Devil Federation, a Distributed Mission Training (DMT) pathfinder federation; and development and fielding of the STOW Data Collection System [1].  This paper begins by examining the uses of playback and the requirements derived from those uses.  Several technical issues involved in designing and developing a federation independent playback tool are then discussed. The paper concludes by drawing on experience from working with several federations to discuss how playback objectives need to be considered during the Federation Development and Execution Process (FEDEP) to make the most effective use of the playback tool.2. Playback RolesA robust playback capability can help to facilitate execution of steps 5, Integrate and Test Federation, and 6, Execute Federation and Prepare Results, of the FEDEP model [2].  In order to use playback most effectively during these steps, consideration must be given to playback objectives during steps 3, Design Federation, and 4, Develop Federation. Playback is also useful for supporting activities such as demonstrations that are somewhat outside of the FEDEP model. The paragraphs below describe how playback can be used to support steps 5 and 6 of the FEDEP process while design considerations are discussed in section 5.2.1 Integrate and Test FederationIt is during this phase of the FEDEP process that federates first come together.  Playback may be used effectively several ways during this phase.  It may be used to do preliminary testing before federates are actually run together. It may be used during an integration test where all federates are present. Finally, it may be used after the integration test for additional individual federate testing.Playback may be used to test federates individually before bringing all federates together. This is accomplished by having federates that produce data record this data and send it to the federates that have subscribed to that information. The consuming federates may then test that they respond correctly to the object discoveries, reflect attribute values, object deletions, and interactions.  This allows federates to identify and correct problems before the integration test making the test time more productive.  The NATO DiMuNDS federation is using playback to perform this type of distributed testing. Since the highly interactive nature of some of the exchanges between federates require both federates to be present, the amount of testing that can be performed in this manner is limited.  However, it does give federates some assurance that they will have some level of interoperability during the integration test.During the integration test when all federates are present, the data exchange should be recorded.  This data can then be used during the test to help identify problems, reproduce problems, and test corrections. It is often useful to create a single federate federation execution to work on corrections while continuing with integration testing in another federation execution. One of the advantages of playing back recorded data is that in a well-designed playback system, the desired data can be extracted to playback without requiring a large setup or run-up time. The data from the integration test may also be used after the test for federates to perform additional testing without having other federates present.  This is very similar to the pre-integration test testing except that the data should contain more of the interactions between federates since all federates were present when it was recorded.2.2 Execute Federation and Prepare ResultsIt is during this phase of the FEDEP process that the federation is executed and the results are analyzed and reported.  Data collected during the execution will be used during analysis and to playback the federation for reviewing and analyzing federation results. Playback is a particularly useful tool for training exercises and analyzing the degree of federation success. For training, playback is effective for post event debrief as a way to review opposition tactics and the training participation performance. For assessing the success of the federation to achieve the sponsor’s objectives, playback is useful for analyzing tactical employment. During analysis, the entire federation or particular portions of the data may be played back to examine what occurred during the execution.  Similarly, selected data can be replayed into a Plan View Display (PVD) or Stealth, for demonstration, to highlight key events that occurred during the execution.3. Playback RequirementsAt its most fundamental level, playback is the ability to recreate what happened in the original federation execution.  In order to do this, the necessary data must be collected. Beyond that, playback should support activities such as integration, testing, and After Action Review (AAR) as discussed in section 2 above. To do this, the playback system needs to support playing back all or selected portions of the data.  Ideally, the playback system will be flexible enough to allow the user to specify data to be played back by a number of means including object and interaction classes, time intervals, and attribute or parameter values.  For example, it may be desirable to playback only air objects that have a particular country code.The first step in being able to playback data is ensuring that all the necessary information is collected.  This is discussed in section 3.1. Section 3.2 discusses the requirements for identifying the data to be played back; section 3.3 describes extracting the identified data from the recorded (collected) data; section 3.4 discusses playing this data into a federation; and finally, sections 3.5 and 3.6 discuss issues that span the preceding categories.3.1 Data CollectionAlthough it is obvious that in order to playback  data as it was originally sent, the information must first be recorded; it is not as obvious what that information is or how to correctly extract it from the RTI to fully support federation recreation.  For example, it is clear that from an update the collector will need to record the object and the attributes and associated values.  In addition, the attributes may be sent using either best effort or reliable transportation mechanisms and may have update regions associated with them.  To completely replicate what occurred during the original execution, this data must also be considered. Briefly, the required information is:the list of objects including their names and their registered classes;attribute value updates including the transportation mode, time ordering, logical time (if applicable), real (wall clock) time of the update, and any region associations;interactions sent including parameters and parameter values, transportation mode, time ordering, logical time (if applicable), real time, and any region information; andobject deletions.Information, which helps the playback system to recreate what occurred, will also need to be recorded.  This information may include:time advances,synchronization pointsevent retractions,federation saves, andfederation restores.3.2 Playback Data SelectionA playback system should provide a means for selecting a subset of the collected data to playback.  This is crucial if the system is to support testing, demonstration, and AAR. The fundamental ways that the desired data may be identified are by class, object attribute, time, or value.For example to support testing, the system needs to allow selection of which data will be played back to the federate(s) being tested. In many cases additional information will not be harmful.  However, there are some cases where it could prevent the federate from being properly tested.   For instance, if the federate tries to register an object with the same name as that used by the playback system, the RTI will generate an exception and prevent the object from being registered.  It is unlikely that it will be desirable for the federate being tested to receive data that it generated in the original execution.  If the classes of objects are well broken out by federate, it may be possible to extract the data based simply on classes.  However, if the same object class is simulated in multiple federates then some additional type of filtering is necessary.  If Data Distribution Management (DDM) was used during the original federation execution, it may be possible to filter by update region.  If federate update regions are not available, then some sort of attribute value filtering will need to be employed.  The same situation is true for sent interactions.  It will also be desirable to restrict the time interval of the data, so that it is not necessary to reproduce the entire federation.  If time management is used, either logical time or real time may be used.  Without time management, only real time can be used. 3.3 Data ExtractionIt is the job of the data extraction portion of the playback system to pull the specified data out of the recorded data. Depending on the design and implementation, this portion of the system may be uncomplicated or very complex. 3.4 Playback to a FederationThis section describes the capabilities that a playback application should support for playing data into a federation to recreate what occurred during the original execution.  To accomplish this the data needs to be played back in such a way that individual updates occur in the same relationship to each other as they did during the original run.  To completely replicate the situation, updates should be sent using the same transport and order type.  In addition to playing back the data as it occurred, it is also desirable to be able to adjust the rate so that data is played back either faster or slower while maintaining the relative temporal relationship between attribute value updates, sent interactions, etc.3.5 Federation Save and RestoreThere are a number of thorny playback issues related to federation save and restore. Different federations use save/restore for different purposes; consequently, the desired behavior of the playback system with respect to save/restore will vary from situation to situation.Perhaps the most common use of save/restore is to support error recovery. For example, a federation might save its state at various checkpoints and roll back to the most recent valid checkpoint in the event of an error. In such cases, the events occurring between a save and a corresponding restore are typically not of interest during playback: they constitute a path of execution that was abandoned due to an error. Rather than playing back saves and restores verbatim, the playback system should use them to filter out events occurring along abandoned paths of execution. The remaining events constitute an idealized representation of the original federation execution. The following diagram depicts an event sequence and its idealized representation.Figure  SEQ Figure \* ARABIC 1. Event Sequence With Save and RestoreIn other situations, the desired behavior is to reproduce the original federation execution as closely as possible – including saves and restores. Such a strategy may be appropriate when debugging federation save/restore behavior, or when a federation uses saves and restores for purposes other than error recovery. Conceptually, the occurrence of a restore need not interrupt the sequence of events as reproduced by the playback federate: the events collected after the restoration of the original execution reflect the restored state of that federation, so these same events can be played back after the restoration of the playback federation. In practice, some adjustments will have to be made to compensate for the RTI saving and restoring its internal state. For example, an object that was registered between the save and the restoration will no longer be registered after the restoration is complete; consequently, it will have to be reregistered prior to its next update. Such adjustments can be computed prior to playback while extracting federation data from the data store.In all cases, it is impossible for the playback system to meaningfully interpret a restore for which there is no corresponding save entry in the data store. This situation can occur if the restored state corresponds to a different execution of the data collector -- or a different federation execution entirely. Such a restore cannot be played back verbatim because, in the absence of a preceding save, there would be no saved RTI state for the playback federate. The save/restore pair does not clearly delineate an abandoned path of execution, so the restore cannot be used to filter out unimportant federation events. As such, the only reasonable action in the face of an unmatched restore is to ignore it.The hlaResults playback system does not currently recreate saves and restores into account when generating playback tracks. However, the hlaResults Data Collection System stores all necessary federation state and save and restore characteristics, enabling playback to replay or skip federation saves and restores. A future release of hlaResults will support save and restore playback.The playback federate nominally supports saves and restores initiated by other federates in the playback execution: it responds affirmatively when requested to save or restore its state. It does not perform any action when requested to restore its state, however. As such, problems can arise if a restored RTI state is incompatible with events in the playback track. Due to the fundamental architecture of the playback system, in which the sequence of events is largely predetermined when extracting fed data from the data store, it would be difficult to have the playback federate react meaningfully to externally-initiated save/restores.3.6 Event RetractionEvent retractions are similar to saves and restores in that some applications of the playback system will require an exact reproduction of what originally occurred (i.e., play back both the event and its retraction), whereas others will call for an idealized representation of the collected data (i.e., pretend that retracted events never occurred in the first place).  Depending on how the system is implemented, it is possible that the data collector will never receive event retractions.  Retractions are only received by federates that advance time using the flush queue request service or are not time constrained.4. Development of a Playback CapabilityA federation object model (FOM) independent playback system was developed by extending hlaResults, a data collections and analysis tool.  This system can conceptually be thought of as four components as shown in figure 2 although these components do not necessarily correspond to actual processes.  The first component, the data collector, is the heart of the hlaResults data collection tool.  As its name implies, this component performs the data collection.  The second component is the playback user interface.  It allows the user to specify the what data is to be played back as well as to control the playback execution.  The third component is the track generator.  This component extracts the data to be played back from the data that was collected and puts it in a form that may be played back with as little processing as is necessary.  The final component is the playback federate.  This component reads the data produced by the track generator and makes the appropriate RTI service invocations.  The development of these components including some of the issues that arose and the design decisions that were made are discussed in the sections that follow. EMBED Word.Picture.8  Figure  SEQ Figure \* ARABIC 2.  hlaResults System Components4.1 Data CollectorTo facilitate a more effective playback capability, several enhancements to the existing hlaResults data-collection system were identified. The guiding philosophy is that the federation data store should be a self-contained record of the federation execution, containing sufficient detail to allow the playback facility (and other applications) to operate effectively in the absence of any other data source. To this end, it was necessary to augment the federation data proper by storing federation meta-data, such as the FOM, the FED, and the execution running time, in the data store.To accurately depict a time-synchronized federation, a federation data store must capture the relationship between “wallclock” time (real time) and federation logical time. The hlaResults data-collection system has always recorded both the wallclock time and the logical time (if any) associated with each federation event. To support playback, the data-collection system was extended to also record time-advance grants. This dual representation offers several advantages over simply recording the event times:The time-advance-grant log represents a centralized, concise record of the progress of federation logical time. Without it, it would be necessary to collate entries from many different tables (corresponding to the various interactions and object classes) in order to observe the progress of logical time.It provides guidance as to how often the playback federate should advance its logical time. Advancing time too frequently (for example, after every single time-stamped event) can incur unacceptable RTI overhead. Advancing time too infrequently can needlessly stall the federation. By recording time-advance grants, the playback system can advance time in increments that mimic those observed by the data collector during the original execution.Several issues arose during the design of the playback system that have to do with the way data is collected.  These are described in the sections that follow.4.1.1 Cumulative State vs. Partial Updates  When the hlaResults data collector receives an object update, it logs the entire cumulative state of the object to the data store. That is, if an update contains values for attributes A and B only, but the collector had previously received updates for attributes C and D of the same object, the resultant entry in the data store will contain the most recently-received values of C and D as well as the new values of A and B. This scheme is ideally suited to analysis: storing the entire object state in a single data-store entry obviates much of the need for queries that collate data from several different entries. Such queries can be quite inefficient and cumbersome to develop.On the other hand, this approach limits the ability of the playback system to exactly reproduce the sequence of partial updates that contributed to a given cumulative state. In order to enable accurate reproduction of the federation a bit mask is stored with each reflect to identify which attributes were received in each reflect. However, other factors make it hard to exactly reproduce the original federation. There are situations in which it is possible for a single object update to be delivered as several reflections. Under most RTI implementations, an update whose constituent attributes have different transport or ordering policies will be split into several reflections. Some existing RTI implementations will also split updates based upon DDM associations, although this behavior is contrary to the interface specification [4]. There is no general way for the data collector to determine which reflections are, in fact, a result of the same update; it simply logs all reflections without any attempt at aggregation. As such, it is possible that a single update in an original execution will be replayed as multiple updates. When presented with a consecutive pair of object states having one or more identical attribute values, the playback facility has no general way to determine which attributes were actually present in the corresponding updates and which were supplied by the data collector based on the cumulative state of the object. As such, the playback system currently adopts the approach of including the entire cumulative state of the object with each update. Whether this is desirable is largely dependent on the context in which the playback application is used and the characteristics of the data being played back. Obviously, cumulative-state updates are desirable in that they can obviate much the need to maintain state in the receiving federates. However, there are several situations in which cumulative-state updates can be problematic.The most obvious concern is the overhead associated with redundant updates: if the encoded size of the attributes that remain static over the lifetime of an object (e.g., entity type, country) is large compared with the encoded size of more dynamic attributes (e.g., location, velocity), the time and space overhead of updating cumulative states could become significant. Cumulative-state updates can also pose a problem for federations that employ dead reckoning or any other strategy in which the absence of an attribute-value update can be significant. (Such a strategy is sometimes referred to as a predictive contract [3].) For example, federation policy might dictate that a vehicle’s location only be updated every 30 seconds unless the vehicle undergoes a significant change in velocity. The vehicle’s location at an arbitrary point in time is to be computed by the receivers based on its latest known location and velocity and the time elapsed since its last update. If changes to unrelated attributes cause the playback application to update the cumulative state at times other than the 30-second intervals, these updates can confuse the dead-reckoning algorithm by asserting an out-of-date location and velocity as current values.Using the bit mask associated with each update, that describes which attributes were received for a reflect, a future release of hlaResults will enable playback users to determine whether full object states or just the attributes received with each reflect are replayed. 4.1.2 Registered Classes vs. Discovered Classes  The hlaResults data-collection system stores object data in tables according to the objects’ discovered classes. For example, consider a military simulation that has an object class “Aircraft”. This object class might have many different subclasses corresponding to specific makes of aircraft. If the data collector is subscribed to “Aircraft” and not to any of its subclasses, all Aircraft subclasses will be discovered by the collector as Aircraft and the states will be logged to the “Aircraft” table in the data store. By eliminating the need to collate aircraft data from many different tables (corresponding to the various “Aircraft” subclasses), this technique can dramatically simplify data analysis.On the other hand, the registered class of an object often conveys significant information in and of itself. For example, a visualization tool might use different symbols to display the different makes of aircraft. For this reason, the data-collection system logs each object’s registered class in an auxiliary table, which can be cross-referenced with the primary object tables to determine the registered class of a given object. The playback system uses the registered classes from the original execution when registering objects for playback. In some cases, discrepancies between an object’s discovered class and its registered class can cause problems during playback. In the aircraft example, suppose that “Aircraft” has a subclass “Helicopter” which defines several helicopter-specific attributes. If the data collector is subscribed only at the “Aircraft” level, data for helicopter-specific attributes will not be collected. Certain helicopter-specific attributes might be required for a helicopter object to be meaningfully processed by certain federates; for example, a visualization federate might need to know the number of rotors in order to display a helicopter. If these attributes cannot be supplied by the playback federate, the playback may not achieve the desired effect.When collecting data exclusively for playback use, this sort of situation can be avoided simply by subscribing to all classes for which objects may be registered. If the collected data are to be used for both playback and analysis, subscriptions should be carefully considered so as to simplify the data as much as possible without losing information that will be required during playback. Also, some object classes have “discriminant” attributes, which convey information that could alternatively be represented using subclasses. For example, an object class “Tank” might have an attribute “TankModel” that is used to differentiate among different makes of tank. Depending on the situation, this information might be more appropriately depicted by creating a subclass of “Tank” corresponding to each particular make of tank.4.2 User InterfaceThe user interface provides a graphical means for selecting the data that is to be played back as well as controlling the playback itself.  All control of the track generation system and the playback federate is done through this user interface.Before proceeding to describe the user interface, it is necessary to define a few terms.  A track is binary file containing a list of services to be invoked on the RTI.  These operations represent the data that is to be played back.A set is a collection of tracks.The user interface (UI) is divided into two functions: manipulating sets including the creation of new tracks for the set and playing back tracks.  The two most interesting parts of the UI deal with track generation and playback.The track generation portion is implemented as a wizard-based interface that steps the user through selecting the data for the track.  The wizard begins by having the user select the data source.  It then uses the track generation subsystem to extract meta data from the data source.  This data includes the name of the FED and OMT files, the date the data was collected, the starting and ending times of the data, and the names of the object and interaction classes.  The wizard then steps through a series of screens which allow the user to specify which object classes/attributes and interactions are to be included, what time interval by either wallclock time or logical time (if used), and whether or not to include DDM information. This information is then conveyed to the track generator which extracts the information from the data source.  At this point, data may only be selected by class and time.  It is planned that value based selection will be supported in the future.The playback controller provides the means for specifying the federation to join, the FED file to use, and the initial rate at which the data is to be played back.  While the data is being played back, the GUI displays a progress bar indicating how much of the data has been played back.  There are plans to include additional runtime controls such as the ability to adjust the rate,  and pause and resume playback.4.3 Track FilesIt is conceivable that a playback federate might interface directly with the federation data store. However, the hlaResults playback federate operates off of a playback “track”: a binary file containing the sequence of commands necessary to effect the desired playback result. The commands in a track file correspond to RTI service invocations and arguments, which are augmented with timing information that is used to modulate the rate at which commands are executed. There are several ways in which the use of an intermediate file format is advantageous:hlaResults supports the use of several different database management system (DBMS) packages to implement the federation data store. The details of interfacing to the data store vary depending on the DBMS employed by a particular federation. A separation of concerns dictates that differences among DBMS packages be abstracted away from the logic for interfacing to the RTI.Reading a binary file is significantly faster than querying a database. Moreover, there is substantial computational overhead associated with distilling the results of a database query into a sequence of RTI commands.A playback track is self-contained: it can be executed in the absence of the original data store and on any machine on which hlaResults is installed. In particular, this allows tracks to be transported among hlaResults installations, even if some installations are using different DBMS packages or no DBMS at all.One of the design considerations embodied by the playback track format is that as much computation as is feasible should be performed at track generation time as opposed to track execution time. There are several reasons why this approach is desirable:A track is only generated once but is typically executed multiple times. The track-generation overhead can then be amortized over multiple track executions. As such, migrating overhead from track execution to track generation reduces the total computational effort expended per track execution.Reducing the computational burden on the track executor (i.e., the playback federate) increases the data throughput that is attainable. Increased data throughput means that more types of federation data can be played back and/or that data can be played back at a faster rate, without requiring additional computational resources.For the above two reasons, optimizing the execution speed of the track generator is less important than optimizing the execution speed of the playback federate. Because most of the complicated logic is implemented in the track generator, the focus of the implementation can be on correctness and simplicity rather than on attaining utmost efficiency. By the same token, the relatively simple track-execution logic is conducive to a highly streamlined implementation of the playback federate.The design of the track format is such that the playback federate need not have any knowledge of FOM data types. In particular, attribute and parameter values are stored in the track as opaque octet sequences; the track executor simply pushes values through the RTI without interpreting them in any way. Another consequence of this design is that the details of the encoding scheme employed (i.e., big-endian, little-endian, etc.) are abstracted away from the playback federate.4.4 Track GeneratorThe track-generation subsystem constitutes the interface between the playback system and the federation data store. In addition to creating playback tracks, this subsystem encapsulates the logic for extracting federation meta-data from the data store.One of the major functions performed by the track generator is the sequencing of events from multiple sources. The hlaResults data-collection system stores different types of events in different tables of the data store: every class of object and interaction is stored in its own table, and there are additional tables for events such as deletions and time-advance grants. These multiple streams of events must be collated into a single sequence of playback commands that preserves the relative ordering of events. The following diagram depicts the sequencing of events from simplified versions of four different tables: an interaction table, an object-update table, the deletions table, and the time-advance table.Another function performed by the track generator is the encoding of attribute and parameter values. For primitive data types, this is a fairly straightforward matter. Compound data types (i.e., complex types, arrays, and sequences) may be mapped to multiple fields – or even multiple tables – in the data store. For compound data, the track generator must collate values from a number of different fields to completely encode a datum. The track-generation subsystem is the only component of the playback system whose logic is tightly coupled with that of the data-collection system. In particular, the track generator must implement the reverse of the algorithms employed by the data collector to map federation data to a database schema. As such, an important design goal is that the track generator be tightly integrated with the existing data-collection logic, so that the implementation of the database-mapping (and reverse-mapping) logic for the entire collection-and-playback system is unified at a central location in the code.One of the issues that arises at track creation time is how to handle playback from a point other than that where collection began.  The playback system is frequently used to play back only a subset of some collected data. During a demonstration, for example, the playback system might be used to play back only the most “interesting” ten minutes of a two-hour federation run. In many federations, objects representing buildings and other relatively static features of the terrain might be updated infrequently -- or not at all -- after their initial updates. If none of an object’s updates occur within the time interval being played back, the object will not be included in the playback.In such cases, it might be desirable to have the playback federate send out an initial update for each existing object, based on the object’s state at the beginning of the playback interval. This option is one of several improvements to hlaResults that are being considered to provide finer-grained control over the data being played back.4.5 Playback FederateThe Playback Federate is the segment of the playback system that replays a simulation by invoking RTI operations.  Currently the RTI operations supported are Publish Object Class, Publish Interaction Class, Register Object, Update Attribute Values, Delete Object, Send Interaction, and Time Advance Request.  Future operations supported will be Request Save, Request Restore, Create Region, Register Object With Region, Associate Region For Updates, Unassociate Region For Updates, and Send Interaction With Region.The playback system is designed to de-couple the Playback Federate from the federation data store created by the data collection system.  This is achieved through the use of a binary file called the track file.  Essentially this file contains a list of operations to be invoked using the RTI.  These RTI operations are chronologically ordered and properly formatted for distribution over the RTI.  The track generation subsystem creates the track file by extracting data from the federation data store.  Complicated and time-consuming data base queries are required to build this track file.  Another reason for creating the track file prior to replay of a simulation is to reduce the workload on the Playback Federate.  This will facilitate its ability to perform RTI operations at high speeds when necessary.Regarding recreating identically what originally occurred during a simulation, the Playback Federate has a limited role.  The majority of the RTI operations it invokes are read from the track file and invoked in the order that they appear in the file.  Under these constraints, the only parameter of variation controlled by the Playback Federate is the rate at which operations are sent to the RTI.  Thus the major operational requirements of the Playback Federate are twofold.  First to invoke each RTI operation in the track file in the order in which it appears.  Second to invoke RTI operations at the desired rate.The requirement to invoke each RTI operation in the track file in the order it appears in the file is fairly easily achieved.  The only concern is that an ill-formed operation not terminate the processing of the remaining operations.  Any well-designed system needs to handle exceptional situations.  The playback federate was designed using object oriented techniques and implemented in a language that provides support for exception handling.  Within that development environment it is easy to ensure that all valid operations in the track file get invoked.The more interesting requirement is that RTI operations be invoked at the appropriate rate.  Factors to consider are the wall clock time, federation time, and playback rate.  The wall clock time is the elapsed time in milliseconds since the start of the data collector.  When the data collector stores an event it is stamped with the wall clock time as well as the federation time.  The playback rate is a linear multiplier that enables a simulation to be replayed at a rate proportional to that of the original simulation.  A playback rate of 1 is intended to identically replay the original simulation.  A rate of 2 is intended to replay the original simulation twice as fast or in one half the time.  Similarly a rate of 1/3 is intended to replay the original simulation one third as fast or in three times the time.  This rate requirement applies not only to the entire time length of a simulation, but more importantly to the length of the time intervals between consecutive invocations of RTI operations.  The following paragraphs explain some of the problems that can occur when attempting to replay RTI operations at a rate proportional to that of the original simulation and the methods used to overcome those problems.After taking into account the playback rate and whether to replay using simulation time or federation time, each RTI operation read from the track file can be associated with a logical invocation time.  The Playback Federate will maintain a simulation logical time and attempt to invoke each operation at its appropriate logical time.  Under light to moderate RTI operation load the Playback Federate should have no problems invoking RTI operations at their expected logical times.  As the playback rate is increased or the simulation activity becomes intensive, the Playback Federate may not be able to invoke RTI operations fast enough.  When this happens we say an operation lag has occurred.  This lag can build up to a considerable amount of time.  In large federation replays, using only a single Playback Federate there is no way to avoid this lag.  In many scenarios the lag may occur in a small time slice of the entire simulation.  In such situations it is possible for the Playback Federate to ‘catch up’ by invoking operations at a faster rate than that of the original simulation.  Designing the Playback Federate to ‘catch up’ as fast as possible has the undesired effect of creating an operation burst immediately after an operation lag.  Even though the entire time length of the simulation could be proportional to that of the original simulation, the time intervals between consecutive RTI operations could be highly distorted for many of the operations.  To reduce the time distortion caused by ungoverned ‘catch up’, a method was devised to ‘catch up’ at a controlled rate.  This method limits the effective playback rate to a configurable factor of the desired playback rate during ‘catch up’ modes.5. Federation Design ConsiderationsIn order to effectively use federation-independent playback it is important that the federation is designed and developed so that the playback application can simply reproduce the data collected. Therefore, embedding information into object updates and interactions which will be out of context during replay significantly reduces the effectiveness of playback.  An example of this is placing RTI generated object handles or object names into object updates or interactions.5.1 Object NamesEvery object in an HLA federation execution has a name that is unique over the lifetime of the federation execution. The Register Object Instance service [4] allows the registering federate the option of specifying an object’s name; otherwise, the RTI supplies a unique name from a pool of reserved names. All object names are recorded by the hlaResults data-collection system.If an object has a federate-supplied name, it is reasonable to assume that the name is somehow significant to the federation. As such, objects with federate-supplied names are registered with the same names during playback. This policy is well suited to the most common playback configuration, in which the playback federate serves as a stand-in for the federate(s) that originally produced the data being played back. In some situations, however, the playback federate might be federated in a way that results in contention over federate-supplied object names. In a military federation, for example, the playback federate might be used as a “force multiplier”, whereby some entities are updated by live simulations and others are supplied by the playback federate. Moreover, future versions of the playback system might support a distributed playback architecture, in which several playback federates would operate in tandem. Such configurations would require some sort of mediation to ensure that multiple federates do not attempt to use the same object names. Object names from the RTI’s pool of reserved names cannot, by definition, be used as federate-supplied names. As such, objects with RTI-supplied names are registered without federate-supplied names during playback. In general, this results in objects having different RTI-supplied names during playback than they did in the original execution.Well-behaved federations do not rely on RTI-supplied names being assigned in any particular fashion. In this respect, one RTI-supplied name is as good as any other. What can be problematic, however, are federations that use object names as attribute or parameter data. For example, a “Fire” interaction in a military simulation might have a “Target” parameter whose value is the object name of the target entity. If an object has a different name during playback than it did in the original execution, any attribute and parameter values denoting that object name may not refer to the same object instance or any object during playback. Therefore, it is not good practice to use object names as attribute or parameter data. Unfortunately, the OMT specification [5] does not provide a standard notation for indicating that an attribute or parameter value represents an object name. Thus, the playback application cannot readily identify which federation data represent object names without additional “hints”. Such hints might be implemented by the allowing the user to designate attributes and parameters using the playback GUI, or by employing ad hoc OMT conventions (for example, by using special note-refs to designate attributes and parameters).5.2 Object HandlesEach federate in an HLA federation execution is supplied an object handle when registering or discovering an object instance. Object handles differ from Object names in that they are always assigned by the RTI and are not guaranteed to be unique across the federation. Therefore, two federates may discover the same object instance with different object handles or two federates may discover different object instance with the same handle. Since object handles will not only differ across federates in the execution, but from execution to replay it is not good practice to use object handles as attribute or parameter data. 6. References[1]	Paul B. Perkinson, Stephen T. Bachinsky, Glenn Tarbox: “Lessons Learned from the STOW Data Collection System” Simulation Interoperability Workshop, Paper 183, Spring 1998.[2]	Defense Modeling and Simulation Office: HLA Federation Development and Execution Process (FEDEP) Model, Version 1.5, 1999.[3]	Daniel J. Van Hook, James O. Calvin: “Execution Logging and Replay: Issues and Approaches”  Simulation Interoperability Workshop, Paper 117, Fall 1997.[4]	Defense Modeling and Simulation Office: HLA Interface Specification, Version 1.3, 1998.[5]	Defense Modeling and Simulation Office: Object Model Template Specification, Version 1.3, 1998.Author BiographiesROBERT V. HEAD is a Senior Software Engineer at the Virtual Technology Corporation, where he is a member of the hlaResults development team. Previously, Mr. Head was a member of the technical support team for the RTI F.0/1.0/1.3 series.PAUL B. PERKINSON received his BS in computer science from George Mason University.  He has eight years of experience in software engineering; featuring object oriented analysis, design, and implementation. For five years he has been employed at Virtual Technology Corporation as the Director of Software Engineering and worked on such large scale distributed simulations as the Joint Precision Strike Demonstration (JPSD) and the Synthetic Theatre of War (STOW.) He was the lead developer for the STOW Simulation Infrastructure (SI) and Data Collection System, the Common Data Infrastructure (CDI) and worked on the Runtime Infrastructure (RTI) 1.3 Next Generation (NG) development team.  Mr. Perkinson is currently the lead engineer for the DMSO sponsored Data Collection Tool (DCT) and VTC’s effort to develop tools to support the Department of Defense’s (DoD’s) High Level Architecture (HLA), the Toolteam.MICHAEL A. THOMA received his BS in Mathematics from the University of Massachusetts, Amherst.  He has over 12 years experience in the software development industry, featuring object oriented design, generic algorithm design, graphical user interfaces, software engineering principles, and optimization techniques. Mr. Thoma worked on the design and development of an HLA federation data collector template for data collector generation. ANNETTE L. WILSON is a Senior Software Engineer at the Virtual Technology Corporation, Alexandria, VA. She has been involved with the HLA since its inception. Ms Wilson is a member of the hlaResults development team. Figure  SEQ Figure \* ARABIC 3.  Sequencing of Events from Data Store