Event Validation and Performance Measurement in a Distributed Virtual Reality EnvironmentPaul A. BeckmanSan Francisco State University1600 Holloway AvenueSan Francisco, CA 94015415-338-6240pbeckman@sfsu.eduKeywords:Virtual reality environments, validation, human performance.ABSTRACT:  This paper discusses the steps taken in one military research to validate real-world events when those events were recorded, replayed, and displayed in a DVRE (distributed virtual reality environment), and also describes attempts to calculate and display real-time performance measures at both low levels (concerning single-entity quantitative measures) and higher levels (concerning multi-entity qualitative measures).  The paper begins with an introduction of the primary and secondary goals of the research program.  It then proceeds with a section on the hardware, software, and networking characteristics of the particular virtual environment used throughout the research program.  The next paper segment broadly describes the steps that were taken to validate real-world events in the virtual world.  These steps are then covered in greater detail, with a perspective toward their impact on the goals of the research, and toward the problems and insights that were encountered.  The major lessons that were learned in the process of completing each step are then discussed.  Finally, some concluding remarks are made concerning the overall success and possible future directions of the research program.1.  IntroductionThis paper describes the steps taken in a research program at IDA (the Institute for Defense Analyses) in Alexandria, Virginia, to validate real-world events that were replayed in a military DVRE (distributed virtual reality environment).  The research program had several major goals and several minor goals, each of which typically related to a current or anticipated problem or opportunity in using virtual environments for military testing and training.  This section of the paper discusses these goals, and why there was a focus on each of them.One of the major goals of the research program was to support military trainers with real-time displays of performance.  Measuring performance can apply to the most low-level and basic tasks, such as maintaining a set speed when driving an armored vehicle, to the highest levels of decision-making.  Since there are an enormous number of performance measures that can be considered at any one time, it could be of great value to military trainers if some of these measures were considered, calculated, and displayed automatically.  Currently, one of the most popular performance evaluation techniques (both in real and virtual exercises) is the AAR (After-Action Review).  During the AAR, the trainer meets with the trainees, and discusses the decisions and actions that occurred during the training exercise.  All of the AAR occurs after the fact, however, and must therefore be based on actions that had already taken place.  For training exercises carried out in virtual environments, real-time performance measures could aid the trainer in altering an exercise while it was in progress, in order to create a situation of greater educational value.Another major goal of the research program was to begin studying ways in which to validate the actions of SAFOR (Semi-Automated FORces), which are computer-controlled entities that operate autonomously within a virtual environment. SAFOR entities are modeled and programmed to act as if those same entities were actually under human control.  However, a computer program can never perfectly emulate the actions of a human being.  Therefore, to ensure the validity of the outcome of any virtual exercise in which SAFOR entities participate, it would be useful to provide some means of measuring the accuracy with which the SAFOR actions mimic the human actions after which they are modeled.  To accurately compare SAFOR entities with human-controlled entities in a virtual environment, though, the actions of the human-controlled entities must first be confirmed to be the same as if those actions had occurred in the real world.A third primary goal of the research program was to provide a means for pre-construction testing of military systems.  Prior to the process whereby military systems are physically built, some type of testing program occurs, in order to ensure that the system is accomplishing its objectives.  In many cases, a prototype system is constructed and tested against criteria that measure how well it performs relative to its objectives.  It was expected that any testing that occurred very early on in the development of a new weapon system could be of great value in determining both the direction of additional system enhancements and the general utility of the system.  This expectation supported the idea of testing weapon systems in a virtual environment, prior to their physical construction, as long as some idea of their physical capabilities and characteristics could be determined and modeled.For the three reasons mentioned, the research program that will be discussed here attempted to complete a variety of tasks that would help to lay the groundwork for the goals described above.  Other minor goals of the research program were to: 1) prove that such a research program without large financial outlays could furnish useful results, 2) provide a direction for research in this area, and 3) provide a basic software support bed for other military systems diagnostic procedures and tests.  In order to achieve these objectives, it was necessary to verify some basic attributes about DVREs in general, and about the specific one used in this research program.In particular, to justify the value of a real-time virtual training aid, the trainer must understand and believe that the training aid is realistic and reliable.  The AAR process is based on the results of the exercise as seen through the eyes of the trainers.  Therefore, what the trainer sees must be close enough to actual events in the real world to justify his or her insights and comments.  If the trainer does not have confidence in the conformity of real-time training aids, especially those that support or usurp part of the trainers activities (such as measuring levels of performance), the trainer will ignore or avoid them.Along the same line, before making any claims about the utility results of a weapon system tested in a virtual environment, it must be shown that the actions and events that occurred or would occur in the real world would be represented in the same manner in the virtual world.  Without this substantiation, those who support, oppose, or merely test and analyze these systems will have just grounds for questioning the validity of their test results.For the reasons just described, the research program that will be discussed in this paper was undertaken.  The rest of the paper will specify the steps that were taken to justify the use of DVREs for weapon system testing, training enhancement, model validation, and other tasks.  These steps were taken in the order that seemed appropriate at the time; in retrospect, some steps may have been taken too early or too late.  However, the results and outcomes that will covered, have, in general, justified the process.  2.  Distributed Virtual Reality EnvironmentsThis section of the paper will detail the steps that were taken to confirm that events that did or would occur in a real world military exercise, would in fact, appear to occur the same way in the DVRE.  We begin with a minor discussion of the DVRE used in this research program.The United States military has available a network of computer-based nodes to use for training exercises.  These nodes exist at many military bases in all branches of the service, in many military testing sites, and at some military analysis sites, such as IDA.  The entities that can be connected to this network can be as simple as basic UNIX workstations emulating a single vehicle, to advanced military vehicle simulators such as M1 main battle tanks.Some of the fundamental supporting elements (not including the network connection, basic CPU, etc.) required to interact in these training or testing exercises include a computer image generator (needed to generate and display a three-dimensional view of the virtual world), an electronic terrain database which contains the data points necessary to define positions in the virtual world, and some type of hardware or software to emulate the actions of an entity in the virtual world.  The computer image generator (CIG) is typically a substantial part of the system, both in size and cost, although cheaper and smaller versions are continually being produced.  The terrain database is generated from some type of data extraction technique performed on the same piece of terrain in the real world.  Some vendors now sell digitized terrain maps of various parts of the world, with physical resolutions in the range of meters.  Entity emulation can occur through computerized or human-controlled models that function like their real world counterparts, or through simulators that are controlled directly by humans.Validation StepsThe broad set of steps required to validate real-world and simulated events in the virtual environment were anticipated to follow the proposed series:1.	obtain and display data from a simple (single entity) exercise2.	confirm the virtual results (via physical placement, instrumenting, etc.)3.	obtain and display data from a multi-entity exercise with no entity interaction4.	confirm the virtual results (via placement of entities and physical features relative to each other)5.	obtain and display data from a multi-entity interaction exercise6.	confirm the virtual results (via muzzles flashes, killed vehicles, etc.)7.	obtain and display data from a real-world exercise that is to be re-created in the virtual world8.	measure performance in the virtual world of this re-created real-world exerciseThe steps were performed in this sequence to best take advantage of the accessible data, and so as not to initially attempt to take on too large or complex of a problem.3.1  Single-Entity ExerciseThe first step was accomplished by getting access and permission to data taken during testing of a UAV (unmanned aerial vehicle) instrumented with a video camera.  This type of airplane is used in reconnaissance exercises, and when augmented with a video camera, can be used to identify targets in real time.  The data that was originally recorded consisted of a series of time-stamped records indicating the location (latitude, longitude, and altitude) and aspect (pitch, roll, and yaw) of the UAV, and the direction (compass and azimuth relative to the UAV) and field of view (horizontal and vertical aperture angles) of the video camera.  The data from this exercise was also useful because it had previously been converted to a format for display on another hardware/software platform (PV-Wave visualization software running on an HP workstation).  The advantage gained from this was that it was already possible to view the flight path of the UAV, and the footprint of the seeker cone (i.e. - view out of the video camera) as it was directed toward the ground.  Since this was a well-instrumented and documented exercise, it was possible to accept the flight path and seeker cone footprint as valid.The next step was to convert the data to a format by which it could be viewed in the virtual environment.  UNIX programs were written to do this, and the appropriate physical form of the UAV was determined for its appearance in the virtual world.  When the UAV flight was replayed in the virtual world, its location and that of the seeker cone footprint were verified to be almost the same as that on the previous platform.  Positions can vary slightly between locations in different platform representations of the same virtual terrain due to use of different map projections and datums used to generate each terrain database.  These very minor location differences from one platform to the other were ascribed to differences in the maps used to generate each electronic terrain.A secondary outcome of this phase of the research was the realization that the apparent lack of success in the use of the video camera to find targets, at least in this exercise, could be attributed to a fairly random and apparently less than optimal visual search pattern.  If it had been possible to view the seeker cone in a virtual world while the exercise was actually running, a different search technique might have been chosen.  It is possible that the evaluation of this weapon system could have been impacted by the irrelevant search characteristics of the person controlling the seeker cone, rather than on the importance of attaching a video camera to a UAV.3.2  Multi-Entity Exercise (No Interactions)The next step in the process was to obtain and display the results of an exercise that included many entities.  This step was incorporated into the research program in order to ensure that the physical relationships between entities in the virtual environment were preserved correctly.  The previous step ensured that one particular entity would be placed in its proper position, and if that entity was associated with any non-physical items (such as the seeker cone of the video camera), those abstract items would be displayed in correct association with their real-world occurrences.  For this set of data, recorded actions were obtained of a sequence of vehicles (M1 tanks) traveling through a wooded area, out onto a field, and along a road (called a road march).  This particular exercise had also been previously documented and verified using PV-Wave, so the result of displaying it in our virtual environment could be calibrated with this prior outcome.The line of vehicles was then displayed in the virtual environment, in the physical location indicated by the instrumented exercise.  At this point, each vehicle could be shown to be following the correct track in the virtual environment, as determined by the track of that vehicle from the datafile and from the PV-Wave display.  However, this exercise began to indicate some of the problems with validating real-world events in a virtual world.When the vehicles exited the wooded area, they took the unusual action of meandering through a field prior to driving onto and following a nearby road.  There appeared to be no military doctrine supporting this type of action in this situation, and the electronic terrain gave no supporting clues.  The initial conjecture was that this was an intentional action on the part of the exercise leader, although no reason could be attributed to it.  The real reason came to light only when an ex-military officer saw the virtual exercise, and commented that he was familiar with that exact location of the real-world terrain.  He stated that in that part of the terrain there was an old riverbed that was often used as a route by tank drivers.  Since the surrounding area was fairly thick with brush, any open areas were used to make up time in transit, hence the apparent random weaving pattern of the line of vehicles, as they followed the old riverbed.Unfortunately, the electronic terrain database did not have enough detail to display washed out riverbeds, and did not have the ability to display underbrush.  Therefore, in the virtual world playback, limitations in the ability to display real world physical terrain features caused an anomaly that was otherwise unexplainable.  This lead to a closer examination of the congruence of electronic terrains with the real-world locations they were supposed to represent.A second event occurred in this exercise that focused attention on another possible problem area in the process of converting real-world instrumented exercises into virtual displays.  Part way through the exercise, one vehicle suddenly turned around and drove quite rapidly back to an area at the beginning of the vehicle line where several other vehicles were waiting to follow the original column of tanks.  Shortly after reaching that area, it turned around and drove rapidly back to the front of the line.  It appeared that the vehicle was driving at close to maximum speed during this flight through fields and woods.  Prior to learning about the heavy underbrush in that area, it was speculated that some type of emergency transport was occurring.When it was learned that heavy underbrush existed in that part of the exercise area, driving there at maximum speed was ruled out as a possibility.  A closer examination of the originally instrumented data file indicated that there was a problem with the radio reception and triangulation process that calculated each vehicle's position.  This vehicle had been (electronically) erroneously placed back at the original staging area for a time until the triangulation process was able to correctly place it back at the front of the line.  The interpolation calculation used to smooth out the abrupt turns in the path of each vehicle had smoothed out the movement from the front of the vehicle line to the back.  Even though this distance was on the order of a kilometer, the large time gap in the originally instrumented position triangulation records made it seem that the vehicle was actually completing a realistic action.  It became apparent that even though an event that occurred in the virtual world was possible, and could be justified without extreme assumptions, it could be due to an aberration in the processes that are invisible to the data conversion procedure.After resolving these problems, this step ensured that multiple vehicles could, with some scrutiny and verification, be displayed in the virtual environment with sufficient congruence to actual events.  These vehicles, however, did not interact with each other, or with any other entities in the exercise.  The next step describes the process by which entity interaction was validated.3.3  Multi-Entity Exercise (With Interactions)Later in the same road march exercise, the row of tanks took up position near a line of trees, and commenced battle with four enemy tanks.  This interaction allowed a check of the validity of events other than changes in position of one or more entities.  These interaction events connected two previously independent entities, and consisted of rounds fired from one tank at another.  The originally instrumented data file contained details about each of these events, from high level information such as who took the shot, when they took it, and who they hit, down to the particular type of round that was fired.  The virtual world display of each interaction was a muzzle flash from the shooting tank and a burst of flame from the target tank.  It was then possible to check these outcomes as represented in the virtual world against the original datafile.Although this was the most complex exercise that had been converted into display in the virtual environment, no anomalies were found.  Perhaps because of the minute details that had originally been recorded, it was fairly easy to validate the timing, participants, and outcome of each individual event (or trigger pull, in this case).The position triangulation process was aided by the fact that there was little entity movement after the battle started, especially relative to the driving that had occurred previously in the exercise.  Finally, the general terrain in the location of the battle was fairly flat, also ensuring adequate radio reception for the position triangulation process.Up to this point, each exercise that was converted to display in the virtual environment had been done merely to prove that such a conversion process could take place with a satisfactory level of confidence.  The next step was similar to the previous one in the respect that it focused on a multi-entity exercise wherein there was an interaction between various entities.  However, it also generated data could be used to support some of the higher-level research goals.3.4  Real-Time Performance MeasuresAs previously mentioned, military trainers often use AARs as educational tools for those involved in training exercises.  If the trainers had information available in real time that could suggest ad hoc variations in a planned exercise, that exercise could be directed toward a more enlightening outcome.  However, to induce trainers to apply this type of logic, they would have to be supplied with tools that would allow them to perceive those critical points in an exercise where intervention would be useful.  One goal of this step was to show that generating visual displays of real-time information could be both possible and useful, and allow trainers to more easily recognize when to intercede in a pre-planned exercise.  Although the exercise that was studied was a testing rather than a training operation, it did provide a forum for experimenting with real-time performance displays.The exercise that was chosen was one that recorded a platoon of 4 tanks performing Tank Table XII [1].  This gunnery test [2], [3] consisted of the four tanks shooting at targets that appeared and disappeared over time.  Depending on the segment of the test, either the tanks or the targets or both could be moving.  The goal of the platoon was to hit as many targets as possible, while conforming to military doctrine for such an encounter (e.g. - each tank must maintain visual coverage of their assigned sector, no shot may be taken across or over another vehicle, etc.).After going through the exercise validation steps mentioned above, it was felt that only minor inspection was necessary to ensure the validity of the results of the real world exercise as shown in the virtual world.  The exercise was then converted and displayed in the virtual environment, and checked for congruity of vehicle movement and interactions (i.e. - shots on targets).The exercise began with four tanks aligned perpendicular to their direction of travel.  At the beginning of the test, targets appeared in front of the row of tanks, at distances from hundreds of meters to a couple of thousand meters.  The tanks began firing, and shortly after the targets appeared (within a minute), they disappeared.  The tanks then began moving, and after passing a particular point in their route, more targets appeared.  The platoon then fired on these targets while moving.  This set of targets then disappeared, and the tanks continued down the range.  After passing another point in their travel, a second set of targets appeared, and the moving platoon shot at these targets.  The tanks then traveled further down the range, came over a ridge, and stopped in a row, again, perpendicular to their direction of travel.  A final set of targets then appeared, which the tanks shot at while stationary.Since the goal of the exercise was to test the platoon's ability to acquire, shoot at, and destroy targets, one vital performance measure that could have been considered was the number of targets hit compared to the number of shots taken.  Another useful performance measure that could have been examined was the percent of frontal sectors covered, since the platoon is required, by military doctrine, to maintain visual coverage of the area into which it is traveling.  A third measure that could have been used was the number of shots taken across or over another member of the platoon.  Since the first of these measures, shot information, was recorded automatically and was strictly quantitative in nature, it was chosen as the measure to display.In the virtual environment, the tanks that performed our particular Tank Table XII exercise appeared as cartoon-like vehicles shaped like M1 tanks.  Each had a turret with an extending main gun barrel that rotated over the hull of the tank.  When a shot was taken, the muzzle of the main gun flashed, and when a hit occurred, the target burst into flames.  However, for the inexperienced observer, it was often difficult to correlate a shooter with the target at which they were shooting, especially when several shots were taken in a short time.  This event information was recorded in the exercise log file, but is difficult to display in a meaningful manner in the virtual world.  Fortunately, the information about exactly which shooter hit which target is not normally as important as the total number of hits, misses, and shots taken by each shooter.Therefore, the goal of the visualization procedure was to give outside observers some idea of the efficiency of each shooter.  Although experienced military trainers were the final target audience, this initial attempt was to prove that such a visualization task was feasible and useful.  An accounting was made of shots taken, shots hitting targets, and shots missing targets, by tracking the events in the recorded exercise log file.  This information was then displayed in a series of columns, similar to a column chart, which floated above each of the platoon member tanks.  To make this visualization process applicable to exercises in which any entity could be a target as well as a shooter, an additional column was added for the number of hits taken by each entity.  (In our exercise of Tank Table XII the targets were unarmed, hence none of the platoon member tanks could be hit.)  The exercise, when replayed with this added functionality, showed each tank starting, shooting, and driving with a set of four columns above it (the fourth column always had a height of zero, since no platoon tank was ever hit).  One column would increase in height by a unit whenever the recorded exercise file indicated that that tank had taken a shot.  If the shot hit one of the targets, a different column over that shooter increased in height by one unit.  Also, the appropriate column over the target that was hit would be increased by one unit.One unit in the height of each column was approximately one-third of the height of the tank itself.  This ensured that changes in the height of the column were noticeable, but the top of any column was not so high that it was not visible.  These four columns were displayed perpendicular to the viewer and in different colors, so it was always possible to quickly understand the shooting efficiency of each tank.  A plan-view of the exercise was also able to display the actual numerical values of each of the columns, but this was deemed to be unnecessary to add to the virtual environment display.3.5  Validating Actions Of Computer-Controlled EntitiesOne initial goal of the research program had therefore been met.  It was possible to track and display one measure of real-time performance of actors in a recorded military exercise, and do so in an understandable manner.  Due to the way that the display software was modified, it was possible to add this visual display of shooting performance to recorded human-controlled exercises, live play training exercises, or even SAFOR exercises.This last capacity, the potential to display the efficiency of computer-controlled entities that were supposed to emulate human actions, was a step in the direction of validating the actions of SAFOR entities.  It had previously been possible to replay the actions of a platoon of SAFOR tanks performing Tank Table XII.  However, it was now possible to quickly and visually determine if their results were in accordance with the results of human-controlled tanks who had performed Tank Table XII with the same target parameters (target location, appearance time, speed of moving targets, etc.) on the same gunnery range.One of the steps taken just prior to displaying this particular exercise in the virtual environment was to ascertain the exact location of all target positions used for Tank Table XII at one gunnery range in Germany [4].   These target locations were loaded into a permanent scenario file that could be brought up at any time and modified to conform to the target parameters of any particular live recorded exercise.  This "virtual test range" created the opportunity to compare SAFOR entities against any recorded Tank Table XII exercise ever performed on this particular gunnery range.  Previously, SAFOR programs, algorithms, and rule sets could be tested against what subject matter experts indicated they should be.  Now they could also quickly be visually compared in the virtual environment to the real actions of humans performing against identical criteria.A problem that arose during a close examination of this exercise reiterated one of the difficulties of matching an electronic terrain to its real counterpart.  This came about because it was noticed during the replay of the real-world human-controlled tanks completing Tank Table XII, that one set of targets was never hit.  This set of targets was quite close to the shooters, and appeared during a period in which the shooters were stationary.  It was thought that these targets would be noticed immediately and shot quickly.  However, it was only after viewing the terrain from the perspective of the row of tanks that the problem became obvious.  When the terrain was viewed from a few meters above the tanks (a normal outsiders perspective that gave a good view of the action), all targets during that segment of the test were in plain view.  However, after lowering the point of view to that of the tank commander (at the top of the tank turret), it was found that there was a slight ridge in the electronic terrain that prevented any of the tanks from seeing this particular set of four targets.It was then apparent that one of two things had happened.  Either there was an incongruity in the translation of the coordinates and elevation of the real terrain to the electronic terrain, or the position of the tank platoon had in fact been such that they could not see these particular targets.  Since there was no indication in the recorded exercise that the platoon had attempted to shoot at this set of targets, it was postulated that in the real world, those targets might be in view from locations close to the shooting point of the platoon, but not from their exact firing position.This piece of information could have been of great use to the instructors in charge of testing this particular platoon.  Since the platoon was being evaluated on their ability to acquire and hit targets, and they apparently could not see this set of very close targets, they were being judged (fairly or unfairly) on their ability to acquire and hit targets that were further away.  If the instructors of this exercise had been able to "drive" along with the perspective of the tank commanders, they would have seen that some targets were not even part of the exercise, due to the exact firing position of the platoon.3.6  Pre-Construction Testing In A Virtual EnvironmentThe third primary goal of the research program, that of demonstrating the utility of pre-construction testing of new weapon systems, was not investigated to the extent of the other goals described above.  It could be accomplished through accurate modeling of the characteristics of the particular weapon system, and the subsequent construction of a virtual entity with those characteristics.  This might occur through altering the maximum speed of a vehicle, the explosive power of an armament, or the viewing capability of a new sensor.In actuality, this type of activity occurs regularly and by accident in most virtual military exercises.  Since it is extremely difficult to model and display the physical characteristics of the natural environment in a virtual world, actors in most virtual environments often have visual powers beyond their real-world abilities.  For example, participants in military exercises that take place in parts of the world with frequent adverse weather conditions (e.g. - sandstorms in the deserts of the Middle East) until recently did not operate under constraints of limited visibility.  The computer processing power necessary to model and display the effects of natural weather phenomena like rain, smoke, clouds, and so forth, have limited the ability to present these occurrences to virtual world participants.  Therefore, when exercises are performed in virtual environments that cannot display weather conditions, participants’ visual capabilities are extended beyond their real-world limits.3.7  Displaying Unit Performance MeasuresThe ability to display a real-time performance measure in a relatively clear manner was established in the development of the column charts that showed the shot analysis of each participant.  However, this measure was of a relatively low level, similar to graphically displaying the speed of the vehicle in the virtual world.  Only a simple calculation was performed, and a simple display used, but the results of the process were substantial.  It was quite easy for even inexperienced viewers to determine the performance level of each participant, once the meaning of the columns was explained.  It was also easy to track the performance level of each participant throughout the exercise, as their percentage of hit targets rose or fell.It was then decided that a more complicated display of real-time performance measure should be attempted.  Some of the criteria desired for this action were that it should: 1) have direct specification within military doctrine, yet 2) also be very much under the control of the individual participant, and finally, 3) be attempted fairly regularly.  Corresponding to these criteria, it was hoped that it would be possible to: 1) set strict success:failure levels, 2) find instances where performance levels varied, and 3) find many occurrences of the event.The event that was chosen for investigation was the action of a tank platoon performing a cross-country march in a wedge formation.  This occurrence matched all of the criteria: the wedge formation is strictly defined by military doctrine, it is under the direct control of the platoon, and it occurs often.A wedge formation for a tank platoon requires the four tanks to take positions in which two tanks travel forward at the same speed, in a line perpendicular to the direction of travel.  The other two tanks in the platoon are in "wing" positions, one behind and to the left of the left front tank, and one behind and to the right of the right front tank.  The distances between tanks are set forth in military manuals, and depend upon visibility, terrain, presence of enemy units, etc.  Choice of speed is up to the platoon commander, and also typically depends on the factors that determine the inter-vehicle distances.To find examples of platoons attempting to maintain a wedge formation, sections of a large force-on-force exercise were examined.  As tank platoons were traveling to the location of a known battle, several formed wedges.  Since the ultimate destination was likely to be a major battle, it was expected that emotions might be high, and individuals might not be focusing on maintaining doctrinally correct formations.  Examination of the wedge formations indicated that there were indeed segments of the exercise where platoons appeared to be trying to maintain this formation for several minutes.  One of these segments became the focus of the real-time performance display of a wedge formation.The goal of this step of the research program was to create a real-time visual display of a platoon's ability to maintain a wedge formation and to illustrate that this type of display could be of use to a military trainer who would be observing the exercise.  The goal of creating a real-time visual display would demonstrate the ability to quickly and easily generate such displays, which might occur on an ad hoc basis in the future.  The goal of showing the utility of such a display to a military trainer was to show that the virtual environment could be modified to take some of the burden off of the trainer, thus releasing them to concentrate on higher level training issues.Since the wedge formation is described quite explicitly in military doctrine, the visual display in the virtual environment was patterned to match that description.  A "template" of the ideal wedge formation was created (for the terrain and visibility over which the selected platoon was traveling) and then displayed "floating" over the platoon.  The template consisted of a line connecting the two leading tanks, with two additional lines attached to each end of this leading line.  Each of these trailing lines was angled backward to indicate the ideal position of each of the wing vehicles.  One end of the leading line was anchored over the platoon leader's vehicle, as that is the vehicle on which the other platoon members determined their position.  The template also had to track the movement of the platoon leader's vehicle, which necessitated a real-time calculation of the velocity (speed and direction) of that vehicle.From this reasonably simple procedure, it was possible to quickly determine (from an aerial viewpoint) the direction of travel of the platoon, as the template was much easier to see than any of the individual platoon tanks.  It was also easy to determine the positions at which each of the other three members of the platoon were supposed to be.  The points at each end of the leading line of the template indicated the points at which the platoon leader and the other front line vehicle should be.  The end of each of the trailing lines of the template indicated the points at which each of the wing vehicles were supposed to be.However, the template only described the ideal position of each member of the tank platoon.  It did not indicate the relative performance level of the platoon in maintaining a correct wedge formation.  To incorporate the addition of this piece of information, the difference between each tank's actual and ideal position was calculated.  Then, the arm of the template at which each member was located was displayed in blue if that member was within a chosen variable distance of the correct point, and displayed in red if that member was outside of that same distance.  This provided a very recognizable display of the overall ability of the platoon to maintain formation.  When an arm of the template turned red, it was quite easy to understand that the platoon member at the end of that arm was out of position.  Also, by making the distance from the ideal point a variable, it was possible to change the performance criteria that were used to control the color of the template arm.  If a tight performance tolerance was required, a small distance was chosen from which each vehicle could stray prior to indicating that they were outside of the dictated successful performance level.  Looser tolerances could be selected by choosing a larger distance over which the vehicle could range before being indicated as failing to maintain the wedge formation.This display, therefore, satisfied the requirements of the goal of this step of the research program.  It provided a means by which relatively naive observers could understand the essence behind a particular performance measure, and could also quickly indicate whether that performance level was being met.  It also showed that it was possible to perform real-time calculations of performance, beyond the simple measures completed earlier in the research.  Finally, it indicated that relatively simple visual displays might be used to take some of the cognitive processing burden off of military trainers, and enable them to concentrate on the task of training higher level duties.Overall, the primary goals of the research program were met, with varying levels of success.  Conversion of real-world recorded exercises was completed with a high level of confidence in the veracity of the virtual world events.  Some confirmation was obtained for the congruence between computer-controlled entities and the human-controlled entities from which they were modeled.  Finally, various measures of real-time human performance were calculated and displayed so that even relatively inexperienced observers could quickly derive their meaning.4.  DiscussionThis section will describe lessons learned through the actions taken during this research project.  These lessons relate to the four topic areas of 1) data collection, 2) data transformation, 3) congruence between real and virtual environments, and 4) realistic measures of performance.The first of these areas deals with the data collection process.  Collecting data during instrumented military exercises can yield enormous amounts of data.  However, it became obvious that collecting more rather than less original data resulted in the ability to take additional project steps.  The first four validation steps (relating to the position of single and multiple entities) of the research project could have been completed with data that had been recorded only about entity position and attitude.  More interesting uses of virtual reality, such as were investigated in the last four validation steps (entity interactions and performance measurement), require more detailed data, and thus more complete instrumentation and data collection.  Also, replicating abstract elements like UAV seeker cones requires collecting more than position and attitude data.A second factor relating to the data collection process that impacted the research project was the variant forms of raw data.  Some data files were available in binary form that needed to be processed with special conversion software.  Some files were stored in ASCII format, although it seemed rarely in columnar form that was consistent from one file to another.  This meant that significant amounts of time were often spent in the data conversion process.  As in many other industries and applications, adherence to one particular standard would have significantly reduced our data conversion time.The major lesson in the area of data transformation was learned after the confusion concerning the previously mentioned anomalous, high-speed round trip transit of one vehicle from the front of the road march column to the rear.  Radio reception instrumentation problems on that particular vehicle combined with the smoothing algorithm to produce the incorrect motion that was displayed.  The instrumentation problem was found only after a painstaking examination of the original data file, and individual plotting of the positions of each tank.  From this episode, the research team learned to be suspicious of any abnormal virtual actions, and to immediately check the original datafile for validation.The third area in which useful lessons were learned concerned the differences between the real and virtual terrain.  This was revealed, in part, by the meandering of the tank column through a supposedly thickly overgrown forest.  The tanks were actually following a streambed that did not appear in the electronic version of that terrain.  This discrepancy was found accidentally when an officer who knew that portion of the real terrain pointed out the disparity.  The difference between the real and virtual worlds also impacted the research program in the attempt to validate the actions taken by human-controlled entities performing real-world tests in the virtual world.  In one example described above, a tank platoon executing a standard gunnery test may have been affected by a slight error in the elevation of a ridge in the middle of the virtual gunnery range.  Targets that were visible from the shooters' position in the real world were no longer visible from the same position in the virtual world, due to LOS (line-of-sight) differences caused by the error in virtual elevation.These two examples indicate that research problems may arise not only in low-level actions such as validating basic events, but also in higher-level actions like measuring performance.  Fortunately, increased knowledge and technology focused on acquiring real-world topology data will help alleviate the particular problems we encountered.  However, many virtual worlds with such discrepancies have already been created and are still in use.The last area of lessons learned related to the level of performance measures and their associated impact on overall exercise outcomes.  Experienced military personnel were conferred about the goal of determining, calculating, and displaying performance in a DVRE used for military training.  A common comment was that the focus on measuring conformance to a wedge formation was much too low of a performance level.  It was stated several times that the outcome of a battle rarely hinges on the ability of one or even many platoons to maintain a doctrinally correct formation.  Military officers said the outcome of a battle is tied much more closely to the decisions made by the participants, and the subsequent actions taken on the basis of those decisions.  These comments suggested that even the "higher-level" performance measures that we were able to derive are not high enough.  However, at our early stage in this research area, we were satisfied with showing that it is possible to derive, measure, and display real-time performance measures associated with interacting multiple-entity exercises.5.  ConclusionThe research program described herein attempted to accomplish three main goals.  One of these was to support military trainers with avenues for pursuing tools to aid in their assessment of performance by soldiers in virtual training situations.  A second major goal of the research project was to investigate methods by which the actions taken by computer-controlled entities in a DVRE could be validated against how human-controlled entities would have acted in the same situation in the real world.  The third primary goal of the program was to create the foundation for testing of virtual weapon systems, perhaps even before those weapons exist in the real world.  The first two goals were supported but not completely achieved.  The groundwork for the last goal was laid, through the knowledge gained about validating real-world events in a DVRE.This general area of research can be fruitful along many dimensions.  While performing experiments in a military DVRE, much was learned about topics as variant as terrain congruence, display techniques, performance measurement, and training tools.  Each of these research areas has its own specialists, but it is particularly interesting when such diverse areas can be studied together in one research program.The lessons learned through undertaking this research have given guidance about both future research directions and problems likely to be encountered.  After working with raw data, it became obvious that collecting large amounts of standardized data would accelerate the upfront task of converting data to a format necessary to display in the DVRE.  Future research in this area might focus on data structures and formats to standardize the data collection/transformation process.Work is also currently underway (and some products available) for displaying finer physical details, such as underbrush, within a DVRE.  Appropriate application of these tools and techniques, combined with more precise techniques for replicating physical environments in a virtual world, could take off some of the burden of event validation in a DVRE.  This will also help researchers by painting a more realistic picture of the original physical environment.Researchers [5], [6], and [7], in other fields, are also learning more about appropriate methods of displaying information.  Such knowledge will certainly help those who are interested in using a DVRE for individual or group training, while attempting to display resulting performance values.  Research into useful procedures for visual displays of abstract entities, such as the UAV seeker cone, will also be of increasing value.  This is evidenced by the growing use of virtual worlds (e.g. – the WWW) for gaming, training, and information supply.  Respectively, these three application areas might be required to display abstract entities such as the path of a bullet, the percent of questions answered correctly, and the relationship between two documents.Finally, future research related to performance measurement might focus on tasks such as an analysis of the voice channel (typically recorded in larger military exercises) for particular words or phrases that indicate turning points in the exercise.  In fact, it was proposed in this research program to simply determine the times in the voice channel in which the amplitude of the signal increased drastically, as those stress points often coincide with major exercise events.  With the advanced voice recognition programs available today, the problem is greatly reduced, and might be feasible attacked.  However, determining the correlation between utterances and associated ensuing actions could be formidable.6.  References[1]	Headquarters, Department of the Army: “Tank Combat Tables”, FM17-12-1, November 1986.[2]	Weapons Department, Fort Knox, KY: “M1A2 Tank Gunnery (Draft)”, ST 17-12-1A2, November 1992.[3]	Headquarters, Department of the Army: “Mission Training Plan for the Tank Platoon”, ARTEP 17-237-10-MTP, September 25, 1996. [4]	“http://www.cmtc.7atc.army.mil/tng/training.htm/” or “http://www.grafenwoehr.army.mil/”[5]	I. Vessey: “Cognitive Fit: A Theory-Based Analysis of the Graphs versus Tables Literature” Decision Sciences, Vol. 22, pp. 219-240, Spring 1991.[6]	C.D. Wickens, and A.D. Andre: “Proximity Compatibility and Information Display: Effects of Color, Space, and Objectness on Information Integration” Human Factors, Vol. 32, pp. 61-77, 1990.[7]	C.D. Wickens, and C.M. Carswell: "The Proximity Compatibility Principle:  Its Psychological Foundation and Relevance to Display Design" Human Factors, Vol. 37, Number 3, pp. 473-494, 1995.7.  AcknowledgmentsThis research program was fully supported by the Institute for Defense Analyses, Alexandria, Virginia.Author BiographyPAUL BECKMAN is an Assistant Professor in the Business Analysis and Computing Systems Department at San Francisco State University and also an Adjunct Research Staff Member at the Institute for Defense Analyses, Alexandria, Virginia.  His research interests focus on training, human performance measurement, and human-system interaction, particularly in virtual environment.