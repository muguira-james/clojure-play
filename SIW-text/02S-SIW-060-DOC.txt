Data Collection on M&S SystemsEmployed in Support of C4I TrainingJohn W. DiemDirectorDigital Training FacilityU. S. Army III Corps Headquarters Fort Hood, TX 76544(254) 287-1910HYPERLINK "mailto:John.Diem@hood.army.mil"John.Diem@hood.army.milNorman L. (Lane) AllredIITRI/Strategic OperationsDigital Training FacilityU. S. Army III Corps Headquarters Fort Hood, TX 76544(254) 532-8321 x2295HYPERLINK "mailto:lane.allred@hood-ctsfmail.army.mil"lane.allred@hood-ctsfmail.army.mil  ABSTRACT:  This paper keys on one of the major findings of the Army DUSA (OR) sponsored study, ”Standard C4I Components for M&S/C4I Interoperability Support.” The study final report states:Detailed lessons learned are not being captured during M&S - ABCS integration events that can benefit other developers and integrators.  Data capture tools are in place to support C4I after action review, both during and post-event.  M&S tools, single or federated, need capture tools and institutionalized methods of collecting and recording information for continuity in service during a supported event and after.  The collected information set would serve well from shift to shift as well as give structure and substance for building and maintaining a professional M&S cadre and provide a feedback loop to M&S systems developers and resource managers.The paper expands on the need for M&S systems data collection and feedback at various levels to optimize M&S performance in support of the C4I customers. Some major simulation systems are developed through traditional defense programming processes, with the benefit of milestone reviews and a forced analysis of the development of the respective programs.  However, most of the M&S systems and federations supporting tactical U. S. Army C4I have been developed expediently to meet near-term demands. The need for rigorous collection and sharing based on M&S performance continues to increase with the complexities of digitally equipped forces.Those tasked with establishing an enduring training capability at the U. S. Army III Corps at Fort Hood Texas are mindful of the need to establish an effective process of examining the tools employed to train the digitally equipped forces.  The M&S systems used in support of the force training must be sustainable and effective on a continuing basis, not just for one major event.  The planners want trusted M&S analysis capabilities for confidence in developing training programs for the Army Battle Command Systems (ABCS) currently fielded and for the adaptations necessary as the ABCS systems mature. Development of an M&S data collection and sharing process would assist all of the U. S. Army M&S domains.1.  IntroductionOne of the major findings of a recently completed study entitled “Standard C4I Components for M&S/C4I Interoperability Support”[1] was:Detailed lessons learned are not being captured during M&S - ABCS integration events that can benefit other developers and integrators.  Data capture tools are in place to support C4I after action review, both during and post-event.  M&S tools, single or federated, need capture tools and institutionalized methods of collecting and recording information for continuity in service during a supported event and after.  The collected information set would serve well from shift to shift as well as give structure and substance for building and maintaining a professional M&S cadre and provide a feedback loop to M&S systems developers and resource managers.This paper expands on the need for M&S systems data collection and feedback at various levels to optimize M&S performance and support of the M&S customers.  The paper also focuses more specifically on needs for immediate and on-going collection of M&S support data during the fielding of new equipment; during the integration process of new equipment; during procedures with existing equipment; and during training by the unit; and the conduct of military operations.2.  BackgroundThe observations reviewed in the above cited study and follow-on observations of the continuing M&S support to C4I detailed that M&S performance data was not gathered in any rigorous manner for use within the M&S community.  General observations of M&S systems performance were gathered and often passed informally.  Planning and programmatic decisions had to be made on best data available, but because of the lack of substantive data, those decisions were probably brokered by force of persuasion, or lack thereof, instead of rigorous data.Some major simulation developments, such as Warfighter Simulation (WARSIM) and One Semi Automated Force (OneSAF), are developed through traditional programming processes, with the benefit of milestone reviews and a forced analysis of the development of the respective programs.  However, most of the M&S systems supporting tactical U. S. Army C4I were developed expediently to meet near-term demands.  Most of these systems have risen, either independently or collectively with others, to the need at hand.  The requirements for these systems didn’t include formal internal data collection or data collective sharing.  The high intensity and rapid iterations of the C4I spiral development and integration begs a process of examination of the M&S systems dedicated to support that C4I.Simulation, Test, Operations, and Rehearsal Model (STORM) is an example of one of those expedient developments.  STORM is a federate of simulation systems organized and orchestrated to provide a valid environment for Army Test and Evaluation Command (ATEC) to evaluate the Force XXI Battle Command Brigade and Below (FBCB2) system that extended ABCS information and capabilities to individual fighting vehicles.  STORM had to be developed in limited time to be ready for the scheduled FBCB2 Initial Operational Test and Evaluation (IOT&E) and be subsequently available for following tests.  STORM continues as a viable testing support federate of several simulation systems and is also used to support training activities.  STORM has been called upon to move quickly from event to event and reconfigure as needed to serve each customer.  There was a lot of learning in the active support to testing and training of C4I operations, but there was no mechanism for capturing on the fly and no time to reflect and document the successes, frustrations and issues of the experience.The Fall 2001 Simulation Integration Workshop (SIW) sponsored by the Simulations Integration Standards Organization (SISO) C4I Forum out-brief highlighted; “We need standard methods and tools for capturing lessons learned when applying M&S tools.”  The need for establishing a C4I M&S information collection and sharing capability is now flagged to the broader related defense and industry community.3.  U. S. Army III Corps ConditionsU. S. Army III Corps, located at Fort Hood, Texas, will be the first fighting force of its size to be fully equipped with a total suite of interoperable, automated C4I systems [2].  As such, III Corps and subordinate units need the ability to assess the adequacy of the M&S tools employed to drive the C4I systems during training, exercises and in some cases, during deployment of units to fulfill operational tasking.All Army M&S domains--testing, training, and experimenting--are involved in the Fort Hood environment as C4I systems are fielded and integrated in the ABCS structure.  The M&S attendant to the developing force provides essential support through all the phases of product development and fielding and on through the training of the forces that will use the new capabilities.  The need for confidence in the associated M&S tools becomes critical as units are equipped with modern ABCS systems and the unit soldiers and staffs are trained.The supporting M&S tools must be continually maintained to keep current with the ABCS software versions in use.  Such maintenance requires continual feedback.  The work done in direct support of the III Corps units affects the broader Army by feeling the way forward as the Army ABCS test bed.4.  StakeholdersPotential stakeholders within the U. S. Army if a comprehensive M&S data collection and feedback system were developed are:U. S. Army Modeling and Simulation Office (AMSO)Simulation Training and Instrumentation Command (STRICOM)Program Executive Office for Command, Control, Communications (Tactical) (PEO C3T)       --Central Technical Support Facility (CTSF)Simulations C4I (SIMCI) Overarching Integrated Process Team (OIPT) (SIMCI OIPT is STRICOM and PEO C3T sponsored)National Simulation Center (NSC)Training and Doctrine Command Analysis Center (TRAC) LeavenworthU. S. Army Test and Evaluation Command (ATEC) and subordinates--Army Evaluation Center (AEC)--Development Test Command (DTC)--Operational Test Command (OTC)Forces Command and Other Major Combatant Commands--Battle Command Training Facilities--Battle Simulation Centers--Ranges--Soldiers, Leaders, StaffsThe several Army Battle Labs5.  Current SituationNo comprehensive, common structure or process exists to gather lessons learned within the M&S support to C4I environment.  Virtually all organizations, government or civilian, fielding and operating M&S tools in support of C4I have deficiency reporting and tracking processes.  Those processes may serve the parent organizations well in traditional systems development and operation, but some issues become immediate in working with the PEO C3T spiral development system.  Expedient actions or reactions by on-site technical and operational staff may fall outside established organizational reporting processes.  System issues may become even more urgent on site during a major event.  The teams handling the issues are gaining sound experience, but the lack of a capture mechanism precludes others from also gaining from the experience.Simulation systems preparation is very event focused.  Those called to organize support for events have responded well to the challenge.  Still, of immediate necessity, the focus is on events and adjustments and groupings of tools for events, not on sustained capability.  Questions about enduring capabilities when simulation tools are not event focused will have to be asked and answered as some uses of simulation tools become entwined with the C4I systems they have heretofore been employed to support.III Corps is building a Battle Command Training Facility (BCTF) that will conduct training for individual soldiers and staffs from the hand-off from the program developers on through the life of the fielded systems to assist commanders in keeping the forces properly trained.  Much of the teaching will be scenario driven and simulation of all forces, friendly and enemy, must be represented through M&S tools.  Validation of M&S support will require some level of review of the M&S tools involved, both in initial certification and on a continuing basis, to insure quality of support.Within III Corps, data must immediately be gleaned from all available environments to set and maintain rigor in the training process.  The III Corps digitized Battle Combat Command Training Center is being established to help commanders train soldiers at all five established levels of battlestaff training.  Each of these levels requires different application of M&S support; the common ABCS tools are applied differently.The training levels are:Level I—Individual Training.Level II—Section/Cell Staff Team TrainingLevel III—Staff Drills TrainingLevel IV—Functional Command Post TrainingLevel V—Full Command Post trainingThe lowest training levels are task based where canned scenarios or vignettes can be used to establish the training situational environment.  The task focus progresses though a crawl-walk-run continuum with increasing overhead requirements to level V, where training is best done with dynamic interactive free play.  The same staff tools that soldiers were trained on more basically in the lower levels can then be applied more abstractly to support mission rehearsal, course of action analysis and support to ongoing military operations by the larger more senior staffs during level V.The Army C4I development is now managed as a system of systems through the integration work at the CTSF.  The supporting simulation tools have yet to achieve parallel rigor.  The ABCS is projected to grow to include integral simulation to support embedded training and course of action analysis.  Pertinent question are:  How will we know when the simulation tools are sufficiently integrated?  What is the basis of confidence in the simulation components?  If no general M&S information collection and sharing program is fielded, limited focused programs will have to be initiated to gather information about the above questions.The maturing of the digitized training process at III Corps mandates a focus on a feedback system.  New systems fielding, integration with the broader family of systems, training and conduct of operational missions are the environments where feedback can be gathered.  A commander who was involved with major testing, training and integration events said, “…we were too busy to stop and codify what we did—we simply moved on to the next major event.  Someone at the institutional level must capture lessons learned and disseminate them across the force.”[3]  “…a common and accurate phrase to describe our situation is, we don’t know what we don’t know.  More poignantly, however, we don’t know what we do know.  We must get better at capturing and disseminating lessons learned. “[4]6.  Simulation System Life Cycle A program to gather information on performance and process of M&S systems in support of C4I operations might lend to the understanding of the life cycle of how the tools evolve.  The data might allow isolated examination of the separate tools, each as a basic component and as member of a federation.  Such a program might lead to better understanding of the impact of the simulations tools, separately and collectively, on ABCS.7.  Potential UsersAn early look at potential principal users of data collected on employment of M&S tools suggests that the data users fall into at least the following categories:Technical and operational staff members for each M&S system employed.  A rigorous information collection and feedback system should be helpful to sustain on-going support to C4I operations.  Potential benefits could be successful operating team hand-off from shift to shift and refinement of on-going support correction and adjustment as interaction with the supported system may dictate.  Additionally, the data would be available post-event for program review and action as appropriate.Unit Commanders and staffs.  Commanders need confidence in the M&S tools and the portrayed environment and surround sound where he trains his fighting teams.  Commanders in effect do home schooling of their subordinate forces and need the assurance of the quality of the supporting M&S.  That assurance comes through repetitive training where those M&S tools are employed.Other related M&S systems within federations or other M&S systems supporting C4I that use common C4I sponsored products.  The strong drive within DoD and related organizations is to reuse where possible common software components and the necessary related segments to foster commonality and economy.  Sharing of current data in a rapidly evolving environment could surely help the Army and DoD achieve the best possible support to the C4I customer by eliminating unnecessary excursions and duplications of effort.M&S systems managers.  A predictable, rigorous data or information collection and display system should help managers assess success and know where emphasis or correction is needed.Planners and programmers.  Functional and resource planners and programmers could make more sound decisions on the types of new capabilities needed and the appropriate allocation of available resources among the several systems currently fielded and in development.  Additionally, they might use the information gathered to decide when systems should be terminated.C4I program managers.  As systems are developed and fielded with embedded M&S, the appropriate program managers need assurance on performance capabilities of those M&S systems.  Embedded M&S for training, course of action analysis and mission rehearsal needs initial validation and continued performance review.  PEO C3T, TRADOC Program Integration Offices (TPIOs) and TRADOC System Managers (TSMs) are all candidate customers.  The PEO C3T staff including the CTSF team at Fort Hood plus the affected divisions could be heavy users as the force modernization goes beyond the first digitized division and on to the Digitized Divisions 2 through N program.8.  Program Management and OversightA developed M&S system information collection and distribution program might be employed in several of the stakeholders’ spheres of interest, but one organization and manager should be designated to develop and direct an initial program.  The intense C4I development and fielding at Fort Hood, Texas provides probably the most fertile ground for developing an initial M&S information collection and distribution system.  The frequent development, certification, training and fielding activities would allow for iterations and refinement of the process with least time and travel requirements.9.  Objectives and CriteriaAn efficient collection program needs to be driven by a focus on objectives.  Collection program objectives would need to be specified in the formative stages of a program to lend clear understanding to collection participants and bound expectations of users.  The measures of effectiveness and the measures of performance construct used in the testing community are a method that could be used in setting initial collection objectives.Significant stakeholder involvement should be expected in setting program criteria.  The users of a collection and sharing program should be many.  One should expect challenges in determining the tools to be used and in determining what would be collected and the rules set for doing so.  Appropriate forums should be set to insure a program is properly focused.10.  Collection PlanningAn umbrella collection plan for general guidance may be appropriate to insure all stakeholders have an opportunity to influence the structure of a collection program.  A plan would also appropriately allow for refinement of process for the close-in work of gathering information on M&S systems in dynamic settings.Key considerations are: 	Where can the data be collected?	How affordable is the collection?	How long does it take to prepare?	What is the overhead to operate a collection program?  	How intrusive is the collection on the supported forces?	For expedient information sharing, data formats must foster a rapid data flow.  The data should be immediately useful without compilation, though compilation might extend the use of the data to a new dimension.11.  Collection FocusSuccessful collection of M&S related employment data would provide a ready window on what may be currently working, workarounds, failures and frustrations.  A climate of learning and progress should allow in the trench actions and results to contribute to the body whole understanding and avoid any thrust to fix blame for inevitable errors in leading edge work.  Many government organizations and supporting government contractors have parochial interests in their parts of the developing M&S capability.  The collaborative work and open cooperation observed during the period of the above cited study showed that several M&S programs could work cooperatively and share.  Any collection program established should work to foster that same climate.A collection program should be focused on what kind of information is to be collected and how well the observed systems were able to perform.  User feedback should also be included; the customer should have input.  Collectively, the data should allow assessment of how much is enough to meet the needs of the customer from any of the domains.An effective program should try to determine:	Did the M&S system work with the C4I system it supports?  Was it reliable?  An M&S suite of tools may gain a given level of confidence in a five hour training session but not sustain that same confidence level during a five day command post exercise.		Did it meet its intended objectives?	Did it replicate the training environment the commander wanted?	Could the commander and the supporting infrastructure afford to use the M&S system?	Was it available?  Was it ready on time when the unit needed it?	Was it maintainable?12.  Collection MethodsDuring the study cited, seasoned professionals that were otherwise involved in the target events willingly collected data on a time-available basis.  Some of them provided general observations after the event in addition to data collected during events.  Data was accepted in almost any form.  The compilation of the information from wherever it could be gathered was time consuming and quick feedback from the data set wasn’t possible. The information gathered was appropriate for the study, but a more rigorous process should be established for a sustaining collection and sharing program.An Internet site would be appropriately used for a data repository with ready access for users.Considerations for establishing a collection and information sharing process should include:Manpower requirements.  Does information need to be collected by direct observation?  Can M&S technical and operational staff members collect desired information by using logs, structured forms and periodic questionnaires?  What cadre would be needed to develop and maintain an appropriately scoped program?Data Collection and Management.  What should be collected?  How should the data be compiled and how soon should it be compiled?  How should the data be stored?  How should the data be managed?  How should the data be disseminated?Collection Effects on C4I Operations.  Data collection on M&S support to C4I operations must be done on a noninterference basis. The collection should neither interfere with the C4I operations supported nor with the M&S support operations. 13.  Proposed ActionThe Army must initiate an M&S data collection and sharing program.  An initial program can help identify the challenges of conducting a program and help assess the need for and the potential return for proceeding with a full-scale program.  The training team at Fort Hood is working through the problem set because they have to do so now.  M&S systems used to train soldiers on their most modern digital tools must be continually validated to insure positive training.  The larger Army may distill out of the developments at Fort Hood and other places in assessing a need for a larger M&S data collection and sharing program.14.  References[1]	Diem, J.W. and Allred, N.L., Dickson, D. B., “Modeling and Simulation Employment of Common C4I Interfaces— Toward an Integrated Future,” Paper 01F-SIW-046.[2]	Department of the Army, Headquarters III Corps and Fort Hood Regulation 350-1, Chapter 12.[3]	Lynch, Rick, Colonel (P) USA, Institute For Defense Analysis Paper P-3616, “Lessons Learned:  Commanding a Digital Brigade Combat Team”, p. 16.[4]	Lynch p. 1.14.  BiographiesJohn W. Diem is Chief, Digital Training Division/ Director Digital Training Facility, U. S. Army III Corps Headquarters, Fort Hood, Texas.  Previously, he was Chief of the National Simulation Center Digital Integration Office, Fort Hood, Texas and was also the AMSO C4I Integration Standards Coordinator where he supported Army-wide simulation-C4I integration for test, training, and experimentation.  During his past 20 years as an Army Officer, defense contractor, and government civilian, he has been involved in the testing and training of automated command and control systems.  To perform these test and training activities, he has employed, developed, or managed a broad variety of simulation-C4I integration efforts to provide test and training environments, data collection and after action reporting, and scenario database development.  He earned a BA and MS from Texas A&M University and served 14 years in the U.S. Army on active and reserve duty as a Military Intelligence Officer in command and staff tactical and signals intelligence positions.Norman L. (Lane) Allred is a Senior Military Analyst with Illinois Institute of Technology Research Institute (IITRI) Strategic Operations Group.  He is an analyst for the Digital Training Facility, U. S. Army III Corps Headquarters, Fort Hood, Texas.  He has worked the last five years in U.S. Army simulation support for testing and training and recently completed a U. S. Army Study titled “Standard C4I Components for M&S/C4I Interoperability Support.”  He served 27 years in the U.S. Air Force in intelligence and space related activities.  He earned a BS in communications from Brigham Young University, a MBA from the University of Montana and a Masters Of Military Arts and Science from the U.S. Army Command and General Staff College.