Progressive, Multi-Resolution Course of Action Analysis David R. Pratt, PhDEllen TowersScience Applications International Corporation (SAIC)12901 Science DriveOrlando, FL 32817(407) 243-3308prattda@saic.comDale R. Shires, Kelly Kirk, Army Research Laboratory (ARL)High Performance Computing DivisionATTN: AMSRD-ARL-CI-HCAberdeen Proving Ground, MD  21005(410) 278-5006Dale.Shires@us.army.milKeywords:Decomposition Planning, Plan EvaluationABSTRACT: We are in the process of developing a Joint, progressive, multi-resolution course of action analysis (COAA) capability. This capability augments commercial off the shelf (COTS) simulation tools by using a well-defined course of action (COA) data interface in keeping with the Department of Defense (DoD) vision for COTS simulation tools. In addition, it makes use of common synthetic natural environment (SNE) representations and reasoning algorithms through a well-defined data interface, consistent with the DoD vision for a common SNE. The progressive COAA tool allows planners to quickly identify candidate high-level plans, and then focus time and computational power on detailed exploration of the viable alternatives. The progressive COAA tool is broadly applicable for training, rehearsal, and real world operations. The approach provides a mechanism for standards-based data exchange between the COAA tool and COTS simulation.  By exploiting multi-resolution modeling (MRM) capabilities of the COTS simulation, we provide a deeper understanding of the data interface needs for COAA and other components that need to link to the COTS simulation. In addition, the project will contribute further understanding to the needs of common SNE for MRM-based COAA. This effort expands on our internal research and development (IRAD) project on variable model fidelity for progressive course of action analysis of the Joint battlespace.  We leverage our experience with a data-centric simulation architecture, MRM, and common synthetic environments, and our ongoing efforts supporting DoD and adapting our COAA system to the Joint context.IntroductionAs part of a series of ongoing collaborative research efforts conducted by SAIC and ARL into next generation simulation and high performance computing (HPC) applications, we are engaged in a process of applying simulation tools to the course of action analysis (COAA) process.  This effort centers on making the process more efficient by presenting the planner with the evaluated results and recommendations from a series of auto-generated plans.  In order to accomplish this within the time allotted, we use a series of plan decomposition techniques to disaggregate the units into a series of lower level units and eventually to the platform level.  While the system described in this paper uses several simplifications to make the problem tractable, we believe that it provides the basis for operational systems.  While implementation of the system is a key element of the paper, we will discuss it at the architectural level in order to maintain the big picture focus. MotivationThe paper is largely motivated by the need to address the time and effort it takes to set up a simulation exercise which often becomes the driving cost.  Thus, it is one of our objectives to produce a realistic set of executable plans given an operational scenario.  While the plans might not be perfect, they should be good enough to provide the context for the adjacent and opposing forces. The longer term motivation is to develop a COAA tool that will allow the planner to enter (or better yet have the data drawn directly from the operations command, control, communications, computer, and intelligence (C4I) system) the current operational state (to include the enemy position), the operational goal, and from these initial conditions, develop a set of ranked operational plans that can form the basis of the next set of orders.  Through the use of simulation and high performance computing (HPC) resources, the ability to perform rapid iterations on the plans and explore non-traditional plans is greatly enhanced.  Thus, both the timeliness and confidence in the orders will increase. Previous WorkThe concept of automating COAA is not unique; one of the more recent examples is that of Project Albert REF _Ref124745472 \r \h [1].  This system primarily focused on the use of agent technology to evolve and understand complex behaviors and responses.  As a tangent-based system, it was largely done at the entity level and proved it was possible to use a few simple behaviors run over multiple iterations to produce realistic looking scenarios.In  REF _Ref124861607 \r \h [2], Tolk discusses the need for and ability of decision support systems (DSS) to support military planners.  It is most interesting that Tolk does not take the traditional computer scientist view of the problem.  Rather, he looks at it from the needs of the user.  In  REF _Ref124861623 \r \h [3] he describes how agent-based systems can support the interoperability requirements needed by such systems. In both cases, the discussion centers on the needs and the function of the DSS system to support COAA. In his seminal paper, “The Base of Sand Problem,” Davis discusses the use of simulation and some of the inherit limitations  REF _Ref124861645 \r \h [4].  Sadly, while the paper is almost 15 years old, it is still as relevant to current COAA simulations as when it was written. As the paper points out, the human element in the evaluation and execution of the models is key.   For this reason, we believe that this type of system only provides recommendations and cannot be considered “the final answer” for planning process automation.Likewise, this project is not the first to suggest the use of multiple resolution models (MRMs).  In his tutorial, Davis presents some of the history and implications of MRMs  REF _Ref124861664 \r \h [5]. It is interesting to note the reference to linking different models together.  Since many of the models were developed in isolation from each other, there are key implementation differences that yield differing results at each level. Thus, while the models may feed each other, the differing algorithms used in the models and the creation / deletion of information calls the validity linkage into question.  For this reason, we chose to extend the U.S. Army’s OneSAF Objective System (OOS) and create aggregate models within the same framework as the entity instance.The elements of the proposed systems have their basis in well-referenced literature. However, as stated earlier, we did not find any references to the same model being used at different levels of aggregation or that the plans were linked at different levels to develop the recommended COAA. Hypothesis REF _Ref124926908 \h Figure 1 shows the approach we are taking for the project. The basic hypothesis is that through progressive refinement of high-level auto-generated plans, a realistic plan can be developed. At each of the levels, three plans will be developed. This will vary routes taken by the entities based upon the route-planning algorithm used (see section  REF _Ref124928980 \w \h 6.2 for more detail).    EMBED Word.Picture.8  Figure  SEQ Figure \* ARABIC 1. Decomposition ApproachAt each level, we will run multiple excursions using different random number seeds for each of the plans. Combined with the natural non-determinism in OOS, this approach will provide the datasets we will use for the data reduction, evaluation, and selection phase. At this point, the “best” plan is brought forward and decomposed.In essence, we are implementing a directed search though the scenario solution space. The use of the evaluation function provides a pruning mechanism allowing us to evaluate nine cases (three at each level) rather than the full tree of 39 cases (three, nine, and 27 at each level). By limiting the cases to three at each decision point, we have artificially constrained the number.  In an operational system, there would be considerably more choices producing a combinatorial explosion of possible cases requiring pruning of the case tree to reduce the problem to a tractable solution space.System DescriptionA common approach to analyzing candidate COAs is to execute them in a training and analysis simulation system such as Joint SAF (JSAF) or the OneSAF Testbed Baseline (OTB). This technique, however, results in a high computational cost of running multiple scenarios within these high-fidelity systems.  One way to mitigate this cost is to employ variable levels of fidelity.  As  REF _Ref31789906 \h  \* MERGEFORMAT Figure 2 indicates, this technique tailors the COAA to use low-fidelity models quickly in the beginning to trim the search tree. This series of runs executes faster than real time without a human in the loop (HITL).  As the search tree is reduced, higher levels of fidelity are employed to obtain more accurate results.  The final step in the process is to run real-time HITL executions to support final COAA.  Prior to this MRM approach, different, and not always interoperable, tools are used as computer-based aids in the COAA process.  Our approach generates a single system that is capable of altering its fidelity to apply appropriate resources to the COAA problem in a timely manner.Figure  SEQ Figure \* ARABIC 2 . Variable Fidelity over Multiple PhasesNowhere in our literature search did we find an approach that uses successive fidelity increments to partition the solution using a single tool.  The use of multiple resolutions and fidelities in a composable simulation system such as the OneSAF Objective System (OOS) provides an important discriminator for this effort.  The OOS architecture and models are designed to support the composition of fidelity and resolutions ranging from simplistic, low-fidelity models to more complex, high-fidelity models of individual soldiers, vehicles, and building interiors.  Composition of these capabilities is obtained either through application building or through parametric composition.  In application building, separate executable versions of the tool incorporating different levels of functionality are included in a single application.  In parametric composition, variable levels of fidelity are included in the models and activated by setting key parameters in the system at exercise run time.  We take the viewpoint that the simulation system is independent of the COA tool, so we do not mandate a particular simulation system (such as OOS) but rather we define data interfaces between the COA tool and the simulation tool.  This means that the COA tool could be implemented with any COTS simulation tool selected by the user, provided that the simulation tool supports the composition ideas outlined above. EMBED PowerPoint.Slide.8  Figure  SEQ Figure \* ARABIC 3.  COAA Framework Conceptual View REF _Ref63243962 \h Figure 3 illustrates the course of action analysis framework as it stands today.  We believe this fundamental architecture is sound for the Joint context; the main extension needed is the selection of a Joint simulation model for the Evaluator piece.  However, components of the architecture will be extended to support Joint operations.  We are in the process of adapting the Planner and Evaluator to satisfy Joint course of action requirements and develop support for synthetic environment analysis tools provided by a common synthetic environment representation. REF _Ref63235682 \h  \* MERGEFORMAT Figure 4 presents a conceptual view of a complete system, which formed the road map for the IRAD prototype.   As indicated, there are several components to the system. A client interface allows the user to set parameters such as the scenario to be used, the number of plans to be created, and the duration of the planning session.  The Planner and Evaluator (implemented in the IRAD prototype using OTB but will be extended in this project to encompass Joint operations) provide complementary functionality.  Planning begins when the Planner creates an initial set of COAs, which it passes to the Evaluator.  The Evaluator then assigns a fitness, or “goodness,” rating to each COA and returns it to the Planner.  The Planner decomposes a few of the most promising COAs into lower echelons (higher fidelities).  This set of COAs is passed back to the Evaluator and the cycle continues until some predefined termination condition is met.  By working together in this way, the Planner and Evaluator allow creation and incremental improvement of candidate COAs: an evolutionary process intended to yield high-quality plans at a reasonable computational expense. EMBED Word.Picture.8  Figure  SEQ Figure \* ARABIC 4.  COAA System Conceptual ViewPlans are made and evaluated starting at the highest echelon and entities are aggregated at each echelon level to reduce computation.  For example, at the Brigade level, entities are aggregated as Battalions, and each Battalion treated as indivisible.  Each aggregate entity has attributes such as strength or attrition.  Plans are then formulated using a small number of these Battalion entities, with rules governing things like logistics and avenues of approach that pertain to a force of Battalion size.  As described above, aggregating the planning at this low level of fidelity allows a larger space of possible plans to be evaluated in the Planner.  The search space is pruned to include only the best of the resulting plans, and the planning moves on to the next lower echelon. Components of the COAA ArchitectureMajor requirements of the COAA architecture include the ability to:Identify a situational awareness package definition that can be sent to the PlannerDefine a simple mechanism for the Planner to generate COAsIdentify a format for the COAs to be sent from the Planner to the EvaluatorDevelop a way to integrate the Planner and Executor, including a communications protocol and implementation and testing of a communications mechanismImplement a methodology for rating plans based on execution outcomeFunctional ScenarioFrom its inception, this effort was targeted as a proof-of-principle rather than an operational system.  As such, we were able to bound the problem space to that of an armored battalion with a section of supporting A-10s advancing to an objective point with the possibility of encountering an enemy force along the way.  Figure 5 shows the notional lay down of the scenario.  EMBED Word.Picture.8  Figure  SEQ Figure \* ARABIC 5. Notional ScenarioFrom some of our preliminary runs, the overall scenario using the direct path planning algorithm requires approximately 30 minutes of simulation time and the red and blue forces do engage each other. There is some variation due to the simulation-induced variability.  Unit Levels and ModelsThe forces in  REF _Ref124926329 \h Table 1 are part of the scenario described above.  The rows indicate the various levels of decompositions we will be using for this project.  The first row represents the traditional model where all forces are aggregate.  Similarly, the third row represents the typical entity model in that all the platforms are explicitly presented.  The middle row represents the most interesting case in that the entity aircraft engage the aggregate enemy tank platoon.   The relative sizes of the aggregate units and entity-level simulated objects are shown in  REF _Ref125557154 \h Table 2 REF _Ref125116733 \h ..  The size of the aggregate units is based on the notional geographic extents of the unit when they are in a diamond formation.Table  SEQ Table \* ARABIC 1. Simulated Battlespace ObjectsCommand LevelGround Entity Ground Entity CountAir EntityAir Entity CountBattalionCompany4/1Section1CompanyPlatoon16/4A-10 Aircraft2PlatoonM-1 / T-80Tank48/16(blue/red)A-10 Aircraft2Table  SEQ Table \* ARABIC 2. Sizes of the Simulated EntitiesUnitWidthLengthCompany614.24m629.36mPlatoon207.12m214.68mEntity3.56m7.34mRoute PlanningAs discussed above, the three path planning algorithm is one of the two methods used to introduce variability. This section briefly discusses the three path planning algorithms. The other means of injecting the variability is though the use of different random number seeds. This results in different random number draws generating different execution and results. Since the system is run in the single threaded closed form mode, the variability induced by human interaction or network delays is eliminated.Direct PlanThe simplest of the three paths is the direct path.  In this case, the entities proceed in a direct line from the origin to destination.  As shown in Figure 7, there is a real chance this path will encounter some obstacles and result in the detailed reactive behavior of the entity slowing down and going around a restricted mobility area.  This introduces yet another level of variability in the system. EMBED Word.Picture.8  Figure  SEQ Figure \* ARABIC 6. Notional Direct PathMinimum CostAs the name implies, this algorithm attempts to take the fastest route from the origin to the destination point.  OOS uses a modified version of the A* search to find the route with the highest trafficability values; generating the shortest route in terms of time. As shown in Figure 8, the entities follow, in line, a direct path to the road and then follow the road and avoid entering the area marked “Obstacle.”  The contact avoidance and station keeping algorithms will introduce some variations, but are minimal.  EMBED Word.Picture.8  Figure  SEQ Figure \* ARABIC 7.  Notional Minimum Cost PathEnvelopmentThe final and most complex path algorithm is the envelopment path.  As shown in Figure 9, the force is split in half with a pincer movement to reach the objective from the side.  The algorithm plots turn points along the route as intermediate points and OOS does the detailed planning.  While the paths are roughly equal length, the time to traverse them depends on the type of terrain and obstacles encountered.  This leads to the two sub units arriving at the objective at different times.  For the sake of the evaluation function, we use the arrival time of the last unit to arrive. EMBED Word.Picture.8  Figure  SEQ Figure \* ARABIC 8. Notional Envelopment PathLanchester EquationsThere are many arguments against the use of Lanchester equations due to their lack of representation of current operational reality  REF _Ref124861688 \r \h [6].  While many of these arguments are valid, these equations do provide a degree of simplicity for aggregate level interactions and have been used extensively to model force-on-force combat.  Thus, we chose to use the Lanchester equations, described in  REF _Ref124861699 \r \h [7] and  REF _Ref124861712 \r \h [8] and shown below, as the basis for the interactions between aggregate units.  We ran one turn per interaction.   EMBED Equation.3  R(t) and B(t) represent the strength at time t of the red and blue forces, and kR and kB the effectiveness of a red and blue individual, respectively.  In this project we based strength on the number of weapons remaining in the aggregate entity.  Each of the weapons represented one platform.  Thus, at the company level, each entity had sixteen weapons and at the platoon, each entity had four.  When the entity had no more weapons, it was considered dead and no longer moved.Evaluation FunctionAs the scenario unfolds, time, space, and position information (TSPI) is logged to a file, as are the interactions (weapon firing and impacts) and their results.  This information is then post-processed and reduced.  The resulting data is collated and used as the input for the evaluation function described below.  We have set up the equation so the smaller the figure of merit, the better the plan.The evaluation function is defined by the following scenario-specific parameters:M = Mission Attainment (Boolean value if the mission was successful (0 = True, 1 = False))T = Time on Target (the value is the delta from the estimated time to complete the operation normalized by the estimated time)Ckf = Casualties count, killed, friendlyCke = Casualties count, killed, enemyCko = Casualties count, killed, other Cwf = Casualties count, wounded / disabled, friendlyCwe = Casualties count, wounded / disabled, enemyCwo = Casualties count, wounded / disabled, otherk1..8 = Weighting constants for each of the terms (defined by the mission parameters)The resulting equation is shown below.F(M, T, Ckf ,Cke ,Cko , Cwf , Cwe , Cwo) =k1M+k2T+k3Ckf+k4Cke+k5Cko+k6Cwf+k7Cwe +k8CwoThe use of the scenario defined constants allows us to change the relative importance of the factors.  For instance, in a given situation, the appropriate time on target is more important than the number of enemy killed or wounded.  In other missions, the minimization of collateral damages to non-combatants might be the most important factor.  Having the ability to adjust the parameters allows us to guide the selection of the plans.  In this prototype, we have chosen to implement a single set of parameters for the evaluation function at each level and for each of the elements.  However, this is not a requirement, and each entity could have its own evaluation parameters.ConclusionsAt this time, we have not completed the implementation and evaluation of the system.  However, preliminary results look promising in both the use of OOS as an aggregate level model and the use of decomposition planning.Acknowledgements<<This publication was made possible through support provided by Army Research Laboratory activities under contract number DAAD19-02-D-0001/Delivery Order 0644.  The opinions expressed herein are those of the author(s) and do not necessarily reflect the views of ARL or the DoD. We are in the process of checking for the exact wording>>ReferencesProject Albert web site,  HYPERLINK "http://www.mcwl.quantico.usmc.mil/Albert/home.cfm" http://www.mcwl.quantico.usmc.mil/Albert/home.cfmTolk, Andreas, and Dietmar Kunde, “Decision Support Systems in the Military Environment”, Chapter 6 in "Innovations in Decision Support Systems", Tonfoni G. and Jain L. (Eds.), International Series on Advanced Intelligence, Advanced Knowledge International, ISBN 0-86803-980-2, pp. 175-210, Magill, Adelaide, Australia, 2003 Tolk, Andreas: "An Agent-based Decision Support System Architecture for the Military Domain," Chapter 8 in Gloria E. Phillips-Wren and Lakhmi C. Jain (Eds.): "Intelligent Decision Support Systems in Agent-Mediated Environments," Volume 115 Frontiers in Artificial Intelligence and Applications, pp. 187-205, ISBN 1 58603 476 6, IOS Press, 2005Davis, Paul “The Base of Sand Problem”,  HYPERLINK "http://www.rand.org/pubs/notes/N3148/" http://www.rand.org/pubs/notes/N3148/Davis, Paul, “Introduction to Multiresolution, Multiperspective Modeling (MRMPM) and Exploratory Analysis”,  HYPERLINK "http://www.mors.org/meetings/tutorial/Davis.pdf" http://www.mors.org/meetings/tutorial/Davis.pdf“The Lanchester Equation” http://www.cs.uiowa.edu/~dsidran/Lanchester%20Alternative.pdfSchofield, Julian, “Lanchester Equation Handout”,   HYPERLINK "http://artsandscience.concordia.ca/poli419n/pdf_word_excel/index/Poli_419_Lanchester_Equation_Hand_Spring_2004.doc" http://artsandscience.concordia.ca/poli419n/pdf_word_excel/index/Poli_419_Lanchester_Equation_Hand_Spring_2004.doc.Barlow, Michael, “Core Java Applet Example: Lanchester Equation”, http://www.cs.adfa.edu.au/~pfe/Applets/lanchester.htmlAuthor’s BiographiesDAVID R. PRATT is currently the Chief Scientist (Fellow) for SAIC’s Training and Simulation Solutions business unit.  As a vice president for technology, his responsibilities include developing and fostering leading- edge information technology and M&S technologies. He also serves as the Forces Modeling and Simulation point of contact for DoD’s High Performance Computing Modernization Program (HPCMP). He received a Master of Science degree and a Ph.D. in Computer Science from the Naval Postgraduate School and a Bachelor of Science in Electrical Engineering from Duke University.ELLEN TOWERS is a software engineer in SAIC’s Training and Simulation Solutions business unit.  She has a Master’s degree in Computer Information Science from the University of Pennsylvania and a Bachelor’s degree in Computer Science from the University of Central Florida.DALE R. SHIRES is a team leader in the Computational Science and Engineering Branch of the High Performance Computing Division at the Army Research Laboratory.  He also serves as a technical representative for the User Productivity Enhancement and Technology Transfer component of the DoD's High Performance Computing Modernization Program.  He has over 10 years experience in parallel computing and computational science.  He received both his Master's and Bachelor's degrees in Computer Science from the University of Delaware.KELLY KIRK is a member in the Computational Science and Engineering Branch of the High Performance Computing Division at the Army Research Laboratory (ARL).  As a member of the Sci Vis team, his responsibilities include developing and incorporating new technologies to provide enhanced ARL’s visualization capabilities. He has over 10 years experience in 3D visualization and distributed programming.  He received a Master of Science degree in Computer Science from Johns Hopkins University and a Bachelor of Science degree in Computer Engineering Technology from Spring Garden College. The counts are listed in the form of number of blue entities / number of red entities at that given level. There are not any enemy aircraft in the scenario.