Implications To The Federation Object Model On Assessing Uncertainty In Simulation Results TitleAssessing Uncertainties in the Probability of Raid AnnihilationStephen Kasputis Stan Grigsby and Donna W. BlakeStan GrigsbyDonna W. Blake Stephen KasputisVisiTech, Ltd.535A East Braddock RoadAlexandria, VA 22314-5884703-535-6640kasputis@visitech.com blake@visitech.com HYPERLINK "mailto:grigsby@visitech.com" grigsby@visitech.com703-535-6640 X307  (SG Voice)703-725-9412 (DWB Voice)blake@visitech.com  HYPERLINK "mailto:grigsby@visitech.com" grigsby@visitech.comkasputis@visitech.comblake@visitech.com HYPERLINK mailto:christiansen@dis.anl.gov KeywordsEYWORDS:PRA, uUncertainties, environment, Environment Concept Model (ECM)Federation Object Model (FOM), Federation Development Process (FEDEP)ABSTRACT: The Probability of Raid Annihilation, PRA, is the measure of a single ship with its combat systems to detect, control, engage and defeat a specified raid of threats within a specified level of probability in an operational environment.  The Navy, led by Program Executive Office for Theater Surface Combatants (PEO TSC), is developing an assessment process for PRA that uses an innovative combination of live testing and a simulation, the PRA Federation.  A crucial element in the assessment process is identifying the uncertainties in the PRA measure, in particular those associated with the natural environment.  The PRA Federation is unusual in that a given threat reacts to the combined ship defenses while all ship defenses simultaneously see the common threat.  This complexity of interactions with the associated environmental effects makes it very difficult to determine uncertainties in the PRA due to environmental considerations.  To further complicate matters, the PRA Federation is designed to permit the interchange between operational and test scenarios, thereby supplementing live testing with simulation results.  This interchange capability demands that the relation between the real world and implemented environment be captured in detail so that resulting uncertainties in the PRA due to the environment can be well-understood and documented.Using the PRA measure as a specific example, this paper illustrates a new technique in evaluating how the outcome of simulations is affected by uncertainties in the natural environment provided.  The Environment Concept Model (ECM) process, developed under the Navy MARitime Environmental Data Standards (MARVEDS) program for use in developing environmental requirements, is applied to identify and document the complexities within the PRA Federation and the links with the operational and test environments.  In particular, the assumptions and constraints in modeling the environmental effects are captured in detail to assess the appropriate level of fidelity and consistency required in the environmental representation.  In other words, the ECM process links the simulation outcome, the PRA measure, back to the required natural environment representation.  Using the same procedure, the uncertainty in the PRA measure can be linked mathematically back to the uncertainty in the required natural environment representation and vice versa.  Thus, the ECM process and documentation capture the traceability needed not only to determine natural environment representation requirements but also to evaluate how uncertainty in that environmental representation affects the uncertainty simulation outcome Simulations are used to support analyses from engineering design decisions to tactics developments, to long-term DoD-wide investment strategies.  Rarely, if ever, do these analyses consider the uncertainty associated with the simulation results upon which they are based.  Estimating that uncertainty is a complex matter.  Some of the aspects upon which that uncertainty depends are static, such as the accuracy of environmental data used as inputs.  Several of the aspects, however, are dynamic and depend not only on the scenario, but also on the topology of the processing and communications resources used for the simulation execution.  Additionally, the modeling of each action, reaction, and interaction in the battlespace has an effect on the uncertainty.  Therefore, the uncertainty associated with the state of the simulation is very much a function of time.  To be effective, determination of uncertainty needs to become part of federation execution.  This paper uses the context of the federation development process to identify the possible sources of uncertainty associated with establishing and executing a simulation.  Once these sources are identified, potential implications for the federation object model are assessed.Probability of Raid Annihilation, PRA, is the Navy’s measure of a single ship with its combat systems to detect, control, engage and defeat a specified raid of threats within a specified level of probability in an operational environment.  Threat performance and combat system performance both can vary significantly with natural environment conditions so the PRA federation incorporates these effects.   In an earlier paper (01F-SIW-007), uncertainty in the PRA measure or federation outcome was linked mathematically to uncertainty in the implemented natural environment representation.  This procedure was based on the detailed documentation and analysis provided by the PRA Environment Concept Model (ECM).  In this paper uncertainty results are presented using this procedure.  The uncertainty assessment includes a reasonable range of uncertainties in the individual environment parameters but maintains consistency within the environment representation by means of the ECM.  Maintaining consistency is required because the uncertainty analysis shows that the uncertainty in PRA measure depends not only on the magnitude of uncertainty in an environment parameter but also on the overall environment representation supplied.  The uncertainty analysis not only provides an assessment of how good the PRA measure is but also provides information on the best cost benefit to improvement in the PRA measure..1. Defining UncertaintySection Title – 12 point bold In characterizing or measuring uncertainty, the first thing that must be done is to define what is meant by uncertainty.   There are several possible interpretations.  For example, Bayesian analysis defines uncertain variables in much the same way as statisticians define random variables.  Fuzzy logic deals with a different type of uncertainty in the definition of fuzzy sets [1].  For example, there may be a need to define something as “new” or “old.”  In non-fuzzy sets, new might be defined as less than one year old.  In that case, on the366th day, items would transition from new to old in one day.  This seems rather counter to logic.  Fuzzy logic handles this by making the transition boundary less precise.  For example, they could define a linear probability of something being new as being 1.0 at one year and zero at 2 years.  At 18 months, something would have a 50% probability of being defined as new.  There is thus uncertainty associated with the definition of an item 18 months old.   Perhaps the most straightforward and intuitive definition of uncertainty is one that captures the low order characteristics of the statistics of the parameter of interest.  An example of how a statement like this would appear for a specific probability P is:  EMBED Equation.3   with a confidence interval of 90%.  This is interpreted as being 90% confident that the true value of the quantity estimated by P it will fall between 0.85 and 0.93.  The definition of uncertainty can also be broadened.  It can include, for example, identification of aspects that are the biggest contributors.  Further consideration may also be desired to include what would need to be done to reduce the uncertainty associated with or introduced by any or all of the contributing aspects.  Thus, it is important to understand what interpretation and aspects of uncertainty are of interest before addressing how to estimate it.2. Sources of UncertaintyTo identify the sources of uncertainty in simulations, we analyze the process of creating and executing one.  Each step of this process is analyzed to identify possible sources of uncertainty associated with it.  It should be noted that the process discussed below is not the Federation Development Process (FEDEP).  Addressing uncertainty in the context of the FEDEP is discussed in Section 5.  Also, the following discussion is presented in the context of physical modeling.  The same issues apply to behavioral modeling and are generally compounded by their complexity and our lack of understanding of some behaviors.2.1 Stating the ProblemThe first step is to understand the problem.  All of the aspects that influence the situation or process must be identified.  Along with these, their dependencies and correlations must also be identified and defined.  Any aspect, dependency, or correlation that is not identified will contribute to uncertainty in the final modeling.  These types of omission fall into the category that is sometimes known as “unknown unknowns.”  The only way to identify this uncertainty is through statistical comparison with real world observations.2.2 Expression of the Problem as AlgorithmsThe next step is to express the physics as algorithms or rule sets.  There are three potential issues in expressing the physical world in algorithms.  The simplest of these is not using all the known aspects in the algorithms.  That is, the aspects that have little effect are abstracted away.  A second issue is the possibility of needing to make simplifying assumptions about the real world to be able to derive algorithms.  An example would be replacing the sine of an angle with the value of the angle in radians in deriving an equation for harmonic motion.   This example demonstrates two characteristics of simplifications that contribute to uncertainty.  The first is that the simplification is an approximation.  The second characteristic is that approximations often restrict use of the algorithm to a specific regime.  In the example provided, the regime is to small angles where the sine of an angle is approximately equal to the angle.  The third issue in expressing the physics in algorithms comes from an incomplete understanding of the physics of the problem.  If the phenomenon to be modeled is not completely understood, the best available algorithms will simply provide an approximation of that phenomenon.  Even if a physical understanding is fairly complete at one level of detail or resolution, it may not be at the level which it is needed for the simulation.  For example, modeling the stresses on a single fiber in a composite material may be well understood.  How to use this model to describe the response of an aircraft wing made of the composite material when subjected to anti-aircraft fire, however, may not be well understood at all. 2.3 Evaluation of the AlgorithmsThere are also issues associated with the evaluation of algorithms on a computer that contribute to uncertainty.  The most of obvious of these is round off error.  While the absolute value of round off error may be small for any given calculation, complex scenarios require many hundreds or thousands of calculations that all build upon each other.  The growth of the potential error and associated uncertainty can become significant in such cases.  Another issue in evaluating the physics expressed in algorithms is that many mathematical expressions cannot be solved exactly; higher order partial differential equations or an N-body problem for example.  In such instances, numerical techniques are typically used to determine an approximate solution or evaluation of the algorithms.  A closely related issue in evaluating the representation of the real world through algorithms is that of representing continuous phenomena discretely.  Consider, for example the modeling of energy propagation.  The best models calculate propagation loss at discrete intervals between source and receiver.  Representing propagation in this manner implies that the medium through which the energy is propagating is piece-wise constant or at best linear between the points at which propagation loss calculations are made.  The error that results from the discrete representation of the continuous world provides yet another source of uncertainty in modeling.  2.4 Definition of Modeled ConditionsClosely related to the topic of evaluation of the algorithms is definition of the inputs for them.  Inputs come with some degree of uncertainty whether it is defined or not.  For the modeling of military operations, these inputs are generally things like the environmental description, and force locations.  For any input, there is a limit to the accuracy with which any given input value can be measured.  The difference between the measured or observed value and the true value adds error and uncertainty to any use of those inputs.For input parameters that are continuous in either time or space, resolution or sampling frequency is another consideration.  This issue is closely tied to the discrete calculation of continuous phenomena such as propagation as discussed above.   Ideally, the sampling frequency for input parameters matches the frequency at which the algorithm is evaluated.  This is seldom the case, however, for very real and practical reasons.  Typically the values of the inputs are under sampled with respect to the resolution at which the algorithms will be evaluated.   Additional input values are therefore generated through an interpolation or modeling scheme.  Again, any difference in the generated input values and the true values adds error and uncertainty to the results.One additional consideration with respect to the sampling of continuous phenomena is that the act of sampling alters the media and therefore the value that is being measured.  The measured values are therefore different than they would be in the absence of sampling.  This can add to the error of our interpolated values as those interpolations are based upon values that are not truly representative of the medium at the sampled points.2.5 Variability of Model PerformanceThe performance of many models and simulations, and, therefore, their associated uncertainty can depend on the conditions under which they are operated.  That is, there are some key factors that affect the performance of the simulation.  This is especially true for distributed simulations.  Examples of such factors are processor or network utilization, or the number of tracks held by an entity.  These factors will vary by simulation and method of modeling.  But it is generally the case that there are operating conditions that affect a simulations performance and associated uncertainty.  It thus becomes critical in accounting for uncertainty in a federation’s execution to not only identify these key operating conditions, but also to monitor and report on them.  2.6 Complexity of Federation ExecutionAs complex as quantifying uncertainty from all sources associated with any specific model may be, tracking uncertainty through a federation’s execution can be much more difficult.  Such execution requires the interaction of several models.  Characterization of the uncertainty associated with any given simulation run requires that not only must the interaction between models be characterized, so also must the sequence of execution.  The sequence, including iterations, is highly scenario dependent.  It is possible, therefore to have low uncertainty of simulation results under one scenario, and significantly higher under another. 1.1 Subsection title – 10 point bold3. Uniqueness and Dynamic CalculationFor simulations that are non-deterministic, distributed or designed to run under different operating conditions and scenarios, last two factors discussed above introduced the dynamic nature to uncertainty in federation execution.  They make the uncertainty of federation’s results unique to that specific execution run and necessitate the consideration of dynamically tracking and reporting uncertainty during runtime.  To see this need consider the following.  For simulations that can be characterized as above, different runs starting from the same initial conditions will likely evolve slightly differently.  The nature, extent, results, a number of number of interactions will differ from run to run.  Because of this the conditions under which these interactions will be simulated will also differ to some extent.  As the purpose of federations is to model these interactions, it can be argued that the sequence or nature of federation execution is unique for each simulation run.  This means the path of uncertainty propagation is unique for each simulation run.  It follows, therefore, that the uncertainty associated with the simulation run results is also unique and suggests the need to dynamically compute it.  Consider now a federation whose execution is completely deterministic.  The results from multiple runs with given identical initial conditions will be identical as will the associated uncertainties.  To be of much practical use, the federation should be capable of executing with different initial conditions or scenarios.  Each of these different scenarios, however, will evolve differently and thus require a unique determination of uncertainty.  While this determination could be done after execution with no loss of accuracy, it would be more efficient to do so during simulation runtime.4. Methods for determining uncertaintyThere are several methods for the determination of uncertainty in federations.  Three of these are briefly discussed as examples and to provide some idea of the possibilities and complexities in determining uncertainty.  The first is a standard statistical method for combining uncertainties.  The second is an adaptation of finite statistical element techniques.  The third is the use of Bayesian networks.  Other possible techniques include application of fuzzy logic and differential inclusions.  4.1 Standard Statistical ApproachThe standard statistical approach of combining uncertainties is effective when multiple factors affect one aspect.  Consider an aspect that is a function of several variables:  EMBED Equation.3  .  If we have expressed the uncertainty of each variable as a standard uncertainty u(Xi), we can calculate the standard uncertainty of the aspect of interest, u(Y), as  EMBED Equation.3  		(Equation 4.1)where u(Xi,Xj) is the covariance associated with Xi and Xj.   The standard uncertainty u(Xi) is defined as the positive square root of the estimated variance u2(Xi)[2].  This technique can be used to determine uncertainty at any point in the execution of a federation.  It can also support sensitivity analyses to identify the major contributors to uncertainty for the problem as a whole or any aspect or subset of the problem.  Consider, for example, the problem of ocean acoustic propagation pictured in Figure 4.1.  This technique could be used to define the uncertainty associated with the receive signal as a function of the all the aspect listed.  It could also provide the uncertainty associated with any intermediate aspects such as the sound speed profile (SSP), the amount of scattering, or the estimated noise level.    EMBED PowerPoint.Slide.8  Figure 4.1.  Relationship diagram for ocean acoustic propagationThis technique also supports sensitivity analyses that can identify the largest contributors to uncertainty or those to which the uncertainty of interest is most sensitive.  The standard uncertainties of any of the aspects can be artificially controlled.  This facilitates such studies by allowing for the standard design and execution of experiments in which some aspects are held constant and others varied in a precise and predetermined manner to assess their effect on the downstream uncertainty.  A brief analysis of equation 4.1 reveals something interesting. The value of a combined uncertainty depends on the covariance associated with the factors that affect it.  Some covariance values can be dependent upon conditions or scenario.   For example, the correlation between temperature and absolute humidity may be different in the desert than in the Caribbean.  This could mean the uncertainty determined under one set of conditions may not be very representative of the uncertainty under another set of conditions.  The immediate caution is that one should not assume the uncertainty under one scenario should be approximately equal to that under another scenario.  This would seem to dictate the calculation of uncertainty should, as a minimum, be done over a number of different scenarios and conditions.   Employment of this statistical approach basically requires the repeated evaluation of equation (1).  This is an intensive effort.  To assess uncertainty under different scenarios requires that the intensive uncertainty calculations be done from start to finish for each scenario since it explicitly uses the covariance values in each step in the propagation of uncertainty.   4.2 Statistical Finite Element ApproachThe specific approach identified, that of stochastic adaptive refinement, addresses the representation theory for random processes.  It is an extension of the basic ideas of the deterministic finite element method to accommodate random functions.  The mathematical problem addressed is that of representing a random process by a denumerable set of random variables, thereby discretizing the process. In a more applied sense, it describes random processes in such a manner that they can be implemented in a finite element formulation of the physical problem.Following the formalization by Ghanem and Spanos [3], a continuous random process is formally defined as an indexed set of random variables, the index belonging to some continuous uncountable set.  The process can be approximated as closely as desired by restricting the index to a set dense in the indexing set.  A random process is then represented by its values at a discrete set of points in its domain of definition.  The random processes involved are substituted for by random variables that are so chosen as to coincide with some local average of the process over each element.This approach is roughly analogous to taking the Fourier transform of a function.  In mathematical notation, the first steps of this approach can be described as follows:  The random process  EMBED Equation.3  is expanded in terms of a denumerable set of orthogonal random variables in the form EMBED Equation.3  		(Equation 4.2) where  EMBED Equation.3  is a set of orthogonal random variables and  EMBED Equation.3  are deterministic functions, which can be related to the covariance kernel of  EMBED Equation.3  .  Since this equation constitutes a representation of the random process in terms of a denumerable set of random variables, it may be regarded as an abstract discretization of the random process. To provide further insight into this approach, this equation can be viewed as a representation of the process  EMBED Equation.3   as a curve in the appropriate Hilbert space.  The random process  EMBED Equation.3  is expressed as a direct sum of orthogonal projections in this Hilbert space whereby the magnitudes of the projections on successive basis vectors are proportional to the corresponding eigenvalues of the covariance function associated with the process.  A final note on the potential applicability of this approach is that these concepts can be generalized to allow for the representation of nonlinear functionals.In the standard statistical approach described previously, changing the scenario may have required a new complete tracing of uncertainty through the data flow architecture, with the multiple evaluation of equation (1), to ensure an accurate estimation of uncertainty.  Such is not the case with the approach described here.  The expansion of the random functions need only be done once.  Once this transformation is made, determination of the uncertainty for any scenario or initial conditions is simply a case of solving a matrix equation.  This method does suffer from two current shortcomings.  First is that application of this method to real world problems is still very much in the research stage.  There is no streamlined process to mathematically defining and transforming the real world random processes.  As a result, any such application may be require considerable overhead time from the few experts who exist.   The second possible shortcoming is that this method is not at all intuitive.  While it holds probably the greatest potential for efficient determination of uncertainty associated with federation execution, it would be difficult for most decision makers to understand the process by which that uncertainty value was derived.  It could, therefore, be difficult for them gain confidence in the results produced by this method.4.3 Bayesian NetworksA Bayesian network is a graphical model for the probabilistic relationship among a set of variables [4].  The Bayesian network has become a popular representation for encoding uncertain expert knowledge in expert systems.  Additionally, methods have been developed and continue to evolve that can learn Bayesian networks for observed data.  Additional properties of Bayesian networks make them potentially useful.   The first is that they can easily handle incomplete data sets. For example, consider a case where two input variables are strongly anti-correlated.  Other methods for extracting knowledge from data can handle such correlation only if all inputs are measured in every case.  If one of the inputs is not observed, these other methods will likely produce inaccurate predictions since they do not encode the correlation between input variables.  Bayesian networks offer a natural way to do this.Another property of Bayesian networks is that they allow one to learn about causal relationships.  This is useful when trying to gain an understanding about a problem domain.  It also allows one to make predictions in the presence of interventions.  That is, they can address questions of cause and effect even when no experiments about the specific effect have been run.A third property of Bayesian networks is that, in conjunction with Bayesian statistical techniques, they facilitate the combination of the domain knowledge of subject matter experts and data.  Bayesian networks have a have a causal semantics that makes the encoding of causal prior knowledge particularly straightforward.  Also, these networks encode the strength of causal relationships with probabilities.  Therefore, prior knowledge and data can be effectively combined with mature techniques from Bayesian statistics.Lastly, Bayesian methods, in conjunction with Bayesian networks, offer an efficient approach for avoiding the over fitting of data.  That is, there is no need to hold out some of the available data for testing; all available data can be used for defining the network.There are some cautions with the use of Bayesian Networks.  The networks are essentially networks of conditional probability relationships.  Each node provides the probability of some condition being true.  For problems such as ship self defense with many degrees of freedom, the networks either must be excessively large, or specifics of the problem must be aggregated or abstracted away.  The abstractions must be done with great care if the system is still to meet the intended use.For even simple problems, construction of the network is often rather complicated.  Deriving the proper construct so as to ensure casual relationship between parent and children nodes, especially for reactive systems such as in ship self defense, can become a significantly labor intensive problem.  Additionally, construction of Bayesian Networks requires defining conditional probability tables for each node.  The number of entries needed in these tables for any node is geometrically dependent upon the number of nodes that affect it.  For problems involving complex interactions where many factors can affect one node, creation of these tables can become somewhat problematic.  This can be mitigated somewhat with careful construction of the network, but this again complicates that effort.  A final caution on Bayesian Networks is that they don’t allow for explicit identification of dependencies between children of a common parent.  Consider a network in which the parent node is the probability that a radar is radiating.  Two children nodes could be the probability of detecting an incoming aircraft, and the probability that the incoming aircraft counter-detects being irradiated.  These networks do not provide for identification of any correlation between these two children nodes.  Such correlations could provide valuable information for insight into both engineering decisions and development of tactics, techniques, and procedures.5. Incorporation of uncertainty considerations into the Federation Development ProcessIf characterization of uncertainty in federation execution is desired, uncertainty considerations must become integral to the Federation Development Process (FEDEP).  Activities that must be considered during the FEDEP are outlined below.5.1 Define Federation ObjectivesDuring this phase, the uncertainty requirements must be identified.  These requirements fall into two different classifications.  The first identifies the accuracy and confidence limits on the objective data or information provided by the federation.  It may be important for an analysis, for example, that a federation provides probability of kill values within  EMBED Equation.3  3% under certain conditions.  The second classification of uncertainty related requirements is when some measures or form of uncertainty itself as one of the pieces of objective information desired from the federation. An example of this could be the uncertainty of enemy troop movements associated with different sensor placements in order to evaluate optimum resource employment.  Once the requirements are understood, the methods of measuring or determining the needed aspects of uncertainty that best meet these requirements need to be identified.  At this point, this identification can be as general as the standard statistical method or Bayesian networks. The general types of data needed to support these methods can then be specified, such as low order statistical moments.  5.2 Develop Federation Conceptual ModelDuring this step of the FEDEP, all the sources of uncertainty associated with the development and execution of the federation must be identified.  Additionally, each source must be classified as significant or insignificant.  Insignificant sources are ones that make very little contribution to uncertainty measures of interest and can be extracted away.  Care must be taken to ensure that such a source is not significant under any possible conditions of the federation execution.For significant sources, details of the method of quantifying uncertainty from each must be identified.  This detail must be to the level of specific algorithms or exact processes.  These details will depend on the place in the conceptual model execution of the factor with which the uncertainty is associated.  These factors can be either fundamental inputs or can use other factors as inputs.  For example, environmental inputs may be fundamental inputs.  As such, the uncertainty associated with them would be that of the measuring technique or accuracy of historical information.  Assessing the uncertainty of modeling of the final intercept stage of an incoming air target may depend on the uncertainties of the detection, track generation, and terminal guidance systems as well as environmental factors.  In that case, use of Equation 4.1 would be appropriate if the standard statistical method was being employed.  To ensure the proper identification and tracing of all the potential dependencies within a federation, a structured approach to conceptual modeling with suitable automated support tools, such as described by Grigsby and Blake [5] is highly recommended.Since the methods for determining uncertainty have been detailed, the specifics of the data requirements of these methods and also be identified.  This data will be either a characterization of fundamental inputs, or the output of another federate.  Since such characterization data identifies information that must be passed to and between federates, it should be part of the Federation Object Model (FOM).  It is during this phase of the FEDEP, therefore, that the initial FOM requirements to support tracking uncertainty are established.  There are additional aspects that must be identified for the FOM.  Because of the need for dynamic determination of uncertainty as discussed earlier, there must be some tracking and communication of the state or value of the operating conditions that govern a simulation’s performance.  While these conditions are not generally thought of as appropriate for a FOM, there is no other formalism within the High Level Architecture to account for these.  Given this and the critical nature of these conditions, it is recommended that operating conditions identified as critical during this phase be included in the FOM.One additional task can be accomplished during this phase.  Once the details for determining uncertainty have been established, the conceptual model of the federation can be used to establish an uncertainty budget, if required.  This would be needed if the uncertainty requirement established earlier included accuracy minimums and confidence interval limits for any of the objective data.  The identified method for determining uncertainty can be inverted within the context of the federation conceptual model to establish uncertainty limits for each step in federation execution, up to and including fundamental inputs.  Because of the probable furcating nature in this backward propagation of uncertainty, subject matter expert opinion may play an important role in the allocation of the uncertainty budget between multiple factors that all affect another factor.  It is also probable that many factors are inputs to more than one factor in the forward propagation mode.  For such factors, the proper bookkeeping of the conceptual model, such as that offered by current software development tools, is critical in ensuring that the most stringent budget limits are identified.  If an uncertainty budget is established, and additional consideration for the FOM could be the dynamic value of uncertainty with respect to the budget.  This may be needed if it is desired to have federation execution change in some way, such as executing at a different resolution, depending upon the trend of uncertainty during runtime.	5.3 Design FederationDuring the Federation Design phase, the requirements established in the previous phases are used to supplement other requirements to establish either selection criteria for use of existing federates, or design criteria for the development of new federates.  These criteria need to ensure that uncertainty is accounted for by the federates, that they determine it in the desired manner, and that they adhere to the FOM for sending and receiving the appropriate uncertainty data.  The importance of the criteria addressing uncertainty must be properly weighted with respect to criteria addressing other requirements areas for overall federation performance optimization.  5.4 Develop Federation During the Federation Development phase, the federation and FOM are finalized.  Generally, some of the federate design or selection criteria are eased as compromises are made with other criteria or program constraints on cost and schedule.  6. SummarySound engineering and operations analysis practice dictates accounting for the accuracy limits or uncertainty of the data used in the analysis.  For data supplied through simulations, this means understanding the uncertainty associated with simulation results.  To properly address uncertainty in federation results, it must be considered from the earliest stages of federation development.  The requirements addressing it must be on par with those of other performance areas such as execution time, processor, storage, and bandwidth utilization, or operator loading.  Development of a complete conceptual model is essential to the identification of all the interactions and dependencies upon which uncertainty propagation during federation execution will depend.  Specific data requirements need to be added to the FOM.  As a minimum, these include data specific to the method used to track uncertainty, such as lower order moments for the standard statistical method, and information on operating conditions that affect the uncertainty associated with model results.  Inclusion of information on operating conditions such as hardware utilization in the FOM is a new concept, but essential if uncertainty is to be properly estimated. 7.  ReferencesBauer, P., Nouak, S., and Winkler, R., “A Brief Course in Fuzzy Logic and Fuzzy Controls,” Version 1.2,  HYPERLINK "http://www.flll.uni-ac.at/pdw/fuzzy" http://www.flll.uni-ac.at/pdw/fuzzy, December 1996.Taylor, B. N. and Kuyatt, C. E., “Guidelines for Evaluating and Expressing the Uncertainty of NIST Measurement Results,” NIST Technical Note 1297, September 1994.  Ghanem, R. G., and Spanos, P. D., Stochastical Finite Elements: A Spectral Approach, Springer-Verlag, New York, 1991.Hackerman, D., “A Tutorial on Learningwith Bayesian Networks,” Microsoft Research Technical Report MSR-TR-95-06, March 1995 (Revised November 1996)Grigsby, S. and Blake, D. W.  “Assessing Uncertainties in the Probability of Raid Annihilation,” SISO paper 01F-SIW-077, September 2001. Author BiographiesSTEPHEN KASPUTIS is a Vice President with VisiTech, Ltd. in Alexandria, VA.  He had held numerous position in the Undersea Surveillance Program Office including Technical Director of the Fixed Distributed System.  He has been the systems engineer for numerous simulation efforts.  He is currently the systems engineer for the modification of JSAF for a prototype Marine Corps training system and directing development of advanced validation techniques.  He has a BS in physics from Penn State, an MS in engineering acoustics from The Naval Postgraduate School, and a doctorate in acoustics from The Catholic University of America.STAN GRIGSBY is a Senior Environmental Systems Engineer with VisiTech, Ltd. in Alexandria, VA.  He supports the MARVEDS and PRA programs.  He served as the Meteorology Officer on the USS Tarawa and developed and managed environmental effects programs for the Navy High Energy Laser Project.  He served as a program manager in the Strategic Defense Initiative Organization.  Currently his work is focused on the application of systems engineering practices to the evaluation of environmental effects on Navy systems.  He has a BS in physics and an MS in meteorology.DONNA W. BLAKE is a Senior Scientist with VisiTech, Ltd. in Alexandria, VA, supporting the MARVEDS and PRA programs.  She is a former Chief of the Office of the M&S Ocean Executive Agent and has performed research in both ocean and atmosphere modeling at several universities and Navy laboratories.  She has served as a program manager for ocean sciences at NASA and for atmospheric sciences at NSF.  She has a BA in physics and an MS in astro-geophysics, both from the University of Colorado, and a doctorate in geosciences from the University of Chicago.IntroductionThis paper describes a promising methodology to assess uncertainties in the Probability of Raid Annihilation (PRA) Measure of Effectiveness (MOE) used by the Navy as part of the assessment for ship self defense.  The methodology builds on a number of tools, techniques and programs in Modeling & Simulation (M&S).  These, including MARVEDS, are described very briefly in Section 2, Background, together with references for additional information.  The PRA process and the role that the ECM plays are described in Section 3.  The new aspect of ECM, in addition to capturing environmental requirements and as a basis for validation, is provided in Section 4 with Conclusions following in Section 5.2.  BackgroundThe Navy Modeling & Simulation Office (N6M) has established the MARitime Environmental Data Standards (MARVEDS) program to develop and promote standards for representing and using the integrated natural environment in simulations.  Standards can include aspects of data representations such as parameters, spatial and temporal resolutions, formats and coordinate systems.  Standards can also address serving methods for delivering dynamic data and even best practices for applying such data in effects models.  The development of such standards is based, in part, on the requirements for the integrated natural environment in Naval M&S.  However, existing requirements do not provide the level of detail necessary to develop such standards.  Therefore, MARVEDS is developing a formalism, including a living document, to capture, collate, and coalesce the integrated natural environment requirements for the Navy programs and offices involved in developing simulations.  This formalism includes the Environment Concept Model (ECM), a procedure and a process, to unambiguously describe the integrated natural environment information needed by a simulation and the how that information is used in the simulation itself.  The role that MARVEDS plays in M&S is graphically presented in Figure 1, which is a variation of the Environmental Reference Model.  For further information, contact Dr. S. K. Numrich, the MARVEDS Program Manager, at  HYPERLINK "mailto:Numrich@ait.nrl.navy.com" Numrich@ait.nrl.navy.com. EMBED PowerPoint.Slide.8  Figure 1.  The Role of MARVEDS in Simulation DevelopmentThe formalism being developed by MARVEDS is based on conceptual modeling, a common technique for representing information systems, especially ones involving complex or ill-defined problems.  In conceptual modeling the system is viewed as objects that can interact in various ways.  Each object has associated properties, not immutable, that determine its interactions with other objects.  The process of developing a conceptual model then involves determining how a system can be expressed in terms of objects, properties and interactions.  The concept model provides a common basis by which stakeholders and developers can agree on the purpose and goals of the system.  In particular, conflicts and inconsistencies can be identified and resolved.  The concept model should capture the agreements and decisions that then lead to the requirements for the system.  The requirements, in turn, form the basis of the validation process for the system.  (See Reference 1 for more information on conceptual modeling.)   Conceptual modeling has many applications and plays an integral role in the FEDEP process.  DMSO has invested in the Concept Model of the Mission Space (CMMS), now the Functional Description of the Mission Space (FDMS).  The documentation for the FEDEP and the CMMS do not address the level of detail needed to capture the integrated natural environment requirements as needed to handle sensor effects in Navy M&S.  These and other DMSO programs are found on the DMSO Web Site:  HYPERLINK "http://www.dmso.mil" http://www.dmso.milThe MARVEDS Program and the Integrated Ship Defense (ISD) M&S Pilot Program collaborated to achieve a consistent natural environment representation across federates that use legacy codes.  (See Reference 4.)  The representation is said to be internally consistent if it has been developed in accordance with known physical and dynamical constraints.  Internal consistency is commonly imposed on the pre-runtime integrated natural environment representation provided as input for a simulation exercise.  Achieving and maintaining a consistent integrated natural environment during runtime for a simulation or federation is much more complex.  Legacy codes frequently have embedded environmental data.  One code may use a constant wind of five m/s from the north while another uses a wind of one m/s blowing from the east.  Further, the pre-runtime environment data may supply a wind that varies temporally in magnitude and direction.  Thus, the winds in the legacy codes and in the pre-runtime data are inconsistent with each other. Conflicts in the legacy codes have to be resolved to achieve consistency in the environment but first such conflicts have to be identified and documented.  (See Reference 4 for examples.)  Concept modeling is ideal for this purpose and, further, is already in use by the M&S community.  The ECM is a process-based product in the form of an electronic document.  The resulting document is composed of three major sections.  First, the document describes the real world scenario(s) the simulation will represent.  The military systems and personnel are identified, as well as the actions they perform.  Often, the scenarios are broken down into smaller vignettes, to clarify the representations.  The document’s second section describes the land/sea/air modeling needed to satisfy all the needed terrain, weather and ocean phenomena.  The ECM documents the independent and dependant variables, algorithms and logic.  The document’s third section revisits the second section’s need-based description, from a different perspective.  The third section describes the land/sea/air modeling as actually implemented, with limitations imposed by science understanding as well as project schedule and budget considerations.  (See Reference 3 for more information on the ECM.)We use the Unified Modeling Language as the analysis and design language to describe environment representations in the ECM.  Reference 5 provides an introduction to this standards-based analysis and design language, and Reference 2 provides a detailed user guide.The extensive ECM documentation also includes details of simulation objects, models, assumptions, constraints, agreements and other related reference material.  As such, this documentation can provide the basis for validation of the system.  (See Reference 6.)Probability of Raid Annihilation (PRA)3.1 DefinitionThe Probability of Raid Annihilation is defined as the ability of a particular stand-alone ship, as an integrated system, to detect, control, engage and defeat a specified raid of anti-ship missile (ASM) threats with a specified level of probability in the operational environment.  The PRA MOE is a system of systems measure that is levied on the ship defense suite as a whole to properly detect, control, and engage (annihilate) a raid of incoming threat ASMs.  The ability to directly test the capability of a ship to withstand a raid is not practical.  Therefore, a combination of live tests and simulations will be used.  In fact, the PRA Federation is unique in that simulation will be able to incorporate directly the results from the live testing.In addition to the PRA metric, an evaluation is needed of the causes of uncertainties in the system, including an estimate of the uncertainty in the PRA metric itself.  Models and simulations are by definition subsets of reality because of the constraints, and assumptions imposed.  These assumptions and constraints introduce uncertainties.  However, live testing is also subject to uncertainties introduced by limited scenarios and observational errors.  This paper describes a process by which these uncertainties can be documented, analyzed and evaluated to ascertain their impact on the final outcome of the determination of the Probability of Raid Annihilation.The Navy, led by PEO TSC, has convened a task group to evaluate the PRA process and, specifically, the environmental effects that must be considered.  This task group includes subject matter experts in the areas of ship defense, threats, radars, electronic warfare and the natural environment.  This task group has collaborated to define the model of the PRA displayed here.  Starting with a simple framework, as shown in Figure 2, additions have been made so that an increasingly detailed system has been captured in the context of this simple model.Figure 23.2 Current applicationFigure 3 shows more detail in the PRA simulation.  Again, however, the detail is shown only for one subsystem, the radar.  The overall system consists of the RAM missile and associated launch and guidance systems, decoy systems, and electronic warfare systems.  A complete evaluation of system performance, system uncertainties, and the effects of the environment require detailed information on all of these subsystems.The primary goal of this work is to document the assumptions in the development of the simulation from a description of the real world.  The first step of this is to compile a list of the various effects that can act on the system.  Next, it is necessary to either incorporate the effect or explain and document why it couldn't or shouldn't be included.  Table 1 contains such a list of environmental effects that could impact a radar or RF seeker.  (This information is displayed in table form, rather than in the Rational Rose Representation used in other Figures, to save space.)Only the sea clutter and propagation effects are retained for evaluation, primarily because appropriate computer models of the other effects are not readily available.  However, the other effects are included in the overall concept model with explanations regarding why they have not been included, facilitating later upgrades and reuse.  Radar/RF SeekerEnvironmentalEffects on      systemSea/Land ClutterDiscrete clutterRain/volume clutterBird/insect clutterPropagationNoiseElectromagnetic      InterferenceWind loading bends arrayTable 1Figure 3The environmentally relevant parameters for the radar are shown in Figure 4.  The arrows with the small heads define sources of information for an object.  For example the “Radar” object will request range information from the “RFPropagation” object and sea clutter from the “SeaClutter” object.  In turn the “SeaClutter” object will request sea state information from the “SeaState” object.For the purposes of this paper the uncertainties will be traced from the determination of temperature profile and hence radar propagation performance to the impact on the final determination of PRA for this ship.  It is understood that this process must be followed for each subsystem in the simulation to develop a complete view of their contribution to the overall uncertainty calculation.  Figure 44.   ECM Captures Uncertainty Information   4.1 Definition of UncertaintyAccording to the National Institute of Standards and Technology (NIST), uncertainty can be described as:“The uncertainty (of measurement) parameter associated with the result of a measurement characterizes the dispersion of the values that could reasonably be attributed to the measurand.  The parameter may be, for example, a standard deviation (or a given multiple of it), or the half-width of an interval having a stated level of confidence. Uncertainty of measurement comprises, in general, many components.  Some of these components may be evaluated from the statistical distribution of the results of a series of measurements and can be characterized by experimental standard deviations.  The other components, which also can be characterized by standard deviations, are evaluated from assumed probability distributions based on experience or other information. It is understood that the result of the measurement is the best estimate of the value of the measurand, and that all components of uncertainty, including those arising from systematic effects, such as components associated with corrections and reference standards, contribute to the dispersion.”  (Italics are the authors’.)(Reference:  HYPERLINK "http://physics.nist.gov/cuu/Uncertainty/glossary.html" http://physics.nist.gov/cuu/Uncertainty/glossary.html,June 27, 2001)	4.2 PRA Scenario Definition The PRA scenario consists of a single ship steaming independently when attacked by a saturation raid of anti-ship missiles.  This is the situation described in UML in Figure 2.The ability of a ship to defend itself depends upon its ability to detect a threat, track a threat, and ultimately destroy the capability of the threat to damage the ship.  The detection of a threat consists of two elements; one is the detection of the presence of a potential threat and next is to determine if the contact is hostile and if so is it a threat to the ship.  Once a contact is detected the track of that contact must be maintained until positive determination as a threat is made and then the fire control system must be able to compute the fire control solution and launch a defensive weapon.  This may be for a hard kill, and electronic attack or a combination of the two.  Finally there must be an assessment as to whether or not the threat was killed.  This process must be repeated for each of the threats in the raid.  (See Reference 7 for more information about threat representation in simulations of ship self defense.)4.3 Environmental Uncertainties4.3.1 Measurement Any simulation provides many opportunities for uncertainty but the focus here is on those related to the natural environment, for both measurements and models.  The first major source is in the measurement of the environmental parameters, e.g., temperature, winds and currents.  Instrumentation has inherent errors as does the ability to record and report these measurements.  Measurements are made at “points” over a period of time.  The size of this “point” and the length of time over which the measurement is made are sources of uncertainties in the value of a parameter to be recorded.  While there are standard methods for obtaining and analyzing most measurements, information regarding the errors or uncertainties is usually not available.  Often, only isolated values of a parameter are recorded and reported for a specific place and time. 4.3.2 RepresentationMeasurements of the ocean and atmosphere environment have less obvious limitations as well.  The observational network is very limited, both spatially and temporally.  Measurements are recorded for a specific location (including altitude) and time,  but are often used for a much larger area and over considerable time periods.  Are such point measurements truly representative?  When a measurement is made at an airport, is it valid for a location near a river five miles away?  The answer to that question is context dependent.  For data represented on a grid, seldom are the measurements taken at the actual grid point.  The evaluation of the importance of these difficulties can only be known when placed in the context of the effect on the system of interest.  This evaluation must address the relative magnitude of the impact of the uncertainties of the system components.To counter the limitations imposed by a limited observation network, environmental scientists commonly use a judicious combination of observations and numerical models, encompassing physical and dynamical constraints, to produce natural environment representations.  Again, the use of numerical models imposes uncertainties on the resulting natural environment representation.4.3.3 Environment EffectsFor this discussion of uncertainty, two environmental effects are of primary interest:  the clutter created by the surface of the ocean and the anomalous propagation created by ducting conditions.  Uncertainty in these parameters is introduced during at least three events: the observation and the extrapolation to the location and time of interest of the relevant environmental parameters, and the model of the effect of these phenomena.  This information is also captured in the Environment Concept Model.It is important in the discussion and calculation relating to uncertainty to determine if the items of interest are independent or correlated.  This information can be documented in the Environment Concept Model as described below.  The method in which the uncertainty behavior of an object is implemented will make use of this information.  In our example it is necessary to capture when the sea state is correlated with the anomalous radar propagation and when it is not.4.3.4 Documented in the Environment Concept ModelIn addition to defining environmental requirements and providing a basis for validation of the simulation, the Environment Concept Model provides the mechanism to capture and document the uncertainty and the relationship of uncertainty with other elements of the system.  Within each object there exists attributes and behaviors.  The characteristics of uncertainty may be unique to each object or entity.  Therefore it is beneficial to allow each object to calculate its own uncertainty.  This behavior stores the measure of uncertainty as one of the objects attributes.  At this stage of the work the uncertainty calculations are described in text and are calculated off line.  The ability to instantiate behaviors as computer code is a capability of the Rational Rose implementation of UML that is yet to be exploited.Figure 54.4 PRA Uncertainty Calculations  The probability of raid annihilation depends upon the ability of the ship’s systems to detect, control and engage the threat.  The ability of these systems to perform is dependent upon the nature of the raid.  The subsystems and components that represent the ship’s capabilities are depicted as objects in the Figures above.  One of the attributes of each component captured by the Environment Concept Model is the uncertainty of the performance of that component.  The relationship of each component is also depicted graphically.  The ability to ensure that each relationship is considered is facilitated by the object description as shown in Figure 5.In the inset it is seen that the SPS-48 must consider the sea clutter and radar propagation because it is a special case of radar.  If one then looks at the sea clutter object, in the inset in Figure 6, it is seen that the sea state object provides information for clutter calculations.It is also seen that sea clutter is used by a number of other objects and therefore these must be considered when manipulating the SeaClutter object.  This documentation is used determine the degree of independence of each of the objects and its behaviors when evaluating uncertainty.As was stated earlier, the current process of evaluation depends upon manually following the relationships and calculations contained in the object model.  Figure 64.5 Relationship of Environment and Other       Uncertainties4.5.1 ScenarioThe definition of a representative environment for a particular scenario remains an issue.  The environmental conditions used in the simulation may be as big a factor in the system performance as any of the other subsystems.  In the scenario of interest, if the potential raid and subsequent engagement occurs in an area of intense rain and wind, the remainder of the subsystems will most likely be of little consequence.  On the other hand, if the raid occurs in a clear, calm day with a moderate sea state and no ducting, then the environment is of little consequence.  The uncertainty calculations are related to the calculations needed to evaluate the relative importance of the various subsystems.  Low uncertainty in a subsystem of minor importance in a specific scenario is of little interest.  And of course, high uncertainty in a subsystem of major importance is a source of concern in the validity of a simulation.  One value of a well-defined concept model is to partition the subsystems into these categories.4.5.2 SystemThe Rose UML description of the system allows the simulation designer to document the characteristics of the system.  This process allows the designer to capture information from subject matter experts and other documentation.  When properly employed the relationship among the subsystems and components is documented and maintained in a readily available format in the object representations as seen in the above illustrations.  In the context of this work, one of the subsystems is the natural environment.	4.5.3 ExampleIn the subset of the PRA system provided above the system is tracked through the ECM from the high level view down to the natural environment parameters.  Figures 3-7 show that there are multiple paths from the ship behavior down to one of the natural environment parameters, say, the atmospheric temperature.  One such path, illustrated in Figure 7, can be demonstrated as follows:PRA MOE is a nonlinear function of the probabilities of kill, P(Kij), for each threat, i, and each ship weapon, j.P(Kij) is a nonlinear function of probabilities of detection, P(Di), control, P(Ci), and engagement P(Eij).P(Di) is a nonlinear function of the probability, I(sensor k), that each individual ship sensor, such as the RF (radio frequency) radar, can detect a given threat.I(RF radar) is a nonlinear function of several factors, including RF propagation, RP, and sea clutter, SC.RP is a nonlinear function of number of environmental effects, including propagation loss, PL.PL is a nonlinear function of the natural environment parameters, including atmospheric temperature, T, and absolute humidity, H. Figure 7Only one path has been followed in steps 1-6.  For example, there are several detection sensors, and sometimes duplicates of a given sensor, so several different paths could be followed in step 4.  In fact, steps 2 – 5 can all involve multiple paths.  Step 6, however, leads to the natural environment parameters, which are limited in number:  temperature, pressure, horizontal wind speed and direction, vertical wind speed, humidity, and density as well as aerosol type and distribution.  For some scenarios, chemical and biological agents are included.  These natural environment parameters are not independent of each other but are related through a set of well-known physical and dynamical relations.  As described in sections 4.4.1 and 4.4.2, there are uncertainties in both the measurements and representations of these parameters.  How can these uncertainties be related to uncertainty in the PRA MOE?The uncertainty in the atmospheric temperature, whether measured or modeled, is a complex and largely unknown function of position and time.  In addition, the uncertainty in temperature is related to the uncertainties in the other environmental parameters.  Although the detailed uncertainty functions are unknown, reasonable bounds on the uncertainties are available.  Then instead of T in step 6, T ( (T can be inserted to calculate the propagation loss, PL ( (PL.  The uncertainty in propagation loss is passed to the RF propagation, RP, in step 5 to determine RP ( (RP.  In step 4, RF propagation uncertainty is passed to the probability of detection for the given radar to determine I ( (I.  In step 3, the uncertainty in probability of detection by a given radar is passed to the total probability of detection relation to determine P(Di) ( P(Di).  And so on, until in step 1, PRA MOE ( (PRA MOE, is calculated.The example described here tracks only one part of the uncertainty in the PRA MOE due to uncertainty in atmospheric temperature.  The atmospheric temperature appears in many of the sensor effects algorithms as well as in other military systems models for the PRA Federation.  To determine how the uncertainty in atmospheric temperature totally affects the uncertainty in the PRA MOE, every one of these links must be traced back and the relevant calculations performed.  Then it will be possible to state that uncertainty in atmospheric temperature of a given size contributes to an uncertainty of a given size in the PRA MOE.Another level of complexity is added when additional contributing factors at any stage of the uncertainty propagation are considered.  When multiple factors affect any object, the proper method of combining uncertainties must be considered.  Consider, for example, the effects of multiple environmental factors on propagation loss.  We define propagation loss (PL) as a function of these environmental factors (EVi) as  EMBED Equation.3  .  If we have expressed the uncertainty of each environmental factor as a standard uncertainty u(EVi), we can calculate the standard uncertainty of the propagation loss, u(PL), as  EMBED Equation.3  where u(EVi,EVj) is the covariance associated with EVi and EVj.  If the uncertainties of the environmental factors were expressed differently, a different method for combining them would be required.5.  Conclusion  This paper has described the use of the Environment Concept Model as a tool and technique to identify, trace and document the objects and assumptions associated with the evaluation of the Probability of Raid Annihilation.  The Environment Concept Model provides the ability to define the properties of systems, models and simulations such that the relationships among these entities are also captured.  Furthermore, the ECM can capture and document the specific algorithms used.  As described here, the PRA ECM has focused the natural environment subsystem.  Finally, it has been demonstrated that the information in the ECM can be analyzed and applied to addressing the uncertainties in the PRA MOE.  In conclusion, the ECM can provide a tool for the tracking and evaluation of uncertainties in addition to defining requirements and providing a basis for validation and verification, as has been shown in earlier paper.6.  ReferencesBoman, M., Bubenko Jr., J.A., Johannesson, P., and Wangler, B.:, Conceptual Modelling, Prentice Hall, 1997 HYPERLINK "" .Booch, G, Rumbaugh, J, and Jacobson, I.:, The Unified Modeling Language User Guide, Addison Wesley, 1999.  Chadbourne, C. and Clark, D.:,  Building, Using, Sharing and Reusing Environment Concept Models,, SISO paper 99F-SIW-093, September 1999.Chadbourne, C., Clark, D. and Neel, T.:, Insuring Consistent Synthetic Environmental Representation across an Engineering Federation - A first Use Case, SISO paper 98F-SIW-097, September 1998.Fowler, M. and Scott, K.: UML Distilled – Applying the Standard Object Modeling Language, Addison Wesley, 1997.Grigsby, S. and Blake, D. W.:  Assessing Uncertainties in the Probability of Raid Annihilation, SISO paper 01F-SIW-077, September 2001.Numrich, S. K., Dobey, V., Chadbourne, C., and Clark, D.:, Environment Concept Model:  A Step Toward Validation”, paper presented at SimTecT Conference, July 2000.Reading, R. A. and Pobat, M.:, Common Threat Representation in Simulation and Testing of Ship Self Defense, SISO paper 00S -SIW-129, March 2000. AcknowledgementsAuthor BiographiesVisiTech gratefully acknowledges sponsorship by two programs.  The PRA Assessment Process is sponsored by seven Navy Program Executive Offices  (PEOs) with the PEO for Theater Surface Combatants (TSC) providing leadership.  Ron Sawyer, PEO TSC Director for Modeling and Simulation, provides program direction and management for the PRA Federation.  MARVEDS is sponsored by the Navy Modeling and Simulation Management Office (N6M).  Dr. S. K. Numrich at the Naval Research Laboratory provides program direction and management.  Stan Grigsby is a Senior Environmental Systems Engineer with VisiTech, Ltd. in Alexandria, VA.  He supports the MARVEDS and PRA programs.  He served as the Meteorology Officer on the USS Tarawa and developed and managed environmental effects programs for the Navy High Energy Laser Project.  He served as a program manager in the Strategic Defense Initiative Organization.  Currently his work is focused on the application of systems engineering practices to the evaluation of environmental effects on Navy systems.  He has a BS in physics and an MS in meteorology.DONNA W. BLAKEonna W. Blake is a Senior Scientist with VisiTech, Ltd. in Arlington, VA, supporting the MARVEDS and PRA programs.  She is a former Chief of the Office of the M&S Ocean Executive Agent and has performed research in both ocean and atmosphere modeling at several universities and Navy laboratories.  She has served as a program manager for ocean sciences at NASA and for atmospheric sciences at NSF.  She has a BA in physics and an MS in astro-geophysics, both from the University of Colorado, and a doctorate in geosciences from the University of Chicago.STAN GRIGSBY is a Senior Environmental Systems Engineer with VisiTech, Ltd. in Alexandria, VA.  He supports the MARVEDS and PRA programs.  He served as the Meteorology Officer on the USS Tarawa and developed and managed environmental effects programs for the Navy High Energy Laser Project.  He served as a program manager in the Strategic Defense Initiative Organization.  Currently his work is focused on the application of systems engineering practices to the evaluation of environmental effects on Navy systems.  He has a BS in physics and an MS in meteorology.STEPHEN KASPUTIS is These are not necessarily the same thing.  Considering the case represented in Figure 1 as an example, the uncertainty in the received signal may be most sensitive to the uncertainty in the noise.  That is, changes in uncertainty in noise result the largest relative changes in received signal.  Yet the situation may be such that the uncertainty in noise is low while that in scattering is high and thus the uncertainty in scattering contributes a greater absolute uncertainty to that of the received signal. To facilitate this aspect of FOM development, the content of the conceptual model should be expanded to identify all conditions that can or will vary during the lifetime of the federation, including computing hardware and network topology.  For example, if a federate is to be capable of running on different computers with different processor speeds, this must be reflected in the conceptual model.PAGE  PAGE  9	