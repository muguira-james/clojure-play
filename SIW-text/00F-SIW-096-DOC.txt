Distributed T&E Testing Utilizing TENA Applications as HLA FederatesJason L. Lucas96 CG/SCTOS201 West Eglin Boulevard, Suite 258Eglin AFB, FL 32542(850) 882-8169lucasjl@eglin.af.milRobert A. Kent96 CG/SCTOS201 West Eglin Boulevard, Suite 258Eglin AFB, FL 32542(850) 882-2693kent@eglin.af.milKeywords: TENA; HLA; T&E; Distributed Simulation; HWILABSTRACT:  Since its inception, the goal of the Test and Training Enabling Architecture (TENA) has been to foster the domain specific software reuse needs of the Test and Evaluation and Training ranges.  The TENA Prototype was developed to serve as a test bed for both the TENA Object Model and the TENA Services deemed necessary to provide functionality for applications.  This paper focuses on the conversion and development efforts for TENA Applications that serve as HLA Federates in a T&E Air-to-Air Missile Federation.  The utility of the TENA Object Model and TENA Services provided in the TENA Prototype will be assessed.  Additionally, results and lessons learned will be presented from a distributed test between multiple TENA Applications communicating via HLA over a long haul network.  Finally, suggestions for changes to the TENA Object Model and Services will be reported.1.  IntroductionThe infrastructure at existing Open Air Ranges (OARs), Installed Systems Test Facilities (ISTFs), Hardware-in-the-Loop Facilities, and Modeling & Simulation Centers is quickly becoming too expensive to support under Department of Defense (DoD) budget constraints.  One of the ways to reduce test and training range infrastructure costs can be realized by minimizing duplication of effort between the numerous test ranges and facilities.  However, the practice of reusing preexisting software for range assets, facility systems, or simulation models is currently rare and almost never a simple and straightforward process.  Several programs are addressing the universal problem of interoperability, sharing, and reuse, but the solutions are not ideal for all applications.  The extent of interoperability requirements is often too broad to be fully defined and satisfied by a given architecture.  The old adage ‘you can’t satisfy everyone all the time’, definitely applies to this problem.  Yet, by limiting the interoperability and reuse requirements to a specific domain, the problem becomes solvable. The Central Test and Evaluation Investment Program (CTEIP) Foundation Initiative (FI) 2010 recognized the limitations of the current paradigms, architectures, and protocols and funded the development of a common test and training range architecture specific to the test and training range domain.  The resulting common architecture is called the Test and Training Enabling Architecture (TENA). [1]1.1  BackgroundThere are three primary elements that comprise TENA; an Object Model, a set of Object Services, and a set of Standards.  These TENA elements were evolved over several years and were documented in a series of reports.  In fiscal year 1999, the FI 2010 program recognized that TENA had matured to the point where TENA Prototype software would be useful in defining the requirements as well as in evaluating a subset of the primary TENA elements.  To avoid confusion between the overall comprehensive TENA definition and the TENA Prototype, the TENA Prototype was given the code name ‘IKE’.The FI 2010 program has partnered with five test ranges to establish Development Test Cells (DTCs) to provide the resources for the development, testing, and evaluation of common architecture products and tools.  The DTCs are located at the Air Armament Center (AAC)-Eglin AFB FL, Naval Undersea Warfare Center-Newport RI, Naval Air Warfare Center Aircraft Division-Patuxent River MD, White Sands Missile Range-White Sands NM, and Redstone Technical Test Center (RTTC)-Huntsville AL.One of the first tasks for the DTCs to perform was a High Level Architecture (HLA) risk reduction exercise by implementing realistic range specific scenarios with HLA.  Eglin’s DTC decided to recreate the Joint Advanced Distributed Simulation (JADS) System Integration Test (SIT) exercise by implementing the scenario in HLA instead of DIS.  The test was dubbed JADS SIT II.  We revisited this scenario for our IKE testing since it is applicable to our typical range activities and we thought it was important to keep a stable scenario in order to contrast and compare the various implementations of HLA and IKE.  After reporting the performance, lessons learned, and results from the JADS SIT II HLA risk reduction exercise, the Eglin DTC was tasked to help evaluate the TENA Prototype known as IKE.JADS SIT II Scenario ComponentsThe participants involved in the JADS SIT II scenario are, as illustrated in Figure 1, a Target Aircraft simulation, a Shooter Aircraft simulation, and an Air Intercept Missile (AIM) simulation.Figure 1.  JADS SIT II ParticipantsThe Target and Shooter simulations are unclassified 6-Degree-of-Freedom (DOF) aircraft models that produce Time Space Position Information (TSPI). The TSPI generated is indicative of the data generated by actual aircraft on the OAR, or from aircraft in one of Eglin’s ISTFs such as the Preflight Integration of Munitions and Electronic Systems (PRIMES) Facility.  The AIM is an unclassified 6-DOF medium range air-to-air missile simulation that is representative of systems that are tested on Eglin’s OAR.  The AIM simulation calculates the miss distance, or point of closest approach, between the AIM and the Target aircraft as a measure of effectiveness.  A synchronous and sequential order of updates needs to be maintained between the simulations to ensure the test objects all stay in phase with each other.  The sequence starts with the Target, then the Shooter, and then the AIM to complete the update.  Numerous engagement scenarios can be configured by setting up ‘Flight Cards’ as input to both the Shooter and Target aircraft.  When run together, the Target and Shooter aircraft fly scripted profiles as defined on the flight cards while the AIM launches from the Shooter aircraft’s position in an attempt to intercept the Target aircraft.  The AIM is configured to launch a new missile a few seconds after the termination of an active missile. 1.3  IKE StructureIKE is composed of three main elements, the Object Model, Object Services, and a set of standards and protocols.  The IKE software itself is coded in Java.  Java was chosen because it offered machine independence between many of the primary test range computer platforms.  The following paragraphs describe the IKE structure presented in Figure 2.1.3.1 Object ModelThe Object Model implemented in IKE is a subset of the TENA Object Model.  The TENA objects included in IKE are environment, sensor(s), participant(s), display(s), and command and control objects.  The objects represented in IKE were the ones deemed necessary to support initial range experimentation.  Additionally, the content of the implemented objects has not been fully defined.  However, the object model organization does not prevent a user from expanding upon the contents of a particular object, i.e. adding additional attributes, relationships, etc.    This provides the user with more flexibility when an application requires more definition than the object model provides with the standard object.  Other applications that request TENA Objects information will only see the standard object content. However, applications may ask for and receive the extra information within the object when a specific request for them is made.1.3.2 Object ServicesThe Object Services element provides a common applications programmers interface (API) to isolate implementation details for object operations.  This provides an isolation layer to applications that promotes reuse and prevents frequent code changes in applications.  The same application code can be used to exchange data using HLA in one test, and DCOM in another.  Figure 2 depicts the structure of the IKE elements.1.3.3 Standards and ProtocolsThe standards and protocols element is implemented in IKE through several mechanisms.  The provision for many different transport protocols is made with the IKE Data Interface (DI) layer.  The IKE DI is designed to include many separate sub-interfaces to both typical transport protocols and user defined transport mechanisms.  The IKE DI layer includes an HLA DI and two examples of custom DIs.  The DIs function like an API between the IKE middleware and a specified protocol.  This concept is designed to foster both reuse and interoperability by allowing range applications the freedom to maintain their existing internal data generation and exchange methods while incorporating both standard and custom transport mechanisms for communicating between ranges.  In addition, the finalized TENA Object Model will provide a set of standard sign conventions, units, etc., to further enhance the reusability of applications. [2]  Figure 2.  IKE Components 1.4  ObjectiveTo more completely understand IKE and to refine the requirements for the future TENA, tests were performed on the IKE software.  These tests included a distributed test between Eglin and RTTC which exercised several IKE applications that simulated a real testing environment.  There were several goals for the distributed tests.  First, we wanted to fully test the HLA DI that was developed for IKE.  We  had observed several possible design and/or implementation  problems with the HLA DI that needed to be investigated.  The performance impact of the problems needed to be assessed.  Our second goal was to cooperate with another DTC to increase the exposure of our tests to personnel with IKE experience.  At the same time we would increase the educational value of the test.  Our last goal was to establish, and characterize a network connection between Eglin and RTTC.  We needed to demonstrate the distributed connectivity between our IKE applications to verify our respective firewalls could be correctly adapted to allow the Run Time Infrastructure (RTI) and other applicable transport mechanisms and protocols to correctly communicate over the network.IKE TestingAfter IKE was released to the five DTC’s for testing,  each DTC was provided an IKE Test Plan.  The plan provided each DTC with the flexibility to execute each test in the plan in a unique manner to evaluate how well IKE performed within each DTC’s own range environment.  The overall goal for the testing was to provide each DTC with the opportunity to evaluate IKE with applications and scenarios that were of importance to each of the DTC’s host range.  The test range scenarios that evolved from performing the tests in the IKE Test Plan emulated real-world testing efforts that are conducted at each DTC’s range.This testing approach exposed IKE to a variety of unique mission areas and environments to more fully evaluate IKE.  The IKE testing was also valuable in familiarizing the ranges with TENA, and in refining the requirements for follow on IKE development efforts.2.1  Test ArchitectureIn an object centric view of the air-to-air missile engagement scenario, the participants are a Target object, a Shooter object and at least one AIM object.  All communication between the objects is performed via the IKE HLA DI and all of the state updates for the objects are managed and performed by the IKE services.As noted previously, IKE instantiated only a subset of the TENA Object Model and Object Services.  This presented us with a limited set of IKE objects to choose from when developing our IKE applications.   In this case, we utilized the TENA Participant Object and the TENA Environment Object to implement the JADS SIT II scenario.2.2  IKE Test StrategyWe attended four training sessions to become familiar with the IKE software and to develop test scenarios to satisfy the IKE Test Plan.  The IKE Test Plan outlined eight high level tests to exercise the functionality of IKE.  The tests performed are listed as follows:Move dataDiscover modifications dynamicallyDisplay TENA participant dataDisplay live data describing a TENA participant on a rangeDisplay TENA participant data received from an HLA federationDisplay TENA Objects from multiple data sources simultaneously on multiple viewsDemonstrate ability to dynamically change range environment (e.g. lat/long)Receive & display raw data from a sensor.As noted above, we chose the JADS SIT II scenario to satisfy the bulk of our DTCs IKE testing points.  The JADS SIT II scenario was chosen because it was very representative of the mission at AAC and we could use our HLA risk reduction test results as a baseline to compare against.  Another benefit of choosing this scenario is that it allows us to directly compare the HLA and TENA architectures and to note the pros and cons of each approach.  Table 1 presents an overview of the testing performed according to the IKE Test Plan. [3]When viewed together, the eight tests indicate the IKE design is primarily focused towards display type applications.  In that regard, the services implemented and the TENA Objects built into IKE are primarily used to support a range display.  While our testing generally ignores this tendency, we must be careful to weigh our results accordingly where our simulation applications may have used some services and objects that may not have been optimized or extensively tested by the IKE developers.It is also important to note that when fully implemented the TENA Object Model, Object Services, Data Interfaces, Standards, etc. will not be biased towards any specific application type, such as display applications in the IKE prototype version.  This characteristic of IKE is a result of its evolution.  It was born out of a range display improvement program where IKE had the requirement to receive data and provide object services to a range display system. 2.3  AssumptionsThe IKE Test Plan stated the tests in a nonspecific general manner.  This allowed each DTC the flexibility to test IKE as each saw necessary.  However, this left significant room for different interpretations of the test requirements.  When we conferred with the other DTC testers, we realized that we were the only DTC that had started ‘from scratch’ to develop our own IKE applications for tests 1 through 3.   We assumed the test plan intended for us to develop our own test applications, where the other DTC’s felt the supplied IKE display applications were sufficient to accomplish the tests.  Our assumption actually aided our later testing by allowing us to systematically ramp up on the processes and techniques necessary to implement our applications.  Along the way, we discovered a few anomalies that we reported back to the IKE developers that resulted in the release of a patch.2.4  Data InterfacesThe DI’s work to isolate user applications from varying data formats across different data sources.  The DI is responsible for communicating data to and from its data source.  In doing so, it is responsible for providing the data back to the Object Model. [4] 2.4.1 Socket Data InterfaceTo perform the tests in the IKE test plan, we developed our own data interface to directly access sockets for network communications.  Our Socket DI was built for several reasons.  The first was that we needed a simple DI that we knew worked when we started our IKE testing.  Another reason was to demonstrate that IKE could be configured to correctly read and transmit custom range data formats.  Finally, we wanted to demonstrate that an IKE application could simultaneously communicate to two different DI’s correctly.  Unfortunately, we discovered the HLA DI implementation does not permit an application to be used with another DI simultaneously.2.4.2 HLA Data InterfaceThe IKE HLA Data Interface was designed to function as a gateway to HLA for the RTI1.3v6.  Although the HLA DI does not provide a complete gateway to HLA, it does provide for basic federate services.  Some of the services not implemented in the HLA DI that were needed to directly compare the IKE JADS SIT II exercise with our previous HLA risk reduction exercise include time management and reliable message transport.  The HLA DI also does not accept complex data types.  However, the DI is designed to be expanded upon to incorporate the majority of HLA functionality.2.5  HLA to IKE Transition ProcessAs previously stated one of our primary goals for testing was to reimplement the JADS SIT II HLA risk reduction scenario as an IKE application to utilize the IKE HLA DI.  This conversion process was not as straightforward as we anticipated.  In our first step, we had to modify our legacy applications to remove the complex data types and utilize individual attributes only.  The second step was to adapt our legacy applications to be callable from Java as several Dynamic-Link Libraries (DLLs).  We found that we could not just precompile the legacy C++ code as a DLL.  We had to utilize the Java Native Interface (JNI) to incorporate our legacy application into the IKE environment. To accomplish this we had to add a headerTest #DescriptionObjectsDataInterfacesStatusResults1Move data.Participant,EnvironmentSocket DI(Successful2Discover modifications dynamically.Participant,EnvironmentSocket DI(Successful3Display TENA participant data.Participant,EnvironmentSocket DI(Successful4Display live data describing a TENA participant on a range.Participant,EnvironmentSocket DI(Successful5Display TENA participant data received from an HLA federation.Target, Shooter, MissileSocket DI,HLA DI(Successful6Display TENA objects from multiple data sources simultaneously on multiple views.Target, Shooter, MissileSocket DI,HLA DI(Successful7Demonstrate ability to dynamically change range environment (e.g., lat / long).Target, Shooter, MissileSocket DI(Successful8Receive / display raw data from a sensor.Target, Shooter, MissileSocket DI,HLA DI(SuccessfulTable 1. IKE Test Plan Overviewfile to our legacy code before we compiled them into DLLs to specify their location to the calling Java program.The third step was to determine how to pass the data produced from our legacy DLLs to the HLA DI.  Initially, we noticed there seemed to be problems with all the data getting to and through the HLA DI.  Our test applications were only receiving some of the attributes some of the time.  We worked around this problem by creating our own objects for the Target, Shooter, and AIM.  We avoided the overhead of always publishing and subscribing to all of the attributes within the IKE Participant and Environment Objects.  Our new objects only had the minimum attributes necessary to represent the Target, Shooter, and AIM.  Finally, we completed the implementation of the IKE JADS SIT II federation by instituting our own logical time management for each federate.  This allowed us to crudely replicate the regulated and constrained behavior of our risk reduction exercise.  Our new logical time was simply an integer counter attribute that is passed to each federate which checks their current logical time versus the supplied update time.  The federate then updates to the current step and publishes their attributes.  This continues until the AIM completes its update, which is only attempted when the updated Shooter and Target data has been received.  The AIM federate then increments the counter attribute for the process to repeat for the next time step.2.6  Distributed TestingA distributed test between Eglin AFB Florida, and the RTTC, Huntsville AL, was conceived to further exercise the HLA DI, and also to put some of the TENA/IKE concepts into practice.  The test configuration was to run the Target and Shooter applications at Eglin, and run the AIM at RTTC.  The computer platforms utilized for the test were a 400MHz Pentium Class PC with 384MB RAM running WindowsNT at Eglin and a 366MHz Pentium with 64Mb RAM running Windows98 at RTTC.  Since this test was performed over wide area network (WAN) connections, several necessary modifications were made to the RTI.rid file.  Eglin ran the RTI1.3v6 and the IKE applications acted as the reliable distributor for the test. The entries in the tcpSocketManager section of the Eglin Rti.rid were configured as noted below:      (auto_reldistr_config 0)	;boolean, OFF      (reldistr_on 1)		;boolean, ON      (auto_discover_on 1)	;boolean; ON      (discov_string "RELDISTR")	;discovery string      ...      (tcp_netdev "")		;reliable net device      (reldistr_forced_discoveries	        (max_port_increment 0)	;zero        (          ("###.##.###.###" 5996 "RTTC")        )       )The tcpSocketManager section of the RTTC RTI.rid file was configured as noted below:      (auto_reldistr_config 0)	;boolean, OFF      (reldistr_on 0) 		;boolean, OFF      (auto_discover_on 1) 	;boolean, ON      (discov_string "RELDISTR")	;discovery string      …      (tcp_netdev "")		;reliable net device      (reldistr_forced_discoveries        (max_port_increment 0)        (          ("###.##.###.###" 5996 "RELDISTR")       )      )In addition to the RTI.rid files, the *.fed files must be modified to specify reliable transport for all attributes.Before any connections could be established, the Eglin network firewall needed to be modified to allow for two way communication between the IP addresses specified in both the RTI.rid files.  The firewall was also configured to allow for the dynamic allocation of ports for the Eglin IP address.Our planned connectivity for the distributed test was to utilize the existing Defense Research and Engineering Network (DREN) connections by establishing a Switched Virtual Circuit (SVC).  Preliminary round trip latencies between Eglin and RTTC over a DREN SVC averaged 30 milliseconds (ms).An initial distributed test was performed to verify the firewall and RTI.rid file configurations.  The initial test utilized an Internet connection between Eglin and a contractor facility, Amtec Corporation, in Huntsville, where a DREN connection was not available.  The round trip latencies varied significantly during the day, with the shortest latencies averaging 110 ms in the morning and the long latencies averaging 900 ms in the afternoon.  All communications were reliable transport, TCP/IP.  Our network personnel notified us that at the time of our testing the Internet connectivity was marginal at best.  Besides competing with Internet traffic, some of the difficulties we experienced in establishing connections and the long latencies were attributed to AT&T network difficulties related to both solar flare activity and severe thunderstorm activity at Eglin and Huntsville.The initial distributed test was not completely successful.  The RTI, Federation Executive, Target Object, and Shooter Object were started at Eglin.  The AIM Object was started at the contractor facility in Huntsville.  All the federates joined correctly, and the federates began to exchange data.  The first missile shot in our scenario requires approximately 13 seconds of missile flight time to intercept the Target.  However, our initial tests were not able to achieve flight times in excess of 8 seconds.  Although the distributed test performed marginally at best, we satisfied our initial goal of verifying the firewall configuration and achieving connectivity via HLA.  The poor Internet connection significantly affected the test, but we attribute the poor results to the implementation of the HLA DI’s stack algorithm.  We conferred with the IKE developers when we first started testing with the HLA DI and noticed the poor performance.  The developers notified us that the HLA DI implementation could drop some attribute updates as they are stacked in a ‘first-in, last-out’ manner in memory.  We then implemented our own logical time management scheme, as discussed earlier, between the applications in an attempt to limit the amount of updates accumulating and being dropped from the stack.The second phase of testing was performed utilizing the DREN between Eglin and a test location at RTTC.  The same computer platforms were used for the second phase of testing.  Due to the limited memory available on the RTTC test computer, we experimented between running the different combinations of the applications at both Eglin and RTTC to determine the best performance.  The best performing combination was running the RTI, Federation Executive (FedExec), and the AIM Object at Eglin and the Target Object and Shooter Object at RTTC.  Even with this best case combination, we still experienced problems.  Instead of terminating around an 8 second flight time as in our initial tests, we were only able to run a couple of missiles out to termination before the test failed during the third missile’s flight.  The improved and faster DREN connection did not alleviate the difficulties we had experienced with the HLA DI implementation over the Internet.  We believe the HLA DI’s stack for each of the objects would slowly grow until the memory utilized would force one of the computers to swap memory to virtual space on the hard drive.  The added delays due to swapping would eventually cause the RTI to give up on federates that quit responding.  The memory utilization history that was observed on the Eglin platform is recorded in table 2.EventMemory UtilizedBefore Test 42.124 MbRTI Start45.341 MbAIM Object and FedExec Start88.060 MbMissile 1, 6 sec flight time97.624 MbMissile 1, 10 sec flight time108.680 MbMissile 1, 13 sec flight time121.616 MbMissile 1, termination, 18 sec flight time121.980 MbMissile 2, termination, 10 sec flight time122.128 MbMissile 3, 4 sec flight time135.140 MbMissile 3, 5 sec flight time137.210 MbTable 2. Eglin Memory Utilization History2.7  PerformanceA fair comparison of federation performance between the HLA risk reduction exercise and the IKE HLA DI could not be made at this time.  The IKE HLA DI does not provide all of the services such as time management that are necessary for the comparison.Since IKE is coded in Java, we initially had reservations about real time performance.  We implemented a Socket DI that directly accesses the sockets for communications.  We achieved real time performance for our three IKE applications communicating via the Socket DI on a LAN.Lessons LearnedAs with any testing effort, there were many lessons learned from the IKE testing project.  Some of the most significant are listed below.Legacy non-Java DLLs can be called from Java applications by utilizing the Java Native Interface (JNI).  However, JNI does require a ‘front-end’ to the legacy code which hard codes the header file created by “javah –jni” when it is run on the application.We validated the concept for having multiple DIs in IKE when we built our own DI to directly access the sockets for communication between the applications.  It proves the case that sometimes a custom transport solution may be better for certain applications.  The IKE implementation of the OM and DI’s requires additions to be hard-coded into several routines.  This implementation could force the IKE middleware to perpetually grow as objects and DIs are added to IKE.  We need to rework the current IKE structure to decouple the OM and the DI’s from the middleware.IKE is designed to execute with event based applications, not  frame based simulations.  This makes the synchronization of events between simulations and live data steams difficult, if not impossible.Currently, when the HLA DI is utilized, it is the only DI that can be run with an application.  We need the ability to use another DI simultaneously with the HLA DI in the same application.  A single TENA application could then import data from range assets through a range DI, and export data via HLA.The HLA DI did not provide all of the necessary services for us to directly compare our IKE HLA implementation to the native HLA implementation.  We need to add time management, and complex data types to the HLA DI.ConclusionsIKE is a prototype.  By definition, it should be used to refine the requirements for a more formal product. Although we experienced difficulties in utilizing IKE for non-display applications, it proved to be a very useful tool to help generate requirements.  IKE also did an excellent job of conveying the concepts for TENA.  We were also very impressed with the extent of TENA content  that was implemented in IKE.    It is also worth noting that IKE functions quite well as a data receiver and it is serving operationally to drive a display system for a range upgrade program.4.1  Does IKE Promote Reuse?There have been several efforts, including the HLA, that have demonstrated interoperability, but it has not necessarily been easy to reuse these applications in test range environments.  Even considering some of the shortcomings that we discovered during IKE testing, IKE has proven that efficient reuse is possible.  The IKE implementation may not have been clean, but in most cases we were forcing IKE to perform tests that were not IKE’s forte. The three fundamental elements of TENA that were built into IKE  do work.  We repeatedly reused our test applications across several systems to perform different tests with different DIs and they ran without any code changes to the applications.  This implies that any range or facility that has implemented a DI to provide data to the IKE middleware can seamlessly utilize any application that is ‘IKE compliant’, i.e. utilizing the OM and supplied services.We now have to ask, “What is the cost to port code into the TENA/IKE environment?”.  Our initial time investment for building the IKE test applications was larger than it would have been for an HLA application.  But most of the extra effort was due to our Java learning curve.  The documentation available to the DTCs when the testing began was also quite limited which contributed to the time it took for us to get familiar with the IKE software.  However, we finally came up to speed after attending a series of ‘hands-on’ training sessions with the IKE development team.  When contrasting the development time for HLA and IKE applications, we must also remember that the typical HLA FOM-o-rama process will be significantly shortened, if not eliminated, by using TENA/IKE applications that use a common object model.Future EndeavorsSome of our planned future endeavors  include:CTEIP/FI2010 has funded IKE II development.  All of the range DTCs involved with testing the original IKE software will participate in the development process.  The DTCs will coordinate to refine the requirements for IKE II.  During the development efforts, the DTCs will participate as members of the IKE II Oversight Team, Test Team, and the Architecture Team. The Eglin DTC has partnered with CTEIP/FI2010 to develop a Joint Strike Fighter (JSF) Virtual Strike Warfare Environment (VSWE) event number 7 Test Bed.  The test bed will locally recreate a scaled down version of VSWE 7 on a secure LAN to facilitate the testing of future products for the Test and Evaluation community.The Eglin and RTTC DTCs have partnered to support customer testing by developing a Distributed Development Test Bed.  This test bed is an Army and Air Force collaboration that will establish a distributed testing capability for helicopters between the PRIMES facility anechoic chamber, hardware in the loop simulation labs at RTTC, and tank targets on the RTTC range.  Additionally, a connection will provide certified threat simulations and another connection to Fort Rucker AL will link flight simulators for training.References [1] “Test Capabilities Requirements Document for Foundation Initiative 2010 (FI 2010)”, U.S. Department of Defense, White Sands Missile Range, White Sands, New Mexico, 12 September 1999. [2]	Dunn, Edward P. III, “TENA: A Domain-Specific Architecture for Live Participants”, 2000 Spring Simulation Interoperability Workshop, Paper 00S-SIW-107, Orlando, FL, March 26-31, 2000.[3]	“TENA Prototype Test Plan”, Central Test & Evaluation Investment Program, Foundation Initiative 2010, Washington DC, 9 June 1999.[4]	“Programmers Guide on Creating a Data Interface (DI) within the Dataware Software Component”, Central Test & Evaluation Investment Program, Foundation Initiative 2010, Naval Undersea Warfare Center, Newport, Rhode Island, 24 January 2000.[5]	“Programmers Guide on Adding an Object Definition to the TENA Object Model”, Central Test & Evaluation Investment Program, Foundation Initiative 2010, Naval Undersea Warfare Center, Newport, Rhode Island, 24 January 2000.Author BiographyJason Lucas is an Aerospace Engineer for the 96th Communications Group, Software Applications Support Flight, Modeling and Simulation Section (96CG/SCTOS) at Eglin AFB, FL.  Jason develops and manages surface-to-air missile simulations and antiaircraft artillery simulations for use in electronic countermeasures and munitions survivability testing.  He also serves on the IKE2 Development Team.Bob Kent is a Computer Scientist in the 96th Communications Group, Software Applications Support Flight, Modeling and Simulation Section (96CG/SCTOS) at Eglin AFB, FL. Bob has 22+ years of experience (20 in government service).  He has programmed extensively using FORTRAN, C, C++, and other Higher Order Languages on many different platforms and environments.  He also serves as the Eglin DTC Technical Lead.