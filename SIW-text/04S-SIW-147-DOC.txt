Scalability of Intervisibility Testing using Clusters of GPUs (Draft)Dr. Guy Schiavone, Judd Tracy, Eric Woodruff, and Mathew GerberIST/UCFUniversity of Central Florida3280 Progress DriveOrlando, FL  32826Troy Dere, Julio de la CruzRDECOM-STTC12423 Research ParkwayOrlando FL 32826Abstract – The processing power of graphical processing units in recent years has been increasing at a rate that exceeds the so-called “Moore’s Law” for general purpose CPUs, while the prices for these GPUs has dropped precipitously.  Beginning in the late 1990’s, researchers realized that this enormous processing power could be used to solve problems other than simply image generation.  Almost in parallel to these developments, other researchers began using dedicated networks of commodity computers and supporting network hardware to construct low-cost supercomputers (Beowulf clusters) capable of solving particular problems formerly requiring much more expensive proprietary supercomputers.  In this paper we examine combining these two concepts with the eventual intention of rapidly accelerating intervisibility calculations for CGF and constructive simulations.  We present initial experimental results on the computation time and scalability of using clustered GPUs to calculate intervisibility over densely populated terrain databases.   I. IntroductionThe transition of computing over the years into a mass market industry has transformed the economics of producing computer hardware, bringing the power of mass production into play to drive prices down while simultaneously increasing the computational power of commodity computing hardware at an exponential rate, an effect that some have called “Moore’s Law”.  This phenomenon has in turn inspired astute researchers into attempts to take advantage this effect by aggregating commodity hardware into cluster computers that for many problems rival the power of special-purpose machines of much higher cost.   Linux-based clusters, known as Beowulf clusters, were first developed at NASA CESDIS in 1994. The idea of the Beowulf cluster is to maximize the performance-to-cost ratio of computing by using low-cost commodity components and free-source Linux and GNU software to assemble a high-performance distributed computing system.At a slightly later date, as the power of 3-D graphical processing units (GPUs) in commodity video cards began to increase, other researchers began to realize that this hardware could be used for purposes beyond their intended use for real-time 3D graphics.  Some early examples of this include the use of GPU hardware acceleration in 1997 by Ihm, Park and Lee [1] for rendering spherical light fields, and the work of Heidrich in 1998 on the use of GPU accelerated calculation for producing view-independent environment maps [2].  Additional work that is relevant to the topic of this paper was published by Holzschuch and Alonso [3] in 2000 on the topic of using graphics hardware to speed up visibility queries in synthetic environments, the research into hardware accelerated visibility calculations of Koltun, Chrysanthou, and Cohen-Or [4], and the work of Rieglar [5] on point visibility in games.  More recently, much progress has been made by Dinesh Minocha and his group of researchers in using hardware acceleration for a variety of problems that map to GPUs (for example, see [6-8]).In this paper we conduct preliminary experiments into combining the two ideas described above.  Our research is aimed at answering the question of what degree of performance can be expected using GPUs to replace the traditional intervisibility algorithms used in CGF applications such as the OneSAF Testbed (OTB), and what kind of scalability can be obtained using Beowulf clusters equipped with GPUs as co-processors to perform intervisibility calculations.II. Intervisibility Algorithm The GPU Intervisibility algorithm relies on recent advances in 3D video hardware.  All recent cards produced by NVidia and ATI have a new OpenGL extension called NV_Occlusion_Query [9].  What this new extension allows is to query the graphics hardware how many pixels were rendered between the time a begin/end pair occlusion query calls were performed.  This extension was originally created to determine if an object should be rendered, but our algorithm takes advantage of it to see what percentage of an entity is actually rendered.The GPU Intervisibility algorithm works like any normal visualization system except that there are a few extra involved.  Because of the likeness to normal visualization systems we decided to use the tools that are available to those systems.  OpenSceneGraph [10] was chosen as the visualization framework because of three main factors.  First it offered an extensible system that could be extended fairly easily to perform the operations needed for this project.  Second it is developed as an open source project so if something could not be accomplished through the framework modifications could be made to the framework to accomplish our goals.  Finally OpenSceneGraph offers very high performance which allows our algorithms to perform more optimally.  Using OpenSceneGraph forces the use of an Update/Cull/Render paradigm and the rest of the algorithm will be described using this paradigm.The Update stage of the scene graph is where all data modifications are made that affect the location and properties of objects in the scene graph.  In this phase all entities positions and orientations should be updated along with all sensor orientations.  The scene graph is also traversed and the distance between each sensor and all entities is calculated.  This distance will be used in the Cull stage to determine if an entity should be rendered and also determines what order the entities should be rendered.  At this time a projection matrix is generated for each sensor to orient the camera in the proper position and direction.  In this algorithm there is only one call to the Update stage per time step.The Cull stage is where all geometry is checked against a view frustum to determine if is should be rendered.  In our algorithm another step is taken to cull entities.  Each entity has the concept of an Area-of-Interest in which if another entity is not in this area then an intervisibility test between these entities is not needed.  In our case we take the distances calculated in the update stage to determine if an entity should be rendered. For this algorithm the render order is critical for proper operation.  All terrain and static objects should be rendered first as they will always occlude.  Then all entities and dynamic objects should be rendered in a front to back order.  This is required so that we don’t calculate the visibility of entities that might be occluded by closer objects.  In this algorithm the cull stage is run once for each sensor that is being rendered.The last stage is the Render stage.  Here all of the terrain and static objects are rendered first.  Then each entity is rendered twice in front to back order wrapped with NV_Occlusion_Query begin/end calls.  The first time an entity is rendered the depth buffer and color buffers are disabled to obtain the amount of pixels an entity uses with out being occluded. Then the entity is rendered again with the depth and color buffers enabled to obtain the amount of pixels actually visible.  After all rendering is performed for each sensor the GPU is then queried for the number of pixels rendered for the entity in both modes and a percentage is generated.The distributed version of this algorithm is very simple in its current form.  Each node that runs the algorithm must have all entities and all the terrain loaded.  Then all of the sensors to be rendered are distributed evenly amongst the nodes and the algorithm proceeds as normal except each node reports visibility information back to the frontend.III. Initial ExperimentThe hardware components and specifications for each node of the computing cluster included:Compute Node – Dual AMD Athlon 1.33 GHZ, 512 MB RAM, Fast Ethernet networkGPU - NVIDIA GeForce FX5900 Chipset256MB DDR SDRAM 400 MHz engine clock 850 MHz memory clock 400 MHz internal RAMDAC 300 Million vertices/ sec 3.6 Billion texels/ sec fill rate 27.2 GB/sec memory bandwidth  8 pixels per clock rendering engine The experimental scenario used in our preliminary experiment is described below: This is the same scenario used in our companion paper submitted to this conference [11], but the figure is repeated here for clarity.A scenario was generated using correlated versions of the Ft. Polk Shugart-Gordon Database. The urban features were removed, since the early version Multiple Elevation Surface (MES) urban structures were not compatible with the OTB Version 1 that we used for comparative testing.  The sensor view frustrum parameters were set at 0.619406 radians horizontal and 0.508736 radians vertical, with no far clipping plane applied. The results for the visual algorithm were generated using a maximum 1600 x 1200 screen resolution and the algorithm described above.  The OTB results were generated using emulation of the actual OTB calls to libctdb to determine intervisibility.  For each number of entities tested, a scenario was configured manually so that some significant number of entities was expected to be within view of each other, and the scenarios were added cumulatively up to the number of total entity sensors of 300.  Each scenario was run 500 times, and the results shown below are the averages of all runs.  A top-down view of the scenario using 68 sensors is shown in a standard OTB planview display in Figure 1, below:Figure 1.  Scenario used for initial experiment.In this scenario view, the “sensors” are in blue, and it can be seen that the area is densely populated with individual trees, and also has significant variations in the terrain elevation.Intervisibility between all entities was compared, using an “Area of Interest” (AOI) in the form of 1 km radius. Results in terms of Intervisibility calls per second are given in Figure 2: SHAPE  \* MERGEFORMAT 2a) SHAPE  \* MERGEFORMAT 2b) SHAPE  \* MERGEFORMAT 2c)Figure 2.  Speedup and Scalability results for using GPU accelerated intervisibility calculations for 1-4 cluster nodes for the cases of 1, 4 and 16 sensors rendered per screen.For the sake of comparison, we give the OTB performance results below, in Figure 3 SHAPE  \* MERGEFORMAT Figure 3.  Performance of OTB in terms of LOS calls per tick and calls/sec.In a direct comparison between the GPU accelerated results and the OTB results, we can see that even using one node with GPU acceleration results a maximum performance ratio for a large number of entities of about 30 % of the OTB case, for the case of 16 sensor per screen and 300 entities.   However, the overall OTB simulation performance begins to degrade rapidly after around 200 entities, as shown by the large increase of the simulation “tick” size, shown below in Figure 4: SHAPE  \* MERGEFORMAT Figure 4. OTB CPU time per “tick”, showing degradation and poor scalability of OTB above 150 – 200 total entitles.On the other hand, the GPU-accelerated calculations show excellent scalability through the range of 300 entities, as shown in Figure 5, below: SHAPE  \* MERGEFORMAT Figure 5.  Scalability of GPU-accelerated intervisibility calculations.In Figure 5, the results show very good to nearly ideal scalability for the cases of 1-4 GPUs.  Since the sensors per GPU are distributed randomly per GPU at the start of the simulation, with no subsequent communication until intervisibility is determined, this excellent scalability is to be expected due to the negligible communication overhead.  That ideal scalability is not obtained is likely due to load imbalances resulting from the differing complexity of geometry being rendered by the different GPUs using this approach.  A pre-processing load-balancing step in the algorithm could be expected to improve the scalability results further by attempting to equalize the geometric calculations necessary for each GPU.  Scalability obtained by increasing the sensors per screen, from Figure 2, is not as efficient.  Part of the reason for this is that as more sensors are added per screen, spatial resolution is lost, but the same amount of geometric calculations must be performed for each sensor.  A level-of-detail scheme that matches geometric complexity to spatial resolution is expected to improve the scalability of rendering more sensors per screen, but at the cost of decreased spatial accuracy in the intervisibility ratio and partial occlusion discretization.Results and Ongoing WorkIn our near-term future work, we plan to accomplish the following:We plan to run more experiments on different scenarios and databases for both the purposes of increasing the statistical significance of our findings, and also to try and pinpoint from an empirical standpoint the “worst case” scenarios and specific situations that are likely to cause intervisibility miscorrelation.We will refine our load balancing scheme to obtain more linearity and better performance in our results.We will investigate geometric level-of-detail representations to improve the scalability of the results in terms of sensors/screen rendered.Increase the number of GPUs and rerun the scenarios.We will mathematically characterize the expected accuracy and error-bounds of the LOS query in terms of screen resolution used in our GPU-accelerated calculations.ConclusionsUse of multiple GPUs is a scalable approach, with potential performance on the order of and exceeding OTB, depending on the number of GPUs used. Parallelization/GPU is effective, parallelization in terms of sensors/screen requires geometry LOD adjustment to match reduced screen resolution/sensor.Approach has potential employment as “Intervisibility Server” that will both improve performance of CGF systems and improve correlation with visual systems.VI.  References[1] Ihm, I., Park, S. and Lee, R. K., "Rendering of Spherical Light Fields", Proceedings of the 5th Pacific Conference on Computer Graphics and Applications, 1997.[2] "Wolfgang Heidrich","View-Independent Environment Maps", "Proceedings of Eurographics/{SIGGRAPH} Workshop on Graphics Hardware, 1998.[3] Nicolas Holzschuch and  Laurent Alonso, “Using Graphics Hardware to Speed-up Visibility Queries”, Journal of Graphics Tools,  no. 2, vol. 5, pp. 33-47 2000.[4] Vladen Koltun, Yiorgos Chrysanthou, and Daniel Cohen-Or, "Hardware-accelerated from-region visibility using a dual ray space", 11th Eurographics Workshop on Rendering, PP. 59-70, June 2000[5] Harald Rieglar, “Point-visibility in Computer Games”, Seminar given  HYPERLINK "http://www.cs.tuwien.ac.at" Computer Science Department of the  HYPERLINK "http://www.tuwien.ac.at" Vienna University of Technology, June 6, 2001 (available online at: HYPERLINK "http://www.cg.tuwien.ac.at/courses/Seminar/SS2001/visibility/visibility_in_games.pps" http://www.cg.tuwien.ac.at/courses/Seminar/SS2001/visibility/visibility_in_games.pps)[6] Young J. Kim,  Ming C. Lin,  and  Dinesh Manocha, “Fast Penetration Depth Estimation Using Rasterization Hardware and Hierarchical Refinement”, Workshop on Algorithmic Foundations of Robotics (WAFR), Dec. 2002.[7] Kenneth E. Hoff III, Andrew Zaferakis, Ming Lin, and Dinesh Manocha. “Fast and Simple 2D Geometric Proximity Queries Using Graphics Hardware “, In Proc. of ACM Symposium on Interactive 3D Graphics, 2001. [8] Kenneth E. Hoff III, Andrew Zaferakis, Ming Lin, and Dinesh Manocha , “Fast 3D Geometric Proximity Queries between Rigid and Deformable Models Using Graphics Hardware Acceleration”, UNC-CS Technical Report, 2002.[9] See  HYPERLINK "http://oss.sgi.com/projects/ogl-sample/registry/NV/occlusion_query.txt" http://oss.sgi.com/projects/ogl-sample/registry/NV/occlusion_query.txt [10] See  HYPERLINK "http://www.openscenegraph.org/" http://www.openscenegraph.org/[11] Guy Schiavone, Mathew Gerber, Judd Tracy, Eric Woodruff, and Todd Kohler, “A Software Tool for Comparing Intervisibility Correlation between CGF and Visual Systems”, Paper # 04S-SIW-148, Presented at the Simulation Interoperability Standards Organization (SISO) Spring 2004 Simulation Interoperability Workshop, April 18 - April 23, 2004,  HYPERLINK "http://www.discoverourtown.com/TownPage.php?Town=267" \t "_blank" Arlington, VA.