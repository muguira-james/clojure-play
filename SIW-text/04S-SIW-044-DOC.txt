Aegis Ballistic Missile Defense Implementation of a High Level Architecture Based Distributed SimulationRobert A. Swift 	Lockheed Martin Maritime Systems and Sensors 199 Borton Landing RoadMS 13000-A Naval Electronics and Surveillance SystemsMoorestown, NJ 08057Rob.swift @lmco.comKeywords:High Level Architecture  (HLA)Hardware-in-the-Loop Simulator (HIL)Computer in-the-Loop Simulator  (CIL)ABSTRACT: The High Level Architecture (HLA) federation of MEDUSA, Lockheed Martin’s Aegis Weapon System (AWS) digital simulation and Raytheon’s Standard Missile-3 (SM-3) System Testbed demonstrated initial developmental objectives to successfully simulate a ballistic missile engagement and intercept via distributed simulation using a phased engineering developmental approach. At the Raytheon Missile Systems Company in Tucson, AZ, the SM-3 System Testbed includes all stages of the missile hardware as well as simulation entities. Working very closely in a rapid prototyping environment, Lockheed Martin and Raytheon engineers have achieved a subsequent developmental objective to create a higher fidelity model using a the SM-3 Hardware-in-the-Loop (HIL) missile model with MEDUSA in a similar  (HLA) federation. TThe challenges to these distributed simulations include threat generation, missile and target track queuing and extrapolation, and a time phased solution to account for link latency and millisecond level timing requirements for tactical uplink and downlink messages between MEDUSA and the SM-3 sSystem entities.BackgroundIn October 1999, as part of the the Navy Theater Wide (NTW) Block 1 Program Definition and Risk Reduction effort funded by Naval Sea Systems Command (NAVSEA) program code PMS400, an End-to-End (ETE) Hardware-in-the-Loop (HIL) concept was developed.  . As part of the NTW Block 1 HIL risk reduction effort, Phase I (of a three phase plan) developmental efforts established a distributed End-to-End   digital distributed simulation that characterized the planned link between the Aegis Combat System Engineering Development Site (CSEDS) in Moorestown, NJ, and the Raytheon Missile System (RMS) Standard Missile 3 (SM-3) HIL. The ETE digital distributed simulation model as originally conceived was comprised of the Lockheed Martin Maritime Systems and Sensors (LM MS2) NESS Aegis Weapon System (AWS) MEDUSA simulator, Aegis Leap Intercept (ALI) version, and the RMS SM-3 Computer-in-the-Loop (CIL) System Testbed (STB).  It has since been expanded to include the AWS CIL along with a Common Scenario Generator (CSG). Among the plethora of major subtasks that were defined by the Program Statement of Work, the most prominent within the scope of this paper were: Provide computer program engineering support of the MEDUSA ALI  digital model to include implementation of new algorithms and code modifications.Establish High Level Architecture (HLA) compliance between MEDUSA ALI and the SM-3 CIL and HIL.MEDUSA is a digital simulator used in operations analysis to examine predictability, correctness, and efficiency of AWS tactical algorithms prior to placing them on a ship. MEDUSA models AN/SPY-1BD (SPY) radars, Command and  Decision (C&D), and Weapons Control Systems (WCS) elements of the AWS, while also featuring a 5-DOF Trim-Aero SM-3 missile model in the NTW baselines. It simulates targets and the missiles that an Aegis ship would fire against these targets. MEDUSA runs on a Sun Workstation in a UNIX and Common Desktop or XWindow computing environment.  It is a Monte Carlo simulator in standalone mode and is capable of providing data output over many seeded runs. In distributed mode, MEDUSA initially was used in a proof-of-concept for threat intercept and for operational analysis of Flight Mission (FM) tests and Integrated Flight Test (IFT) flight tests when combined with the Raytheon SM-3 STB. Of note, the ALI version of MEDUSA did not have a surveillance (SURV) capability.  However, the subsequent  MEDUSA Ballistic Missile Defense (BMD) 04 version will have the surveillance SURV feature that allows for the acquisition and tracking of  ballistic missile threats  with advanced  AN/SPY-1B capability.The RMS SM-3 STB is a managed federation of modeling and simulation capability,  using the Department of Defense HLA standard to connect, in real time, digital simulations, CILs, and HILs. Remote Site Managers (RSMs) serve as the interface between standalone simulators in Tucson and Moorestown. Actual SM-3 modeling federates are the the SM-3 surrogates, the SM-3 CIL, the SM-3 6-DOF, and the SM-3 HIL.  In the summer of 2000, the above stated program was renamed ETEDS for End to End Demonstration System and in 2001 it was again renamed the End to End Distributed Development System or ETEDDS. The latter is currently a mainstay of  the Aegis Ballistic Missile Defense (BMD) program. In late 1999 and early 2000, the NTW development programs evolved into the BMD programs as the LM NESSMS2 programs in turn began a shift towards a broader capability focus under the Missile Defense Agency. LM NESSMS2 programs were then seen as contributors to a broader based BMD with a more strategic implementation.Three Phased Developmental Approach Using the FEDEPInherent in the program lifecycle was a three phase developmental approach to eventually bring CSEDS and the SM-3 HIL into a viable development system for risk mitigation based on an  Aegis BMD missile engagement as depicted in figurefigure  1.Phase I entailed a proof of concept whereby the AWS,  as represented by MEDUSA and later  AWS CIL,  would provide missile initialization and missile midcourse guidance via uplinks to the SM-3 STB utilizing the SPY, C&D, and WCS elements of the AWS . To close the fire control loop, MEDUSA received the missile status and downlinks from the SM-3 STB Surrogates initially, and later in development the SM-3 CILCIL. The MEDUSA link to the SM-3 STB was via a RSM situated in Moorestown, NJ as depicted in figure 2.. Phase I connectivity between MEDUSA and the RSMSM-3 CIL STB utilizedinvolvedd  TCP/IP sockets, which facilitated the passing of the uplink and downlink messages.. Phase II was a refinement of Phase I to further demonstrate the feasibility for linking the AWS CIL and eventually CSEDS with the SM-3 HIL but instead utilizing HLA as the medium for data exchange. Phase III incorporated AWS-CIL and MEDUSA as interchangeable AWS modeling components, both capable of effecting a successful intercept of a ballistic missile. Additionally, either AWS component, hereto known as an AWS HLA federate, could assume the role of target generator, AWS model, or both. Refer to  figure 2 for a depiction of the three phase development architecture. MEDUSA also was designated to be HLA compliant and to operate interchangeably with the SM-3 CIL and HIL.Phase II was a refinement of Phase I to further demonstrate the feasibility for linking the AWS CIL with the SM-3 HIL  but utilizingHLA as the medium for data exchange. Phase III incorporated AWS-CIL and MEDUSA as interchangeable AWS models, both capable of effecting a successful  intercept of a ballistic missile. For the purpose of this paper, the focus is on the evolution of MEDUSA in the three phased  developmental approach and the HLA capability the LM NESSMS2 MEDUSA engineering team achieved working in a rapid prototyping environment with the RMS SM-3 engineering team.The Federation Development and Execution Plan  (FEDEP) is a systems engineering approach to HLA federation development. The FEDEP was extremely useful in creating a robust Federation Object Model (FOM) and Conceptual Model in Phases II and III. Phase I  Conceptual ModelThe concept details a time phased, distributed simulation architecture between CSEDS and the SM-3 HIL that The concept details a time phased, distributed simulation architecture between CSEDS and the SM-3 HIL that closes the Fire fire cControl lLoop in real time for all phases of a ballistic missile engagement from radar search and detection through SM-3 target intercept and kill evaluation. The integration testing exercised MEDUSA ALI and the SM-3 CIL software with the ALI scenario Version 1.3 target. This scenario was recorded during a Navy test shot of a live SM-3 missile against a live TTV-1 (Target Test Vehicle) target from an Aegis  ship in the autumn of 1999. The objective was to allow MEDUSA to send guidance commands to the SM-3 CIL using uplinks and receiving downlinks similar to those used in the tactical weapon system. To achieve this interaction, UNIX socket technology  was used to allow MEDUSA and the Moorestown RSM to communicate. The Moorestown RSM acted as MEDUSA’s HLA proxy and it was connected to the Tucson RSM using a secure encrypted ISDN line in a HLA environment. Both MEDUSA and the CIL ran an identical copy of the threat target files. Time synchronization was achieved using synchronization messages and blocking socket reads.The messages transacted between MEDUSA and the SM-3 CIL were:Missile InitializationSystem Testbed ControlMEDUSA ControlMissile StateTarget StateUplinkDownlinkA common header was affixed to each message which contained a transmit time tag. In the absence of radar modeling of the SM-3, the downlink messages were appended with the missile position and velocity for incorporation into MEDUSA missile midcourse guidance algorithms. This fresh position and velocity data is then used in forming the next uplink message.To account for system latencies between Moorestown and Tucson, a managed time phased approach was used with a forced latency of uplink transmitted data from MEDUSA to the SM-3 CIL. As originally designed by Robert Manthy of RMS, the SM-3 clocks were set to run a  fixed time behind the AWS  clocks. This fixed time offset allowed the SM-3 RSM in Tucson to queue uplink data until the time tags on incoming data matched STB time. At the Moorestown RSM, downlink messages were essentially arriving “late” from the forced latency sothey had to be extrapolated (position and velocity) by the Moorestown RSM to bring them up to current state time before transmitting them to MEDUSA.The major hurdles for MEDUSA modifications were extracting its Trim-Aero missile model so that the remote SM-3 could be used. Also, MEDUSA runs at logical time much faster than real time in standalone mode, so a timing scheme had to be developed which to allow allowed MEDUSA as well as other federates to running at real time while simultaneously handling the link latencies. had to be implementedThird, a TCP/IP client socket application was installed as well as a message handler to send and receive messages to/from the RSM. Finally, coordinate transformation routines had to be incorporated to translate between Earth Centered Earth Fixed (ECEF), Ship Base Earth Fixed (SBEF), and East North Up (ENU).After many test runs in a rapid prototyping environment, the RMS SM-3 and LM NESSMS2 MEDUSA engineering teams recorded a successful simulated intercept of a Theater Ballistic Missile (TBM) threat on December 12, 1999. This was the demonstration that the proof-of-concept, for this distributed simulation system was indeed viable.This architecture has proven to be invaluable in supporting many Integrated Flight Tests (IFTs) and Flight Missions (FMs) for pre- and post- mission assessment.  The distributed model was able to accept a live target feed from the Field Operations Center, now MIDCON (Missile Defense Communications and Operations Node), during these flight events and prosecute the threat on a real time basis.Phase II ModificationsPhase II work commenced in mid 2000. The noteworthy tasks for the MEDUSA team were the establishment of a HLA interface for MEDUSA, assisting AWS CIL in becoming HLA compliant, and the establishment of a robust HLA federation where MEDUSA and the AWS CIL could interoperate with the SM-3 STB as a proof-of-conceptproof of concept and for further risk reduction prior to a link between CSEDS and the SM-3 HIL. In addition, the ‘MOORESTOWN’ federation FOM  federation and corresponding FOM was developed featuring actual operational tactical messages (missile initialization, uplink and downlink, kinetic warhead (KW) eject) as HLA interactions. The message taxonomies and their associated timing schemes are classified. Missile and TBM threat objects were included in the FOM as well. Of particular note, the HLA FOM is an object  oriented approach to the representation of the data model used in a federation. It contains tables for objects (classes) and their attributes as well as interactions and their parameters. The rules for HLA compliance as originally formulated by the Defense Modeling and Simulation Organization (DMSO) mandate the use of a FOM, as it is the centerpiece of shared data for the entire HLA federation.A serious challenge to the MEDUSA engineering team wasSubtasks included revamping the target track code in MEDUSA to allow for receiving or sending (subscribing or publishing in HLA parlance) target tracks in accordance with the HLA rules as opposed to reading tracks solely from a target track file. Target updates also had to be extrapolated (2nd order) to bring stale time tags up to present state times. Timing would now be based solely on a system provided Global Positioning System (GPS) time hack. Where paths existed to accommodate message passing via sockets, new paths had to be created to integrate an Application Program Interface (API) to accommodate HLA Run-Time Infrastructure Interface (RTI) services in conjunction with the federation FOM. (The RTI is analogous to an operating system that provides services to the federates for federation management, time management, and the brokering of data represented in the FOM as classes and interactions.) To allow for operation with the RTI and to facilitate the use of an API, MEDUSA had to be ported to the Solaris 8 operating system as well as the Sun 5.2 C++ compiler. The initial RTI was agreed to be DMSO RTI-NG 1.3v4. The MEDUSA engineering group also initiated the effort of writing and exercising a Federation Development and Execution Plan (FEDEP) as depicted in  FEDEP version 1.5. Based on previous experience with this document, they felt that this would prove to be a criticaln invaluable tool to the construction of the MOORESTOWN federation, and also serve as a conduit to fully describe the complicated Conceptual Model of this federation. MEDUSA was outfitted with the Raytheon Common API (CAPI) to facilitate a rapid transition to an HLA interface (as opposed to designing and coding one from scratch). The CAPI is quite powerful in that it features a code generator for C++ code, taking actual Federation Object Model (FOM) Object Model Tool (.omt) files as input. It also has a code generator for the RTI interface, making the (Common) API to the RTI API much more compact and user friendly. The LM MS2 team saved many man-hours in development time by using the CAPI, and the accompanying expertise provided by RMS engineers proved invaluable to the MEDUSA effort.MEDUSA would no longer need the RSM to act as its HLA proxy so the RSM federate, renamed the SM-3RemoteFed federate, would need to be modified to let MEDUSA assume the role of brokering data directly to the RTI. In addition, a bridging federate was added developed and added to the federation by the RMS team that links the MOORESTOWN federation with the SM-3 STB federation  SM-3 STB federation in  Tucson. The bBridged federate is a unique application in that it is a member of both federations simultaneously while facilitating the throughput of messages (FOM object attribute updates and interactions) seamlessly between federations. An Integrated Product Development  Team was formed and the Program Integration Team (PIT) consisted of members of Navy, LM NESSMS2 ETEDDS   and RMS Program Management Officers and Technical Directors, as well as engineers from the MEDUSA and the SM-3 STB engineering groups. In 2001,  Aegis Combat System engineers also joined the ranks of the PIT in support of the AWS CIL. Of note were the weekly teleconferences held between RMS and LM NESSMS2 to facilitate an action item list  as well as programmatic milestones to keep the effort moving forward. In addition, several Technical Interchange Meetings  were held at both Tucson and Moorestown to facilitate the sharing of ideas and the resolution of problems. Most importantly however, was the continued ability of RMS and LM NESSMS2 engineers to work in a harmonious if not sometimes stressful rapid prototyping environment.             Security and ArchitectureThe need for security was paramount from the very beginning of Phase I. Computers from different contractors are interacting on an encrypted  secure data link that has firewall protection from development LANs Originally, the secure link between LM NESS was configured to have an ISDN link encrypted with KIV-7 encryptors. Currently the link is comprised of a secure Defense Information System Network – Leading Edge Services (DISN-LES) VPN with KG-75 encryptors.  In addition, a RMS Sun Workstation  which houses the RSM, the SM-3 RemoteFed federate, and the bridging federate is located in a DMZ. ()provides firewall services to LM MS2This allows for isolation  from the LM MS2  classified LAN in Moorestown, and to facilitate the passing of data between these applications and the HLA RTI, MEDUSA, and/or the AWS CIL. These LM NESS federates also run on classified Suns and PCs on a  classified LANLM MS2.. The data being passed between computers of the two different contractors was and remains classified. Robust security plans (LM NESS SSP-122 and RMS SSP-1034) were developed  by both contractor’s security specialists. These SSPs were then approved by the Defense Security Service (DSS) to allow for the passing of data in these distributed models while adequately protecting sensitive development assets through the use of routers and firewalls on the LAN. See figure 3 for a logical depiction of the classified ETE network2.Phase III  MOORESTOWN FEDEP ObjectivesThe FEDEP is a systematic approach for the development of a HLA federation. The crux of the FEDEP is essentially the development of a FOM and Conceptual Model, the latter being a description of the how, what, when, where, etc. of the entire federation execution. Included in the FEDEP steps is the development of a robust set of objectives. The FEDEP objectives for the MOORESTOWN federation are as follows (all objectives have been achieved). The names of LM MS2 and RMSLM MS2 computers have been replaced by LM1, LM2, LM3WWWW, and RMS1(all objectives have been achieved):Federate names: MEDUSA, CSG, SM-3RemoteFed and BridgeMoores.Name of the federation is MOORESTOWN. The actual FOM name is RMAST-0.6.5.MEDUSA federate, the CSG federate, and the SM-3 federates will join the MOORESTOWN federation through an HLA interface.Name of the federation is MOORESTOWN. The FOM name is RMAST-0.6.5.Previous socket connection between SM-3RemoteFed federate and MEDUSA (or CSG) will not be used in this federation.  MOORESTOWN federation and the SM-3 STB federation will be connected via the bridged federate BridgeMoores.MEDUSA will reside on LM1XXXXX or LM2YYYYY Sun WS. SM-3 federates and the bridged federate will reside on RMS1ZZZ WS. The AWS CIL CSG federate will reside on LM3WWWWW PC.RTI will reside on any of the computers listed in previous bullet.FOM will be completed after all objects/attributes and interactions/parameters are identified in the Federation Conceptual Model.All federates will have access to all objects and interactions in the FOM.LM1, LM2, and LM3XXXXX, YYYYY, and WWWW will require a connection to the same physical and data link layers that RMS1ZZZ is connected to, so as to facilitate connection to the RTI.Federation will use RTI 1.3 NGv4 until a mutual agreement is reached concerning RTI upgrades.LM1, LM2, and LM3XXXXX, YYYYY and WWWW firewall(s) may have to be updated to allow for connections specified in the RTI Runtime Initialization Data (RID) file, as LM3WWWW is on a different classified subnet from LM1, LM2.XXXXX, YYYYY, and ZZZSecurity officials from RMS and LM MS2 will be consulted and briefed prior to instituting any changes to the current configuration (DISN-LES and firewalls).Federation will use RTI 1.3 NGv4 until a mutual agreement is reached concerning RTI upgrades.Security officials from RMS and LM MS2 will be consulted and briefed prior to instituting any changes to the current configuration (DISN-LES and firewalls).RMS will continue to implement time phasing as necessary. Exact values for phasing, queuing and extrapolation will be determined in a prototyping and test environment if necessary, and LM MS2 engineers should be ready to assist the RMS team.SM-3RemoteFed will continue to do all downlink interaction time extrapolations in accordance with the overall time phasing scheme of the federation. Discussions have commenced between the LM MS2 and RMS engineering teams regarding the migration of RSM functionality into MEDUSA and CSG, as well as the need for a bridged federation.  FOM uplink and downlink interactions will be changed to emulate the actual tactical messages. In the absence of radar signal return modeling, actual missile position may be ‘piggybacked’ onto the tactical downlink portion to form a SM-3 simulation downlink message.All federates will rely on a common GPS time hack (Universal Coordinated Time (UTC)) as a means of time synchronization. Applications on RMS1ZZZ may use NTP.All federates will use ‘time since midnight’ to time tag their published object attribute updates and interactions. This time is derived from UTC time and is the time since midnight of the current federation execution day.Federation will proceed in real time as opposed to sim timeTime delays and latency issues will be tested and benchmarked for inclusion in the AWS CIL and possibly the MEDUSA  and CSG federates. Extrapolation and latency numbers should be “tweekable” immediately prior to runtime to facilitate rapid prototyping.RMS will continue to implement time phasing as necessary. Exact values for phasing, queuing and extrapolation will be determined in a prototyping and test environment if necessary, and LM MS2 engineers should be ready to assist the RMS team.SM-3RemoteFed will continue to do all downlink interaction time extrapolations in accordance with the overall time phasing scheme of the federation. Discussions have commenced between the LM MS2 and RMS engineering teams regarding the migration of RSM functionality into MEDUSA and CSG, as well as the need for a bridged federation.  FOM uplink and downlink interactions will be changed to emulate the actual tactical messages. In the absence of radar signal return modeling, actual missile position may be ‘piggybacked’ onto the tactical downlink portion to form a SM-3 simulation downlink message.FOM will be completed after all objects/attributes and interactions/parameters are identified in the Federation Conceptual Model.Targets will be generated from a target data file or from live feed from a MIDCON to a federate.   This federate then will publish the target track and the other MOORESTOWN federation federates will subscribe to it. A schedule will be developed showing test runs after preliminary prototyping is accomplished. Federation Execution will follow.MOORESTOWN Conceptual Model and ScenarioThe other The most noteworthy challenges to this distributed simulation are threat generation and a time phased solution to account for link latency and millisecond level timing requirements for tactical uplink and downlink messages between AWS simulators and the SM-3 STB missile model. Target threats are typically generated by any federate at 1 Hz frequency. Actual midcourse guidance commands are will be sent to the SM-3 missile entity in accordance with actual (classified) tactical specifications. The scenarios for this federation  initially emulated initial risk reduction experiments involving the MEDUSA and  AWS CIL simulators in conjunction with and the SM-3 STB federation. The SM-3 STB will run a negative time skew in relation to the MOORESTOWN federation to account for queuing and latency. This is nearly identical to the scheme that was used in Phase I. See Figurefigure  35 for a logical depiction of the forced latency time phasing scheme. 3All LM MS2 federates in the MOORESTOWN federation will utilize a common UTC time hack from GPS (IRIG B). RMS applications residing on RMS1ZZZ will rely on NTP for the time hack. The RTI timing scheme for all federates will be unregulated/unconstrained and will proceed in wall clock (real) time. A copy of a common target data file will be available for each federate. Each federate will maintain a local copy of the threat generated from this file. Any federate in the federation will have the ability to publish the target track updates from this file at 1Hz intervals, or utilize the live target feed from MIDCON. aAnd the other federates shall subscribe to these target updates. MEDUSA or AWS CIL will publish mid-course guidance via tactical initialization and uplink interactions to the SM-3 CIL. The SM-3 CIL will in turn publish missile position and velocity in SM-3 Leap object attribute updates to the subscribing SM-3RemoteFed federate. This federate e SM-3RemoteFed will extrapolate for skewed time tag, latency before republishing missile data in a tactical downlink interaction coupled with missile velocity and position parameters. The AWS federate publishing the midcourse guidance interactions will subscribe to the downlink interactions. The subscriber will then apply this missile data to the next midcourse guidance uplink calculations. The composition of any scenario will be a federate to model the AWS, the SM-3 RemoteFed federate, a target generation federate and a bridging federate to link the SM-3 STB federation to the MOORESTOWN federation. The target generator will be any AWS or SM-3 federate. The target generating federate will receive a live target feed from the MIDCON or read from a scripted target data file as a basis for publishing target track updates to the federation. Presently, only one ship, one target, and one missile round out the requisite modeled entities. This will not however, preclude future development for multi-ship, multi-salvo and/or multiple threat scenarios for this federation or other derived federations. In all cases the BridgeMoores federate will publish SM-3 missile data to the MOORESTOWN federation and correspondingly subscribe to AWS data so as to publish to the SM3 STB in Tucson. Target data will be handled by the BridgeMoores federate depending on where it originates (is published from). The exit condition from any scenario will be the intercept or miss of a ballistic missile target with a SM-3 missile. Figure Figure 45 depicts the interactions that take place between MEDUSA and the RSM/STB. The RSM includes combined functionality of the SM-3RemoteFed federate and the bridging federate. TTV1 is the TBM threat as represented in the FOM. Security and ArchitectureThe need for security was paramount from the very beginning of Phase I. Computers from different contractors are interacting on an encrypted secure data link that has firewall protection from development LANs. Originally, the secure link between LM MS2 was configured to have an ISDN link encrypted with KIV-7 encryptors/decryptors. Currently the link is comprised of a secure Defense Information System Network – Leading Edge Services (DISN-LES) VPN with KG-75 encryptors/decryptors.  In addition, a RMS Sun Workstation which houses the RSM, the SM-3 RemoteFed federate, and the bridging federate is located in a “DMZ”. This DMZ could also be referred to as a DEMARC (demarcation point), which provides firewall services to protect LM MS2 sensitive assets from the outside world. This DMZ allows for isolation and protection of the LM MS2 classified LAN in Moorestown, while facilitating  the passing of data between the RMS federates  and the HLA RTI, MEDUSA, and/or the AWS CIL, which also reside in the DMZ. The LM MS2 federates also run on Sun workstations and PCs on a classified LAN for development and test purposes, but these assets are totally isolated from the DMZ. Portals exist in the firewall for the downloading of executable images from the LM MS2 development LAN to the computers in the DMZ. Source code is fully protected and is never placed in the DMZ. The simulation data being passed between computers of the two different contractors was and remains classified. Robust security plans (LM MS2 SSP-122 and RMS SSP-1034) were developed by both contractor’s security specialists. These SSPs were then approved by the Defense Security Service to allow for the passing of data in these distributed models while adequately protecting sensitive development assets through the use of routers and firewalls on the LAN. See figure 5 for a logical depiction of the classified ETE network3.TestingRMS, MEDUSA and AWS CIL engineering test teams devised a comprehensive four tier test plan to integrate all three federates simultaneously into the federation. AWS engineering teams, working individually with RMS engineers, achieved separate TTV1 ballistic missile intercepts respectively using AWS CIL and MEDUSA in conjunction with the SM-3 HIL in the last quarter of 2002.  Target tracks published in testing were generated from FM-2 and FM-3 target tracks that were recorded during flight missions. These successful intercepts were proof-of-concept that the systems integration of CSEDS and the SM-3 HIL was a viable opportunity for Navy risk reduction programs.ConclusionThe greatest single factor that produced these successful events and milestones was the level of cooperation between the LM MS2 NESS and RMS engineering teams. They effectively proved that a time-phased distributed simulation using HLA was indeed viable, and therefore laid the groundwork for even higher fidelity distributed models. The challenges of time phasing with the associated queuing and extrapolation of target threats and missiles, as well as threat generation were effectively met and conquered using a phased developmental approach. This approach allowed for “lessons learned” and re-engineering in a way that nurtured the increased fidelity as opposed to creating additional problems as the distributed model became more complex. In summation, anything less than the level of effort produced by both management and engineers would have been short of verified risk reduction and proof-of-concept for the ultimate endgame, having CSEDS and SM-3 HIL conduct a distributed engagement and prosecution of a ballistic missile threat. A modified Conceptual Model and FOM consisting of a multi-ship, multi-missile, and multi-threat federation has been developed in support of ETEDDS BMD ‘04. Software development is proceeding based on this new model.LM NESS MS2 Modeling, Simulation and Operations Analysis has leveraged much from this effort and we are now involved in several different HLA simulation efforts to support operational analysis and effectiveness, test and evaluation, and Verification Validation and Accreditation (VV&A) using a plethora of simulation platforms and tools.  Our many different clients include in the U.S. Navy, U.S. Coast Guard, and customers abroad.Figure 1 created by RMS engineering team for the Navy Theater-Wide TBMD End-To-End Demonstration System (ETEDS) Requirements Document Ver 0.12 Figure 3 originally created by LM NESS AWS CIL engineering team and then slightly modified by MEDUSA team3 2 Figure 34 created by LM NESS MS2 AWS CIL System Engineering3 Figure 5 originally created by LM MS2 AWS CIL engineering team and then slightly modified by MEDUSA teamAbout the AuthorRobert A. Swift received a B.S. in Physics from Rutgers University and a M.S. in Computer Science from Drexel University. He was the lead software engineer for the MEDUSA ALI ETEDDSdistributed simulation effort.  Currently, he is coordinating test and evaluation (T&E) for the USCG Deepwater program at LM NESSMS2, Moorestown, NJ.  Mr. Swift retired from the United States Air Force Reserve in December 2002. He was a command pilot with over 3,000 flying hours and a mission ready aircraft commander on the Lockheed Martin C-130E Hercules.