DTE 4: ATEC Distributed Test Capability to Support FCS TestingRalph LiebertUS Army Electronic Proving Ground Ft. LewisCSTE-DTC-EP-TT-LFt. Lewis, WA 98433253-967-8106 HYPERLINK "Ralph.liebert@epglewis.dtc.army.mil" Ralph.liebert@epglewis.dtc.army.milTimothy ClardyUS Army Redstone Technical Test CenterCSTE-DTC-RT-E-SARedstone Arsenal, AL 35898256-876-5555 HYPERLINK "Tim.clardy@us.army.mil" Tim.clardy@us.army.milMichael J. O'ConnorITT Industries6767 Old Madison Pike, Suite 160Huntsville, AL 35806256-964-1470 HYPERLINK "Michael.oconnor@itt.com" Michael.oconnor@itt.comKeywords:Synthetic Environment, Distributed Test and Evaluation, C4ISR, Live, Virtual, Constructive,Future Combat SystemABSTRACT: The Global War on Terrorism (GWOT) and the Operation Iraqi Freedom (OIF) conflicts provide numerous examples of the asymmetric threats US forces are facing.  Materiel solutions like the Army’s Future Combat System (FCS) are being developed to assist soldiers overcome these difficult challenges.  Acquisition of these new systems is a challenge and Test and Evaluation (T&E) is still an important component, which has fundamentally not changed.  The mission to generate, collect and analyze data for system evaluation remains the primary objective.  The advent Network-Centric Warfare (NCW) and supporting systems like FCS coupled with increasingly complex mission battle space has lead organizations like the Army Test and Evaluation Command (ATEC) to pursue novel T&E strategies.  One of these new strategies is distributed testing, which leverages the integration of unique fixed test assets and expertise from geographically dispersed test facilities.  ATEC is integrating live, virtual and constructive (LVC) test capabilities using an established network, the High Performance Computing Modernization Program’s (HPCMP) Defense Research and Engineering Network (DREN).  Many of the simulation capabilities are from the Developmental Test Command (DTC) Virtual Proving Ground (VPG) and were first integrated in the Synthetic Environment Integrated Testbed (SEIT) the progenitor program of the current distributed test capability in ATEC. The culmination of the distributed test capabilities was demonstrated in a recent, 30 AUG to 02 SEP 04, Distributed Test Event 4, which was the fourth in series of developmental phases of the distributed test capability for ATEC.  This paper will discuss the network, infrastructure and capabilities brought together to create this capability as well as the test expertise and processes used to create a distributed test capability.  Finally the authors will discuss the benefits of using distributed testing to support T&E for complex Army systems in complex mission environments.1. IntroductionCurrent and Future US Forces along with Coalition Partners are challenged to operate in increasingly dynamic and challenging battlefield environments, while facing opposition forces employing asymmetric threats. The US Army is developing the Future Combat System that is based on Network Centric Warfare (NCW) tenants and is challenging the acquisition model currently in use. To face this challenge, the United States Army Test & Evaluation Command (ATEC) initiated the development of a distributed test capability to address the complexities of testing in this new network-centric environment. The test is conducted in a complex mission context to collect accurate data on the systems use on the battlefield and inform evaluations and acquisition decisions.To develop the distributed test capability ATEC is engaged in a program to tie its geographically dispersed test centers together to benefit from the resultant synergies realized from the integration of multiple test capabilities functioning in an interactive and dynamic test framework. Several ATEC programs have been leveraged to help create the basis for integrating test capabilities throughout the command’s remote sites. These integrated test capabilities have been demonstrated most recently in an event conducted 30 AUG to 02 SEP 04, the Distributed Test Event 4 (DTE 4).  In DTE 4, ten geographically dispersed sites were linked with the Defense Research Engineering Network (DREN) and a common infrastructure developed through the ATEC Test Integration Network (ATIN) program. The distributed test capability is supported by live, virtual, and constructive (LVC) test tools developed through DTC investment in instrumentation and modeling and simulation (M&S), developed through the Virtual Proving Ground (VPG). Many of these synthetic environments and test capabilities are integrated into the standardized and interactive Synthetic Environment Integrated Testbed (SEIT), which is an implementation of high quality test environment representations and stimuli in a doctrinally correct tactical battlespace for common application throughout ATEC testing.  The DTE 4 capability enables the integration of dispersed test capabilities currently in use at the ATEC test centers supporting Army materiel Test and Evaluation (T&E). High-resolution environmental representations include the relevant radio frequency (RF) environment for testing Army communications equipment, an infrared (IR) environment for testing IR-based targeting sensors, and a chemical and biological (CB) threat environment for testing CB agent sensors. Also integrated into the DTE is a mobility server for determining platform mobility effects due to terrain and a robotics intelligence model to emulate the actions of an autonomous Unmanned Ground Vehicle (UGV). In addition 15 live systems emulating FCS manned and unmanned platforms and sensors as well threat systems are integrated seamlessly into the overall LVC test environment. These high-resolution and live emulated test components and environment representations are immersed and interact with a constructive semi-automated forces (SAF) model, OneSAF Testbed Baseline (OTB), providing an overarching environment that provides blue and red force structures and doctrinally correct tactical scenarios as well as low fidelity tactical platforms to associate high-resolution virtual or live test systems. Table 1.1 contains information about the ten DTE 4 participating sites and the LVC capabilities. To facilitate broader applicability, development, and utility, the DTE 4 capability is organized in threads that are end-to-end representations of a test item, requisite environments, and relevant command and control infrastructure designed to support commodity-specific testing. Testers can use these standalone threads individually to assess the performance of sub-system or component test items while leveraging the benefits of the realistic mission space. Together the threads enable system-of-systems (SoS) testing. This open framework allows for optimization of the overall capability to support differing programmatic test requirements and has potential applicability to support joint analysis and training M&S requirements.DTE 4 uses the High Level Architecture (HLA) and legacy Distributed Interactive Simulation (DIS) architecture to facilitate dynamic interactions among components. DTE 4 employs a distributed test framework founded on the High Performance Computing Modernization Program’s (HPCMP) DREN, which extends to the ten DTE 4 participant sites.Particularly, DTE 4 is focusing on the integrated contractor/government testing planned for the US Army’s Transformation program the FCS. The DTE 4 team is working closely with the FCS Lead System Integrator (LSI) (Boeing-SAIC Team) through the Combined Test Organization (CTO). The CTO is a tripartite of FCS LSI, ATEC, and FCS Program Office personnel responsible for planning and coordinating integrated T&E for the FCS. DTE 4 team is coordinating with the FCS LSI T&E and M&S personnel to insure that development of M&S and live test capabilities supporting distributed testing for ATEC supports the FCS test requirements. The original requirement is to support the FCS LSI-lead Integration Phase System Development and Demonstration (SDD) testing (IPS-1) scheduled for 3Q FY05 and documented in the Integration Phase Plan 1 (IPP-1) [1].  The IPP concept of testing has evolved and now the emphasis for the DTE capability is to be focused on the Integration and Verification (IV) testing and the LSI experimentation.  IV0 phase testing is documented in the FCS SDD IV0 plan [2] and the experimentation we plan to support is documented in the FCS SDD Experiment Increment 1.1 Plan [3].SITETEST MISSIONLIVEVIRTUALCONSTRUCTIVEAberdeen Proving Ground (APG)Ground MobilityStrykerVehicle DynamicsMobility ServerRobotic InteligenceLethality/VulnerabilityAviation Technical Test Center (ATTC)Rotary Wing Platform / RSTA Sensors Flight DynamicsIR Sensor Dugway Proving Ground (DPG)Chemical and Biological DefenseStrykerChem/Bio SensorWeather Effects Electronic Proving Ground (EPG)Command, Control, Communications,Computers, andIntelligence (C4I)Shadow 200(UAV simulator)RF NetworksC2 NodesBattle CommandNight Vision Electronics and Sensor Directorate (NVESD)*RSTA Sensor R&DGround Platform Simulator Platform Sensors Operational Test Command (OTC)Army Operational TestingNetworked ObserverRedstone Technical Test Center (RTTC)Small Missiles /RSTA SensorHelicopter (UAV)IR SensorsPlatform SensorsAerial SensorsOTBWhite Sands Missile Range (WSMR)Large Missiles5 T-72sHelicopter (UAV) TOC, JANUSYuma Proving Ground (YPG)Ground MobilityEnvironmentalStrykerNLOS-C Emulator  * NVESD is not an ATEC test capability, rather it is part of the Research, Development and Engineering Command (RDECOM). Table 1.1. DTE 4 Participants, Missions, and LVC capabilities1.1 BackgroundThe DTE program started as an initiative by the US Army ATEC Developmental Test Command (DTC) VPG, which includes personnel from the seven DTC test centers, and has the mission to integrate M&S technologies into the Army T&E. VPG chartered its Synthetic Environment Focus Group (SEFG) to develop an integrated and standard environment representation to support testing. The SEIT program was developed to bring together mature test environments in an interactive and dynamic framework that contribute to a distributed test capability and is adaptable throughout the ATEC T&E. As noted in addition to SEIT several other ATEC programs and VPG Focus Group activities, notably the Tools FG, are brought to bear to develop ATEC distributed testing. As DTE demonstrations have expanded to support ATEC distributed testing, capabilities for requirements definition and traceability, scenario generation, test planning, test execution, and data collection, analysis, and reporting are included. In conjunction with the distributed test infrastructure, particularly the Inter-Range Control Center (IRCC) at WSMR and the Distributed Test Control Centers (DTTC) being implemented at ATEC test sites, these capabilities provide a robust distributed test framework. This paper will describe the environment representations and distributed test support capabilities as well as the architecture selected to facilitate the distributed test framework.DTC completed three Initial Operating Capability (IOC) developments and demonstrations during CY03 with increasing levels of capability. Previous papers and reports describe IOC 1, 2, and DTE 3. The IOC 1 Final Report [4] and a paper for the 2003 US Army Simulation and Modeling for Acquisition, Requirements and Training (SMART) Conference [5] describe the IOC 1. The technical details for IOC 2 can be found in the Demonstration Control Document for IOC 2 [6].  In addition to the aforementioned IOC programmatic and technical descriptions, two Simulation Interoperability and Standards Organization (SISO) papers, 04S-SIW-082 [7] and 04E-SIW-022 [8], describing DTE 3 were prepared and presented at the Spring 04 SISO Integration Workshop (SIW S04) and at the European 04 SIW (SIW E04). Statistics from the DTE 4 demonstration are shown in Table 1.2 and this paper and others submitted to SISO for the S05 SIW will provide greater detail.ItemValue1.  Duration of scenario:89 minutes2.  Number of Mission Execution Threads:9 METs3.  Number of sites participating:12 sites4.  Number of different time zones for sites:5 time zones5.  Number of entities:334 entities, 217 blue, 117 red6.  Number of computers:140 computers7.  Number of simulations:35 different simulations, multiple instances8.  Number of operators:70 operators / ~ 300 Total9.  Number of live platforms:13 live platforms10.  Number of test ranges involved:6 test ranges, operating concurrently11.  Amount of bandwidth used over network:80 Mbps at IRCC, 40 Mbps at RTTC, 10 to 20 Mbps at each site12.  Number of days to establish site connections:3 days for DTE 4 vs. 21 days for DTE 3 and 50 days for IOC 213.  Number of pages in Time Ordered Events List:350 pagesTable 1.2. DTE 4, 30 August to 02 September, Statistics 1.2 Synthetic Environment Integrated Testbed Goals•	Identify synthetic environment capabilities required to support Army T&E•	Develop capabilities that provide accurate information for supporting T&E•	Integrate ATEC Synthetic Environment M&S and T&E capabilities to provide “best-value” to the warfighter•	Establish collaboration among Subject Matter Experts (SME) and leverage expertise in multiple technology areas•	Leverage the highest quality synthetic environment M&S and T&E capabilities from across DoD, with emphasis on DTC capabilities•	Create a common, integrated, multi-level resolution environment to support life cycle M&S and T&E requirements•	Integrate engineering level simulations representing requisite T&E technology•	Develop the overall SEIT architecture using manageable SEIT threads and architecture standards1.2 Distributed Test Event 4 GoalsDemonstrate DTC test center capabilities to support distributed testing using live, virtual, and constructive representations of test articles and environmentsDevelop and support distributed testing lessons learnedDemonstrate the capability to support the execution of operational mission threads developed for Future Combat Systems (FCS) to assess the Network Fires and Force Health Protection Integrated Processes (IPs)2. Models and Simulations and Distributed Test CapabilitiesThe following paragraphs describe the M&S and live elements integrated into interacting threads for DTE 4. Integrated components for DTE 4 were distributed across the DREN from the ten sites.2.1 C4I M&SRole Player Workstation (RPWS). The RPWS is a multi-function workstation that enables the user to view a tactical situation in real time or near real time in the form of US Army MIL-STD 2525B military symbols overlaid on an electronic map (CADRG, DTED, and Imagery).  The RPWS allows the user to create, send, receive, and display Joint Variable Message Format (JVMF) and United States Message Text Format (USMTF) messages.  The RPWS is accredited for testing in the Simulation Training Operations and Rehearsal Model (STORM) federate for Developmental and Operational testing of Force XXI Battle Command Brigade and Below (FBCB2) lower echelon force battle command system and has DoD Information Technology Security Accreditation Plan (DITSCAP) certification.Digital Army USMTF/VMF Stimulator (DAUVS). The DAUVS serves as a communication gateway between the RPWS devices and the Army Battle Command Systems (ABCS) operating on EPLRS or SINCGARS radio networks and tactical operations center (TOC) local area networks (LAN).  The DAUVS serves to forward messages between the RPWS devices playing different tactical roles.  The DAUVS is accredited for testing in the Simulation Training Operations and Rehearsal Model (STORM) federate for Developmental and Operational testing of Force XXI Battle Command Brigade and Below (FBCB2) lower echelon force battle command system and has DITSCAP certification.  DAUVS does not have any DIS or HLA inputs or outputs.Orion. Orion is a software suite used to assess the ability of US Army systems and equipment to operate in their intended electromagnetic environments, including threat forces, and to determine the effects of those environments. The Orion models RF propagation and effects (path loss) in a mixed live and simulated environment that the user can integrate with a wide variety of simulations and other tools. This basic C4I analytical capability, built on a core extensible framework, supports two-dimension (map based) and three-dimension (VR style) interfaces along with simple transceiver, link, and grid analysis for virtual entities.2.2 Infrared M&SInfrared Scene Generator using MPI Vega. Real-time infrared scenes are generated using the Multigen-Paradigm Vega scene generator and DIS add-on module based on entities received via the DIS.  It populates the scene with models based on DIS packets.  It simulates a laser range finder and is matched to a specific entity's IR sensor on the battlefield.  For DTE 4, the infrared scene from the Silicon Graphics, Inc. (SGI) platform was fed to the Dynamic Infrared Scene Projector (DIRSP) Engineering Grade Array (DEGA) infrared scene projector via digital port and projected into the input aperture of the real infrared sensor.OpenSceneGraph Scene Generator. Generates real-time infrared scene based on entities received via the DIS protocol using the OpenSceneGraph developed scene generator.  OpenSceneGraph is an open source PC based scene generator API.  The scene generator populates the scene with models based on DIS packets.  It simulates a laser range finder and is matched to a specific entity's IR sensor on the battlefield.  For DTE 4, the infrared scene from the OpenSceneGraph Linux based PC platform was used as a pristine IR scene with no sensor effects added.NVESD Paint the Night. Description: Generates real-time infrared scene based on entities received via the DIS protocol using the NVESD developed IR scene generator.  Paint the Night is a government developed cross-platform scene generator based on OpenGL.  The scene generator populates the scene with models based on DIS packets. It simulates a laser range finder and is matched to a specific entity's IR sensor on the battlefield.  For DTE 4, the infrared scene from the Paint the Night Linux based PC platform was degraded with sensor effects (blur and noise) to simulate an actual IR scene through a sensor.2.3 Chemical/Biological M&SNuclear, Chemical, Biological and Radiological Environment Server (NCBR). The NCBR is a propagation server for nuclear, chemical, biological, and radiological hazards.  The NCBR wraps existing community-standard transport and dispersion models to integrate them into the distributed simulation network.  The hazard can be initiated by a weapons detonation or manual laydown from the distributed simulation network. The hazard data is extracted from the model and packaged for publishing on the distributed simulation network.  The NCBR publishes a three-dimensional (3D) representation of the hazard environment for use by sensor models and visualization.  The user can modify the publication rate of the data based on sensor and network requirements.  The NCBR also publishes two-dimensional (2D) conformal data for ground deposition, concentration at two meters, lethal dose, and dosage.  The NCBR is accredited for developmental testing of the Joint Service Lightweight Standoff Chemical Agent Detector (JSLSCAD), the premiere Joint Service IR-based standoff chemical agent detection system.  For DTE 4 this release was generated by Detonator.Chemical/Biological Dial-A-Sensor (CB DAS). CB DAS is a reconfigurable sensor server for chemical and biological sensors.  The sensor performance is based on user set parameters.  The parameters are defined in an XML file based on sensor taxonomies.  The supported sensor types include chemical point air and ground sensors, chemical active and passive standoff sensors, biological point air sensors, and biological standoff active sensors.  Based on the sensor definition and detections, CB DAS produces tactical and ground truth messages.  For DTE 4, CB DAS played three JSLSCAD (chemical standoff passive) sensors and three chemical point ground sensors.  CB DAS generated tactical telemetry messages with the sensor detection vectors.  CB DAS also played ground sensor for the Robotic Intelligence federate attached to the UGVs.  These emulated the MM1 and double wheel sampling system (DWSS).Detonator. Detonator generates a series of chemical “detonations” to simulate the destruction of the chemical bunkers.  Release information is passed to the dispersion model.2.4 MeteorologicalFour Dimensional Weather (4DWX) System. The 4DWX System generated realistic weather data for use by the SEIT. The 4DWX is a physics-based model that predicts atmospheric phenomena down to a resolution of 1.1 kilometers. The model can simulate ground truth measurements to provide historical, virtual, and real-time weather. The 4DWX uses large-scale numerical weather prediction models, terrain and land surface characteristics, and data from weather measurement systems to create the meteorological data sets.Ocean, Atmospheric and Space Environment Server (OASES). The Defense Modeling and Simulation Organization (DMSO) developed the OASES as part of the EnviroFed program. The OASES ingests and publishes the natural environment for distributed simulations. It converts standard meteorological files such as Gridded in Binary (GRIB) for use by the distributed simulation. The OASES does not generate the meteorological data. The user determines what data to publish during the input process. For the DTE 4, 4DWX data in GRIB format served as the meteorological data for the OASES HLA meteorological server.2.5 Distributed Test Support CapabilitiesMÄK Stealth. The Stealth is a commercial-off-the-self (COTS) tool for 3D visualization of distributed simulation exercises developed by MÄK Technologies. The Stealth supports the HLA and DIS.  For the DTE 4, the Stealth provided visualization of terrain, entities, hazard environment, and sensor viewing angles.MÄK Logger. The Logger is a COTS tool for recording and playback of Protocol Data Units (PDU) for the DIS and of objects and interactions for HLA. The Logger stores the data in binary files. For the DTE 4, a logger was run for both the DIS and HLA to capture all data passing on the network.MÄK DIS/Real-time Platform Reference Federation Object Model (DIS/RPR FOM) Gateway. The DIS/RPR FOM Gateway is a COTS tool used to translate between the HLA RPR FOM and DIS data. The Gateway is connected to both the HLA and DIS networks. For the DTE 4, only selected data were transferred between the HLA and DIS networks.MÄK Plan View Display (PVD). The PVD is a commercial-off-the-self (COTS) tool for 2D visualization of distributed simulation exercises developed by MÄK Technologies.  The visualization of the hazard environment requires a plug-in developed by ITT for Dugway Proving Ground.  The PVD supports the HLA and DIS.  For DTE 4 the PVD provided visualization of terrain, entities, and hazard environment.Starship. Starship is a test planning, monitoring, command and control tool used for conducting distributed systems of systems testing.  It is a PC-based, MS Windows software suite to command, control, and display the status of any capability in a test (e.g., instrument, control, live battlefield system, simulated battlefield entity).  Starship interfaces to distributed test instrumentation via a test communications infrastructure and allows the tester to monitor the status of systems under test and control test instrumentation in near-real time. Starship provides graphical and textual reports both during test execution and for daily test reviews. The underlying object-oriented design and eXtensible Markup Language (XML) technology implemented within Starship provides maximum extensibility, scalability, flexibility, and reuse. Starship is adaptable to different communications media (LAN, WAN, radio, secured radio, encrypted LAN, DREN, and Internet) and to DoD protocols (DIS, HLA, and TENA).  During DTE 4 Starship interfaced with a Remote Reconfigurable Intelligent Instrumentation to Control, Collect, Stimulate, and Simulate (RICS)2 instrumentation device at each of the distributed nodes. Remote Reconfigurable Intelligent Instrumentation to Control, Collect, Stimulate, and Simulate (RICS)2. (RICS)2 is a controller, collector, simulator, stimulator executing on a Windows NT platform capable of running in diverse environments. The software and hardware architecture suite maximizes COTS software and hardware with internal GPS and data radios to provide time tagging and a remote instrumentation network. Primary uses of the RICS2 are to send and receive ground truth data for training, and performance tests of Tactical C4I systems and networks.  Starship and RICS displayed health and status on various DTE 4 infrastructure components.  Starship and RICS exchange information through an XML specified interface.Simulation Application Suite (SAS). SAS provides an interface between simulations and Army C4ISR systems. SAS stimulates Army Battle Command Systems (ABCS) to support C4ISR testing and training environments with messages that are realistic in content, volume, timeliness and media of transport.  SAS can also operate independently from the simulation in a standalone mode by using a simulation playback file or building messages.  SAS is a Windows based Test Tool that operates on a single desktop or notebook computer and interfaces directly with Starship, the system that provides command and control for EPG test tools.  For DTE 4, SAS received inputs from DIS and automatically generated and sent C4I messages (Location Messages JVMF K05.01, Spot Reports JVMF K04.01, Air Track FAAD Data Link Messages) to a Brigade TOC equipped with the Maneuver Control System (MCS) and the Air and Missile Defense Workstation (AMDWS) allowing display of the Common Operating Picture (COP).Digital Collection, Analysis, and Review System (DCARS). The DCARS is a tool for real-time data collection, after-action reviews, and in-process and post-event analysis. It collects command and control (C2) and situation awareness (SA) messages and inserts them into a database for recall, replay, and comparative and thread analysis. Simultaneous collection and recall is a feature that permits graphical and tabular analysis of all or few entities. Access is via web browsers and clients loaded onto common personal computer (PC) platforms with Microsoft Office software for portability. DCARS has been accredited for use in numerous C4I developmental tests at EPG, has DITSCAP certification and DoD Net Worthiness certification.Test Conduct and Reporting System (TCRS). The TCRS is a requirements-driven system that attains efficiencies through detailed research, analysis, and coordination during test planning; focused and quality assured data collection during test conduct; and predefined reporting formats. TCRS is used to decompose tactical missions into tasks related to system requirements, which drives the development of a Time Ordered Event List (TOEL). The TOEL in turn drives distributed test execution, data collection, and reporting.2.6 GeneralOneSAF Testbed Baseline (OTB). The OTB is a distributed simulation wargaming tool. It represents a full range of military operations, systems, and control processes from individual combatant to battalion level. It allows an operator to position units on a terrain database and task them to perform a series of realistic maneuver operations (e.g., move, occupy position, attack, etc.). .).  OTB was used to provide the tactical scenario to demonstrate the other applications in DTE 4.Vehicle Dynamics Mobility Server (VDMS). The server is a high-resolution representation of vehicle mobility effects attributed to terrain effects. Engineering scale platform aspects interact with terrain elements providing shock and vibration as well as six degrees of freedom motion predictions. This information may be articulated to any subsystem on the platform in position.Robotic Intelligence. This model played three cooperating autonomous UGVs with chemical deposition detection sensors. The Robotic Intelligence federate used data from chemical point sensors generated by the CB DAS to plan routes to map chemical contamination on the ground.WSMR Live Interface. This interface inserts live tank and aircraft information received from the WSMR Real Time Data Processing System into the distributed simulation environment. It can relocate the position of entities to another location.  It can also simulate weapon or payload releases.  This was specifically used in DTE-4 to integrate a helicopter representing a Vertical Takeoff UAV and five T-72 enemy tanks into the scenario.DPG Live Interface. This interface converts range data from live vehicles into DIS or HLA simulation data.  This enables live vehicles to participate in virtual testing.  This was specifically used in DTE 4 to integrate and test the NBC RV Stryker during testing at DPG.ATC Live Interface. This interface converts range data from live vehicles into distributed simulation protocol data.  This enables live vehicles to participate in virtual testing. For DTE $4, a live Stryker on APG mobility test course was integrated into the scenario as a support vehicle for causality removal.RTTC Live Interface. This interface inserts a live entity into the distributed simulation environment.  This live entity is a UH-1 aircraft playing the surrogate role of a UAV. Position data of the UAV surrogate is trans-located to the terrain of the distributed test simulation scenario.  TSPI data is relayed to a ground station from the aircraft via RF modem/GPS package called LOCAITS (Low Cost Airborne Interim Tracking System).  The RAVIN (Real-time Acquisition Virtual Instrumentation Network) router converts the data to DIS PDU format.  Real time video, sensor/seeker testing and video are also available with the use of the configurable SEAIP (Stabilized Electro-Optical Airborne Instrumentation Platform).FLIGHTLAB. FLIGHTLAB is a flight vehicle modeling and analysis tool developed by Advanced Research Technology (ART), that allows users to interactively produce models from a library of modeling components by arbitrarily selecting the modeling components, interconnecting them into a custom architecture, and assigning aircraft specific data to the parameters of these components. FLIGHTLAB’s simulation language and scope provides an interpretive operating environment with a Matlab-like syntax that supports vector/matrix operations and interactive data and command access. For DTE 4, FLIGHTLAB provided a virtual helicopter.Advanced Concept Research Tool (ACRT). ACRT is a vehicle simulator used to represent an FCS Reconnaissance and Surveillance vehicle. The vehicle simulator included InfraRed (IR) gunner and driver views provided by the Night Vision Image Generator (NVIG), Situational Awareness views provided by the RPWS, and control of unmanned and unattended entities provided by the Universal Controller (UC).Comprehensive Munition and Sensor Server (CMS2). Provided Unattended Ground Sensor (UGS), Intelligent Munition System (IMS) and mine simulations.Universal Controller (UC). The UC is a control station for unattended and unmanned systems (UAV, UGS, IMS, and UGV).Missile Simulator. Simulates real-time position monitoring through differentially corrected of  GPS of all equipped assets.  Simulates targeting data for fires and forget weapon systems and computes the appropriate weapons impact footprint as well as probability of kill.  Utilized to simulate the NLOS –C Weapon System.Drone Formation Control System (DFCS) UAV/Threat Tank Simulation. The DFCS UAV/Threat Tank Simulation provides the WSMR Live Interface with simulated UAV/Tank data modeled to accurately reflect the parameters of the selected participants and provided in the DFCS data format to the WSMR Real Time Data Processing System (RTDPS).  This data is subsequently fed to the WSMR Live Vehicle Interface for integration into the exercises.Lethality Server. The lethality server is designed to operate as a simulation support tool.  It monitors the virtual environment for munition detonations, calculates the resulting damage to vehicles or other entities, and provides that damage in a timely manner allowing simulated entities to represent those damage effects in an appropriate way (e.g. become mobility or fire power “killed”).  During DTE-4 the server executed all of these tasks except for the very last step (it never published the damage results).  This provided the opportunity to evaluate the server’s performance without disrupting the normal operation of the other simulated entities.  These simulated entities were allowed to process damage as they normally would (through their own internal process).  In parallel the server calculated damage effects under the same conditions.  This provided a basis to evaluate the server’s performance and correctness.3. Database DevelopmentTwo environmental databases were developed to provide correlated natural environment stimuli to the LVC capabilities. The databases contained information about terrain and weather conditions pertinent to the tactical scenario.3.1 Terrain DatabaseYPG personnel develop terrain databases and formats for a 60 x 60 Km terrain box on WSMR ranges for use in the DTE 4. A 30 meter posting Close Terrain Data Base (CTDB) is used with a 10 x 10 sub-meter terrain used for the VDMS and UGV representations. The terrain databases are synchronized, correlated, and optimized for use by different live, virtual, and constructive test capabilities. Terrain correlation is dependent on sub-sampling techniques used in various production tools.3.2 Weather DatabaseThe Surface Atmospheric Measurement System (SAMS) from DPG on WSMR ranges provided surface measurements of wind direction and speed, air temperature, relative humidity, and pressure. The Geosynchronous Orbiting Environmental Satellite (GOES) provided images of cloud fields. These data are collected and integrated with the 4DWX system operated by DPG.  DPG generated scenario specific meteorological profiles that are presented in the HLA distributed test environment via the OASES.4. ThreadsDTE 4 has five simulation threads (federates) and one live system thread representing integrated test center capabilities. Individually, threads can be used to test components or subsystem or the threads interact with each other to test SoS. The following diagrams show the interactions in each thread. Other federates may be involved in each thread, but only the ones relevant to the thread are shown. Figure 4.1 shows the Chemical and Biological (CB) Intelligence Surveillance and Reconnaissance (ISR) thread. Figure 4.2 shows the Infrared ISR thread. Figure 4.3 shows the C4I thread. Figure 4.4 shows the Robotic Intelligence thread. Figure 4.5 shows the Mobility thread. Figure 4.6 shows the live systems thread. SHAPE  \* MERGEFORMAT Figure 4.1 CB ISR Thread SHAPE  \* MERGEFORMAT Figure 4.2 IR ISR Thread SHAPE  \* MERGEFORMAT Figure 4.3 C4 Thread SHAPE  \* MERGEFORMAT Figure 4.4 Robotic Intelligence Thread SHAPE  \* MERGEFORMAT Figure 4.5 Mobility Thread SHAPE  \* MERGEFORMAT Figure 4.6 Live System Thread5. ArchitectureThe integration of diverse components and the distributed nature of the capability requires an architecture to enable interaction among the live and simulated elements of the DTE 4. The program uses the HLA with a modified RPR FOM and the MÄK run-time interface (RTI) as the backbone for distribution across the DREN. Locally, some thread components or federates use the legacy DIS architecture and the MÄK DIS-to-RPR FOM Gateway located at each distributed node enables translation of DIS information into HLA and back, as required. Figure 5.1 graphically depict the architecture and threads (federates) used in DTE 4.Figure 5.1 Graphical depiction of the DTE 4 architecture and threads6. Increasing Distributed Test CapabilityThe SEIT / DTE development phases employ an evolving and increasing level of capability to support distributed testing for increasingly complex test requirements, culminating with a demonstration. The SEIT / DTE demonstrations utilize HLA federates, DIS applications, physical test equipment, sensors, and human operators to represent the operational battlefield. Tactical scenarios include blue/red forces, C2 messaging, CB hazards, CB and IR sensors, platform mobility effects, autonomous UGV activities and live ground and aerial platforms coupled with near-real time meteorology data. Additionally, the SEIT / DTE demonstration uses several simulation and test tools including a simulation logger, a DIS-to-HLA (RPR FOM) gateway, a 3D stealth visualization tool, several test planning and execution and data collection and analysis tools to complete the distributed test environment.6.1 DTE 4 DemonstrationDTE 4 built on the foundation established in IOCs 1 / 2 and DTE 3 and occurred in August 2004. Technologically, DTE 4 was similar to DTE 3. This event reused the threads, meteorology inputs, and architecture previously described; although the DTE team optimized some of the underlying thread capabilities to support FCS test requirements and new terrain for the WSMR ranges was developed.  DTE 4 is unclassified. In addition, the scenario was changed to reflect nine Mission Execution Threads (METs) developed by the FCS LSI to support the first integrated testing for FCS and centered around the Future Force element scheduled to employ the FCS materiel, the Unit of Action (UoA).Through the decomposition of the UoA mission and nine METs into tasks related to FCS required capabilities, a TOEL is developed to drive the distributed test and provide requirements traceability to ensure the generation of test data that result with valuable information to support FCS evaluation. This test framework and process generates data for the assessment of capabilities and limitations of components, subsystems and the overall SoS in an appropriate mission context. Additionally, the TOEL provided a “script” to conduct distributed testing by indicating simulation activities, operator activities, and data collection points and drove some data collection elements for C4ISR testing.7. Path AheadDTE program is still optimizing its environmental and test system representations and distributed test capabilities to enhance its capability to support Army testing, in particular the FCS. The next capability demonstration is planned for the Distributed Test Event 5 (DTE 5) scheduled for August 2005. 7.1 DTE 5 PlansDTE 5 will leverage on the technologies, processes and expertise developed in DTE 4.  DTE 5 will incorporate capabilities from other Army commands and other US services. The Cross Command Collaborative Effort (3CE) is a program established to integrate Army M&S from ATEC, the Research, Development and Engineering Command (RDECOM) and the Training, Requirements, Analysis and Doctrine Command (TRADOC) to support Army acquisition requirements. In addition, DTE 5 will incorporate distributed test and M&S capabilities from the US Air Force (USAF) and US Navy (USN) being developed in the Multi-Service Distributed Event (MSDE) program to support Joint Test and Evaluation (JT&E) requirements.  The basic concept for DTE 5 is to provide risk mitigation to the FCS program for the Experiment 1.1, assessing integration of existing and future C4ISR systems, in an overall Joint Task (JT) scenario with USAF and USN elements.8. Summary8.1 General BenefitsDTE 4 development is driven by Army T&E and M&S requirements to support Army cross domain customer requirements. The layered architecture results with autonomous elements that interact through common communication protocols and enables a more realistic representation of C4ISR in tactical scenarios.  This distributed test capability is a critical to support the ATEC FCS evaluation strategy. And has poised ATEC distributed test capabilities to integrate with other Army command and service elements. 8.2 Test BenefitsThe SEIT / DTE is a fast-tracked program that supports ATEC’s goal of distributed testing, integrating in-use live and simulated T&E capabilities to achieve enhanced synergy.  Distributed testing leverages local Subject Matter Experts (SMEs) and fixed capital assets and augments physical testing providing increased & enhanced test parameters beyond live testing. Near real-time data analysis and products are demonstrated to help inform rapid acquisition decisions. The DTE program is creating a SME culture within DTC enhancing mission appreciation among test center personnel and an environment to rapidly implement distributed testing. And finally provides a tactically relevant environment for element and SoS T&E.9. ConclusionsThe DTE capability was developed with a relatively low-cost and accelerated schedule to meet the pressing requirement for FCS testing. The developer controlled development and implementation costs by leveraging mature capabilities and high quality expertise throughout the DTC. The DTE provides an avenue for demonstrating the usefulness of M&S-based test technologies developed through the DTC VPG and has greatly advanced ATEC distributed testing. Additionally, the resulting capability has a much broader application to joint and coalition service research and development, test and evaluation, and training applications and systems.Broadening DTE scenarios to include representation of Joint Forces will enable realistic interactions of Current and Future US forces to further provide required test environments for US materiel solutions. DTE and MSDE provide the proper avenue to immerse US live and multi-resolution virtual representation of tactical systems for assessment and evaluation in appropriate Joint mission environments representing the asymmetric threats employed by the existing and present enemy.10. References [1]	Remmick, Nathan: “Future Combat System System Development and Demonstration Phase Integration Phase Plan”, Future Combat System Lead System Integrator Test Plan, January 2004.[2]	Remmick, Nathan: “Future Combat System System Development and Demonstration Phase Integration and Verification Phase Plan”, Future Combat System Lead System Integrator Test Plan, October 2004.[3]	Basciano, Tom: “Future Combat System System Development and Demonstration Phase Experiment Increment 1.1”, Future Combat System Lead System Integrator Test Plan, November 2004.[4]	Clardy, Timothy; Dennen, Kevin; Liebert, Ralph; Valentine, Peter; Carr, Stewart; Hanaway, Michael; Meyer, Hal; Music, Mark; Hernandez, Ruben; O’Connor, Michael; Briscoe, Derrick; Ryan, Robert: “Formal Report For The Demonstration of the Synthetic Environments Integrated Test Bed Initial Operating Capability 1,” US Army Developmental Test Command Report, June 2003.[5]	Liebert, Ralph; Carr, Stewart; Hanaway, Michael; Clardy, Timothy; Dennen, Kevin; Will Clayton; Meyer, Hal; Music, Mark; Hernandez, Ruben; O’Connor, Michael; Jones, Dennis; Ryan, Robert: “US Army Developmental Test Command Virtual Proving Ground (VPG) Synthetic Environments Integrated Test Bed (SEIT) IOC 1,” Simulation and Modeling for Acquisition Requirements and Training (SMART) 2003 Conference, September 2003.[6]	O’Connor, Michael: “Demonstration Control Document For The Synthetic Environment Integrated Testbed Initial Operating Capability 2,” US Army Developmental Test Command Report, September 2003.[7]	Liebert, Ralph; Clardy, Timothy; O’Connor, Michael; “Synthetic Environments Integrated Test Bed (SEIT): Building a Simulation-based Distributed Test Capability” Spring 04 Simulation Interoperability and Standards Organization Integration Workshop (S04 SIW), 04S-SIW-082, April 2004.[8]	Liebert, Ralph; Clardy, Timothy; O’Connor, Michael; “Synthetic Environments Integrated Test Bed (SEIT): A Distributed Test Environment” European 04 Simulation Interoperability and Standards Organization Integration Workshop (E04 SIW), 04S-SIW-022, July 2004.Author BiographiesRALPH LIEBERT, Chief of the Electronic Proving Ground Ft. Lewis, has been with the civil service for 10 years in Army Test & Evaluation (T&E) and has been involved with instituting Modeling & Simulation (M&S) for use in T&E for seven years. Mr. Liebert started his tenure with the Army as a test officer and laboratory technician working in Chemical and Biological Defense T&E at Dugway Proving Ground and is currently managing C4ISR T&E at EPG Ft. Lewis.  He is managing M&S for EPG to support T&E for Future Combat System (FCS) and is the co-chair for the Synthetic Environment Focus Group part of the Developmental Test Command's Virtual Proving Ground. He has B.S. in Microbiology from the University of Louisiana Lafayette and has completed graduate studies in Microbiology from the University of Montana.TIM CLARDY has a B.S. in Electrical Engineering from Auburn University and a Masters in Business Administration (MBA) from the Florida Institute of Technology. Mr. Clardy currently serves as a senior electrical engineer in the Subsystems Test & Analysis Branch, where he is the Site Manager of the High Performance Computing Center, and has over 10 years of experience in test and evaluation. He has extensive background in modeling and simulation, computing technologies, and electro-optics sensors and missile systems. Also, Mr. Clardy is the branch lead engineer for the Future Combat System (FCS) and serves on numerous committees including Chair for Distributed Simulation and Test Working Group, Co-Chair of the DTC Virtual Proving Ground Synthetic Environments Focus Group, numerous other committees and working groups and is a member of the Army Acquisition Core with certifications in multiple technology areas.Michael J. O’Connor is a Principal Simulation Architect with ITT Industries Advanced Engineering & Sciences Division.  He received a bachelor of computer engineering from Auburn University in 1987 and a masters in computer science from the University of Alabama in Huntsville in 1991.  Mr. O’Connor has been involved in the distributed simulation community for over ten years.  In that time he as served as the Editor of the Real-time Platform Reference Federation Object Model (RPR FOM), Chair of the SISO Standards Activity Committee, and currently serves as the SISO Executive Committee Vice Chair.  Mr. O’Connor is currently applying the standards developed by SISO in his role as simulation integration lead for the US Army Test and Evaluation Command’s Virtual Proving Ground Distributed Test Event initiative.(RICS)2NLOS-CSimulator(2)(2)OneSAFTestbed (OTB)ORIONDistributed Interactive Simulation (DIS) Protocol Data Units (PDUs)VEGADIRSPEngineeringGrade IR ArraySensorOperator StationDIS/RPRGW High Level Architecture (HLA) Runtime Infrastructure (RTI)MaK StealthStarshipNuclear, Chemical,Biological and Radiological (NCBR)Dial-A-Sensor (DAS)2.07.0DISSimulationIDPhysicalHardwareIDHLA FederateIDBUSIDLEGENDSimulationIDGATEWAYID Digital ArmyUSMTF VMFStimulator(DAUVS) Role PlayerWorkstation(RPWS)(17)(5)(2)IR Targeting StationRoboticIntelligenceLive Vehicle InterfacesVEGAMobile IR Scene Projector(MIESP)SensorOperator StationMaK LoggerC4 Thread  IR ISR ThreadCB ISR ThreadMobility ThreadLive System InterfaceUtilitiesDPG Live Vehicle InterfaceIOC 2Digital Collection, Analysis and Review SystemMCS (H&L)AMDWSFBCB2Vehicle DynamicsMobility ServerSimulationApplication Suite(SAS)