Enhanced Distance Learning for DVTE: Real Time Feedback in an Integrated SCORM Environment David L. DrakeRyan P.Z. BruntonJustin BuschKatherine L. Morse, Ph.D.Science Applications International Corporation10260 Campus Point DriveSan Diego, CA 92121858-826-2278HYPERLINK "mailto:drakedavid@saic.com"drakedavid@saic.com, HYPERLINK "mailto:bruntonr@saic.com"bruntonr@saic.com,  HYPERLINK "mailto:jbusch@saic.com" jbusch@saic.com, HYPERLINK "mailto:kmorse@epsilonsystems.com"morsek@saic.com,Capt. Erik JilsonUSMC TECOM3300 Russell Road, Building 2006Quantico, VA 22134-5001703-784-9596 HYPERLINK "mailto:erik.jilson@tusmc.mil" erik.jilson@tusmc.milKeywords: HLA, ADL, SCORM, DVTE ABSTRACT: The DoD education and training community recognizes that the use of simulations can significantly enhance the student’s educational experience. Our team has developed several integrated HLA-SCORM prototypes in the last few years. For the first time an operational simulation, the Marine Corps Deployable Virtual Training Environment (DVTE), has been integrated with SCORM conformant content delivered in an open source Learning Management System (LMS), providing real time feedback from DVTE to the LMS for individualized, focused remediation of the student’s performance within DVTE.The course that is presented here is based on the Marine Corps doctrine for Call for Fire. Real time detection of student activity within a High Level Architecture (HLA)-compliant simulation being communicated back to an LMS for the purposes of evaluation is a critical step in the integration of distributed learning and simulation. With this result, other goals are now achievable. Among these is the capability to have multiple students working within a collaborative (or competitive) simulation, while the LMS gathers (near) real-time feedback for individual student scoring. The actions taken during this type of collaborative training can also be analyzed as a team effort, and scored thusly. The important advancement is that the simulation being used in this situation need not have been designed exclusively as a training system. This also opens the possibility to have the integrated LMS/simulation train students to use the simulation itself.DVTE BackgroundThe Deployable Virtual Training Environment (DVTE) [1] is a prototype Marine Corps system to address training at the individual, team, and unit levels. It consists of two parts: the Combined Arms Network and the Infantry Tool Kit. It is composed of Commercial Off the Shelf / Government Off the Shelf (COTS/GOTS) technology and is hosted on a self-contained network of easily configurable laptop computers. DVTE provides first-person battlefield viewpoints via individually simulated weapon systems. It contains an emulation of a tactical communications network and provides a state-of-the-art after action review capability.DVTE’s Combined Arms Network (CAN) provides a deployed unit with the opportunity to train in a combined arms environment when the live training is not available. Maneuver commanders have the opportunity to exercise the assets of the Marine Air-Ground Task Force (MAGTF) against a robust, realistic enemy force. Flexibility is key, as the commander can task organize his unit against the threat. His Fire Support Team (FIST) can control mortar and artillery fires, while also coordinating rotary and fixed wing fires against moving, fighting targets. Tactical communication networks are replicated for realistic Command and Control (C2). In its current implementation, DVTE relies on a live evaluator to observe the exercise, time stamp significant events, and provide feedback to the students during a replay outbrief. With the project described in this paper, Marine Corps Training and Education Command (TECOM) is taking the first step toward an automated evaluation of student interactions with DVTE and provision of required remediation.Figure  SEQ Figure \* ARABIC 1. DVTE Sample Screen ShotHLA-ADL Integration BackgroundIntegrating existing High Level Architecture (HLA)-compliant simulations with Advanced Distributed Learning (ADL)-compliant [2, 3] web-based instructional content provides the student with a richer learning environment; one in which active interaction with simulations supports the proven instructional paradigm of “learning followed by doing.” By employing open standards-based technologies, we maximize reuse, existing investment, interoperability, and deployability. By directly integrating these technologies, the system can perform an intelligent, real time assessment of the student’s interaction with the simulation and feed the results directly back to the learning management system. Based on these detailed results, the learning management system can provide the student with focused, individualized remediation, automatically redirecting the student to instructional content specifically designed to address the student’s needs as measured in the simulation. Until now, this level of individualized assessment and remediation has required one-on-one attention by a trained instructor.Our team’s work on the HLA-ADL integration began with feasibility analysis and a rudimentary, single-system implementation nearly four years ago. Since that time we have evolved the technology [4, 5] to support integrated instruction in a network-centric environment, eventually allowing it to be deployed in the Global Information Grid (GIG). While evolving the architecture we have also applied it to increasingly complex instructional scenarios. The most recent of these is its application to DVTE as described in this paper.Instructional Goals and StrategyThe goal is not to replace the live evaluator, but rather to provide feedback to individual students on their execution of specific limited scope procedures, e.g. terminal air control (forward air control), and target location for artillery call for fire of the Forward Observer/Forward Air Controller (FO/FAC). These procedures are sufficiently defined by doctrine to lend themselves to objective, automated evaluation without the need for artificial intelligence techniques necessary for subjective, qualitative analysis. The existing training is delivered at basic infantry skill schools, artillery schools, air control schools, and Expeditionary Warfare Training Groups. FO training is also provided at Field Artillery School, Ft. Sill, OK. Existing live training is effective, but there are not many opportunities to train with live fire and it has associated costs, inherent dangers, and logistical issues.Furthermore, without this instructional aid, Marines who are in transit to deployment must be trained prior to the teamwork exercise by the live evaluator. The live evaluator is a senior member of the unit who performs DVTE training as a collateral duty (i.e. running DVTE training takes this senior unit member away from mission critical tasks). The DVTE preparatory training time, and individual skills assessment and feedback also take time away from training exercise execution because it must be done by the live evaluator for each student. Performing these activities in parallel for all the students will expedite this portion of the training, leaving more time to execute additional teamwork training exercises. It is clear the long-term cost savings will be in more effective use of classroom time and live training for review, and less time for the live evaluator. Making such an integrated system should provide the following benefits:Reduce time spent by both students and the live evaluator in DVTE preparatory trainingReduce time spent by both students and the live evaluator in individual skills assessment and remedial instructionIncrease time for the live evaluator to perform primary mission dutiesIncrease time to execute additional DVTE training exercisesAllow FO/FAC refresher training to all Marines any time, anywhereCourse Content A controlled training event scenario has been created to establish boundaries for the ADL content and DVTE simulation development and focus the context of the event on a Call for Fire procedure conducted by a Marine, who is not necessarily the designated Forward Observer/Forward Air Controller (FO/FAC) for his unit. This scenario is congruent with the concept that DVTE will be employed by Marines to obtain refresher training for infrequently practiced skills in preparation for a military operation expected sometime in the near future. The following Marine Corps Orders (MCOs) specify the requirements for live and classroom training for these skills:FAC - MCO 3500.37, Aviation Training and Readiness Manual, Tactical Air Control Party OfficerCall for Fire - MCO 1510.35D, Individual Training Standards Order for OccFld 03, Infantry (Enlisted)FO - MCO 3501.26, Artillery Unit Training & Readiness ManualIn addition to the MCOs listed above, the following materials were used as sources of definitive details for the course content:US Army Field Manual 6-30 “Tactics, Techniques, and Procedures for Observed Fire” Marine Corps Warfighting Publication (MWCP) 3-1 “Ground Combat Operations” MCWP 3-16 “Fire Support Coordination in the Ground Combat Element”MCWP 3-16.6 “Supporting Arms Observer, Spotter, and Controller”The "Sustainment Training for Call for Fire by a Forward Observer" course covers the following:Terms used for Call for FireThe six elements of Call for FireThe four types of methods of target locationHow to use DVTE for practicing Call for FireA Call for Fire capability test using DVTEThe course is written to be Shareable Content Object Reference Model (SCORM)-conformant. There are five Sharable Content Objects (SCOs) embedded in the course content, and they each contain a quiz regarding the material presented to the point they appear at within the course. The tutorial content tested by the quizzes is structured as a collection of Assets within the Learning Management System (LMS), rather than being divided into SCOs. This decision was made because the test scores are sufficient to capture student capability and progress. The SCOs represent four enabling objectives, including the ability to perform each of the three transmissions in a Call for Fire, and the ability to use the DVTE simulation environment.With the highly interactive nature of DVTE, we concluded that additional complex visual and auditory media objects were unnecessary in the course content (the non-DVTE content). Since the content was to aid in the memorization of the Call for Fire protocol, thereby being very textual in nature, we decided to use an iconic speech bubble concept as our primary organization tool. It paints a simple and memorable image if how a Forward Observer communicates to the Fire Direction Center (FDC), and how the FDC responds. The bubbles are used consistently throughout the course.  REF _Ref504623905 \h Figure 2 shows one of the content screens employing the speech bubbles.Figure  SEQ Figure \* ARABIC 2. Speech Bubble Example - Call for Fire The six elements of a Call for Fire can be confusing to the uninitiated since they are packaged within three primary transmissions, which can be followed by additional transmissions to adjust and augment the Calls for Fire. By using the speech bubbles, we directly addressed this complexity using a common visual method. REF _Ref504624070 \h Figure 3 illustrates the 1st Call for Fire transmission, with all its possible components. Formally, these types of diagrams are called “railroad diagrams,” and are particularly useful for understanding complex protocol formatting. These diagrams aid those that learn either visually or textually, since both types of presentation styles are incorporated. Figure  SEQ Figure \* ARABIC 3. Railroad Diagram Example – First TransmissionThe railroad diagrams used in this course were developed for this course and are not presented in the available literature on Call for Fire.Instructional ScenarioYou, as the Forward Observer (FO), are dropped off in the 29 Palms desert near grid location 838074. There have been reconnaissance reports of opposing forces vehicles near grid location 839088. You are ordered to position yourself at a good vantage point and neutralize all of these vehicles. You can communicate to your Fire Direction Center (FDC) verbally, which has a supporting battery of M198s. Your full call sign is B6A2, the FDC’s full call sign is B6A1. Your Mission: Move to a good vantage point, target all enemy vehicles or units observed, and neutralize them. (In the demonstration scenario, there are 9 targets to be destroyed, grouped into two clustered areas.)The general flow of the instruction first orients the trainee to the objectives and goals of the specific training session. Then the trainee receives a brief refresher upon the specific Call for Fire skills that they will need to perform during the DVTE training. Following this introductory material, the actual scenario begins. The student is instructed that he or she has been placed in the 3D simulation at a point in the desert that is in range of enemy vehicles, and is ordered to destroy them. The trainee is presented situations requiring the accurate employment of Call for Fire procedures. Their ability to correctly perform these procedures is assessed and, if improperly performed, they are informed of their deficiencies and provided the opportunity to repeat their performance of the necessary procedures.There are several factors that influence the assessment of trainee performance. First among these factors is the data that the DVTE simulation produces. To satisfactorily identify and later communicate trainee performance, this project is dependent upon the data generated by the DVTE simulation. The trainee’s actions must spawn the transmission of specific data packets through the Runtime Infrastructure (RTI) used by DVTE for this technology to operate. In the delivered integrated demonstration software, the LMS is informed of the status of every target in the scenario (level of destruction, if any) and when rounds have exploded. If more data were available from the RTI that was of interest in grading the student, it could also have been extracted and passed to the LMS. The LMS immediately changes the browser page based on the passed information. It also terminates the lesson when the student successfully destroys all of the targets, or the student has run out of time. These actions are recorded as part of the student’s grade. The current course takes a student approximately 90 minutes.Figure  SEQ Figure \* ARABIC 4. Laptop Setup for the Integrated SystemIn the current instruction, it should be noted that mistakes in the Calls for Fire, such as incorrect call signs, failure to state “over” or “out” properly, or incorrect target descriptions, are not caught using this methodology. The instruction could be changed to handle this in one of two ways. The Fire Direction Control (FDC) Operator could track these mistakes and fold the information into the student’s score. This requires a great deal of dependency on the FDC Operator to provide a quality assessment on the student.Another option would be to have the student use the Student System, which is also displaying the LMS in a browser, to type in the call for Fire. That typed message could be analyzed by parsing software for its correctness, and pass the analyzed calls on to the FDC Operator. This is a better but much more complex system. The advantage to such a system would be to automate the grading process for the Call for Fire, which gets to the heart of the training. Due to the complexity of this system, it was out of scope for this project, but it is feasible.ArchitectureThe architecture has two components:The software architecture including the assignment of software components to physical machinesThe physical layout of the machines to support the instructional scenario.The physical layout of the laptop machines is illustrated in  REF _Ref504625048 \h Figure 4.Note that in the setup, the FDC Operator should have his/her laptop situated so that the student cannot see its screen. This is because the FDC Operator will have access to the exact position of the targets that the student will be targeting during testing. The two laptops in front of the student should be situated so that the FDC Operator can view what the student is doing. This is necessary for communication between the two people, and to prevent the student from misusing the systems. The systems have not been hardened against mischief. The student, if allowed free range of play on the systems, has access to the Joint Semi-Automated Force (JSAF) graphical interface, and access to the entire Linux operating system and installed applications. The FDC Operator should monitor activity on this system that is not associated with properly using the LMS and at a minimum, curtail it, and at the extreme, report it. In addition, the FDC Operator is responsible for verifying that the student is not using joystick button 8, which would give the student an unfair advantage by providing a battlefield perspective that would not be possible for an in-field Forward Observer.The Learning Management System (LMS), the course content, and the Listener Federate were incorporated into the laptop that contained the Joint Semi-Automated Force, allowing us to deliver the integrated system without additional hardware. In the diagram below, these processes are running on the “Student” laptop. The software and communications architecture is illustrated in  REF _Ref504625155 \h Figure 5.The components of the software architecture are:JSAF: The Joint Semi-Automated Force (JSAF) is a simulation system that generates and controls entity level platforms such as infantrymen, tanks, ships, airplanes, munitions, buildings, and sensors, which interact at the individual level in a robust synthetic natural environment. The individual entities are task organized into appropriate units for a given mission and can be controlled as units or single entities. The simulated synthetic environment is a representation of real world terrain, oceans, and weather conditions that affect the behaviors and capabilities of the synthetic forces. JSAF evolved from the DARPA Synthetic Theater of War (STOW) Advanced Concept Technology Demonstration, and its operational sponsor is the Joint Forces Command (JFCOM) Experimentation Directorate, J9. JSAF acts as the “ground truth” for the DVTE system. It is written as a HLA federate, and as such, communicates to other federates through the RTI. Although JSAF has a graphical user interface, it is not used when the LMS training is underway.FATS: The Forward Artillery Training System (FATS) acts as the driver for the DVTE 3D Viewer, permits a FDC Operator to input details regarding the munitions to be fired, track the activity within the field of operation, and interacts with JSAF through the RTI. Both FATS and JSAF retain information regarding the state of the artillery, but JSAF is considered the “ground truth.” For that reason, the DVTE 3D Viewer may show a vehicle burning, but JSAF may not consider it destroyed. The communication between FATS and the DVTE 3D Viewer is in a proprietary format, and is not accessible or readable by other processes.Figure  SEQ Figure \* ARABIC 5. Software ArchitectureDVTE 3D Viewer: The DVTE 3D Viewer runs as a process on the “Visualization” laptop. Technically, the process that is displaying the 3D view is a process called FATS_IG. The viewer takes over the entire screen so that access to the operating system or other processes is not easily done. The scenario used for the training is a landscape of the 29 Palms Marine Corps training area. Using a joystick, the student will be able to move his first-person character around on the 3D terrain. In this scenario, the first-person character does not have access to weapons, but instead has access to military-grade binoculars. By making Calls for Fire to the FDC Operator, who can then enter coordinates and descriptions of rounds into FATS, rounds can be brought to bear on targets in the 3D viewer. The system provides delays to the incoming rounds due to travel time, and the sounds of explosions are heard at the appropriate volume based on the distance and orientation of the first-person character acting as the Forward Observer, relative to the detonations.Browser: The web browser used for this DVTE/LMS integrated system is Firefox 1.0. It is freely available, runs on all popular operating systems, provides W3C compliant HTML support, and is lightweight. Firefox is said to be lightweight because it doesn’t have extraneous code in it for extra features such as email support or a web page designer. This makes it fast and efficient, and easier for its developers to test for quality. It is from within Foxfire that the student will be able to interact with the Learning Management System.Learning Management System (LMS): The LMS process provides the course material, quizzes, instructions on how to run the tests, and with the help of supporting processes, interaction with the DVTE simulation. The LMS used was the Avatal Learning System. It is SCORM 1.2 conformant and is freely available and distributable. The course content (assets and SCOs in the form of HTML with embedded JavaScript) was packaged in a specialized zipped format for the LMS to be able to access and use, as required by the SCORM 1.2 specification.Listener Federate Applet: When the FATS and JSAF processes are running, they communicate to one another using the Defense Modeling & Simulation Office (DMSO) RTI 1.3NG. FATS and JSAF have been written to use the RTI in connectionless mode, which means that no additional processes are needed for their communication; rather a socket port is agreed upon and used for the transactions. When the student opens the course content page that tells the student to interact with the DVTE simulation, the Listener Federate Applet is loaded. This applet acts as a federate within the federation created by FATS and JSAF, which means that it is also communicating over the RTI in connectionless mode. However, due to security restrictions in Java plug-ins and library limitations in DMSO RTI 1.3NG, the Web Enabled RTI libraries (developed by SAIC) are used to accomplish this communication that would otherwise not be possible.There is a significant amount of RTI traffic between FATS and JSAF. JSAF reports on the position of all of its objects 25 times per second. The Listener Federate Applet is only interested in the number and status of the targets, so it filters out all of the rest of the RTI traffic. If the status of the targets change, such as being destroyed, that information causes a JavaScript method to be executed, changing the state of the student’s browser screen (the icon for that target). In addition, the score for the student is updated. When the student’s timer (run as another JavaScript) stops the interaction with the DVTE simulation, the score is recorded and the browser screen is changed to show the results. This also happens if the student is successful in destroying all of the targets. In that case, the Listener Federate Applet initiates the termination of the interaction, and displays the student’s score.Choosing an LMSThe Avatal Learning System was the LMS used for the project. The selection process was driven by several criteria. First, the LMS needed to provide a SCORM 1.2-conformant architecture. Second, due to budgetary constraints, the LMS needed to be available at low-cost. Third, it was desirable that the LMS be open-source software that could be installed and maintained by SAIC software engineers in the absence of paid technical support from the original LMS developers. The critical decision to select Avatal was its stability and thoroughness of implementation. Not all of the existing freely available LMSs are stable, and many of them either do not support SCORM 1.2, or do so incompletely. Although Avatal includes certain drawbacks (it has very sparse overall documentation and its internal documentation is in German), it met all of the needs described above, and satisfied all of the specification conformances in the list below.The following are the top sixteen criteria used in the evaluation, each receiving an appropriate weighting factor:Shareable Content Object Reuse Model (SCORM) ConformantProvides XML-based Content Management SystemProvides Support for XML Data FormatInstructional Management Systems (IMS) ConformantSupports Open Architecture (non-proprietary formats, common scripting)Demo/Trial Software is availableSupports Unlimited Number of Stored CoursesEasy Navigation and Access to FeaturesSoftware Updates/Upgrades ProvidedProvides Lesson Documentation and Online HelpCreation of Online Course CatalogControl of Course MaterialControl of Student, Instructor AccountsProvides Student and Instructor AuthenticationMinimal processor, memory, hard drive requirementsLow Cost of MaintenanceConclusionsThis prototype represents a significant step forward in integrated instruction and simulation. Note only have we demonstrated that this technology and methodology can be applied to an extant operational simulation, we have also proven that near real time communication back to an LMS from such an operation simulation is possible and tractable from an instructional perspective. Furthermore, this capability was delivered within the context of the existing standards and software, proving the benefits of open standards and realizing the cost benefits of reuse.In addition, as the DoD moves to the GIG, this technology can result in the following important benefits:The simulation and learning content can stay home-based with their dedicated hardware, technical support, and configuration management.The warfighter can access this training environment either while home-based or while deployed.Simulations and training are guaranteed to be absolutely up to date at the time of student use.Use of open standards preserves prior investment and reduces cost and risk associated with proprietary approaches.The student engages in the proven instructional paradigm of “learning followed by doing.” The system automatically performs intelligent, real time assessment of the student’s interaction with the simulation and feeds the results directly back to the learning management system, enabling focused, individualized remediation. Automated remediation reduces reliance on instructors for one-on-one student assessment.Future WorkHaving proven that real time communication between an operational simulation and an LMS are possible, other capabilities are now achievable. Among these is the capability to have multiple students working within a collaborative (or competitive) simulation, while the LMS gathers (near) real-time feedback for individual student scoring. The actions taken during this type of collaborative training can also be analyzed as a team effort, and scored thusly. The important advancement is that the simulation being used in this situation need not have been designed exclusively as a training system. This also opens up the possibility of having the integrated LMS/simulation train the students to use the simulation itself.The Marine Corps is currently evaluating opportunities for applying this capability to other instructional tasks and environments.References<http://www.visitech.com/trng_sys/trng_sys_1_dvte.html>.<http://www.adlnet.org>.“Sharable Content Object Reference Model (SCORM) Version 1.2,” Advanced Distributed Learning Initiative, October 1, 2001.Jake “Jack” Borah, Katherine L. Morse, PhD, Victor P. DiRienzo Jr., “The Next Generation High Level Architecture Training System,” 01S-SIW-063, Proceedings of the 2001 Spring Simulation Interoperability Workshop, Orlando FL, September 2001.Katherine L. Morse, PhD, Jake “Jack” Borah, Victor P. DiRienzo Jr., “Simulation Assisted Learning Using HLA and SCORM,” 02F-SIW-010, Proceedings of the 2002 Fall Simulation Interoperability Workshop, Orlando FL, September 2002.Author BiographiesDavid L. Drake is a Program Manager with in SAIC working in the area of Modeling and Simulation infrastructure development. Mr. Drake has 26 years as a computer professional in simulation, computer security design, implementation and evaluation at companies including SAIC, Computer Sciences Corporation, and the MITRE Corporation. At SAIC, he has been a senior computer scientist and a manager for the Commercial Security Products Research and Development Division. While at the MITRE Corporation, he was lead developer for the Practical Verification System, a formal specification and automated verification. Mr. Drake received a Bachelors degree in mathematics from State University of New York at Buffalo and did graduate studies there in artificial intelligence. Mr. Drake received additional computer science training at Stanford Research Institute in California, Northeastern University, and Wang Institute in Massachusetts. He has published articles and given speeches on security and risk assessment topics and has a patent pending on the process for enterprise-wide intrusion detection.Ryan P.Z. Brunton is a Software Engineer with SAIC. He received his B.S. in computer science (2001) from the University of California, San Diego. Prior to completing his B.S. he worked at the MOVES Institute at the Naval Postgraduate School. Mr. Brunton’s key areas of expertise are modeling & simulation, object-oriented design and development, and the extreme programming methodology.Justin Busch is a computational linguist who has been with SAIC for over 5 years. He holds a bachelor's in linguistics from Claremont McKenna College and a master's in computational linguistics from the University of Southern California. Mr. Busch also holds a patent for the design of a concept-based search engine. At SAIC, his work has included ontology design and automated question-answering under various DARPA-sponsored programs, and development of training materials for the DVTE program.Dr. Katherine L. Morse is a Chief Scientist with SAIC. She received her B.S. in mathematics (1982), B.A. in Russian (1983), M.S. in computer science (1986) from the University of Arizona, and M.S. (1995) and Ph.D. (2000) in Information & Computer Science from the University of California, Irvine. Dr. Morse has worked in the computer industry for over 20 years, specializing in the areas of simulation, computer security, compilers, operating systems, neural networks, speech recognition, image processing, and engineering process development. Her Ph.D. dissertation is on dynamic multicast grouping for Data Distribution Management, a field in which she is widely recognized as a foremost expert.Capt. Erik Jilson is in the U.S. Marine Corps technology division, Training and Education Command. Capt. Jilson received his B.S. from the United States Naval Academy (1995), and his M.S. in Modeling, Virtual Environments, and Simulation from the Naval Postgraduate School (2001). His thesis was on Modeling Conventional Land Combat in a Multi-Agent System using Generalization of the Different Combat Entities and Combat Operations.