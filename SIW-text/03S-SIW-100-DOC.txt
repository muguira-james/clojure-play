Large Scale Federation Design for JVB using the RTI-NGKeith SnivelyDynamic Animation Systems, Inc.12015 Lee-Jackson Hwy, Ste. 200FairOaks, VA 22033703-333-5432 HYPERLINK "mailto:ksnively@d-a-s.com" ksnively@d-a-s.comAnnette WilsonVirtual Technology Corporation5510 Cherokee Ave., Suite 350Alexandria, VA 22312-2320(703)658-7050 HYPERLINK "mailto:awilson@virtc.com" awilson@virtc.comRoger WuerfelSAIC5400 Shawnee Rd. Suite 110Alexandria, VA 22015(703) 333-5427 HYPERLINK "mailto:Roger.D.Wuerfel@saic.com" Roger.D.Wuerfel@saic.comKeywords:RTI, RTI-NG, JVB, Federation Design, C4ISR ExperimentABSTRACT:  In designing a large-scale HLA-compliant simulation, federation developers consider the capabilities of a particular RTI implementation including performance, scalability, fault tolerance, and usability features. The C4ISR Experiment required the JVB simulation environment to support a federation consisting of over 150 federates simulating more than 20,000 objects.   This paper discusses design elements of the federation, RTI configuration parameters, and custom enhancements made to RTI-NG to address each of these issues for JVB.  In particular, we discuss DDM schema design and performance tuning.  Furthermore, we discuss run-time configuration parameters of the RTI-NG to optimize the behavior of components such as the asynchronous I/O thread.  Finally, we discuss customized modifications to the RTI-NG to increase usability.  These enhancements include the ability to recover ownership of orphaned objects from crashed federates and remove multiple federates from the federation simultaneously.IntroductionThe importance of simulation programs for supporting acquisition and training purposes continues to grow within the government and commercial industries.  The U.S. Department of Defense emphasizes Simulation and Modeling for Acquisition, Requirement and Training (SMART) and Simulation Based Acquisition (SBA) initiatives to reduce costs in evaluating prototype equipment and gain some insight into value added for military operations without the need for extensive field exercises.  As the importance of using simulations has grown, so has the need for larger scale exercises.  While simulations are encouraged to use designs that promote interoperability, such as utilizing HLA, realizing simulations that encompass more than a few dozen federates has rarely occurred.  Many times, the simulations need to be scaled back in terms of number of participants, objects, data rates or simulation rates.  Other times, a large-scale exercise is realized through light weight RTI implementations that strip away many of the features of the interface such as reliable message delivery, ownership, MOM and time management or by falling back to other simulation communication protocols.  While suitable for some federations, these approaches shut out the ability to run exercises that require these services inside an HLA environment.The Joint Virtual Battlespace (JVB) environment is a component-based framework to provide SBA capability to its customers(.  The objectives of an experiment define the requirements of the JVB architecture and hence the communications framework.  For the C4ISR experiment, the Federation Object Model (FOM) requires the ability to reliably exchange messages between federates.  The design also calls for the use of ownership management and MOM functionality.  Given requirements for interoperability with a variety of existing simulators, it is necessary to run within an HLA environment.The federation thus requires a full-featured RTI implementation.  In addition, the C4ISR Experiment Federation calls for a federation consisting of over 150 federates simulating more than 20,000 objects.  The RTI must also be able to scale well and be robust in order to support the exercise.  Based upon an evaluation of existing RTI implementations considering capability, performance and robustness, the JVB team chose the DMSO RTI-NGv6 for its architecture.However, choosing an RTI is only the first step.  The developers must take into account the strengths and weaknesses in the implementation of an RTI when designing the federation.  Most RTIs require at least some amount of configuration to optimize performance and scalability for a given use case.  Items that must be taken into account are:Size of the federation.Number of objects the federation will support.Data transport types requiredPhysical layout of the networkEach of these items will dictate how an RTI must be used and configured so that the federation executes effectively.  In addition, when running simulations at a scale that have rarely, if ever, been tried, federation designers need to work closely with the technical support staff for the RTI to advise on best ways to use the RTI implementation and work out any issues that may be encountered.  For this effort, a member of the RTI-NG development team was brought onto the JVB team to advise in the design of the federation, make enhancements to the RTI-NG to better support the C4ISR Experiment federation and correct any problems encountered.  The following sections of this paper discuss each one of these points and how the federation was ultimately realized.Data Distribution Management Schema and ConfigurationOne of the primary focuses in designing the C4ISR Federation is to distribute the simulation load across federates and limit the amount of data each federate needs to send and receive.  The Data Distribution Management service of the RTI provides a mechanism to accomplish this goal.  By partitioning object class attributes and interactions into various spaces and using regions for publishing and subscribing to data, federates can effectively filter the data they receive from the RTI.  Further, the RTI implementation may use of this information to reduce the amount data that needs to be transmitted between each federate on the network.  In order to effectively design a DDM schema, it is important to understand how the RTI implements the DDM service and the options that are available.  Misunderstanding the implementation of the service or configuring it improperly for a particular use case can actually harm performance rather than help[2].RTI-NGv6 has three built in DDM strategies: simple, static space partitioned and static grid partitioned.  Additionally, users may create their own DDM strategy after obtaining a few extra header files from the RTI-NG developers, and use it within the federation [6].  However the timeline for the JVB experiment did not allow for creation of a customized DDM implementation.   In each strategy, the RTI-NG creates a set of channels on initialization for which a set of FOM data is associated.  When federates subscribe to any data associated with a particular channel, it informs other federates of its interest and will subsequently receive all data sent by federates on this channel.  Note that this may be more data than the federate is interested, so the Local RTI Component (LRC) performs additional filtering.  When a federate sends data, it will be sent to every channel for which that data applies by the LRC, which may be more than one channel.  One goal of any DDM schema should be to limit the number of times data must be sent to multiple channels, which causes multiple writes for UDP multicast data as well as TCP data, and to limit the amount of filtering that must be done on the receive side.  These can be competing goals.  For a fuller discussion, see [(].The Simple DDM strategy uses a single channel on which all data is transmitted.  This means every LRC in the federation receives all data sent by federates and must filter the data according to the local federate’s subscription set.  While useful for small federations and debugging purposes, this strategy would be detrimental to a large-scale federation.The Static Space Partitioned strategy creates a channel for each space specified in the FOM, plus one for the “default” space.  Data is routed between federates based upon the space associated with the attribute or interaction in the FOM.  Additional region information will only be used on the receive side by the LRC to perform exact filtering.   The C4ISR experiment contains many objects of the same class though, so this type of filtering is ultimately limited for this federation.The Static Grid Partitioned strategy creates at least one RTI channel for each space specified in the FOM.  In addition, the user may use the RID file to specify a grid partition scheme to apply to the individual spaces.  The user specifies the number of segments to divide each of the n dimensions for the space.  Each n-dimensional box in the grid then has a channel associated with it.  When data is transmitted, it will be routed to those channels that correspond to boxes for which the region intersects.  This strategy allows for much greater filtering of data on the send side, but also presents the user with more ways in which to negatively affect performance.  If regions for published attributes or interactions overlap a large number of grids, the LRC could be forced to perform many writes for each message sent.  In fact, if an attribute is updated that is associated with a space and no region is used, the update will be sent to EVERY channel associated with the space.  This strategy provides the right level of filtering for the C4ISR experiment, but must be used with care.JVB used spaces within the FOM to segment interactions and objects according to function within the federation.  This way, federates concerned with communication events would not receive entity updates.  Given the scale of the exercise though, many copies of an individual federate application would participate in the exercise using the same type of objects and interaction classes.  This load was then distributed using geographic regions and an additional routing space number.  Federates would then publish and subscribe to a certain routing number and geographic region. The geographic regions were used to restrict the objects reflected by the simulations modeling the platforms to those within sensor range of owned objects.  The purpose of the routing number was to distribute responsibility for modeling the communications between the entities to the communications federates.  The assignment of platforms to routing numbers was made as part of the scenario definition process prior to execution.To avoid problems with sending data to multiple regions, all publication regions were restricted to a single channel.  The RTI-NG may be configured to automatically enforce this restriction via the RID parameter RistrictPublicationRegions.  Any attempt to send data to a region that intersects multiple channels will result in an exception.  Furthermore, once this parameter is set there is no need for the RTI to attempt to detect multiple updates, which must be weeded out by the receiving LRC.  The user can also then set the RID parameter FilterDuplicatePackets to OFF to short-circuit this filtering process.  Note:  there is a potential that UDPmulticast packets may be delivered twice by the network, which will then cause multiple updates to be delivered to the federate with this configuration.The DDM schema exclusively uses point regions. When a region extent is created, it is normalized to contain the center point of all overlapped grid segments.  Therefore, the subscribed regions always overlap the entire range of each segment: a single point.  The use of point regions simplifies the filtering that must be performed by the RTI.  The receiving LRC does not need to perform any additional filtering and may queue up a callback for the federate.  Perfect filtering by the receiving LRC can be short circuited by setting the RID parameter ReceiverSideFiltering to disabled.  For JVB, the use of point regions limited the work performed by the RTI while achieving the desired level of filtering, especially given that a routing number is inherently a point region.  Of course, even with these settings, each reliable message must be somehow “exploded”, or written to each individual receiver.  Therefore the JVB federation limited the amount of reliable data that needed to be sent as much as possible.  Most object updates were sent using the best-effort transport.   The RTI-NG was configured to disable object and interaction class relevance advisories as well as attribute instance relevance advisories.  This modification helps given that the JVB federation has more than 20,000 objects containing more nearly 500,000 attributes.  Attempting to compute these advisories would incur a serious performance hit on every federate process in addition to the data that would need to be transmitted between federation nodes.  Scope advisories were left in place, as these are required when using the DDM service.  In addition, RTI-NG allows users to specify the transport type for various types of administrative messages.  MOM updates and interactions were sent using best effort transport, as were other types of RTI administrative messages, including requests for attribute value updates.  In both cases, the savings to performance and network writes outweighed the problem of occasionally missing these messages, which could easily be dealt with by retransmitting requests at the federate level.RTI Configuration and CustomizationInterconnect Strategies:The primary concern with the JVB federation in configuring the RTI-NG is the scale of the federation in terms of number of individual processes that would contain federates.  For the C4ISR Experiment, ultimately more than 150 federates participated in the exercise.  This number of federates can affect performance during joining and resigning federates, updating subscription information and sending reliable data.  Furthermore, robustness issues related to dead or misbehaving federates must be considered.  The JVB federation design had already limited the sending of reliable through the DDM strategy.  To further address these issues, federation designers need to have an understanding of how federates are connected by RTI-NG and the options that are available.  Any process that contains one or more federates joined to a federation is termed a federation node.  The federation nodes are responsible for the actual sending and receiving of all messages for all the contained federates.  The RTI-NG uses an implementation of the The ACE Orb (TAO) Real-Time Event Service to handle the routing, sending and receiving of reliable federate data.  Each federation node contains an instance of the Real-Time Event Channel (RTEC) that is then “federated” with the RTEC instance in other federation nodes via a gateway object.  The gateway handles propagating the subscription information to the remote event channel, receiving events and pushing the events onto the local event channel, which is listened to by the local federates [4].  These gateways form a logical connection between the federation nodes and are simply referred to as connections in this paper.  However, these connections should not be confused with TCP/IP socket connections.  There is not necessarily a 1-1 mapping between gateway and socket connections.  Please refer to [(] for a more detailed explanation.The Federation Executive process is responsible for instructing each new federation node to which other federation nodes to connect.  The manner in which the nodes are connected is determined by the interconnect strategy specified in the RID file.  There are currently 2 strategies available in RTI-NG:Fully connected; each federation node has a connection to every other federation node.Centrally connected; each federation node connects to a TCP exploder located in the fedex process.Both models have strengths and weaknesses.  The fully connected model allows for low latency communication between federation nodes and avoids a single point of failure for data flow.  However, each process is responsible for exploding messages to all subscribed federation nodes.  Also, the total number of connections in the federation is O(n^2), where n is the number of federation nodes.  Since each node is connected to every other, misbehaving federation nodes can directly affect performance of other nodes.The centrally connected model offers the fewest number of required connections, O(n), and relieves nodes from having to explode messages.  However, it offers a single point of failure for reliable data flow and does not scale well in terms of hardware use.  The central exploder is responsible for relaying all reliable data and the sheer number of processes sending and receiving data in this experiment can overwhelm the process and host.While the centrally connected model is attractive due to its simplicity and the fact that it adds a layer of “insulation” between federation nodes for robustness concerns, the limitations presented are difficult to mitigate.  Simply adding additional hardware resources, such as memory and processors, to the central exploder’s host is ultimately limited, especially on 32-bit PC platforms utilized by JVB.  Also, there really is no way to remove the central point of failure issue.The JVB federation therefore decided upon using the fully connected model.    This decision is aided by the fact that several steps could be taken to mitigate some of the scalability problems with this interconnect strategy.  These steps included design considerations of the JVB federation itself as well as software modifications to RTI-NG.The first approach was to limit the amount of data that needed to be sent by each federation node.  This task had already been addressed with the DDM schema designed for the C4ISR Experiment as well as using best-effort transport for some RTI administrative messages, as discussed in the previous section.Source code modifications were then made to the RTI-NG to eliminate bottlenecks and improve performance in setting up the connections between processes and maintaining them.  In designing the DDM scheme, a large number of grid partitions were used by JVB, between 800 and 900, each which correspond to a unique channel.  All the RTI channels need to be initialized by each federation node at joining of the first federate.  The initial mass launching of 72 OneSAF Test Bed (OTB) federates took well over 20 minutes.  Enhancements were made to this initialization process that helped substantially reduce this time,  lowering it to around 5-10 minutes.  This initialization time could have been further reduced by using the delayed instantiation of reliable channels feature available with NGv6, but given that start up had become a manageable amount of time JVB decided to do all instantiation up front rather than during exercise run.The final approach was to locate all the federation processes at a single site with a fast network connection between all processes.  This technique helps in reducing the amount of time it takes to send TCP data between hosts by reducing latencies and necessary TCP retransmits.  It also prevents issues with a federation node needing to send the same data multiple times across a WAN link.  The JVB exercise took place at Ft. Knox in the Mounted Maneuver Battle Lab (MMBL) where Extreme Gigabit Ethernet switches were used to provide the backbone of the network hosting 300+ PC platforms.Process Model and Network Layer:Another concern for a large-scale federation is to tune the performance of each process so that it can keep up with the simulation load.   Performance of RTI-NG can be greatly affected by the configuration parameters specified in the RTI.rid file.   Among the most important are those that control the behavior of the process model, the networking layer and the DDM strategy.  The process model for the RTI controls the number of threads used by the RTI and handling I/O and timed events[(].  The networking layer controls the bundling of object updates and sent interactions.  The DDM strategy controls filtering performed by the RTI.  The basic goal of tuning these parameters for the JVB federation was to maximize throughput and responsiveness of each federate process.  The idea is that if federation nodes are not able to efficiently handle incoming data they can slow down other nodes sending data to them.First the threading model to be used was determined along with the configuration parameters for that model.  Currently RTI-NG offers two threading models:Polling – The RTI runs only in a single thread with the federate application.  The federate must call tick() in order to give the RTI processing time.Asynchronous I/O – The RTI spawns a second thread for handling internal operations, including network reads and writes.  The advantage of polling mode is the federate controls when to give the RTI processing cycles.  It also avoids the need to grab a mutex when invoking RTI ambassador methods.  However, the federate must be especially careful not to starve the RTI.  In the case of the fully connected federation used by JVB, starvation can mean the TCP receive buffers fill up and TCP/IP flow control can kick in, slowing down the sending federate applications.The advantages of the asynchronous I/O mode are that the RTI can perform any necessary tasks, other than delivering callbacks, in the background thread and the federate does not need to call tick() in order to give the RTI processing time.  This can ease the burden on the federate programmer from worries about starving the RTI for processing time and can protect the federation against problems where a federate spends long periods processing simulation events outside the RTI.  The drawback is considering and planning for the effects of context switching and resource usage by the background thread.For the most part, JVB federates used the Asynchronous I/O process model.  However, individual federates are free to choose their own process model as this configuration is not required to be uniform across the federation.  Many of the hardware platforms used during the JVB exercise contained 2 or more CPUs, so this configuration further allowed for the distribution of RTI tasks across multiple CPUs without stripping away necessary processing time from the federate simulation. The background thread for the RTI works by periodically waking up to see if there is any work that needs to be performed by the RTI.  It checks for any pending input or output operations as well as any timed tasks need to be performed.  There are two parameters that can be used to tune the performance of the background thread inside the ProcessSection.ProcessModel.AsynchronousThread section of the RID file:MinimumSleepDurationInSeconds:  The minimum time interval for which the background thread will sleep.MaximumSleepDurationInSeconds:  The maximum time interval for which the background thread will sleep.The RTI-NG uses an adaptive algorithm that determines how long to sleep, based upon the amount of work performed by the background thread in its last period of execution.  If no work is performed, a longer sleep period is set for the sleep interval.  Otherwise the sleep duration is decreased.  The minimum and maximum values set bounds on the sleep interval and are stable points for active and inactive simulators respectively.  For the JVB federation, the minimum sleep duration was set to 0.01 seconds, or 10 milliseconds, and the maximum to 0.05s, or 50ms, in order to reduce response times by the LRC to other RTI processes and decrease the likelihood of encountering TCP flow control.  This also helps response times of federate processes to the status command on the rtiConsole, which is used to monitor the health of the federation.  Included as part of the Process Model is the RTI scheduler.  The RTI scheduler is the component responsible for actually handling I/O and timed events.  There are four available options in the section ProcessModel.Scheduler of the RID file:MinimumPollingIntervalDuringTickInSeconds:  Sets the minimum timeout used when checking for input.  On UNIX systems, this translates to the value used for a call to select().MaximumPollingIntervalDuringTickInSeconds:  Sets the maximum timeout used when checking for input.  ExecuteCommandsPollIntervalInSeconds:  When the RTI starts delivering callbacks, sets the timeout used to poll the network for input.SingleCallbackPerTick:  Only deliver a single callback in no argument call to tick().For the JVB exercise, only the MinimumPollingIntervalDuringTickInSeconds and MaximumPollingIntervalDuringTickInSeconds were set.  The minimum time can limit the amount of time the RTI spends in select() or waitForMultipleObjects() on Windows when no input is available.  For many operating systems, if no input is available to cause a return from a call to select(), the minimum nonzero time period for a call is 10ms.  It can actually be longer on some OS’s.  This wait can waste processing time needed for other LRC or federate tasks.  This value was set to 0.0 to enable a strict polling mode.  It is generally not recommended that the maximum value be set to 0.0.  This value will be used during a timed call to tick() when all input and callbacks have been serviced but the minimum time has not been reached.  In this case, a non-zero value to the poll call can yield processing time to other processes and threads and prevent the federate application from “ringing” the processor.  The ExecuteCommandsPollIntervalInSeconds was set to 0.05, again to ensure responsiveness of LRC processes and ensure that I/O is being serviced.Next, the bundling parameters for the network layer were tuned.  RTI-NG currently allows bundling to be configured separately for the TCP and UDP channels.  Bundling of messages is done on a per-channel basis by the RTI-NG.  For the JVB federation, 800-900 channels were used and bundling is performed on each individual channel.  There are two options for bundling:MaxTimeBeforeSendInSeconds:MaxBytesBeforeSend:By using bundling, messages data may be packed together and sent simultaneously, saving on packet overhead and system calls.  As a general rule, users should set the amount of latency that is acceptable for their federation as the time before send.  For the C4ISR experiment, a value of 10 ms was used along with the default of 64 KB for the maximum size.  The entities in the exercise were simulated using OTB, which has an internal scheduler for updating each vehicle every 57ms.  Using a 10 ms latency meant that messages would nearly always be received within a single scheduler loop from the send time.Fault Tolerance and RecoveryAnother major concern for a large-scale federation is how to deal with misbehaving and dead federate processes.  The problem breaks down into several issues:  How can problems be avoided, how can problems be detected and how can the federation recover when problems do occur?  Many of the steps already taken to ensure the performance and scalability of the federation help address avoidance of problems within the federation.  Federate processes that are not keeping up with processing of incoming data can affect the performance of sending federates in the case of TCP messages.  Many of the configuration parameters for the RTI are aimed at preventing this situation.  Another common source of federation error occurs during joining and resigning a federation if a user does not wait long enough and kills the process believing that it has frozen.  When there are dead or overloaded federates in the federation, especially a large federation, joining or resigning can take several minutes and may require the misbehaving federate to first be removed using rtiConsole.  The join or resign will then proceed normally.  However, if the joining federate process has already been terminated, then it is left in a half-joined state.  This state can be detected and corrected using rtiConsole, but requires user intervention and will cause any other federates attempting to join or resign the federation to hang in that API call.To help avoid this problem, the JVB federation appointed several individuals who were responsible for monitoring the state of the federation and dictated when federates were allowed to join and resign the federation.  The primary means of monitoring the federation was accomplished through rtiConsole application.  The rtiConsole application has a status command that actively iterates over all federates in the federation and obtains a status from each process.  Additionally, the rtiConsole can list all the federation nodes in the federation.  For each node, the console will display the federation node ID, the host endpoint information for that process, the interconnect ping status and the list of federates located at that node.  In the case of the half-joined federate mentioned above, this federate list might be empty.The interconnect ping is a mechanism the Federation Executive process uses to monitor the status of all the federation nodes.   For each federation node, the fedex will send a ping to the node at a certain time interval, which can be configured via the RID file.  If the fedex does not hear back from the node before a timeout, then the node is listed as TIMEDOUT.  It is possible for the fedex to get an exception attempting to contact the node process, in which case the ping status will be RAISED EXCEPTION.  Finally, if the node has responded the status will be RECEIVED RESPONSE.  However, since the rtiConsole is a text-based interface, it is difficult to monitor all 150+ federation nodes using these commands.   A modification was made to the “list” command for rtiConsole that allowed the user to specify a “-l” flag that would print out the host endpoint information and interconnect ping status along with its handle and name on a single line, which was easier to scroll through.The rtiConsole can also be run in a command line mode.  The JVB team wrote shell scripts which would ping all federates and get the node status every 5 seconds.  Any status that indicated a problematic node would then be displayed.  It was up to the user to determine whether or not that federation node process needed to be removed.  This determination usually entails checking the process on the host platform.   Often, processes that had merely timed out would eventually recover, but the federation monitors could keep any other federates from joining or resigning until all processes were again responsive.Once a federate process did need to be removed from the federation, there was a question of how to deal with objects it owns.  In NGv6, the only option available was to delete all owned objects and release any remaining owned attributes.  However, JVB desired to have federates rejoin the federation and continue simulating the original object instances.  To accomplish this goal, RTI-NG team developed a capability to tell the federation what to do with a federate’s objects and attributes upon removal.  The available actions are:  delete all objects and release all attributes, release all objects and attributes and take no action.  In addition, a new command was developed which would allow the user to force ownership of a removed federate’s objects and attributes onto another federate in the federation.  In order for this to work, the “divesting” federate must be removed specifying no action.  When the ownership is transferred to the new federate, several events occur:The target federate implicitly publishes all object attributes for which it is getting ownership if it has not already.The target federate receives discover object instance callbacks for any objects it has not already discovered of those it will gain ownership.The target federate receives attribute ownership assumption callbacks for all the attributes for which it becomes the owner, including the privilege to delete attribute.Each of these actions are used to guarantee that the target federate is not placed in an inconsistent state after gaining ownership.  Since region information is not transferred with ownership in RTI 1.3 API, the federate must associate regions with all newly owned attributes as necessary.Often times during exercise execution, events occur in the federation causing several simulators to crash or hang simultaneously.  This is especially the case when a large number of instances of the same federate are executing.  However, NGv6 only allows for removal of a single federate process at a time.  When running in a fully connected mode as with JVB, removal of a federate requires the fedex to contact every remaining federate to indicate that the given federate has been removed.  This can cause the fedex process to attempt to contact other dead or frozen processes and slow down the removal process.  Therefore the remove command for rtiConsole was enhanced to allow the user to specify an arbitrary number of federates to be removed simultaneously.  The fedex can then remove all federates in a single sweep without attempting to contact any of the removed federate processes.  During the JVB federation exercise, rtiConsole was used at one point to remove 52 federate processes simultaneously and the federation was able to continue its simulation.  As a note, when removing multiple federates with a single command, the objects for all federates must have the same action specified.TransparencyOne of the most difficult problems to debug when running any federation is that of determining why federates are not receiving data that they are expecting to receive.  A first approach at gaining insight into the problem is to monitor the actions that the federate(s) in question are performing through the RTI API.  RTI-NGv6 offers a logging intercept for this purpose.  The logging intercept simply translates all calls into the RTI::RTIambassador and callbacks through the RTI::FederateAmbassador objects into a readable format and prints them out to standard output.  The intercept can be activated using the RID file or dynamically activated and deactivated using the rtiConsole.  While useful, this capability can quickly become overwhelmed in a large federation where federates are consuming and producing large quantities of data.To help process this output, the logging intercept was enhanced for JVB to take several configuration parameters in the RID file.  Among those offered are the ability to log output to a file rather than standard output, to filter methods that are logged by a list of keywords and to automatically log all exceptions regardless of other settings.  This capability was extremely useful in verifying exactly what data federates were sending and receiving as well as what the subscription and publication sets were for each federate.  This capability often helped direct whether or not debugging efforts should focus on the application layer.Nevertheless, for some cases merely logging all API calls is not sufficient to determine the nature of the error.  In one encountered case during the JVB exercise, federates would cease receiving best effort object updates during a simulation run.  According to logged API calls, the publishing federates were sending the data, but the receiving federates would suddenly stop receiving them even though no changes in subscriptions had been made.  RTI-NGv6 can be configured via the RID file to print to standard output the multicast channel mapping for DDM grids at startup.  Using this mapping, the user can then determine based upon the object class and associated region information (if any), which multicast group(s) the update or interaction will be sent.  On UNIX systems, the command “netstat –ng” can first be used to determine if the receiving federate is properly joined to the multicast group in question.  In the case at the JVB federation, the group was properly subscribed.  By using a custom multicast ping program, it was verified that data was not flowing between the two machines on the given multicast address.  The problem was then addressed at the network layer.Integration EventThe C4ISR Experiment integration event was held in three phases at the MMBL at Ft. Knox, Kentucky between 23 Sep. 02 and 30 Oct. 02.  Testing of the federation continued nearly continuously to address problems and performance issues through the end of November.  The later stages of testing marked the first time the federation ran at the necessary scale for the experiment.  This also marked the first opportunity the RTI-NG had of running in an environment able to support over 150 federates, each of which was responsible for a non-trivial simulation load. A number of problems and issues that were never encountered in smaller federations needed to be addressed on site.  The issues mainly revolved around robustness issues of the centralized federation executive process and effectively dealing with dead federate processes.  Several race conditions needed to be fixed in the federation executive process, mainly dealing with the process of joining and resigning the federation.  In addition, timeouts were inserted into the process for waiting for responses from dead federates.  Occasionally when a host went down it would cause the fedex to hang indefinitely waiting for a response.  The timeout mechanism allowed the federation to recover and continue.  Finally, LBTS calculations would occasionally become frozen when federates crashed and were removed.  Even though JVB was not using time management, LBTS calculations still occur on resigning and joining of federates to guard against special cases of the specification.    A new NULL implementation for the LBTS algorithm inside the fedex was created.  This also eliminated some recurring latencies on join and resign of federates and had a noticeable impact on improving performance during federation startup and shutdown.  After these modifications were made, the RTI-NG was able to reliably support the federation of all 156 federates to run the various simulation scenarios.  At times the federation would be up for 12+ hours before resetting for a new vignette.Various additional capabilities were added to rtiConsole application as needed.  These included the ability to inspect ownership information for a particular object and delete all of a federate’s objects.   Typically these modifications could be accomplished by applying changes only to rtiConsole itself.Future DirectionsThe JVB program will continue to be involved in simulation exercises in the future and to develop its simulation capabilities.  As a piece of this ongoing effort, improvements will continue to be made to the use of the RTI as well as enhancements to the RTI-NG capabilities.  There are several areas where improvements can be made to the infrastructure to improve scalability as well as increase the ability to support other types of simulations, such as those operating over a WAN link. One of the key concepts is a new strategy for connecting federation nodes in RTI-NG called Hierarchical Interconnect.  This strategy uses a set of distribution nodes that are used for creating reliable data paths between the federate processes.  Each distribution node together with a set of associated federation nodes forms a federation segment.  Messages are then passed between these segments through the distribution nodes.  The segments themselves may be either centrally connected through the distribution node or fully connected with other federation nodes in the same segment independently of the connection strategy of other segments in the federation.This strategy has several important advantages:  First it reduces the number of necessary connections from a fully connected federation by an order of magnitude but avoids the scalability issues of a centrally connected federation by using multiple nodes for distributing reliable messages within the federation.  This reduction in connections streamlines the join and resign process in a federation with a large number of federates.  Also, hierarchical interconnect solves the problem of running simulations across a WAN connection that is not addressed by either the fully connected or centrally connected strategies.  The distribution nodes can be used to guarantee only a single copy of each reliable message is transmitted across the WAN link, making much more effective use of network resources.  Another advantage is the distribution nodes add an insulating layer between federation nodes and can absorb many of the ill effects from misbehaving nodes.Another concept is the addition of a reliable or semi-reliable multicast protocol as a new transport type offered by the RTI.  This allows the existing network infrastructure to handle the duty of routing data to the necessary receivers.  Currently two possibilities exist for implementing this capability.  First, TAO implements a version of a reliable multicast protocol.  Supporting code will need to be written to allow the RTI to create connections between federation nodes, via a new gateway.  Additionally, GMU is currently prototyping a mechanism to allow the RTI-NG to connect via the Selectively Reliable Multicast Protocol (SRMP) daemons [7].   In both cases, the reliability of the multicast does have a limit.  Users must tune several parameters that control resources to use in attempting reliable delivery, such as how many sent messages to cache, which have tradeoffs in performance and level of reliability.   Using a reliable multicast protocol however shares many of the advantages of the hierarchical interconnect, but all the work in routing messages is handled by the network infrastructure.  Another area for enhancements will be to increase the transparency of RTI-NG.  Currently modifications are being made that will allow users to inspect configuration data and performance statistics for the DDM layer.  Users will be able to view the layout of the RTI channels as well as view which processes are subscribed to those events.  Additionally, the number of messages sent, received and filtered on each channel will be compiled.  All statistics will be available through use of the rtiConsole application.  Federation developers can use these statistics to help determine the effectiveness of their current DDM strategy and its use.  In addition, these added capabilities would allow for quicker debugging when messages are not arriving at a federate process as expected.Finally, enhancements to the process model for better support of multithreaded applications can be made.  Creating a means by which federate applications can register to receive callbacks asynchronously can help improve performance by decreasing latency and making fuller use of multiple threads.  Creating thread pools that the RTI would use for delivering callbacks, can further extend this capability.Conclusions:The MMBL C4ISR Experiment is the largest federation execution to date that included nearly all the RTI service areas.  RTI implementations are reaching the maturity level to be able to support such exercises and will continue to improve in supporting such exercises.  Large-scale federations such as the C4ISR Experiment will continue to require RTI developer support to meet the unique demands of such a federation.  This requirement will begin to relax as federation designers gain more experience and expertise in how to architect large-scale federation exercises that make effective use of a particular RTI's capabilities and the RTI implementations themselves become better optimized for these federations.  Changes made during the C4ISR experiment, such as the ability to remove multiple federates simultaneously, introduce the practical features necessary to manage very large federations.  However, differences in performance, DDM implementations and threading models will continue to demand such large-scale federation design to be specific to a given RTI implementation for the near term.References[(] S. Harkrider, W. Braudaway, J. McDonnell:  “JVB Federation Design”  Simulation Interoperability Workshop, 02F-SIW-061, September 2002.[(] Hyett, M., Wuerfel, R., Implementation of the Data Distribution Management Services in RTI-NG, Simulation Interoperability Workshop,  02S-SIW-044, March 2002.[3] Hyett, M., Wuerfel, R., RTI-NG Process Model, Simulation Interoperability Workshop,  01S-SIW-067, March 2001.[(] C. O’Ryan, D.Schmidt, J. Noseworthy:  Patterns and Performance of a CORBA Event Service for Large-scale Distributed Interactive Simulations  International Journal of Computer Systems Science and Engineering, 2001[5] JVB Various  JVB DDM Implementation  2002.[6] Hyett, M., Wuerfel, R., Connectionless Mode and User Defined DDM in RTI-NG V6, Simulation Interoperability Workshop,  03-SIW-102, March 2003. [7] Moen, D. and Pullen, J.M.:  A Performance Measurement Approach for the Selectively Reliable Multicast Protocol for Distributed Simulation, Proceedings of the IEEE Distributed Simulation and Real Time Applications Workshop(DS-RT’01), Cincinnati, OH, August 2001.Author BiographiesKEITH SNIVELY is a Senior Software Engineer for Dynamic Animation Systems, Inc.  He is currently a developer for the DMSO 1.3 RTI Next Generation on a subcontract to SAIC, where he has been a developer for the last three years.  Mr. Snively has over 6 years experience with modeling and simulation and has previously supported the Countermine and M&S Divisions at NVESD as a software developer and integrator.  Mr. Snively received an M.S. in Mathematics from the University of Virginia.ANNETTE WILSON is a Technical Lead at the Virtual Technology Corporation, Alexandria, VA. She has been involved with distributed simulation for over ten years.  Ms. Wilson has been involved with the HLA since its inception. She participated in the definition of the HLA 1.3 Interface Specification and IEEE 1516 standard as well as the development of the DMSO RTI 0.x, RTI F.0, and RTI 1.3 prototypes.ROGER WUERFEL is a Senior Software Developer in the Distributed Computing Technology Division of SAIC.  He is currently the technical support manager for the RTI 1.3 Next Generation and has been working with the RTI 1.3 Next Generation development team for 4 years.  Mr. Wuerfel has over 12 years experience with simulation, including real-time, human-in-the-loop flight simulation and real-time distributed simulation.  He received his B.S. in Aeronautical/Astronautical Engineering from The Ohio State University and is pursuing his M.S. in Modeling and Simulation from Old Dominion University.