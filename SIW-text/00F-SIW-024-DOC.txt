Toward An Object Oriented Design For Reproducible Results in Military Simulations.Robert L. YoumansTeledyne Brown Engineering300 Sparkman Dr. NWP.O. Box 070007Huntsville, AL 35807-7007256-726-1046robert.youmans@tbe.comKeywords:OOD, Object Oriented Design, ModSAF, Military Simulation, CGF, Computer Generated ForcesABSTRACT: It is a valid requirement for military simulations to produce reproducible results, devoid of "artifical dependencies." We describe the notion of an "artificial dependency" and our design to avoid them.  There are several potential sources of these dependencies, including network databases, asynchronous task scheduling, and asynchronous or single-valued state changes.  We provide an object oriented design which addresses some of these artificial dependencies.  This type of design should be considered when producing the next generation of CGF software (e.g., OneSAF).1. IntroductionIn the military simulation community today there are several popular, large and widely used simulations, which are being used for myriad purposes.  ModSAF is an example from this group.  There are also projects ongoing to design and build large simulations to be used in the future.  OneSAF is an example from this group.  It is only natural to base this future work on current successful projects (as some of the OneSAF work is based on ModSAF).  As developers and users of military simulations ourselves, we have had opportunities to participate in development projects of much smaller scale than these examples. As a result, we have some lessons learned from the study and design of military simulations, which we think may be useful to the community at large.  In particular, we have produced object oriented designs with features which promote reproducible results in our simulations.We have been involved in two different projects which have produced this work.  We have some international customers who are interested in studying simulation architectures.  For them we have dissected and analyzed some simulation architectures, presenting some of the advantages and disadvantages of various approaches to the simulation of military operations.  At the same time we have designed and built our own new simulations, taking advantage of our experience and the state of the art in technology today.  One result of these efforts is that we identified some design features that help avoid undesirable characteristics of some existing simulations.  We included these in our new models with great success.  This paper provides these insights to the simulation community at large.  The hope is that these types of ideas will be considered as new large scale simulations are designed and built for the military simulation community to use.We motivate the requirement for reproducible results with a discussion of two historically diverse groups of the military simulation community and the trend toward more combined use of their respective tools.  Following this is a discussion of artificial dependencies in military simulations and some examples we have identified.  We then present an object oriented design which reduces some of these artificial dependencies and improves the overall quality of the simulation architectures in which it is used.1.1 Simulation Community BackgroundThere are many ways to look at the history of military simulation.  This author's background includes the U.S. Army simulation community, and for the purposes of motivating this paper, it is useful to compare the army analysis and training communities.  With regard to the Army simulation community, there are historically three groups of simulation users and developers:  the training community, the analysis community, and the research & development community.   For the purposes of comparing uses of military simulations, we will compare the training and analysis communities.Historically, the analysis community has fostered the development of simulations with specific analysis purposes, to support the design and analysis of new weapon systems.  These studies typically involved weapons which do not exist and are modeled in an environment many years into the future.  For the simulations used by these studies, great emphasis was placed on detailed output and rigorous control of input data to aid in the detailed investigation of the problem being studied.  The ability to determine "why" something occurred in a simulation is crucial to this type of work.  Consequently, great emphasis is placed on reproducible and well formed results. Also, during the early days of this type of work, computing power was comparatively low, and graphics was of secondary importance (today, of course, this is no longer true). This community produced many fine simulations, analysts, and analyses that are still recognized today.The training community has historically promoted the development of simulations to support the conduct of training exercises involving real people.  Examples of these exercises include: command post and staff training exercises (CPXs) and pilots and other crews operating in training simulators.  For these simulations, generally running in real time, the main objective is providing entity behavior appropriate for the experience of the users.  The main "result" is the realism of the experience of the users. Of lesser importance is the degree to which results can be reproduced and analyzed in detail for cause and effect.  These simulations frequently run over networks.  There have also been many contributions to the simulation community made by this class of simulations.As the military simulation community continues to evolve, these historical differences are becoming blurred.  Also, the types of analyses and exercises are changing as the allocation of funding for various projects changes.  We are seeing the days where analysis is conducted alongside exercises.   Some may observe that reproducible results are not actually required for training simulations to be useful, and strictly speaking, this observation has validity.  However, we are also observing a trend where simulations are being used for more and more diverse purposes.  We believe that the ability to have the simulation be reproducible (accepting variations with man-in-the-loop) leads to better products whenever it can be achieved. Certainly, designing architectures with these capabilities in mind will enhance the quality of the final product.The important question is:  how can simulations which have been designed, built, and used in one of these communities, be successfully used for purposes mainly existing in another?  And most importantly, when we build new simulations, how can we use our experience from previous projects to make the best use of them when the simulation community will likely be very different from any of these previous ones? 1.2  Ideal Simulation RequirementsIn an ideal simulation environment, we would be able to use a simulation to support an experiment where man-in-the-loop is present, and/or conduct a detailed analysis (without man-in-the-loop) and get usable, quantifiable results in either situation.  If we have an ideal simulation and we use it with a particular set of inputs, we should get a well-defined set of outputs.  Even in the case of stochastic models, it is possible to control the seed of the random number stream so that reproducible results are obtained.  In other words, an ideal simulation provides reproducible results.  Of course, all real simulations are not ideal, and many examples of useful simulations exist that do not meet this requirement.  Also, the man-in-the-loop of a simulation architecture will introduce inconsistencies which cannot be controlled.  We are focusing our attention on the architecture of the software, accepting the man-in-the-loop when that is appropriate.  We still maintain that it is a reasonable requirement that a simulation be designed to minimize the dependency of its output on external factors.  In other words, we desire to minimize artificial dependencies.2.  Artificial DependenciesWe define the term artificial dependency as:  the condition when the output of a simulation is influenced by some factor which is not included in the required input data set or other data which is input as the simulation runs.  In a military computer simulation, if the outputs produced depend on anything other than the inputs to the simulation, then we say an artificial dependency exists.  Generally, artificial dependencies are detrimental to the ability to determine cause and effect in the results of a simulation.  When stochastic processes are involved and replications and variance analysis are needed to determine valid average results, these dependencies can interfere with the statistical analysis.There are several sources of artificial dependencies.  Here are a few:2.1  Example:  Network Databases And Distributed SimulationsIn this example, an artificial dependency exists if the results of the simulation are affected by the state of the network (e.g., latency, collisions, waits, dropped packets, etc.). Entity state data which resides as a network database can be effected by the underlying network topology.  For example, in a DIS-based network, the simulation results can be dependent on the load level of the network, if there are enough objects in the scenario to cause data to be dropped and/or re-sent.  As the entities interact, their behavior depends on the data they have received, which depends on the network state. 2.2  Example:  Asynchronous Task SchedulingConsider a simulation architecture that consists of  a "ring" of arbitrary tasks which execute periodically in an arbitrary order.  This is the type of task management used in ModSAF, where the desired "tick" interval is 67 milliseconds (15 Hz).  The intent for these tasks is to run according to the real-time clock.  We state that an artificial dependency exists if the results of the simulation can be effected by some external situation other than the input data for the simulation.  In this example, if some other process causes the task management software to be unable to maintain the 15Hz tick rate, the results and output from the simulation can be different simply because one task missed its scheduled tick.  It is unlikely that this task can be identified, and due to the rapid execution of the management software, the task(s) that are effected can be different each time the simulation is run.  This is, of course, a consequence of the failure to keep up with the real time clock.  The point here is that it is an external process, not the simulation software itself, which is causing it.2.3  Example:  Asynchronous State ChangesA simulation architecture which maintains the state of its objects using only one instance of each state variable can exhibit an artificial dependency when the object state is tested on and modified by separate tasks.  Contrast this architecture with one which contains explicit state classes, and these classes contain all the state data which changes over time, and each object maintains a current, previous, and future state.  For example, if an object velocity is maintained as a single unique variable (or structure), some task may test an external condition and change the velocity (e.g., halt the object).  Some other task may then test something about the velocity for another purpose.  If there is only a single instance of the object's velocity, a dependency exists about the order in which these tasks test and modify the velocity.2.4  Example:  Task InterdependenciesConsider a simulation architecture which is deterministic and has a fixed sequence of tasks executed in a defined order using simulation time and not related to the real time clock.  This is the general architecture of systemic constructive simulations with no man-in-the-loop.  An interesting test which can reveal an artificial dependency is to compare a scenario with one which is identical except the forces are reversed.  If the same model details and data are used for each side, it is reasonable to ask why these results should not be the same.For example, the enemy force can be on the attack and the friendly force defending.  Consider an enemy unit which moves into an observed area and triggers artillery missions (via an observer).  When this mission is fired, the enemy then fires a counter-battery mission of its own against the friendly artillery.  Then consider the sides to be reversed with everything else identical.  The results of such an experiment should be identical.  When we conducted this investigation on a simulation some time ago, we discovered a module that had "too much" activity contained in it given the manner in which the forces were being simulated.  The module which determined whether or not to fire an indirect fire artillery mission also actually fired it, which introduced an artificial dependency between the indirect fire module and the friendly and enemy forces.  The enemy force was evaluated first and got to determine whether it fired or not and then actually fired before the friendly force did the same thing.    In this case the enemy force did not fire its counter-battery mission.  But with the sides reversed, the friendly unit tests its situation and discovers the enemy has fired, so the friendly unit fires the counter-battery mission.  This is an artificial dependency related to the complexity of the task and the order of the evaluation of the units by the task.2.5  Artificial Dependency ConclusionWe believe that simulation architectures which take into account design features that reduce the occurrence of these types of artificial dependencies are an improvement upon existing work.  This leads to more reproducible results in simulations and the ability to conduct more cause and effect analysis using the tools.  Obviously, it may not be possible to completely remove these dependencies.  But, fewer artificial dependencies in the design of a simulation architecture will result in an overall better design.In particular, dealing with entity state changes explicitly can result in the capability to perform comparisons and tests about object states which spans time steps.  This leads to the ability to perform tests about rates and can lead to predictive decision-making, which is also an attractive simulation feature.3. Object Oriented DesignHere we present features of our object oriented simulation architecture design which contribute to reduced artificial dependencies.  They can be categorized as:Explicit, multiple object state classesSynchronized object state transitionsTask categories and/or prioritiesTask domain reductionFor notation we use the widely accepted UML notation for inheritance/generalization and membership/ aggregation.3.1  Multiple Object State ClassesFigure 3.1 shows a UML representation of the relationship of simulation objects (SimObject) to their state objects (SimObjectState) in our design.  Each SimObject contains instances of the SimObjectState; in this example each SimObject contains 4 state objects each of type SimObjectState.  The data contained in the SimObjectState is the data about the object that changes over time or is updated by the cyclic tasks or processes that the simulation is performing.  Examples include:  location/position, velocity, state (alive/dead, engaged/not engaged, etc.), strength, orientation, etc.This design feature allows us to control the access and ways in which the state data is referenced and modified.  For example, all tests of state data are performed using the CurrentState object, and when the state is modified, the changes are made to the FutureState object.  This separation of state data reference and update reduces the artificial dependency introduced by ad hoc state updating by many tasks (Example 2.3).  It also precludes the artificial dependency among interacting tasks where one has an advantage by being first (Example 2.4).  This design is analogous to integration of a system over finite time steps;  if there is some problem with this state updating, simply adjust the time step, dt, within which the state objects are updated.There are some added capabilities provided by this simulation object state design:Evaluate first order derivativesComparisons involving state objectsHigher order derivativesFigure 3.1  SimObject - State RelationshipSince we have the PreviousState and CurrentState instances, rate calculations (first derivative when time is the independent variable) can be made about the state information present in the model.  Also, comparisons about states (e.g., engaged currently, but previously not) can also be performed.  Further, with the inclusion of other state objects (more previous states), second order derivative testing and evaluations can be obtained.  This makes available predictive decision-making methods and a host of other attractive modeling not available without this structure (or if it is available, it is not generalized, but only special purpose, case by case development).3.2  Synchronized Object State TransitionsAt some point in the cycle of processing for each object in the simulation, the state objects themselves must be updated.  This is in contrast to the updating of the data contained in the state objects (Figure 3.2).  In this process, the PreviousState instance is replaced by the CurrentState instance, etc., and the FutureState instance is initialized to some well-defined condition.  This should occur after all other tasks have completed their processing.  The design feature that ensures this is the notion of task categories or priorities.  If the simulation architecture allows for arbitrary task libraries (e.g., ModSAF), the tasks need some category or priority to ensure the task for updating these states (i.e., a "system" task) executes last among all tasks for a cycle of "tick" calls.Figure 3.2  Example Flowchart Updating Object States3.3  Task Categories and/or PrioritiesThere are two basic types of task managers used in the majority of military simulations:  an arbitrary task library manager (e.g., ModSAF) and a fixed task manager where the tasks are fixed in the model code and  cannot be changed.  In the task manager with an arbitrary task library, we need to exert more control over the task executions to reduce the variations in dependencies among the tasks.  Our design extends the basic task manager by introducing task categories or task priorities so that the various tasks can be grouped together.  In each time cycle within the task manager, all tasks in the same group are executed before tasks in other groups (Figure 3.3).As an example, we can define the following groups of tasks:System InitialDetectionManeuverDecision/CommandFireCommunicationSystem FinalFigure 3.3  Task Manager with PrioritiesNow with this design we can ensure that all objects get the opportunity to process their tasks within the same group before any processing on the next group is completed.  Combining tasks with the simulation object states, we can also ensure that each task is looking at the same data.  These design features can produce a major reduction in artificial dependencies in a simulation architecture.Task Domain ReductionIn example 2.4 we described a simulation architecture in which a “task” (software module, actually) performed an excessive number of simulation functions.  This routine performed both the decisions to fire mission and computed the resulting damage.  When combined with the management software to perform this on all objects in the simulation, an artificial dependency occurred where some objects were treated differently based on the order in which they were evaluated.  This is clearly not only dependent on the input data, but it is not what most users expect to occur.  Designing tasks and software routines that perform small numbers of the objects' functions can reduce this type of dependency.  In the example, the routine that determines to fire or not should be separated from the routine that computes the resulting damage.  Then, using the FutureState/CurrentState structures, all the objects get to participate equally in the fire decision process.Generalizing this example, a task model design where the tasks each perform a small number of the objects' functions is preferred over one where there are a smaller number of tasks, but each tasks performs many functions.  In an ideal task model each object receives an equal opportunity to evaluate and modify its state.  One could possibly draw an analogy from the mathematical domain of numerical analysis, with the process of integrating some complex system of equations.  In such an analogy, this limitation of task domains is analogous to separating a complex integral and adding up the parts.3.5  Network DatabasesThe artificial dependency related to network databases and network performance (latency, collisions, dropped packets, buffer overruns, etc.) cannot (we believe) be reduced using these design features.  However, there is a technology under development and growing steadily which is designed to address this situation.  It is, obviously, HLA, the High Level Architecture and the RTI (Run Time Infrastructure) services.It should be possible to combine the design features described here with the RTI reliable connection (TCP/IP) and significantly reduce network related artificial dependency.  This is an area for further study and research.4. SummaryWe have postulated that reproducible results in military simulations are desirable.  We did this by describing the military simulation community as a diverse group with historically two principal members:  training and analysis.  Recognizing different uses and purposes for simulations, we then looked at the current and future simulation community and observed a decrease in the distinction among these groups.We then defined the term artificial dependency and used it to describe some examples where simulation architectures do not provide reproducible results.  We understand the difficulty in removing these dependencies completely but believe reducing them improves our products.  We believe that addressing this type of situation when using existing architectures to build on for future projects (e.g., ModSAF designs used in OneSAF) will contribute to an improved simulation.In our small scale projects we have discovered some object oriented design features which help reduce the artificial dependencies we have seen.  We presented these to the community for discussion and further development.  Finally, we call on HLA, combined with other simulation design features, to address the network database dependency.  We believe the incorporation of these concepts into the architecture of military simulations is a positive step as we move into a new period of military simulation development.Author BiographyBOB YOUMANS is a Senior Systems Analyst at Teledyne Brown Engineering, Huntsville, AL (a company of Teledyne Technologies, Inc.).   He has a M.S. in Operations Research from the Naval Postgraduate School, 10 years of service with the U.S. Army, and has built and run military simulations in the Army with the TRADOC Analysis Command, White Sands Missile Range, NM while on active duty.  He is currently involved with many aspects of military simulations and studies at Teledyne Brown Engineering.