Simulating Decision Making where Cooperative Agents Use a Hybrid Reasoning Framework Dr. Joseph G. Kovalchik, Mr. Jonathan W. Labin and Mr. Eric R. RosenlofJohns Hopkins University Applied Physics Laboratory11100 Johns Hopkins RoadLaurel, MD 20723-6099240-228-6264HYPERLINK "mailto:joseph.kovalchik@jhuapl.edu"joseph.kovalchik@jhuapl.edu, HYPERLINK "mailto:jonathan.labin@jhuapl.edu"jonathan.labin@jhuapl.edu, HYPERLINK "mailto:eric.rosenloff@jhuapl.edu"eric.rosenlof@jhuapl.eduKeywords:expert system, fuzzy logic, hierarchical planner, Bayesian network, case-based reasoning, neural network,integrated warfare analysis, multi-mission warfare, HLA federation ABSTRACT: This paper presents the details of simulating decision processes. The motivation for simulating decision processes is discussed. Our methodology includes understanding the process to be simulated, developing the agent structure for this process and mapping reasoning technologies to the process steps assigned to the appropriate agents. Cooperative agents and a hybrid framework of various reasoning technologies are employed to simulate the decision process. Characteristics of the framework are provided. The benefits provided by each technology included in the hybrid reasoning framework are illustrated. These technologies encompass case-based reasoning, neural networks, Bayesian networks, a fuzzy expert system and a hierarchical planner. A concrete decision process example is developed and a typical sequence of technology application to this example is presented along with various supporting algorithms. IntroductionThis paper presents recent improvements to the APL Integrated Multi-warfare Simulation (AIMS) Commander Federate that occurred over the last year. These changes address the growing interest in the Defense community in the ability to perform simulations that incorporate a Commander’s decision process in warfare tactical situations. The following sections provide background information on previously completed work, discuss the motivation for simulating decision processes, and highlight the hybrid reasoning framework contents. Following the details on the newly implemented reasoning technologies, an example is given to demonstrate the new functionality.Background Previous papers [ REF siw2003 \h  \* MERGEFORMAT 1,  REF siw2006 \h  \* MERGEFORMAT 2, 3] presented details on the AIMS federation in which AIMS addressed the growing interest in the Defense community in the ability to perform multi-warfare analysis – analysis that crosses the domains of multiple mission areas. There was an emerging need for analysis to be performed at the “multi-warfare” level, motivated by transition to “capabilities-based” acquisition, creation of multi-mission structures (e.g., Sea Shield), and the need to assess performance/effectiveness of multi-mission platforms. Work covered in the previous reports provided details on a fuzzy logic expert system [4, 5] and a hierarchical ordered planner [6, 7] and will not be covered herein. This year’s efforts extended the reasoning capabilities of the Commander Federate.Project OverviewThe Johns Hopkins University Applied Physics Laboratory (JHU/APL) focused efforts to improve the simulation of decision making processes. This work was motivated by the conviction that such simulations would provide autonomous, robust handling of emerging simulation events. In addition, it provides an avenue for refinement/evaluation of doctrine and associated decision support technologies. MethodologyOur methodology used to simulate a decision process consists of several steps. Analysts must first gain an understanding of the decision process to be simulated by interviewing subject matter experts. An agent structure is developed to represent the competing objectives inherent in the process. After developing the agent structure, reasoning technologies are mapped to the process steps and assigned to the appropriate agents. Analysts create a domain specific file using the appropriate reasoning software GUI editor and export the domain specific file for an agent’s future use. The agents load domain specific files as needed for their function, provide problem specific inputs (state), and use appropriate generic engines to create solution outputs. This process is illustrated in  REF _Ref175472873 \h Figure 1.Figure  SEQ Figure \* ARABIC 1: Framework Preparation and UseHybrid Reasoning Technology Framework In order to implement the process, a framework that contains a hybrid of reasoning technologies available to be used by cooperative agents was developed. The cooperative agents represent competing aspects of the decision to be made. It is well understood that each reasoning technology is more suited toward solving particular types of problems. For that reason, this framework includes several types of generic reasoning engines, each of which is written in Java. Agents use the most appropriate reasoning technology for a given step in the process. By including a generic engine for a given technology, not only is development simplified, but domain specific information can be encapsulated in small files that could be later loaded and used by agents when appropriate. The small files limit the amount of computation effort needed by the agents. The hybrid reasoning technology framework is depicted in  REF _Ref175470902 \h Figure 2.Figure  SEQ Figure \* ARABIC 2: Hybrid Reasoning Technology FrameworkReasoning TechnologiesThis section provides an overview of each of the newly added technologies that include case-based reasoning, neural networks, Bayesian networks, and agents. The overview covers background information as well as the process for its use.Case-Based Reasoning (CBR)CBR is the process of solving new problems based on the solutions of similar past problems. It has been argued that case-based reasoning is not only a powerful method for computer reasoning, but also a pervasive behavior in everyday human problem solving. CBR tends to be a good approach for rich, complex domains in which there are myriad ways to generalize a case. A case consists of a problem, its solution, and, typically, annotations about how the solution was derived. The process for its use includes: Retrieve: Given a target problem, retrieve cases that are relevant to solving it. Reuse: Map the solution from the previous case to the target problem. This may involve adapting the solution as needed to fit the new situation. Revise: Having mapped the previous solution to the target situation, test the new solution in the real world (or a simulation) and, if necessary, revise. Retain: After the solution has been successfully adapted to the target problem, store the resulting experience as a new case in memory.Our project used a modified version of NaCoDAE [8]. While NaCoDAE includes a conversational CBR feature, it was not used in this year’s effort. The stored case closet to the current case at hand is used as the starting point for the new solution. An example of the GUI is shown in  REF _Ref175473917 \h  \* MERGEFORMAT Figure 3.Figure  SEQ Figure \* ARABIC 3: CBR User InterfaceNeural Networks Neural networks can be used to infer a function from observations and learn from a set of examples. This is particularly useful in applications where the complexity of the data or task makes the design of such a function by hand impractical. The tasks to which artificial neural networks are applied tend to fall within the following broad categories:Function approximation, or regression analysis, including time series prediction and modeling. Classification, including pattern and sequence recognition, novelty detection and sequential decision making. Data processing, including filtering, clustering, blind signal separation and compression. The process for its use includes:Use the GUI to set up neural network Train the neural networkExport the neural network to a fileImport file during runtime when requiredOur project adopted the Java Object Oriented Neural Engine (JOONE) [9]. JOONE is a Java framework to build and run artificial intelligence applications based on neural networks. JOONE consists of a modular architecture based on linkable components that can be extended to build new learning algorithms and neural networks architectures. The GUI editor is illustrated in  REF _Ref175474577 \h Figure 4. The process of training the network is shown in  REF _Ref175474604 \h Figure 5.Figure  SEQ Figure \* ARABIC 4: JOONE EditorBayesian NetworksA Bayesian network is a directed acyclic graph whose nodes represent variables and arcs represent statistical dependence relations among the variables and local probability distributions for each variable given values of its parents. One advantage of Bayesian networks is that it is intuitively easier for a human to understand direct dependencies and local distributions than complete joint distribution.Figure  SEQ Figure \* ARABIC 5: Training Neural NetworksThe process for its use includes:Build networkPopulate conditional probability tablesExport network structure to fileImport and run network during runtimeThe particular engine that was chosen was a modified JavaBayes [10]. The GUI editor used to create the network and associated conditional probability tables is illustrated in  REF _Ref175475358 \h Figure 6.Figure  SEQ Figure \* ARABIC 6: JavaBayes GUIRepast Agent UtilityThe Repast Agent Utility [11] includes a variety of agent features: Provides a fully concurrent discrete event scheduler that supports both sequential and parallel discrete event operations.Allows agent reasoning to be performed within the simulated/prescribed timelinePossesses automated Monte Carlo simulation framework Allows exploration of different results produced by varying the time that agent reasoning takesOffers built-in simulation results logging and graphing toolsContains integrated geographical information systems (GIS) supportThe process for its use includes:Extend the class SimModelImpl as the implementation of the agent modelSchedule simulation events using a Repast ScheduleChoose the Repast Space that agents inhabit Design the graphical display using Repast Display MappingsDesign the data collection plan using Repast DataRecorderDevelop agent classes for each type of agent requiredImplement a problem specific designTypically, the model determines when each agent is to actMessages to neighboring agents should be sent through the model by manipulating the Repast SpaceExample: Multi-Warfare SimulationThe generic nature of the framework can be applied to any domain of decision making, however, a planning problem for a future operation will be presented. An example scenario is given in the context of multi-warfare analysis where the simulation of decision making generates coordinated responses to unfolding events across multi-warfare areas such as 1) allocating competing resources across multi-warfare areas; 2) accounting for the warfare area dependencies; and 3) producing autonomous plans. The first two responses were covered in previous works [1, 2, 3]. The scenario used in this effort is illustrated in  REF _Ref175476570 \h Figure 7.Figure  SEQ Figure \* ARABIC 7: ScenarioAgent StructureIn this scenario, our goal is mission success with minimized risk to Blue forces. The following reflects the competing goals of the process and provides insight into the structure for the agents. The Strike Warfare Commander recommends operating from the coastal edge of the Carrier Operating Areas number two (CVOA2) to facilitate higher target service rate; the Air Defense Commander recommends operating from a more seaward CVOA – either CVOA1 or CVOA3 to minimize vulnerability to shore based missiles; and the Under Sea Warfare (USW) Commander notes that CVOA1 and CVOA3 are off continental shelf and in deeper water making carrier more acoustically vulnerable to enemy submarines. Thus the USW Commander recommends CVOA2. The Carrier Strike Group (CSG) Commander must resolve these competing recommendations. The structure of the Agents involved in this decision process is displayed in  REF _Ref175477025 \h  \* MERGEFORMAT Figure 8. Note: CSG Warfare Commander’s staff structure is nominal and is an illustrative example only. It is realized that CSG organizations can vary.Figure  SEQ Figure \* ARABIC 8: Agent StructureAgent Responsibilities and InteractionsEach of the agents has specific goals it would like to achieve. They must cooperate to achieve at least a minimum acceptable level for each of them. The goals of the CSG commander include:ReadinessOverall Mission planning and executionAsset allocationMovement and stationing of the forceRules of Engagement determinationWarfare priority settingDefense of the forceWarning and weapons statusThe goals of each of the warfare commanders include:Within assigned missionReadinessAssigned mission planning and executionAsset requirementsAsset movement and stationingDefense of assigned unitsWarning and weapons statusCross-mission cooperationMulti-warfare mission planning and executionMovement and stationing of the forceAsset prioritiesDefense of the forceWarning and weapons statusThe main algorithm that represents the decision process to be modeled is given in  REF _Ref175478538 \h  \* MERGEFORMAT Figure 9. It is used to simulate the commander level decision making that would be involved in developing a concept of operations (CONOPS). The CONOPS would in turn be used to execute the assigned mission. Each of the steps is explained in more detail below. For those that prefer a flow chart of this process, one is provided in  REF _Ref175478706 \h  \* MERGEFORMAT Figure 10. Figure  SEQ Figure \* ARABIC 9: Main Decision AlgorithmThe following sections provide details on the process above. The first step is to receive a tasking message from a higher authority. This message contains a time ordered list of missions, targets and their respective value, a list of candidate CVOAs, mission start/end times, mission start/end locations, and mission start/end times. Once the message is received, the CSG commander agent will decompose the message into mission phases. If a transit is necessary, a separate transit phase is identified. For each mission in tasking message, if the location achieved after a mission execution is not the same as the location for the start of the next mission, the CSG Commander creates a transit phase to CVOA for next mission. This transit phase is then followed by a mission execution phase. Figure  SEQ Figure \* ARABIC 10: Algorithm FlowchartThe CSG Commander orders the other warfare commanders to construct a CONOPS for the phase currently being planned. The following information dealing with the current phase is provided to the Warfare Commanders (WC): targets and respective weights, inter-phase dependencies, probability of each asset surviving the previous phases (execution order), mission weights for each WC, and WC risk thresholds.Each WC analyzes combinations of routes that connect the CSG to the CVOAs, inter-phase dependencies, asset assignments, and threats. A WC is designated to send out the first candidate CONOPS for deliberation. The designated WC starts with current asset assignments, known threats and environmental information and develops a CONOPS that satisfies the risk tolerance threshold for his/her specific mission area of responsibility. Satisfying risk tolerances within one warfare area can be accomplished by varying the selected motion plan, time of start, time of end (decided by time of start and motion plan), and blue asset allocation to warfare areas / formation and area of operations (CVOA in this case). Note: Depending on operational situation, the motion plan could alternatively refer to position of intended movement, patrol, sector, grid, or formation but is used to convey location, direction and speed of each asset. Once the first candidate CONOPS is available, each WC assesses this candidate CONOPS and calculates asset and mission risk affecting his mission area. If risks are unacceptable for his area of responsibility, the WC proposes a mitigating CONOPS that reduces risks for his warfare area by varying: motion plan, time of start, asset ownership assignments/formation and area of operations. Each WC uses a steepest decent algorithm to choose his proposed mitigation CONOPS.The CSG Commander, considering all alternative WC CONOPS, selects the CONOPS developed by the WC whose assets and mission risk are the most above his minimum acceptable risk threshold for the candidate CONOPS. Priority is given to the WC who has determined that the carrier strike group is at most risk to threats from his mission area if the candidate CONOPSis executed. As shown in  REF _Ref175540937 \h  \* MERGEFORMAT Figure 11, the Air defense Commander (ADC) would have priority. Tie breaking algorithms consider the alternative that generated the largest decrease in WC calculated risk and warfare priority.Figure  SEQ Figure \* ARABIC 11: Candidate Risk AssessmentThe CSG Commander broadcasts the selected alternative CONOPS as the newly proposed CONOPS. Each WC performs risk calculations for proposed CONOPS and returns the asset and mission risk to CSG Commander. The CSG Commander calculates total risk to the proposed CONOPS and compares it to the candidate CONOPS. If the risk of the proposed CONOPS is greater than the risk of the candidate CONOPS, the candidate remains. However, if the risk of the proposed CONOPS is less than the risk of the candidate CONOPS, the proposed CONOPS becomes the new candidate CONOPS. The CSG Commander distributes the candidate CONOPS and queries for mitigations. This negotiation repeats until no further mitigations are submitted or threshold risk levels are achieved for each mission area.Mapping Reasoning Technologies to the ProcessOnce the process to be simulated is understood and the agent responsibilities have been elaborated, the reasoning technologies are mapped to the appreciate steps in the process for each agent. The expert system, acting as the communications officer, notifies the CSG commander of the new tasking message. The CSG commander invokes the hierarchical decomposition planner to decompose tasking into phases. For each phase to be planned, the CSG commander invokes the CBR system to retrieve the CONOPS closest to the problem at hand for use in solving the new phase tasking. Agents, using an expert system to control their actions and technology selection, revise the CONOPS to match new phase tasking. In doing so they invoke the Bayesian network to choose the parameter to modify that most probably will give biggest reduction to risk in their warfare area. The neural network is used to evaluate proposed formations of assigned assets. Last, when the revised CONOPS is found, the CSG commander places it in the case library for future use.Future WorkOur future work will involve several possible additions. Adaptive control algorithms can be used to set parameters such as the aggressiveness of the Commander Federates actions from one run to the next. Currently, the decision algorithms run without regard to representative times that humans would need to make those decisions. Adding these process times to the simulation time would provide realistic decision delays. Enhancing the execution monitoring aspect of the commander federate is also a next logical step. Last, performance optimizations will be investigated.Summary This paper presented the details of simulating decision processes. The motivation for simulating decision processes was discussed. Our methodology included understanding the process to be simulated, developing the agent structure for this process and mapping reasoning technologies to the process steps assigned to the appropriate agents. Cooperative agents and a hybrid framework of various reasoning technologies was employed to simulate the decision process. Characteristics of the framework were provided. The benefits provided by each technology included in the hybrid reasoning framework were illustrated. These technologies encompassed case-based reasoning, neural networks, Bayesian networks, a fuzzy expert system and a hierarchical planner. A concrete decision process example was developed and a typical sequence of technology application to this example was presented along with various supporting algorithms. AcknowledgementsThe authors would like to thank the management of the National Security Analysis Department, of the Johns Hopkins University / Applied Physics Laboratory for their support in funding this research.References[1]	Dr. Joseph Kovalchik, et. al., An Interoperable Multi-Mission Warfare Federation for Analysis, Proceedings of the Fall 2003 Simulation Interoperability Workshop, October 2003  [2]	Dr. Joseph Kovalchik and Mr. Jonathan W. Labin, APL Integrated Multi-warfare Simulation (AIMS): Providing Resource Conflict Resolution in Multi-Warfare Analyses, Proceedings of the Spring 2006 Simulation Interoperability Workshop, April 2006.[3]	Dr. Joseph Kovalchik, Mr. Jonathan W. Labin, and Mr. Eric R. Rosenlof, Simulating the Commander’s Decision Process: Proactive Planning in Command Modules, Proceedings of the Spring 2007 Simulation Interoperability Workshop, March 2007. [4]	Jess, The Rule Engine for the Java Platform,   HYPERLINK "http://herzberg.ca.sandia.gov/jess" http://herzberg.ca.sandia.gov/jess, Ernest J. Friedman-Hill, Distributed Computing Systems, Sandia National Laboratories, Livermore, CA, Version 6.1p8 (23 March 2005).[5]	NRC FuzzyJ Toolkit for the Java(tm) Platform, User's Guide, Version 1.5a, Integrated Reasoning Institute for Information Technology, National Research Council Canada, R. A. Orchard , May 23, 2003.[6]	O. Ilghami and D. S. Nau. A general approach to synthesize problem-specific planners. Tech. Rep. CS-TR-4597, UMIACS-TR-2004-40, University of Maryland, October 2003. [7]	Okhtay Ilghami, Documentation for JSHOP2, Technical Report CS-TR-4694, University of Maryland, February 10, 2005[8]	Breslow, L. A. and Aha D. W., NaCoDAE: Navy Conversational Decision Aids Environment, Navy Center for Applied Research in Artificial Intelligence, December 1998. [9]	Marrone, Paolo., The Complete Guide: All you need to know about Java Object Oriented Neural Engine (JOONE), January 17, 2007.[10]	Cozman, F. G., JavaBayes Version 0.347, Bayesian Networks in Java User Manual, University of Sao Paulo, December 12, 2002. [11]	Collier, N., Repast: An Extensible Framework for Agent Simulation Technical Report, Social Science Research Computing, University of Chicago, Chicago, Illinois, 2000.Author BiographiesDR. JOSEPH G. KOVALCHIK is a Principal Professional at the Johns Hopkins University Applied Physics Laboratory. His experience spans both academia as Chairman of the Computer Science Department, U.S. Naval Academy, and industry, as Director of Software Development. While at JHU/APL, he has been involved in the development of automated reasoning systems and is currently a member of the Modeling and Simulation Group. Dr. Kovalchik received a B.S. degree in Mathematics from the U.S. Naval Academy, an M.S.E. degree in Electrical and Computer Engineering from the Johns Hopkins University, and an M.S. and Ph.D. degree in Computer Science from the Naval Postgraduate School, Monterey, CA.MR. JONATHAN W. LABIN is a Software Engineer at the Johns Hopkins University Applied Physics Laboratory. Mr. Labin has developed several HLA federations including the Human Exercise Federation. In addition, he has evaluated several commercial RTIs with respect to their compliance with regard to both HLA 1.3 and HLA IEEE 1516 standards. He received his Bachelors of Science and Masters of Science degrees in Computer Science at the University of Maryland Baltimore County.MR. ERIC R. ROSENLOF is a Principal Professional at the Johns Hopkins University Applied Physics Laboratory. He is a retired naval surface warfare officer with command at sea experience. He currently serves as the Undersea Warfare Assessments Section Supervisor within the Naval Operations Analysis Group in JHU/APL's National Security Analysis Department. Mr. Rosenlof received a B.S. degree in Oceanography from the U.S. Naval Academy in 1978, Annapolis, MD., a M.S. degree in Oceanography & Meteorology from the Naval Postgraduate School, Monterey, CA. in 1985, and a M.A. degree in National Security and Strategic Studies from the U.S. Naval War College in Newport, RI in 1994.Approved for Public Release: Distribution is Unlimited