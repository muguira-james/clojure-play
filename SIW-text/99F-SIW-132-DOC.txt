Architecture of the SIMulation EXercise (SIMEX)Paul MondayLockheed MartinP.O. Box 613Ft Knox, KY  40121502-942-1092mondayp@adstii.com Keywords:ModSAF, SC4 ABSTRACT: The SIMulation EXercise (SIMEX) Experiment at Ft Knox, KY evaluated the effect of future systems and innovative force structure on battlefield effectiveness.  It featured a large number of simulated entities and a situational awareness model that generated a world picture accessed via a surrogate command, control, communication and computer system called SC4.The situational awareness (SA) model was based on Spot reports sent by the friendly forces to generate a common SA picture that showed only those enemy forces that had been spotted and where they were spotted. The SC4 included productivity tools, like email, whiteboard, video telephone, and conferencing, a variant of ModSAF enhanced with items like pop-up Situation Reports and simplified Fire Support, multi-display stations, and 3-D views of the SA perspective.  In order to simulate the approximately 4000 entities, ModSAF was modified to reduce its network traffic rate and improve its reliability.  Many future combat systems were modeled, including variants of the Medium Armored Vehicle (MAV), missile-in-box (MIB), Future Scout Cavalry System (FSCS), robotic scouts, T90, BMP3, etc.1. Situational Awareness ModelFuture battlefield command-and-control (C2) networks will carry information that describes the location and situation for friendly (Blue) vehicles via reports like Position and Situation, and the location of enemy (Red) vehicles via reports like Spot and Contact. The C2 network modeled here assumes that some agent fuses the information on Red vehicles into a common situation awareness (SA) picture, and that there will be sufficient network bandwidth so that all Blue forces can see the same SA picture.2. Simulation NetworkMost entities were simulated by a derivative of ModSAF 4.0.  All rotary-wing air and air defense vehicles were provided by ATCOM.  Raptor munitions were provided by the Raptor minefield emulator.The network traffic generated by the simulations was reduced by limiting transmission of Entity State (ES) PDUs to once per 3 seconds per vehicle.  In ModSAF, the heartbeat rate for Transmitter PDUs was reduced to 60 seconds, and all ModSAF radios except for artillery were disabled.With about 2200 vehicles, the PDU rate on the Simulation network was 500 to 600 PDUs per second.Figure  SEQ Figure \* ARABIC 1 Network Configuration2.1 Digital Spot Report PDUAll of the simulated vehicles on ModSAF and ATCOM sent Digital Spot Reports (DSR) whenever the vehicle spotted an enemy vehicle.  The DSR described the enemy vehicle and the acquisition level.  If several vehicles were spotted at the same time, a separate DSR was sent for each.  In addition, a DSR was sent every 60 seconds as long as the enemy vehicle was continuously spotted.The DSR is similar to the Target Acquisition VVA PDU that is an option for the ModSAF baseline.  If enabled, that PDU is sent when any sensor acquires or loses a target, even if another sensor on the vehicle has already acquired the target.  This causes a much higher effective transmission rate than for the DSR.  The VVA PDU is also larger than the DSR.3. C2 NetworkThe C2 network used DIS 2.03 and experimental PDUs to convey the SA picture.  This picture was constructed from the stream of PDUs sent by the simulation systems by a single machine called the Sensor Server.The traffic on the C2 network consisted of the following surrogate reports:Position Reports (location of Blue vehicles): Carried by the Entity State PDU, each report described the marking, location, velocity, type, etc. of a single vehicle.Situation Reports (supply status of Blue vehicles): Carried by the experimental Vehicle Status PDU, each report described the activity, fire permission, and supply level for a single vehicle.Unit Reports (force structure of Blue): Carried by the experimental Aggregate State PDU, each report described the marking, location, and members of a single unitEnemy Position Reports (kind and location of spotted Red vehicles): Carried by the Entity State PDU, each report described the location and type of a single vehicle.Enemy Unit Reports (inferred force structure of the Red): Carried by the experimental Aggregate State PDU, each report described the location and members of a single unit.Each surrogate report contained the time-of-day at which the information was initially gathered.  This allowed a receiver of the report to take the age of the information into account when he interpreted it.  For example, if a Red T90 was identified at 10:30am, every subsequent Enemy Position Report for that T90 would contain the 10:30 time, until it was acquired by another Blue vehicle.  Each report was transmitted every thirty seconds for each vehicle or unit, so the overall traffic rate on the C2 network was less than 200 PDUs per second.4. Sensor ServerThe Sensor Server generated all of the reports on the C2 network that comprise the SA picture using information from the Simulation network.  The subtasks it performed include:collection and storage of recent Blue Entity State and Vehicle Status PDUs,generation of complete Blue force structure,transmission onto C2 network of Entity State, Vehicle Status, and Aggregate State PDUs for Blue vehicles/unitsmaintenance of a list of all spotted Red vehicles,dead-reckoning the location of spotted Red vehicles,generation of inferred force structure of spotted Red vehicles,generation and transmission onto C2 network of Entity State and Aggregate State PDUs for Red vehicles/unitsThe Blue force structure was constructed starting with the ModSAF Aggregate State PDUs.  Then a parameter-specified force structure was added.  Finally, an inference scheme based on vehicle marking filled in the holes.  A spotted Red vehicle was shown in the SA picture for thirty minutes after the last DSR on it.  If moving, it was dead reckoned for five minutes.  During this period, the location and velocity was based only on the situation at the time of the DSR.The type of Red vehicle reported in the Enemy Position Reports depended on the acquisition level of the observer.  If the Red BMP3 was detected, the vehicle was called a USSR vehicle, while if it was identified, the vehicle was called a BMP3.The Red force structure was inferred using the type of vehicles spotted and their geometry.  For example, if there were three tanks close together, a tank platoon was inferred.  Seven tanks made a company.Since the SC4 stations used the difference between their current time and the reported “good-at” time to age the icons, the Sensor Server and all of the SC4s were synchronized using NTP.5. SC4The Surrogate C4 device (SC4) was a workstation that provided:plan-view display of the SA pictureemailwhiteboardconferencing and video teleconferencebrowser-based view of satellite images3D view of the SA picture3D view from nose-camera on unmanned aerial vehicle (UAV)5.1 SC4 DisplayThe SC4 Display was provided by using a variant of ModSAF 4.0.  This version had most simulation-related tools removed and several C2 tools added.The tools that were removed included:Damage EditorMessage LogEnvironmental DisplayForce Designation PulldownPriviledge PulldownHHour EditorLocal Force PulldownScenario ControlsTime ControlsObstacle ToolOcean ToolEnvironment ToolBomb ButtonFire Support ToolUnit EditorLink EditorIFF ToolMine Mark EditorChemical ToolSupplies EditorROE ToolThe tools and features that were added included:Graphical depiction of icon agingGraphical on-icon statusSelection for icon displayPopup Situation and Salute reportsFSE Tool and Fire Support OverlayFind ToolField-of-View ToolSnail ToolFLOT ToolStatistics ToolPIR Tool5.1.1 Icon AgingThe location of a Red vehicle was considered reliable if it had been spotted recently, and got less reliable the longer it had been since it was spotted.  If the Red vehicle moved or was killed after it was last spotted, the SA picture did not reflect the new situation until a Blue vehicle sent another DSR.The age of the information behind an icon was shown by changing the color and line thickness.  For the first minute (Good time), the icon was thick and red.  For the second minute (Fair time), it was medium and pink, and after that it was thin and light-pink.  After thirty minutes, the icon was removed from the display by the Sensor Server.  The actual values of the Good time and Fair time could be set by the user.Figure  SEQ Figure \* ARABIC 2 Blue and Red Icons5.1.2 Graphical Unit StatusVarious status elements for Blue units could be displayed on the right side of the unit’s icon, as shown in Figure 2.  The four boxes in the example show Overall, Slant, Fuel, and Ammo status.  The colors represented the following levels:Green: 80-100%Amber: 60-80%Red: 40-60%Black: 0-40%Fuel and Ammo status described the amount of supplies the vehicle currently had, compared to its basic load.  The Slant status described the vehicle’s kill level (firepower, mobility, catastrophic).  The Overall status was a combination of the other three.5.1.3 Selection of Displayed IconsA selector was added so that the user could remove icons for dead Red vehicles and units.5.1.4 Popup ReportsIf this feature was enabled, a popup report was produced when the operator selected a vehicle or unit.  There were three kinds of reports, depending on whether the selected entity was a friendly unit, friendly vehicle, or enemy vehicle/unit.The SitRep used colored gumballs to summarize kinds of status.  Pressing one of the colored buttons caused a SitRep on the named unit (123A1) or vehicle (123A66) to be displayed.Figure  SEQ Figure \* ARABIC 3 Friendly Unit SitRepThe Friendly Vehicle SitRep was similar. The Enemy SALUTE displayed information about an enemy unit or vehicle.  The background color changed as the information got older.Figure  SEQ Figure \* ARABIC 4 Enemy SaluteThe Salute also showed when the vehicle/unit was spotted (T), and named the three most recent spotters (R1,R2,R3).5.1.5 Fire Support Element (FSE) Tool and OverlayThe FSE Tool replaced the baseline ModSAF’s Fire Support Tool.  It was designed to be as easy to use as possible, and to allow one user to relay a fire request to another. Figure  SEQ Figure \* ARABIC 5 FSE ToolThe tool had three sections.  The middle section showed the parameters for current fire mission.  To create a mission, all the user had to do is to click on the map.  Each mission was given a unique number, like AB1001, using the standard mission block scheme.To send a mission to a fire unit, the user selected one of the fire units from the Outgoing Missions list on the right and pressed the Send button.  To relay the mission to another user, like a higher command, the user selected one of the relay destinations and pressed the Relay button.  Note that this use of a list of fire units means that the user could keep his PVD zoomed to the target area.If someone has relayed a mission to this user, it would appear on the Incoming Missions list on the left.  The user could select a mission and delete it, relay it, or send it to a fire unit.Besides showing active fire units, the Outgoing Missions list also showed the status of each current mission, using terms like Prepare Guns, or Complete.  This made it easier for a user to send a mission to a fire unit that wasn’t already busy.The FSE Tool automatically generated and maintained the Fire Support Overlay.  This overlay showed the number, location and status (via color) of all ongoing missions, even if initiated by another user.  This overlay could be displayed or not at the choice of the user.5.1.6 Find ToolThe Find Tool allowed the user to easily center the map on any vehicle or unit.  Using the various filters, the user made a list of matching vehicles/units.  If he selected one and pressed the Center button, the map was centered one that vehicle/unit.Figure  SEQ Figure \* ARABIC 6 Find Tool5.1.7 Field-of-View (FOV) ToolThe FOV Tool was designed to show the field of view of one or more vehicles in a semi-transparent manner, and to allow the results to stay on the map even after the tool was closed.  The stippled pattern showed the area that a vehicle can see.  It was placed on a separate overlay, so that the user could turn the results on or off at any time.Figure  SEQ Figure \* ARABIC 7 Field-of-View Display5.1.8 Snail ToolThe Snail Tool added dashed lines showing where vehicles were.  The results were saved on the SNAIL Overlay, which could be displayed later as needed.Figure  SEQ Figure \* ARABIC 8 Snail Display5.1.9 FLOT ToolThe Forward Line Of Troops (FLOT) Tool displayed a projected FLOT for Blue or Red vehicles, based on their recent movements.  Its result was placed on the FLOT Overlay for later display as needed.Figure  SEQ Figure \* ARABIC 9 FLOT Display5.1.10 Statistics ToolThe Statistics Tool quickly displayed status statistics on selected units.  There were several formats.  The example in Figure 10 shows the status by vehicle type by battalion.Figure  SEQ Figure \* ARABIC 10 Statistics Display5.1.11 Priority Information Request (PIR) ToolThe PIR Tool let the user define important events ahead of time.  The machine monitored for the occurrence of an event, and alerted the user accordingly.  An event could be Red vehicles entering an area, Red firing artillery at an area, a Blue unit going Amber on ammo, etc.  When an event occurred, an alert was posted on the top menu.Figure  SEQ Figure \* ARABIC 11 PIR Tool5.2 Email, ConferencingCommercial software was used for email, browsing, whiteboard, video telephone, and conferencing.  Scripts were used to allow one user to send an overlay to one or more other users.  The PVD had a built-in monitor that notified the user for new mail or for the reception of an overlay.5.3 3D ViewsTwo kinds of 3D views were provided.  The first was of the SA picture, using a Stealth device on the C2 network.  This allowed the commander to better visualize the battlefield.  The second was from a nose camera mounted on a UAV.  This view was of the real battlefield.  Video switches were provided to select from the various displays.5. New ModelsSeveral new ModSAF models were developed or significantly modified for this experiment.The Squad model was used to represent a group of 10 infantry with a single entity.  The Squad entity was given the squad’s complement of guns and ammo.  Weapon parameters were modified so that the effectiveness of the squad entity was similar to separate infantry entities.  If hit, the squad incurred partial damage that knocked out a fraction of the squad’s guns.  When the squad was completely disabled, it died.  This model was essential for this experiment since it reduced the simulated entity count from 4000 to 2200.The Mast model was used on the robotic scout vehicles.  The mast automatically raised and lowered, and sensors on the mast had a better view when elevated.The Cued Sensor model allowed sensing by one sensor to cue another sensor.  On the robotic scout vehicle, a radar sensor cued a high-resolution FLIR.The Precision Guided Mortar Munition (PGMM) model launched an autonomous warhead from a mortar at ranges up to 15km.  When long-range sensors were available, the system proved very effective.6. New vehicles/unitsOver one hundred mostly future vehicles were created for the experiment, including Medium Armored Vehicle, Future Scout Cavalry System, Fighting Vehicle, Missile-in-Box (MIB), UAV’s, robotic scouts, BMP3 variants, etc.  Infantry squads were equipped with combinations of grenades, RPGs, AT missiles like Kornet, various machine guns, and mortars.  New munitions included Common Modular Missile (CMM), CKEM, TERM, and ATACMS_B2.Over 300 units were created.  Each of the 100 companies was different in composition.  Many of the smaller units had similar components but the desired icon was different.7. Other EnhancementsNew, unclassified vulnerability data was developed by putting every target and every munition into classes, and developing Pk data for each combination.  The experimental Instrumentation PDU was used to capture user actions on the SC4 stations for later analysis.  The experimental Status Change PDU allowed the analysis to accurately attribute kills to the correct killer.Most useful in preparing for the experiment was a utility that produced a listing of all of the important parameters for each vehicle and unit.  Since the specifications for the vehicles, i.e. guns, ammo, targeting rules, sensors, etc. were constantly changing, being able to quickly produce a human-readable printout saved a lot of time, and made the parameters accessible to all of the SMEs.Also useful before the experiment was a program used to test network equipment.  It could send a specified rate of numbered PDUs to a mirror that reflected the PDUs back to the sender.  The sender could then analyze for delay and drop rate.  One of the MWTB’s central network resources turned out to be designed for point-to-point activity and was unusable for the experiment.8. ProblemsIt would be nice to say that there were no problems.  Actually, there were lots of problems that mostly fit into five classes: core dumps, can’t move, won’t shoot, too many PDUs, and indirect fire hangups.The core dump problem wasn’t too bad after handlers were added for software common errors, like NANs, and null pointers.  Finding the errors was the problem.One of the most common operational problems was having vehicles get stuck.  Even on roads, vehicles would get stuck for no apparent reason, disrupting a unit’s movement.  This reduced the credibility of the exercise until an override was added that allowed vehicles to always move at least slowly so they could get past the sticking point.“It sees the enemy but won’t shoot” was a frequent complaint, and a real frustration to the commanders.  Since it was often hard to determine what was causing the problem, especially in such a complex situation, some of these were never fixed.Constant effort addressed the amount of traffic on the network.  Some of the manned simulators used the network to communicate between host and CIG.  This was handled with routers.  ModSAF minefields generated huge PDUs, which killed some simulations, so it was changed to not describe every mine.The indirect fire sequence, from FSE Tool through the FDC vehicle to the guns, always became unstable when things got busy.  The typical symptom was that a fire unit would take forever to act on a mission.  The problem was hard to reproduce offline.  After the experiment, testing showed that the problem was probably caused by ModSAF’s use of Signal PDUs for every communication between the FDC and gun.  Taking this communication off the network frees up the network and greatly unburdens the indirect-fire vehicles.Author BiographyPAUL MONDAY is an Operations Research Analyst at the Mounted Warfare Test Bed, Ft. Knox, KY.  He has been working on ModSAF, data analysis, and simulation software for the ADST and SIMNET programs for 12 years.