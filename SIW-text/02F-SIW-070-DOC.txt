MRMAide™: A Technology for Implementing Mixed resolution ModelsDr. Robert McGrawAllyn TreshnaskyRAM Laboratories, Inc.6540 Lusk Blvd, Suite C200San Diego, CA 92121858-677-9207rmcgraw@ramlabs.com Dawn TrevisaniAir Force Research Laboratory, IFSB26 Brooks RoadRome, NY315-330-7311Dawn.Trevisani@rl.af.milKeywords:Keywords: mixed resolution modeling, multi-modeling, sensitivity analyses, clustering algorithms, data abstractionABSTRACT: Model abstraction has been used to resolve differences in fidelity and resolution across diverse modeling paradigms.  These techniques foster model reuse and reduce simulation runtime by focusing model fidelity only on the more critical aspects of the simulation.  Traditionally, abstraction has been implemented by hand.  This has been a tedious, error-prone, and non-portable process.  The Mixed Resolution Modeling Aide (MRMAide™) technology is an effort to semi-automate the implementation of abstraction techniques for both stand-alone models/components and entire federates/simulations to resolve the issues associated with Mixed Resolution Modeling (MRM).  Its goals are to aid in the development of simulations whose fidelity can be varied, and to make legacy models more interoperable within such simulations.  MRMAide™ has three phases of operation: pre-processing, data abstraction, and validation.  During pre-processing the components to be linked together are evaluated in order to identify appropriate mapping points.  During data abstraction those mapping points are linked via data abstraction algorithms.  During validation developers receive feedback regarding their newly created models relative to existing baselined models.  This paper presents some of the issues faced during the ongoing development of MRMAide™ technology.  This technology will be demonstrated through the use of unclassified SPEEDES (JSMIMS CCSE) training models and JMASS JTEST and ACAT models.This work has been funded through a Phase II SBIR award from the Air Force Research Laboratory’s Information Directorate, Rome Research Site.IntroductionWhen looking at many of the programs that are taking shape today, one can’t help but notice the flavor of “Joint” with respect to forces, and the notion of “common information” amongst the services to improve awareness, assist decision makers and create a complete battlespace for trainees.  For instance, the concept of Global Strike Task Force (GSTF) will require the capability to fuse joint, coalition, and inter-agency information.  One of the elements required of this concept (GSTF) is Predictive Battlespace Awareness (PBA) which provides a commander with an accurate picture of reality and, from previous decisions and alternative actions, tells him where he is most likely to be in the future.  Included is the Common Operating Picture (COP), which correlates and fuses data from multiple sensors and intelligence sources to provide warfighters the situational awareness needed to be able to act and react decisively.  Other programs include Effects Based Operations (EBO) used for planning, executing and assessing joint military operations, and Joint Battlespace Infosphere (JBI), a combat information management system that integrates data from a wide variety of sources, aggregates information, and distributes it in the appropriate form and level of detail to users at all echelons.  The Joint Synthetic Battlespace (JSB) is a virtual environment that supports live, virtual and constructive simulations and is used for evaluating new concepts and elements in a simulated environment whose fidelity and resolution can be selected for the application.  JSB environments enable simulations at the campaign, mission, engagement and engineering levels.  These are just a few examples of current programs and focus areas.  In other words, simulations today are no longer stove-piped, uni-purpose simulations.Battlefield simulation is a complex, multidimensional, multiperspective problem that requires models and simulations of all resolution levels in order to capture the many facets of the battlefield and to replicate its complexities.  In order to be able to perform more accurate analyses, improve fidelity for training purposes, support acquisition decisions, and provide better tactical planning and decision-making capabilities, we need the big picture; and we need it to be represented with more accuracy than has been done in the past.  The ultimate plan is for models and simulations at the various levels in the hierarchy10 to be able to be reused and interconnected with models and simulations at other levels in the hierarchy (e.g., missile flyout models can be interfaced to air-to-air engagement simulations, etc.). The idea stems from the very natural desire to increase the level of fidelity (read: accuracy) in these higher-level simulations by incorporating the accuracy of more detailed – and ostensibly, verified and validated – models.  Early approaches to improving the accuracy of aggregate-level simulations involved a concept known as “model integration;” essentially the coupling of existing models, whereby a high-level simulation invoked a more detailed model of a process or function (some approaches actually embedded this high-resolution code within the coarse simulation) which was felt to be represented too coarsely in the high-level model.  However well-intentioned, model integration as a way of increasing realism is not, in our opinion, the best answer.  For every model that gets interfaced to, or integrated with, another simulation, the run-time has to increase. It’s impossible not to; especially considering that there are some extremely complex engineering-level models at the lowest level of the pyramid that could ultimately be invoked at the theater-level, to be run in place of their rudimentarily-modeled counterparts in that simulation. What would result would be an extremely accurate answer, but one that was so late as to be completely unusable by anybody.   We still desire the accuracy of the detailed model, yet cannot afford the run-time expense.  Ideally the detailed model would run in time-step with the higher level simulation so as to reap the benefits of the accurate results; in time for them to be useful.Existing simulation frameworks can handle differences in synchronization, timing, language, and platform.  However, they can’t handle differences in resolution and fidelity very well.  In order to incorporate those models into a simulation, developers are often required to create “wrappers” or “interface layers” for them.  This is a costly and complicated process.  Developing these wrappers requires that the differences in resolution be resolved.  This process is known as Mixed Resolution Modeling (MRM). The Mixed Resolution Modeling Aide (MRMAide™) technology is an effort to assist the user with the application of abstraction techniques to resolve MRM issues.  MRMAide™ suggests ways of resolving differences in fidelity and resolution across diverse modeling paradigms.  The goal of MRMAide™ is to provide a technology that will allow developers to incorporate model components into scenarios other than those for which they were designed.  Currently, techniques in support of MRM are implemented by hand.  This is a tedious, error-prone, and non-portable process.  MRMAide™, in contrast, will automatically suggest to a developer where and how to connect different components and/or simulations.MRMAide™ automates the creation of these wrappers and/or interface layers.  MRMAide™ has three phases of operation: pre-processing, data abstraction, and validation.  During pre-processing the components to be linked together are evaluated using advanced sensitivity analyses and clustering algorithms in order to glean information about the components’ behavior and identify appropriate mapping points between them.  These algorithms require no a priori knowledge about the scenario being modeled.  During data abstraction those mapping points are linked via abstraction algorithms.  These algorithms will make use of, but are not limited to, statistical distributions, equations, substitution, neural networks, and aggregation and disaggregation.  During validation developers receive feedback regarding the performance of their newly-created models relative to existing baselined models.  The current work presents an overview of the various problems encountered during MRM and the various technologies utilized by MRMAide™ to overcome those problems.  Developers using MRMAide™ will be able to devote more time to the real issues underlying their simulations instead of having to kludge together brittle solutions to the MRM problem.Mixed resolution modelingIn the current work, MRM refers to the process of integrating models that were designed at different levels of fidelity and resolution into a single simulation.  This involves being able to vary the fidelity and resolution of models.  This is done to improve simulation efficiency as well as to integrate legacy models into current simulation frameworks.  There are two basic questions that should be addressed when performing MRM:What level of fidelity and resolution is appropriate for a given model?How can that model be connected to other models (at possibly different levels of fidelity and resolution)?The first question touches upon certain ancillary issues.  Firstly, it is implied that a developer engaging in MRM has some idea what level of fidelity model components in his simulation are designed at.  This needn’t be a quantitative value; merely knowing that one model component is designed at a higher level of fidelity than other model components is enough.  Knowing this allows the developer to identify where and when to apply techniques in support of MRM within the simulation.  Secondly, a developer might also wish to use these techniques to vary model fidelity in order to satisfy certain computational constraints.  Generally speaking, as a model becomes more fine-grained, the computational overhead involved in simulating that model increases.  However, it seems intuitive that the more detailed that model is, the more accurate the simulation will be.  Of course, this is not always the case.  Consider a very coarse-grained model M1 of an object traveling through space at a constant velocity.  Now consider a finer-grained model M2 of the same object that takes into account drag, gravity, acceleration, etc..  If there is even a very small error in one of the parameters of M2 then over time, as more and more calculations based on that parameter build up, the error can increase until the simulation results are no longer reasonably accurate.  With a large set of parameters it becomes more likely that one or more of them are either unavailable or unreliable.  M1, in contrast, does not suffer from this problem and so long as its gross-level parameters are reasonably accurate the entire simulation should be reasonably accurate.  At any rate, there ought to be a balance between accuracy and computational cost.  Sometimes it makes sense to sacrifice a small amount of accuracy for large increases in computational speed. Such techniques in support of MRM that allow for varying model fidelity dynamically while a simulation is running is often referred to as “variable resolution modeling.”The second question asks how a component modeled at a particular level of fidelity can communicate with another component expecting data at a different level of fidelity.  Put another way, what is the set of transformations that are required in order to change the format of one component’s attributes into a format that other components expect and know how to communicate with?There exist various methods for identifying and generating such transformations.  These can involve abstracting away certain unnecessary or less critical high fidelity parameters.  These can also involve formulating new parameters based on existing low fidelity parameters. Existing Approaches to MRM One approach to MRM in general and to multi-modeling in particular is to design hierarchical model sets that consistently describe the same phenomena, but where each node of the hierarchy represents a different level of fidelity3.  This approach makes it very straightforward to switch fidelities either between simulations or within a single simulation.  This is accomplished by embedding some sort of “monitoring agent” in the simulation that checks simulation parameters and switches the model being used when those parameters pass some predetermined threshold (see Lee and Fishwick4, and Sekine et. al.8 for examples).  This technique does have its shortcomings, though.  It requires very well-structured and formally defined models.  This places a heavy burden on the developer.  Moreover, each level of the hierarchy is dependent on the next-lowest level.  This means that developers cannot truly execute any level of abstraction independently.  This seems to somehow “miss the point” of MRM.  Each new level adds another set of transformation functions.  These functions act cumulatively which means that both model complexity and computational time is increased.  It is possible to devise abstraction hierarchies where each level is more independent by simply approximating the data generated at the lower levels.  This is an improvement over the previous method, however it still requires that the model already be in a multi-modeling format.  This is not a valid assumption for many legacy models and, in any case, it creates more work for the developer.The identification of appropriate mapping points between models of different fidelity is largely an intuitive task.  As such, it is difficult to formalize, highly subjective, and often requires specialized knowledge of the domain being simulated.  There are some techniques that can be used to assist the identification task.  Sensitivity analyses can be used in order to determine how various parameters or combinations of parameters influence the simulations.  Sensitivity analyses are typically very slow and can generate uninformative results, however, there are useful extensions to sensitivity analyses that can be applied to modeling and simulation.  Davis et. al.3, present a set of methods known as “exploratory analysis” which, through investigating the uncertainty of model parameters, is able to glean more information than traditional sensitivity analyses.  MacDonald and McGraw5 present methods known as “fractional factorial extremum experimentation” for scaling down the parameter space that sensitivity analyses are required to search.     Performing the actual mapping between models of different fidelity is a bit more straightforward (but not much).  One technique for abstracting a set of parameters is simply to approximate some subset of parameters.  This can be done by rounding off values or by breaking up continuous values into discrete chunks.  Often times mathematical equations can be substituted for running a full-blown simulation to generate parameters.  If the behavior of one or more model parameters over time is well understood and can be represented by an equation then oftentimes the partial derivative of that equation may be substituted.  Omission or substitution are other useful abstraction techniques.  Parameters can either be removed completely or replaced by constant values or values that give no information to other model components.  For instance, it might make sense to replace a parameter with its mean or modal value if it is determined that the value does not significantly influence the behavior of the simulation.  Aggregation of parameters involves grouping similar parameters into single units.  This aggregation can take the form of a weighted average of the component parameters or some other compounding function can be used.  Statistical distributions can also be used for data abstraction.  Individual parameters can be replaced by random samples based on some probability distribution that accurately describes the range of values for those parameters.  This seems to be the most prolific of abstraction techniques used for MRM.  It requires, however, a data set of recorded parameter values for simulation runs in order to identify the appropriate probability distribution.  Such a data set can be time-consuming to generate.  Finally, techniques from artificial intelligence may be used for data abstraction.  Currently, neural networks have been the most widespread AI technique used.  Neural networks are useful pattern matching tools; they can be used to perform the transformation function from one model component’s parameter set (treated as a pattern of activation across a vector) to another such parameter set. Mixed Resolution Modeling AideMRMAide™ is actually a suite of tools linked via a common Graphical User Interface (GUI).  Each tool is intended to help automate one or more of the tasks described above in order to facilitate techniques for implementing a mixed resolution model.  To use MRMAide™ a developer needs to identify a source component he wants to incorporate into a simulation and a either a target component he wants to replace or else a target simulation (federate) he wants the source component to communicate with.  After successfully using MRMAide™ to perform implement these techniques, a user should wind up with one or more wrapper classes that may be inserted into a simulation in place of an existing model component.  Thus, MRMAide™ facilitates model reuse.  MRMAide™ can also provide benchmarking data that describes how the wrapper class performs relative to existing (baselined) model components.  The basic algorithm to create a wrapper is fairly straightforward: Determine which target component parameters are needed to communicate with the simulation RTI, or which target RTI Application Program Interfaces (APIs) are needed to communicate with the source componentDetermine which source component parameters, if any, can be used to map to those target parameters or APIsDetermine how to perform that mappingCreate a new class that is ostensibly based upon the target component or RTI but that incorporates the functionality of the source component – this new class will look like a native component to the simulation RTI but will behave internally like the source componentMRMAide™ provides a GUI that is capable of displaying a model component’s parameter set in order to allow a user to graphically link model components’ parameters and then associate MRM techniques with each link.  This display is fully rendered in three dimensions.  Users are able to rotate and zoom the display in order to more effectively view what may become a rather crowded and complicated representation. MRMAide™ is portable across different platforms (Windows, UNIX, Linux, and Mac OS X) in order to be applicable to the widest range of models.  MRMAide™ will allow users to save state.  This is an especially useful feature for developers who wish to compare the results of multiple wrapper configurations.  MRMAide™ is an ongoing work in progress.It is important to understand what MRMAide™ is not.  MRMAide™ is not a panacea intended to solve all MRM problems.  MRMAide™ can suggest ways to link model components, but the user is always free to ignore those suggestions.  MRMAide™ is meant to be accessible and used by non-experts, but obviously, the more a user knows about the simulation domain, the better.  Also, it should be kept in mind that any time techniques in support of MRM are used, the accuracy of a simulation is inherently altered.  Figure 1 shows the main MRMAide™ GUI.  The GUI is broken into three panes: the component pane on the top left displays information about a simulation’s source component and target component, the canvas pane on the top right is used as a blackboard area for users to create and manipulate mappings among the source and target, the filter pane on the bottom is used to simplify the display on the canvas pane since it may get very crowded very quickly.  Running along the toolbar are buttons to perform sensitivity analysis, run clustering algorithms, create wrappers, validate models, rotate and zoom in and out of the canvas pane, and provide user help.Figure  SEQ Figure \* ARABIC 1: The main MRMAide™ GUI (shown under the KDE desktop environment for RedHat Linux 7.1)Before walking through the different phases of MRMAide™’s operation, the format of the model components that MRMAide™ can interact with should be reviewed.  It would be very impractical to design a tool that was able to parse any component format.  In addition to all of the different coding languages available, there are also many simulation architectures that use their own internal scripting language to specify model components (JMASS, for example).  Furthermore, even restricting MRMAide™ to work with only a single language and architecture is impractical due to the idiosyncrasies of developer’s coding techniques.  In an attempt to circumvent this problem MRMAide™ relies on a standard commenting scheme to inform it of a component’s structure.  MRMAide™ has a built-in XML parser for this purpose.  Figure 2 shows a sample component file with embedded XML comments in it and MRMAide™’s representation of the component defined by that file.  XML is a good choice for the commenting scheme because it is an extensible standard, able to change as MRMAide™ becomes more complicated or as the type of information required for particular simulation scenarios changes.  It is hoped that particular XML tags will carry with them semantic information based on how particular parameters are intended to be used within a model.  This will be a great help to developers that may be unfamiliar with the simulation domain.Figure  SEQ Figure \* ARABIC 2: Parsing a model component using XMLEach parsed attribute can be further examined and manipulated by adding it to MRMAide™’s canvas pane.Pre-ProcessingThe first phase of the MRMAide™ process is the pre-processing phase.  During this phase, appropriate mapping points are determined.  This is accomplished through advanced sensitivity analysis and clustering algorithms.  Strictly speaking, pre-processing is not a requirement for implementing MRM techniques.  However, many model parameters have very little bearing on the outcome of the simulation (see, for example, McGraw and Clark6).  It would be wasteful to spend time analyzing those parameters.In order to determine what parameters are important to the simulation and which parameters may be abstracted away, a sensitivity analysis is performed.  This is a non-trivial task.  In fact, looking at the impact of each parameter can be computationally prohibitive.  An N-dimensional vector where each dimension can vary among K values has KN possible values.  For many realistic simulations N is very large and the range of K is continuous.  Some way of scaling down the search space is needed.  A preliminary variable assessment can be performed on the parameters.  This assessment can be wholly subjective, in which case it is hoped that the embedded XML comments will provide sensitivity information.  The assessment can also be more rigorous.  A “sensitivity coefficient” aij can be determined for each parameter Xj: EMBED Equation.3  aij can be estimated according to the percentage of change in the output Y from its nominal value (the value of Y when all inputs X are set at their nominal values).  Rather than investigate each possible value of Xj, investigations can be limited to its mean plus or minus some multiple of its standard deviation.  Once a set of variables has been marked as “important,” basic statistical correlation techniques can be used to rank those importances. (from MacDonald and McGraw5.)This method requires no a priori knowledge about the scenario being modeled other than what the baselined results are (in order to estimate the Y parameter above).  To a first approximation then, if a developer maps nothing else he better make sure to map those parameters with high sensitivity coefficients.Clustering Algorithms may also be used as a pre-processing tool.  Clustering algorithms are useful whenever one needs to classify an excessive amount of information into a set of manageable and meaningful smaller amounts.  Using an analogy from vector analysis, a clustering algorithm can be said to divide up state space into discrete “chunks” such that each vector lies within one chunk.  It is useful to think of these vectors as sets of features or parameters.  For the current work it is useful to think of simulations in terms of vectors traveling through some multidimensional space over time.  Each vector represents the parameter set of a particular model present in the simulation.9  What kind of clustering algorithm is useful for MRMAide™?  One that makes few assumptions about the structure of a model or the distribution of its parameters, one that does not require a pre-known number of clusters, and one that can be automated.  A technique that will be referred to as “Multi-Scale Clustering” (MSC) satisfies these requirements.First the dissimilarity of each vector relative to every other vector is computed.  MSC is flexible enough to utilize many different measures of dissimilarity.  For the current work, an extension of the power distance is used: EMBED Equation.3  Here i and j correspond to the vectors being compared, N corresponds to the number of parameters being compared, ck corresponds to a variable weight that is applied to some particular parameter k, and r corresponds to a weight that is applied to large differences between vectors.  Of course, not all models will fit neatly into this equation.  Consider parameters that can vary only between a set number of discrete states.  In these cases the basic power distance formula may be augmented.After a dissimilarity matrix has been generated, a similarity threshold s is slowly increased.  At every stage of the MSC process only those vectors whose dissimilarity is less than  are eligible to be placed in the same cluster.  When s equals 0, all vectors will be placed in their own cluster.  As s increases the number of clusters k will decrease.  When k equals 1, a full hierarchical clustering will have been generated.  Figure 3 shows an example of this.  The longer a segment is, the more robust the cluster represented by that segment is.  Figure  SEQ Figure \* ARABIC 3: Multi-Scale Clustering; the shaded region corresponds to a clustering schema where k=4It is important to note that MRMAide™ does not cluster individual parameters within vectors.  While this might be useful as an aggregation technique for data abstraction, it is not useful as a pre-processing step.  Instead, MRMAide™ clusters individual vectors within a simulation.  This type of clustering can allow developers to draw inferences about the behavior of model components within a simulation.  A particular clustering schema can tell a developer where parameter values are likely to be located within state space over the course of a simulation.  Why is this useful?  With respect to multi-modeling, data abstraction algorithms that are applied to parameters over all time can result in inappropriate information.  Consider a one-dimensional vector that breaks down into two clusters when analyzed by MSC.  Figure 4 illustrates how replacing a binomially-distributed parameter with its mean clearly gives an inaccurate value.  Accuracy can be greatly improved, however, it that same parameter is replaced by one of two means depending upon which cluster it is in.Figure  SEQ Figure \* ARABIC 4: One uninformative mean versus two informative means.Thus, clustering can be used to suggest “breakpoints” within the simulation where data abstraction functions might be switched on the fly.  Clustering can also help developers simply by reducing the dimensionality of a problem.  It can be very daunting to keep track of the many changing parameters within a given simulation.  Finally, clustering can also uncover hidden relationships among parameters – it can show that certain parameters are linked together and so may be good candidates for aggregation based implementations.How does all of this information get incorporated into MRMAide™?  As a component is parsed, an internal representation is built up based on its underlying structure.  This representation contains (among other things) lists of parameters.  Each parameter is able to have associated with it sensitivity coefficients and relevant clustering information.  Parameters are displayed on the canvas pane as shown in Figure 5.Figure  SEQ Figure \* ARABIC 5: Displaying parameters on the canvas paneDouble-clicking on a sphere will bring up extended information about the corresponding parameter.  The filter pane may be used to restrict the amount of data displayed on the canvas pane.  For example, filtering based on sensitivity may alter the canvas pane to highlight only those parameters that have a sensitivity value higher than some specified threshold.  As mentioned previously, a developer may wish to concentrate only on very sensitive parameters first.Clustering algorithms and sensitivity analyses work together in MRMAide™ to help identify appropriate mapping points to link together via MRM algorithms.  These algorithms get configured during MRMAide™’s data abstraction phase. Data AbstractionInformation that is abstracted away must be replaced properly in order for the wrapper model to remain consistent with the baselined model.  Data abstraction algorithms are configured graphically using MRMAide™’s canvas pane.  To link parameters or sets of parameters, a developer simply selects a source parameter and drags the mouse to the target parameter he wishes to link to.  This will create a view like that shown in Figure 6.Figure  SEQ Figure \* ARABIC 6: Creating associations (part one)Once a developer has established what associations are to be used, it is time to configure them.  To do this a developer simply double-clicks the line corresponding to the association being configured.  This will bring up a dialog box like that shown in Figure 7.  MRMAide™ provides several built-in data abstraction algorithms to choose from. Figure  SEQ Figure \* ARABIC 7: Creating associations (part two)Statistical distribution refers to replacing parameter values with random samples from particular distribution functions (such as uniform, gaussian, binomial, exponential, poisson, etc.). Equation refers to replacing parameter values with mathematical equations which can be computed as needed throughout the simulation.  Substitution replaces parameter values with other values: either that parameter’s mean or median, or else some other useful constant.  Network refers to using a neural network to approximate the mapping from source to target, treating each component as a single vector moving through the simulation space.  This technique, while useful in the end, can be very time-consuming to configure and train the network properly.  Aggregation refers to grouping sets of parameters into single units using some compounding function such as a weighted average.  Within MRMAide™, aggregation would require that multiple source parameters are associated with some number of target parameters.  Those associations would then be treated as a single association.  Finally, a developer is free to implement a custom data abstraction algorithm.  Such an algorithm would take the form of a function written in C or C++.  To do this requires familiarity with the models being manipulated.  More data abstraction algorithms can always be added as they are discovered. As mentioned earlier, it is possible to associate algorithms with particular clusters.  So, for example, using MRMAide™ a developer could specify one computationally-intensive data abstraction algorithm to be used to generate a parameter value when the component finds itself in a cluster where accuracy is very important and another less computationally-intensive algorithm for all other cases.Once all of the associations have been accounted for (i.e.: have been “configured”), MRMAide™ can create the wrapper that is to be inserted into the simulation.  Ostensibly that wrapper will be based upon the target component or simulation (federate) but will incorporate the functionality of the source component.  That is, the wrapper will look like a native component to the simulation RTI, but will behave internally like the source component.  Whenever an abstracted parameter is requested by the RTI the value received will actually be the return value of a member function inserted by MRMAide™. ValidationOnce MRMAide™ has created a wrapper, the simulation should be run using that wrapper in order to record benchmarking data.  This data can then be compared against baselined data from simulation runs using the original target component.  Whenever data is abstracted some amount of statistical accuracy will be lost.  There is always a trade off between computational efficacy or speed and statistical accuracy.  Computational efficacy can easily be quantified in terms of CPU time, memory usage, network traffic, etc.  The level of accuracy, in contrast, is a much more abstract concept.  It really only makes sense to talk about accuracy in terms of variance from baselined models.  It is assumed for MRMAide™ that the baselined model has already been validated and is therefore justified in being used as the basis of comparison for wrapper models.  Thus, comparison testing involving the behavior of the actual phenomena being modeled is not part of the MRMAide™ validation process. However, operational validation and verification to test that the wrapper is an accurate representation of the target model will be performed.MRMAide™ will present validation data graphically, locating the current wrapper implementation, the baselined model, and any prior wrapper implementations on a series of histograms detailing performance and fidelity information.  By providing validation feedback, users are able to try different approaches for implementing techniques in support of MRM and fine-tune the speed/accuracy tradeoff of their simulation.Future work and ApplicationsMRMAide™ is an ongoing work in progress.  Not all of the features and algorithms have been incorporated into the GUI yet.  And there are extensions that we would like to see built into  MRMAide™ in the future.  The pre-processing phase of operation is not yet final.  Specifically, the XML parser can be extended to handle a wider range of XML tags.  The current XML schema only indicates the parameter name and type (if it is an attribute) or return type (if it is a function).  Information such as a function’s arguments, an attributes size (if it is a collection class), developer comments (perhaps indicating relative sensitivity), etc. would be useful.  Because XML is an extensible language, MRMAide™’s XML schema ought to be able to grow as needed.  The ability to save state has not yet been implemented into MRMAide™.  This is a useful feature that will not only allow developers to save and come back to their work later, but will let them save multiple MRMAide™ generated models that can be compared amongst themselves.  An appropriate and efficient format for MRMAide™ state files needs to be decided upon before this feature is realized.The validation phase of operation needs to be implemented.  This will allow users to receive feedback about the performance of the models they develop with MRMAide™.  In order to do this, appropriate measures of effectiveness need to be determined for simulations.  For baselined simulations such measures are already defined.  Those same measures should be tracked for simulations using MRMAide™ generated models.  The results can then be compared to see how much accuracy is lost.  Note that accuracy in this situation will always be lost, it will never be gained.  MRMAide™, since it knows nothing about the simulation domain, must assume that the baselined measure of effectiveness is completely accurate.  So, for example, a MRMAide™ model that results in a simulation whose missiles detonate one meter closer to their targets has an inaccuracy of one meter.  Methods for tracking resource usage should also be integrated into MRMAide™.  This way a developer will be able to quantify the gains in memory usage and/or processing time relative to the losses in accuracy.The most obvious area for improvement is to expand MRMAide™’s use cases as much as possible.  This means applying MRMAide™ to more models, especially ones that entail more complex MRM techniques.  As situations arise that require different abstraction algorithms, those algorithms ought to be incorporated into MRMAide™.  In addition to expanding the range of models that MRMAide™  can work with, simulation or RTI based MRM needs to be implemented within MRMAide™ .  Implementing MRM across an RTI does not require a target model to link with; MRMAide™ simply links the appropriate RTI API’s to those of the source model.conclusionsThe ability to apply abstraction techniques in order to not only utilize legacy models -- thus preserving development and run-time -- but to “intelligently” approximate the “behavior” of large complex models is critical in most every application of simulation for analysis, training, and operations.  Today’s plans, programs and joint operations provide opportunities for model abstraction, due to the reality that most simulations that are needed for high-level reasoning and communication, training, decision support, and exploratory analysis are very large and extremely complex.  Therefore, they will inherently be faced with the necessity to resolve MRM issues if they are ever to be used in a timely fashionMRMAide™ is a promising tool suite for assisting the user through the model abstraction process.  Using MRMAide™ developers will be able to:discover the underlying structure of model componentsidentify appropriate mapping points among those componentsconfigure MRM data abstraction algorithms to link those mapping points create wrappers based on those algorithms and insert them into simulationsvalidate the functioning of those wrappersThese are not trivial tasks.  MRM and multi-modeling are clearly wanted and needed by the modeling and simulation community, but current MRM implementations are insufficient.  While there are several examples of good solutions to specific MRM problems out there, none of those solutions are portable enough, general enough, nor automated enough to be applicable to much more than the specific simulations they were designed for.   These hand-coded MRM implementations are tedious and error-prone.  Developers using MRMAide™ will be able to devote more time to the real issues underlying their simulations instead of having to kludge together brittle solutions to the MRM problem.AcknowlegementsThis work is being supported by AFRL Information Directorate, Rome Research Site, Contract Number F30602-01-C-0058.  Special recognition is due to Dawn A. Trevisani and Alex F. Sisti.ReferencesC.G. Cassandras, C.G. Panayiotou, G. Diehl, W-B. Gong, Z. Liu, and C. Zou, “Clustering methods for multi-resolution simulation modeling,” Enabling Technology for Simulation Science IV, Proceedings of SPIE Vol. 4026, pp. 37-48, 2000.S.V. Chakravarthy and J. Ghosh, “Scale-based clustering using the radial basis function network”, IEEE International Conference on Neural Networks, 1993.P.K. Davis, J.H. Bigelow, and J. McEver, “Exploratory analysis and a case history of multiresolution, multiperspective modeling”, Enabling Technology for Simulation Science IV, Proceedings of SPIE Vol. 4026, 2000. K. Lee and P.A. Fishwick, “A semi-automated method for dynamic model abstraction,” Enabling Technology for Simulation Science I, Proceedings of SPIE Vol. 3083, 1997.R.A. MacDonald and R.M. McGraw, “Assessing candidates for model abstraction”, Enabling Technology for Simulation Science IV, Proceedings of SPIE Vol. 4026, pp. 180–191, 2000. R.M. McGraw and J.E. Clark, “Evaluating the performance versus accuracy trade-off for abstract models”, Enabling Technology for Simulation Science V, Proceedings of SPIE Vol. 4367,  pp. 71–81, 2001.R.G. Sargent, “Validation and verification of simulation models,” Winter Simulation Conference Proceedings, pp. 39–47, 1999.S. Sekine, M. Kanou, M. Ogata, and A. Higashide, “Advanced technique for mrm (multi-resolution models),” Simulation Interoperability Workshop, Spring 2001.A. Treshansky and R. McGraw, “An overview of clustering algorithms”, Enabling Technology for Simulation Science V, Proceedings of SPIE Vol. 4367,  pp. 41–51, 2001.D. Trevisani and A. Sisti, “The Air Force Hierarchy of Models:  A Look Inside the Great Pyramid”, Enabling Technology for Simulation Science IV, Proceedings of SPIE Vol. 4026, pp. 150-159, 2000.D. Trevisani, A. Sisti and M. Mayhew, “Model Abstraction and the Simulation Sandbox”, Enabling Technology for Simulation Science VI, Proceedings of SPIE Vol. 4716, pp. 211-217, 2002.