Lifeforms in V-DISLance R. MarrouMark A. FaulkStephanie I. B. EncarnacionScience Applications International Corporation (SAIC)12901 Science DriveOrlando, FL 32826 USA(407) 243-3710, (407) 243-3553, (407) 243-3797 (phone) (407) 243-3586 (fax) HYPERLINK "mailto:lance.r.marrou@saic.com" lance.r.marrou@saic.com,  HYPERLINK "mailto:mark.a.faulk@saic.com" mark.a.faulk@saic.com,  HYPERLINK "mailto:stephanie.i.banaag@saic.com" stephanie.i.banaag@saic.comMr. Brian KemperU.S. Army Program Executive Office for Simulation, Training, and Instrumentation (PEO STRI) 12350 Research ParkwayOrlando, FL. 32826 USA(407) 384-3816 (phone), (407) 384-3611 (fax) HYPERLINK "mailto:brian.e.kemper@us.army.mil" brian.e.kemper@us.army.milABSTRACT: Distributed Interactive Simulation (DIS) is an infrastructure that promotes interoperability amongst various training systems.  DIS, together with the enumerations document, does not provide a satisfactory or comprehensive solution for implementing lifeforms in either the virtual or constructive simulation domains. The U.S. Army Program Executive Office for Simulation, Training, and Instrumentation (PEO STRI) Project Manager Combined Arms Tactical Trainer (PM CATT) initiated the Synthetic Environment (SE) Core Architecture & Integration (A&I) program.  This contract is tasked with developing a Virtual Simulation Architecture (VSA) with the goal of providing the Warfighter with enhanced training by increasing interoperability between training systems, increasing the reuse of products developed for training systems, protecting the investments made in developing current virtual training simulations, and increasing the adaptability and extensibility of the virtual training simulations that are developed to enable the easy incorporation of new features.  A large segment of the PM CATT virtual domain programs uses DIS, so this standard is important in legacy, current, and future training systems. Establishing a single flavor of DIS that will be used by the training and simulation programs under PM CATT and then communicating the desired changes to the standards community at the Institute of Electrical and Electronics Engineers (IEEE) and the Simulation Interoperability Standards Organization (SISO) is one of the initiatives contributing to resolving the interoperability issues within the U.S Army virtual domain. This paper details the SE Core VSA solution for lifeforms as defined in VSA DIS (V-DIS).  We describe how an exemplary training system would evolve to meet this specification.  We tackle the main aspects of lifeform requirements, including enumerations, weapons, entity associations, action sequences, head gazing, and weapon aiming.IntroductionDistributed Interactive Simulation (DIS) is an infrastructure that promotes interoperability amongst various training systems, whether they belong to the same vendor or not.  It links multiple types of simulations from the constructive, live, and virtual domains, and across different types of networks.The U.S. Army Program Executive Office Simulation Training & Instrumentation (PEO STRI) Synthetic Environment (SE) Core program is supporting the Training of our Warfighters by providing a common virtual environment (CVE) that links system and non-system simulations into a fully integrated and interoperable training capability. The SE Core concept includes the development of a Virtual Simulation Architecture (VSA) responsible for providing the Warfighter with enhanced training by increasing interoperability between training systems, increasing the reuse of products developed for those training systems, protecting the investments made in developing current virtual training simulations, and increasing the adaptability and extensibility of the virtual training simulations that are developed to enable the easy incorporation of new features.Through the development and application of the VSA architecture framework, standards, and common products, SE Core is supporting the overarching objective that we "train the way we fight," training in a way that helps ensure mission performance in the contemporary operating environment (COE).  SE Core components will support virtual simulations at home station, Combat Training Centers (CTC), en route to and at deployed locations for training or wartime mission planning and rehearsals. SE Core is applying an incremental building block approach to the identification and development of key capabilities that represent the highest contributors to the achievement of interoperability and ultimately fair fight in support of combined arms training.  The result of force structure changes combined with the reality of current operations has yielded an environment where the level at which the Army needs combined arms training is now at a much lower echelon (platoon and company level). In order to provide effective combined arms simulation training at this level, virtual training system interoperability and fair fight must be achieved. Some of the key SE Core capabilities that represent the highest contributors to the achievement of interoperability and ultimately fair fight in support of combined arms training include common communication protocols, common Semi Automated Forces (SAF), common environment, common databases, common visual models, common sensor models, and common digital communications. SE Core mission is consistent with the overarching objective to provide the ability to train the effects of the full spectrum of the combined arms force even when only selected elements of the force are available for training.  This enables repetitive training in a realistic, stress-producing Live Virtual Constructive-Training Environment (LVC-TE), easily tailored to meet mission-specific training and rehearsal needs for active and reserve components A large segment of the Project Manager Combined Arms Tactical Trainer (PM CATT) virtual domain programs uses DIS; as such, the evolution of this standard is a key component to the improvement of interoperability in legacy, current, and future training systems. An example of this improvement is the simulation of lifeforms.The current Lifeforms enumeration scheme in the DIS specification does not provide enough characteristics to accurately describe lifeforms for present training systems.  The SE Core DIS specification for the VSA (V-DIS) proposes a lifeforms scheme based on the work originally presented by Hill  REF _Ref188869904 \r \h [6] (and in more detail, in a Simulation Interoperability Standards Organization (SISO) enumerations Change Request, co-authored by Richard Byrd, dated 18 November 2006) that includes the missing characteristics.  This schema supports higher fidelity lifeform entities while remaining backward compatible with existing DIS lifeform enumerations (e.g. categories 0-5 for the land domain).  Interoperability between the old and new lifeform schemes can be achieved using a straightforward gateway approach.This schema will not only support humans and animals, but also plants and microbes.  Note that we are not suggesting that millions of trees start getting heartbeated.  But, with higher fidelity simulations, things like trees, plants, and even microbes (natural or weaponized) will need an Entity Type identifier so that interaction can occur with them (e.g. an IED affixed to a plant, a biological agent on an envelope, a person tied to a tree, etc.).  Providing this flexibility for future needs while solving our immediate problems is consistent with the V-DIS strategy.Lifeform entities will be assigned to the domain that is their natural habitat, not their current location.  For humans, this is the Land domain.  Human paratroopers, for example, are not placed within the Air domain. Humans are also subdivided into military and civilian, animals and plants into domesticated and wild, and so forth as detailed in the following sections.  Note that we will also present a recommendation on present domain to denote when a lifeform (or other entity) moves from one domain into another.Goals of the SpecificationIn developing the V-DIS lifeform schema, there are several key driving design goals. V-DIS must support all current and known future PM CATT lifeform requirements.V-DIS must provide an evolutionary path for migrating existing simulations to the V-DIS lifeform specification.V-DIS must leave room for future expansion.V-DIS should be sellable to the DIS community at large. V-DIS should leverage existing DIS improvements from both the standards community and from within the V-DIS program domain. V-DIS value-added specifications are intended to be rolled into the DIS standards; not to be a one-off solution for PM CATT.V-DIS must be able to be implemented within the PM CATT simulation systems. The network and processing demands must not exceed available legacy simulation infrastructure. The complexity of decoding must not be excessive.Enumerations OverviewThe category and subcategory fields consist of grouping similar lifeforms, either based on established classification systems or simplified schemes.  A reasonable classification scheme is necessary to support the V-DIS goals outlined above; in particular, to support future expansion.  In general, where multiple Subcategory groups are needed for a single Category entry, we block out a range of numbers for that group.   REF _Ref188768847 \h Table 1.1 shows how the category field is utilized as the top level partitioning for the lifeforms in the land domain.  Note how the categories are blocked off by number.  For brevity, the entire table is not provided.Table  STYLEREF 1 \s 1. SEQ Table \* ARABIC \s 1 1 Lifeforms Category for the Land Domain06-79 Humans06-39 – Military personnel06-24 – Regular Forces06 – Military, general, 07 – Army, …<additional values skipped>25 – 39 Irregular Forces25 – Paramilitary, 26 – Militia, …<additional values skipped>40-79 – Civilian personnel41 – General, 42 – Management…<Additional values skipped> 80-199 – Animals80-139 – Domesticated080 – Alligator (captive)…<additional values skipped>140-199 – Wild140-165 – Mammals140 – General, 141 – Aardvarks…<additional values skipped><additional values skipped>200-249 – Plants200-229 – Domesticated230-239 – Wild240-249 – Trees250-255 – MicrobesThe V-DIS schema also allows additional permanent attributes such as sex and age to be specified within the entity type, as will be detailed in the following sections, depending on the category. Because there are more attributes desired than can fit into the remaining three Entity Type fields (Subcategory, Specific and Extra), several have been combined using an encoding scheme.  Note that using these fields as bit-fields does not restrict their usage as enumerations.  Programmatically-speaking, you can enumerate all possibilities (or those you are interested in and map the others) for septuple-matching or whatever method you desire to use.  REF _Ref188768857 \h Table 1.3 shows an overview of how these additional, key attributes are mapped into the three fields (and also the meaning of the category field). As with the existing DIS Entity Type structure, this allows the lower level of fidelity training systems to ignore some or all of the extended characteristics.Table  STYLEREF 1 \s 1. SEQ Table \* ARABIC \s 1 3 Mapping into Entity Type FieldsFieldHumanAnimalPlantCATOrganization or FieldClassificationClassificationSCATRank or Title(Sub)SpeciesType or SpeciesSpecificSex, Age, WeightSex, Age, Color(Sub)SpeciesExtraRace, SkinWeight, Group, CapabilityHealth, Group, Life Cycle, LeavesThe Lifeform Entity Appearance Record is used to provide additional attributes such as clothing, which may dynamically change during the course of an exercise.  This record is intended primarily for humans, but similar records could be designed for other lifeforms as the need arises.Human LifeformsThis section provides a more detailed view of the partitioning and usage of the Entity Types fields for human lifeforms. An overview of the assignment of fields for Human lifeforms is as follows.  The Kind shall be 3 (Lifeform) and the Domain shall be 1 (Land) for humans.Country. The country code is typically a human’s country of citizenship (but may be used to identify military rank, should the citizenship differ from the military organization). If a human has multiple citizenships, then the one that might pertain to the rank or some other attribute should be used.  If this still creates a conflict or ambiguity, then a special VP record should be used.Category.  The category field represents the basic military organization or civilian industry.  For civilians, the major job categories are based on the U.S. Department of Labor Standard Occupational Classification (SOC) guide, which covers almost any conceivable job in a developed or developing country.  This guide was chosen for its extensive list of jobs as well as its online access, which makes it easy to find the jobs associated with a specific major industrial category.Subcategory. The subcategory field represents rank for military personnel and a specific job title (specialty) for civilian personnel.  Job titles and rank support proper selection of a visual model and might also affect behaviors. The military rank schema supports two types of rank designations.  A Common rank is common to many countries and cultures, while a Country type is unique for that specific country.  The most significant bit (7) of the Subcategory field denotes whether the rank is a Common Military Rank (0) or Country Specific (1),.  Thus, common military ranks range in value from 0-127, and country-specific ranks range in value from 128-255.Civilian categories use the Subcategory to define a specific job classification or specialty. A civilian job Subcategory includes common job descriptions and may also include specific Standard Occupational Classification (SOC) job descriptions. When a specific SOC job description is listed, the SOC reference number is included (e.g., Derrick Operator SOC 47-5011).  Low technology civilian occupations in developing countries will need to be added as they are determined.Specific.  The Specific field indicates sex, age, and weight by age. The General Age Group attribute is merely to allow a general age designation or to identify whether the lifeform is a little person (as identified by the Little People of America).  The Weight by Age attribute is to allow variations in the appearance of a human, based on weight.  It is a simplified version of the World Health Organization (WHO) classification system, which should be consulted if the precise weight range is needed for each value.Weight by Age. This attributes indicates the weight by age of the human.  The weight by age is defined as an enumeration across bits 5-7 of the Specific field, providing a possible eight enumeration values. The value for 0 will be reserved for “Not specified.” General Age Group. This attribute identifies the age of the person in a general grouping, such as newborn, teenager, and adult. The general age group is defined as an enumeration across bits 1-4 of the Specific field, providing a possible 16 enumeration values.  The value for 0 will be reserved for “Not specified.”Sex.  This attribute indicates the person’s gender as either Male or Female.  There is no option for unspecified. The Sex is defined in the least significant bit (0) because it is the one most common value that needs to be set within this field.Extra.  The Extra field indicates race/ethnicity and skin color. Variable Parameter and Entity Appearance records may be used to provide more detailed information.Skin Color. Although specifying the race/ethnicity provides a pretty good idea what skin color a particular person is, various countries have natives with skin color ranging from fairly light to very dark.  The Skin Color is defined in the most significant nibble (bits 4-7) of the Extra field, providing an enumeration of 16 values.  An enumeration value of 0 is “Not specified” and values of 1-15 denote the color from darker (lower value) to lighter (higher value, similar to intensity levels).General Race/Ethnicity.  A condensed set of race/ethnicity choices are included.  The intent of this attribute is to assist in picking an appropriate visual model for a human entity or to identify race/ethnicity for specific behavioral modeling. The categories used are based primarily on the U.S. Office of Management and Budget.  The General Race/Ethnicity is defined in the least significant nibble (bits 0-3) of the Extra field, providing an enumeration of 16 values.  The value for 0 will be reserved for “Not specified.” General Race/Ethnicity will also include the following two values (in addition to other, specific races/ethnicities):Homogenous Country Code. The person represents the typical physical appearance of someone from a country that has a homogenous racial/ethnic appearance (e.g., Chinese, Japanese, etc.)Indigenous Country Code. This represents an indigenous person from a country that has only one indigenous group appearance (e.g., Aboriginals in Australia).Here we present an example enumeration.  The following is a male Iraqi captain: Kind: 3 (lifeform); Domain: 1 (land); Country: 102 (Iraq); Category: 7 (Army regular forces); Subcategory: 5 (Captain, common rank); Specific: 0 (unspecified weight and age, male); Extra: 8 (unspecified skin color, homogenous ethnicity).Extended Lifeform Appearance VP RecordThere are still relevant data not captured within the proposed entity type changes for lifeforms.  At SE Core, we’ve recognized several parameters required for several PM CATT training systems that are certainly not currently in DIS and don’t even fit well within an entity type schema.  To solve this issue, we’ve designed a VP record as shown below.Record Type. This field shall identify the record as an Extended Lifeform Appearance VP record. It shall be represented by an 8-bit enumeration.Clothing Scheme. This field describes the clothing scheme for the lifeform.  It shall be represented by an 8-bit enumeration.  In a two-part clothing scheme, Primary is the top and Secondary is the bottom, where applicable.Clothing Decal Scheme. This field describes the decals for the lifeform.  It shall be represented by a 16-bit enumeration.Primary Condition/Material.  This field consists of four subfields: Head hair (2-bit enumeration), Material (the type of material for the primary or top clothing, 2-bit enumeration), Exterior damage (the condition in terms of damage of the primary clothing, but if topless, this could signify scarring or perhaps amputation, 2-bit enumeration), and Clean (the cleanliness of the primary clothing, or perhaps of the lifeform in general, 2-bit enumeration).Primary Color. Specifies the color scheme if the Clothing Scheme is set to Solid Color (1).  It will specify the color scheme of the first tone in a two-tone clothing scheme.  Otherwise, the Primary Color should be set to a closest match value in the case where the clothing scheme is not recognized.  For example, this may contain a value for light brown for a sand camouflage clothing scheme.  It shall be represented by an 8-bit enumeration.Secondary Condition/Material.  This field consists of four subfields: Facial hair (2-bit enumeration), Material (the type of material for the secondary or bottom clothing, 2-bit enumeration), Exterior damage (the condition in terms of damage of the secondary clothing, but if bottomless, this could signify scarring or perhaps amputation, 2-bit enumeration), and Clean (the cleanliness of the secondary clothing, 2-bit enumeration).Secondary Color. Specifies the color scheme of the second tone in a two-tone clothing scheme.  It shall be represented by an 8-bit enumeration.Extended Equipment. This 32-bit record of Boolean types defines the additional equipment that is visibly deployed by the lifeform.Status.  This field consists of three subfields: Invincible (1-bit enumeration), Disguise (how well the lifeform is disguised, 3-bit enumeration), and Present Domain (current domain, including a specific sub-domain, 4-bit enumeration). Weapons.Primary Weapon. This field defines the primary weapon held and at the ready, if any.  The numbering scheme of the weapons possessed should be from 1 to 15, based on their order within the Attached Parts list.  A value of 0 means no weapon ready.  This field will denote which weapon is affected by the Head Gazing / Weapon Aiming VP record.  It shall be represented by a 4-bit unsigned integer.Number of Weapons. This field specifies the number of weapons possessed by the lifeform.  Not all weapons will be specified as Attached Parts, so other entities desiring more information may use this field to determine if more information is required (e.g. for looting a body). It shall be represented by a 4-bit unsigned integer.Unique ID. This defines the lifeform uniquely.  This will be an enumeration of people identified by name or position.  In some cases, they will be the same, but eventually the placeholder for position will change.  For example, George W. Bush will not be the U.S. president forever, so there will be an enumeration for both George W. Bush and the U.S. president.  Not all positions should be enumerated, however.Table  STYLEREF 1 \s 2. SEQ Table \* ARABIC \s 1 1 Extended Lifeform Appearance VP RecordFieldTypeRecord Type8-bit enumerationClothing Scheme8-bit enumerationClothing Decal Scheme16-bit enumerationPrimary Condition / Mtl8-bitsPrimary Color8-bit enumerationSecondary Condition / Mtl8-bitsSecondary Color8-bit enumerationExtended Equipment32-bit record of BooleansStatus8-bitsWeapons8-bitsUnique ID16-bit enumerationWeaponsA new kind was proposed to the SISO enumerations group to categorize Portable Weapons. These are weapons that are capable of being carried or moved by humans.  This kind includes small arms such as rifles, pistols, machine guns, sub-machine guns, weapon launchers (e.g., missile, grenade and rocket), flare pistols, hand-held directed energy and other lethal or non-lethal weapons.  Portable weapons, when not standalone entities, may be attached to a lifeform, platform or other kind of entity. This is indicated by their inclusion as an Attached Parts VP record for the applicable Entity State planned view display (PDU). Portable weapons are usually weapons that are held in the hand when fired. The enumeration for this kind was proposed as 10.  For further details on this proposal, please refer to the Change Request submitted by Frank Hill and Richard Byrd.Head Gazing / Weapon AimingHead gazing and weapon aiming provide a difficult challenge for interoperability.  The most obvious solution to simulate where a lifeform is looking and aiming its weapon (if any) would be to use articulated parts.  Using articulated parts has problems, however, that can be overcome with an alternate solution.  First, the cost associated with articulated parts is 16 bytes per articulation parameter.  At a basic level, the head will likely need to be animated with two degrees of freedom, similar to a tank’s turret and main gun.  The neck can, of course, also tilt side to side, but that movement is likely not necessary for current exercises.  These two degrees of freedom therefore cost a total of 32 bytes.  If you consider that a weapon could be aimed with the same number of degrees of freedom, then that would be another 32 bytes.  The second problem is the latency of the head gazing / weapon aiming.  It is most likely a critical element within the exercise to realize if and when a potential enemy is tracking you.  For the same reason the Designator PDU has a target, head gazing and weapon aiming should also have a target.  Dead Reckoning of articulated parts would require more parameters and thus more bandwidth.  Although not a problem in itself, a third situation arises, depending on the implementation of action sequences.  If articulated parts are not used for detailed action sequences, then using articulated parts for head gazing / weapon aiming would create a conflict.The alternate solution is to provide a similar mechanism to the Designator PDU: identify the entity and/or object being tracked.  For that purpose, we propose the following Head Gazing / Weapon Aiming VP record.  This VP record shall only be issued when necessary.  If not transmitted in the Entity State or Entity State Update PDU, then the head gazing / weapon aiming parameters revert back to their default states (most likely of the visual model).  This VP record need not be transmitted if the parameter would conflict with a Lifeform Action Sequence VP record.  If both are transmitted and a conflict is identified, then the Lifeform Action Sequence VP record takes precedence. Record Type. This field shall identify the record as a Head Gazing / Weapon Aiming VP record. It shall be represented by an 8-bit enumeration.Head Gazing Type. This field shall identify where the head is gazing (direction, station, or entity/object). It shall be represented by an 8-bit enumeration.Weapon Aiming Type. This field shall identify where the weapon is aiming (direction, station, or entity/object). It shall be represented by an 8-bit enumeration.Out Station ID. This field shall specify the station ID that the head is gazing out of (or through) and/or that the weapon is aiming out of (or through).  For example, you would identify a particular window on a vehicle by station ID, if the lifeform were aiming his weapon out that window. It shall be represented by a 16-bit unsigned integer.Tracked Station ID. This field shall specify the station ID on the tracked entity/object.  This provides a higher level of detail for tracking than just the entity/object, but less than global position.  This field could be used to have a lifeform watching a particular doorway on a building or maybe the cockpit on an aircraft, for example.  It shall be represented by a 16-bit unsigned integer.Tracked Entity/Object ID. This field shall identify the entity using an Entity Identifier record (see section 6.2.29 of Draft 13) or object using an Object Identifier record (see section 6.2.66 of Draft 13).  Whether the target is an entity or object is denoted by the Head Gazing Type and/or Weapon Aiming Type.  The two types shall not conflict.Table  STYLEREF 1 \s 2. SEQ Table \* ARABIC \s 1 2 Head Gazing / Weapon Aiming VP RecordFieldTypeRecord Type8-bit enumerationHead Gazing Type8-bit enumerationWeapon Aiming Type8-bit enumerationPadding8-bits unusedOut Station ID16-bit unsigned integerTracked Station ID16-bit unsigned integerTracked Entity/Object ID48-bit record of enumerationsPadding16-bits unusedWhen the Head Gazing Type or Weapon Aiming Type indicates a tracked condition, the Tracked Entity/Object ID is tracked by the head gaze or the aiming of the weapon.  Both Head Gazing Type and Weapon Aiming Type use the same enumeration values.  It is the responsibility of the receiving simulation application to properly reposition the head / weapon to “point at” the correct entity / object.  Enumeration values of Down, Up, Straight Ahead, Left, and Right provide general locations when the other options are not used.  A specific, global location (such as a terrain position) can also be specified, but a World Coordinates record (see section 6.2.97 of Draft 13) would need to be provided in a subsequent VP record or Attribute PDU (due to the size of a World Coordinates record).The lifeform entity could be gazing out a particular station, as identified in the Out Station ID.  This station ID will be associated with the entity (via an Entity Association VP record) and must be the same for both the head gazing and weapon gazing (though only if both identify an out station).  Similarly, the lifeform could be tracking a particular station on the tracked entity or object.  This station is identified by the Tracked Station ID and must be the same for both head gazing and weapon aiming (if both are tracking).Animal LifeformsThe assignment of entity type fields for Animal lifeforms is defined in this section.  An animal should only be listed once, even though it could fit under several categories. Kind shall be 3 (Lifeform).  The Domain is the primary habitat, although for birds it shall be 2 (Air).  Country shall be 0 because animals do not have a defined country.Category.  The category field represents the basic classification of an animal.  For further information on the zoological classification used within V-DIS, please refer to the submitted CR or to the V-DIS 1.0 Specification.Subcategory. The Subcategory field is used to indicate a species or subspecies.Specific. The Specific field is used to represent the sex, age, and color of the animal.Sex.  This attribute indicates the animal’s gender as either Male or Female.  There is no option for unspecified. The Sex is defined in the most significant bit (7).  Unlike with humans, the gender will not usually be pertinent.General Age Group. This attribute identifies the age of the animal in a general grouping, such as newborn, young, and mature. The general age is defined as an enumeration across bits 4-6 of the Specific field, providing a possible eight enumeration values.  The value for 0 will be reserved for “Not specified.”Color. This attribute indicates the general color of the animal.  A few general colors like black, brown, and white will be provided as well as an option for “Based on species/breed (when only one color and pattern exists for an animal).” The color is defined as an enumeration across bits 0-3 of the Specific field, providing a possible 16 enumeration values. The value for 0 will be reserved for “Not specified.”Extra. The Extra field is used to represent weight, group, and capability.Weight.  This attribute indicates the general weight of the animal. The weight is defined as an enumeration across bits 6-7 of the Extra field, providing a possible four enumeration values. The value for 0 will be reserved for “Not specified/Normal.”Capability.  This attribute is used to indicate any special capabilities of an animal.  The capability values depend on the type of animal.  An example is a dog trained to detect explosives. The capability is defined as an enumeration across bits 3-5 of the Extra field, providing a possible eight enumeration values. The value for 0 will be reserved for “Not Specified.”Group.  This attribute indicates if the entity represents more than one animal.  This is a special case that should only be used where there are large numbers of animals in a group that need to be seen visually or be detected by a sensor, no physical interaction with other entities will occur, and use of the Aggregate State PDU is not feasible.  Additional parameters in a VP record may be needed to define the exact quantity being represented, their distribution, and other characteristics needed to support accurate visualization and sensor detection.  Examples include flocks of birds, schools of fish, and herds of animals.  The group is defined as an enumeration across bits 0-2 of the Extra field, providing a possible eight enumeration values. The value for 0 will be reserved for “Single Entity.”PlantsThe assignment of entity type fields for Plant lifeforms is defined in this section.  Kind shall be 3 (Lifeform).  The Domain is the primary habitat.  Although no plants exist in the Air domain, that domain could be used for non-aquatic epiphytes (those living primarily on other plants, like Spanish moss).  Country shall be 0.Category.  The category field represents the basic species of a plant.  For further information on the zoological classification used within V-DIS, please refer to the submitted CR or to the V-DIS 1.0 Specification.Subcategory. The Subcategory field is used to indicate the plant type or species.Specific. The Specific field is used to indicate the plant species or subspecies.Extra. The Extra field used to represent a plant’s health, group, life cycle, and status of its leaves.Health.  This attribute indicates the general health of the plant. The health is defined by the most significant bit (7) of the Extra field.  This is a low-fidelity implementation for health, so if more detailed information be required, a VP record should be used.Life Cycle. This attribute indicates the general age of the plant, based on its type or species. The life cycle is defined as an enumeration across bits 5-6 of the Extra field, providing a possible four enumeration values. The value for 0 will be reserved for “Not Specified.”Leaves. This attribute indicates the status of any leaves on the plant. This attribute is defined as an enumeration across bits 3-4 of the Extra field, providing a possible four enumeration values. The value for 0 will be reserved for “Not Specified.” Group. This attribute indicates if the entity represents more than one plant.  The group is defined as an enumeration across bits 0-2 of the Extra field, providing a possible eight enumeration values. The value for 0 will be reserved for “Single Entity.”MicrobesMicrobes are microscopic, living orgasms and include viruses and bacteria.  Microbes are included as an entity type primarily to support simulating contact with infectious agents, either natural ones or biological warfare variants.  The assignment of fields for Microbe lifeforms is defined in this section. .  Kind shall be 3 (Lifeform).  The Domain is where it is initially created and primarily exists (not how it may be transmitted).  Country shall be 0Category.  The category field represents the class of microbe.Subcategory. The Subcategory field is used to indicate a specific type of microbe.Specific & Extra. The Specific and Extra fields are presently undefined for microbes.Action SequencesAnother difficult challenge for simulating lifeforms is action sequences.  These are single, functional sequences, such as getting into a vehicle, standing up, walking, or even vomiting.  (Vomiting has a recognized real training benefit, since it helps students recognize the potential presence of nuclear, biological, chemical agents.)  In a pure sense, these could be represented by many articulated parts, but the obvious problem with that is the sheer number of parts and articulated parameters for each.  This may put serious pressure on the network, not to mention the size of the Entity State PDU if fully populated.  A quick estimate of potential requirements for the number of articulated parameters: head (3 – rotate, bend, tilt), hands (6 – rotate, bend, and open), arms (8 – shoulder bend, lift, and rotate, elbow), torso (2 – twist and bend), legs (6 – leg lift and bend, knee), and feet (2 – lift).  That equals 27 articulated parts and does not include if you also want to articulate each finger separately or model the location of the eyes, tongue, toes, or any facial expressions (which has been recognized to be important  REF _Ref188945202 \r \h [8]).The method that is probably best in terms of storage is to use an enumeration scheme.  Enumerate all the actions or positions that lifeforms can perform, and then identify which one(s) are being used by the entities.  By enumerating action sequences rather than articulating limbs, it will leave the level of fidelity up to the receiving application.  A high-fidelity simulation could become very detailed and realistic, while a low-fidelity simulation might simply cause a human to switch states (e.g. prone to standing).In an effort to support these actions sequences, we propose the following Lifeform Action Sequence VP record. This VP record is a type of animation control; though how the animation sequence is performed by the receiving application is not defined (it could be implemented in the image generator (IG) or the host or not at all, depending on various factors including level of fidelity of the simulation).  The loop mode, direction, and state all help identify the type of animation.  Loop mode does not change through the life of the action sequence, though direction might.  This VP record shall only be transmitted during an actual action sequence (just prior to start, during, and just after termination) or for as long as any high-fidelity information (e.g. body position) is required.Record Type. This field shall identify the record as a Lifeform Action Sequence VP record. It shall be represented by an 8-bit enumeration.Action Control.Loop Mode. This field identifies if the animation of the action sequence should repeat (continuous) or run and then terminate (one shot).  It shall be represented by a 1-bit enumeration.Animation Direction. This field identifies the direction of the animation (forward or reverse). It shall be represented by a 1-bit enumeration.Animation State. This field commands the animation to start, stop, pause, or resume. It shall be represented by a 2-bit enumeration.Action Direction. This field identifies the direction of the action sequence (not the animation playback). It shall be represented by a 4-bit enumeration.Action Sequence Type.  This field identifies the action sequence.  It shall be represented by a 16-bit enumeration.Body Position Type.  This field identifies the current body position of the lifeform.  This field could be used in a lower fidelity model (which does not support complex or detailed action sequences) or perhaps to ensure synchronicity on the animation playback.  It shall be represented by a 16-bit enumeration.Number of Frames.  This field identifies the total number of expected frames in the animation action sequence.  It could be explicitly defined by exercise agreement, in the scenario file, or be used for a general status with respect to the total current Frame Count. It shall be represented by an 8-bit unsigned integer.Frame Count. This field identifies the current frame in the animation action sequence.  If the animation sequence is not identical across different simulation applications, then this field could still be used as a general status with respect to the total Number of Frames. It shall be represented by an 8-bit unsigned integer.Target Station ID. This field identifies the station ID associated with the given Action Sequence Type (not Body Position Type).  For example, this could define the door through which a lifeform exits a vehicle. This is used in conjunction with the Entity/Object ID. It shall be represented by a 16-bit unsigned integer.Entity/Object ID. This field identifies the entity or object associated with the given Action Sequence Type.  For example, this could identify the vehicle that a lifeform is attempting to enter.  The Action Sequence Type will identify if this field refers to an Entity Identifier record or an Object Identifier record.Table  STYLEREF 1 \s 6. SEQ Table \* ARABIC \s 1 1 Lifeform Action Sequence VP RecordFieldTypeRecord Type8-bit enumerationAction ControlLoop Mode, 1-bit (0=one shot, 1=continuous)Animation Direction, 1-bit (0=forward, 1=reverse)Animation State, 2-bit (0=Stop, 1=Pause, 2=Start, 3=Resume)Action Direction, 4-bitsAction Sequence Type16-bit enumerationBody Position Type16-bit enumerationNumber of Frames8-bit unsigned integerFrame Count8-bit unsigned integerTarget Station ID16-bit unsigned integerEntity/Object ID48-bit record of enumerationsMultiple action sequences could be operating at the same time for one entity (e.g. walking and chewing gum).  The Body Position Type can be used to identify the current body position.  If the Action Sequence is implemented by the receiving application, and a sequence is currently running, then the Body Position Type should be ignored.  This field provides a means for low-fidelity simulation to use this record for both sending and receiving (higher complexity positions perhaps without the higher complexity animations).  The Number of Frames identifies the expected number of frames of the action sequence and most likely will be something designed in a common scenario file or external means (e.g. same vendor).  Even if the total number of frames received is not identical, or if there is reason to believe that the originating entity animation is not similar, this field can still be used as a percentage adjustment when also given the Frame Count. Example Action Sequence Types include Standing Up, Falling Down, Crawling, Walking, etc.Mounting / TowingLifeforms will need to be mounted on other entities (typically platforms), such as dismounted infantry climbing aboard a Bradley or a rider getting on a donkey.  To support mounting, we will adopt the proposed Entity Association VP record as given in Draft 13.  Both entities involved in the association (physical or behavioral) create this record within their Entity State PDU and discontinue them once the association is over (after a final identifier of dissociation within the record).Towing, including something like sling loads, will be accomplished using the same mechanism.  The difference between the two is that the fields in the Entity Association VP record identify the connection as either towed or mounted, or maybe even something else altogether.   REF _Ref188946258 \h Table 7.1 provides a revised enumeration on the Entity Association Status.  The “Target” is the entity/object being acted upon (the one being towed, carrying or mounting) and the “Carrier” is the entity/object doing the towing, carrying, or acting.  In cases of mutual physical association, both may be the target or carrier.Table  STYLEREF 1 \s 7. SEQ Table \* ARABIC \s 1 1 Entity Association StatusValueDescription0Not Specified1Physical Association Target2Non Physical Association3Association Broken4Physical Association CarrierWe’ve also revised the enumeration for the physical association type to be more consistent and to include values for indoors and roof-level mounting (on a high-resolution or destructible building).   REF _Ref188946471 \h Table 7.3 details the proposed enumeration.Table  STYLEREF 1 \s 7. SEQ Table \* ARABIC \s 1 3 Physical Association TypeValueDescription0Not Specified1-29Towed / Mounted1Towed in Air2Towed on Land3Towed on Water Surface4Towed Underwater5Mounted Attached6Mounted Unattached and Unsupported7Mounted Unattached and Supported30-59Restraint30Restrained to a Lifeform31Restrained to a Platform32Restrained to an Object60-89Missions60Unspecified Mission61Refueling Operation62Search and Rescue Basket63Search and Rescue, Rescue Collar64Engagement/Object 2 is Being Engaged65Return To Base/Object 2 is the Destination Object90-119Other Associations90Line between Communication Towers91Line Between Power Towers92Indoors93RoofThis scheme for mounting / towing does not account for an offset of the entity, however.  For example, one vehicle can tow another using a solid connection or a line.  If solid, then the offset will be static, but if it is a line (cable of some sort), then the offset will be dynamic, and it should not be the responsibility of receiving applications to perform the calculations of the position.  Also, the reason that the Entity Association VP record is needed in the first place negates using the position of the towed entity (dead reckoning hiccups, bungee-like positioning and orientation, etc.).What is really needed is an offset.  Therefore, we simply propose an Entity Offset VP record as given below.  This offset need not always be used for towing / mounting.  For these records, we refer to the entity that is carrying or towing the other entity as the carrier.  The entity that is being towed or carried is the mounted entity.  Both the carrier and the mounted entity can produce this record.  If the carrier produces it, then the Offset Type (see  REF _Ref188947188 \h Table 7.5) in the carrier’s Entity Offset VP record should be set to Modified by Carrier (the given offset is added to the mounted entity’s offset / position) or Station Location (the given offset is the station’s offset from the carrier’s origin).  If the mounted entity produces this VP record, then it should use Carrier Origin (the default value for the Entity Coordinate Vector record) or Station Location (and then the station offset from the carrier’s origin needs to be defined either in a scenario file, the carrier’s Entity Offset VP record, or somewhere else).  Carrier Origin is the normal function of the Entity Coordinate Vector Record, an offset from the origin of the carrier entity.  Station Location would indicate an offset from the position of the given station on the carrier instead of the origin of the carrier.  Note that the carrier can define the station location offset with an Entity Offset VP record.Table  STYLEREF 1 \s 7. SEQ Table \* ARABIC \s 1 5 Offset Type EnumerationValueDescription0Carrier Origin1Station Location2Modified by CarrierRecord Type. This field shall identify the record as an Entity Offset VP record. It shall be represented by an 8-bit enumeration.Offset Type. This field shall identify additional details about the type of offset, such as whether it is offset from the carrier origin, station location, or modified by the carrier.  It shall be represented by an 8-bit enumeration.Entity Association ID. This field shall identify the ID of the Entity Association VP record to which this offset applies.  The Entity Association ID is the numerical value of the Entity Association VP record within the PDU (similar to the attached/articulated part ID). It shall be represented by an 8-bit unsigned integer. (Although articulated and attached part VP records require a 16-bit unsigned integer for the ID field, no part ID can ever be more than 255, due to the number of possible parts and the numbering scheme.)Mounted Entity Offset. This field shall identify the offset.  It shall be represented by an Entity Coordinate Vector record (see 6.2.95(a) or Draft 13).Table  STYLEREF 1 \s 7. SEQ Table \* ARABIC \s 1 7 Entity Offset VP RecordFieldTypeRecord Type8-bit enumerationOffset Type8-bit enumerationEntity Association ID8-bit unsigned integerPadding8-bits unusedMounted Entity Offset96-bit recordSummaryThe SE Core program is working to improve simulation interoperability across the PEO STRI virtual simulation programs.  We’ve presented a design intended to fully support lifeform interoperability.  Our work has leveraged significantly off previous proposals (lifeform enumerations, portable weapons, Variable Parameter records, etc.), but we have also included a fair amount of original design and have attempted to tie it all together consistently.ReferencesFaulk, Mark, Richard Fuchs, Jeffrey Todd Littlejohn, Brian Kemper. “A Product Line Approach for the Virtual Domain.” 06F-SIW-041, SISO Simulation Interoperability Workshop, Fall 2006.IEEE 1278.1-1995: “IEEE Standard for Distributed Interactive Simulation – Application protocols”.IEEE 1278.1a-1998: “IEEE Standard for Distributed Interactive Simulation – Application protocols”.IEEE 1278.1-200XD13: “IEEE Standard for Distributed Interactive Simulation – Application protocols”.  Draft 13, under review by DIS PDG.Marrou, Lance, Mark Faulk, Terry Tyson, and Brian Kemper. “Enhancing Virtual Simulation Systems Interoperability through V-DIS.”  07F-SIW-076, SISO Simulation Interoperability Workshop, Fall 2007..Hill, Frank. “Distributed Simulation in the 21st Century.” Proceedings of I/ITSEC, 2006.Castleberg, Paul, Philip Colon, and John Berger. “Modeling and Simulation of Sensor Systems to Experiment Against Contemporary Asymmetric Urban Threats.” Proceedings of I/ITSEC, 2006.Marshall, Henry, Pat Garrity, Tim Roberts, and Gary Green.  “Initial Real-World Testing of Dismounted Soldier Embedded Training Technologies.” Proceedings of I/ITSEC, 2007.Author BiographiesLANCE R. MARROU is a senior systems engineer at SAIC in Orlando, Fla.  He is currently a lead in the SE Core Architecture & Integration program, developing V-DIS.  Mr. Marrou received his master’s degree in computer science from the University of Central Florida.  He has been working with simulation and training systems since 1992 and has more than 20 years experience in software and system design.MARK A. FAULK is a senior systems engineer at SAIC in Orlando, Fla.  He is currently the system architect for the Synthetic Environment (SE) Core Architecture & Integration program, developing a virtual domain product line architecture for the Army.  Mr. Faulk received his bachelor’s degree in computer science from the University of Central Florida.  He has over 13 years of experience with simulation and training systems and more than 23 years in software and system design.  Mr. Faulk has been involved with multiple simulation programs including CCTT, VCCT, UK CATT, CTIA, and EST 2000.  He has performed design, development, and consulting in the areas of C4I communications, interoperability (DIS and HLA), user interface, After Action Review, and network communications in the virtual and live domains.STEPHANIE I. B. ENCARNACION is an engineer at SAIC in Orlando, Fla.  She is currently in the SE Core Architecture & Integration program, developing V-DIS.  Mrs. Encarnacion received her bachelor’s degree in computer engineering from the University of Central Florida.  She has been working with simulation and training systems since 2005.BRIAN E. KEMPER is the lead architect for the U.S. Army Program Executive Office for Simulation, Training, and Instrumentation on the SE Core program.  Mr. Kemper received his undergraduate degree in electrical engineering from the University of Central Florida.  Mr. Kemper has 21 years of systems engineering experience in both industry and civil service, supporting DOD military, training and simulation, and NASA design and development initiatives.  HYPERLINK "http://www.bls.gov/soc/soc_majo.htm" www.bls.gov/soc/soc_majo.htm U.S: http://www.defenselink.mil/specials/insignias/ Non-U.S.: http://hemsidor.torget.se/users/k/klix/grader_e.html www.bls.gov/soc/soc_majo.htm http://www.lpaonline.org/ OMB, http://www.whitehouse.gov/omb/