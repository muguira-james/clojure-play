Providing an Improved Real-Time Natural Environmentfor the Navy’s Fleet Battle ExperimentsChristopher G. ScannellJoseph B. CollinsThe Naval Research Laboratory4555 Overlook Avenue, SWWashington, DC 20375202-767-1127, 202-404-7041HYPERLINK "mailto:christopher.scannell@nrl.navy.mil"christopher.scannell@nrl.navy.mil, HYPERLINK "mailto:joseph.collins@nrl.navy.mil"joseph.collins@nrl.navy.milKeywords:Fleet Battle Experiment, synthetic natural environment, HLA, federation, RTIABSTRACT:  A consistent, high fidelity representation of the atmosphere and ocean is a requirement of the Navy's Fleet Battle Experiments (FBEs) in order to achieve the necessary fidelity of behavior of the simulated entities represented in the Joint Semi-Automated Forces (JSAF) federates.  The most significant requirement of this type during FBE-Kilo was to provide a sufficiently high-fidelity ocean environment to the Acoustic Transmission Loss Server (ATLoS) so that it could accurately service acoustic transmission loss requests from JSAF sonar entities.  This paper discusses the architecture used to accomplish this, including the selection of the Navy environmental models used, the manner in which the data from the Navy models were made available to the simulation via Tactical Environmental Data Services (TEDServices), and the manner in which they were published via the Ocean Atmosphere Space Environmental Services (OASES).  Difficulties encountered will be discussed as well as approaches for mitigating these difficulties in future Navy M&S exercises.1.  IntroductionThe Naval Research Laboratory – Washington, DC (NRL-DC) has supported the Navy Warfare Development Command (NWDC) in three Fleet Battle Experiments (FBEs).  Each FBE is conducted by the U.S. Navy with one of the Fleets to develop new doctrine, concepts and tactics and to help evaluate future Navy force structure.  Due to the interactions between real and simulated entities inherent to FBEs, sufficient real-time consistency is required between the natural environment experienced by the simulated forces and by the real forces to prevent undermining the validity of the exercises.  NRL-DC’s Advanced Information Technology branch’s involvement with the FBEs has been focused on providing a synthetic natural environment (SNE) to the simulation of sufficient fidelity to achieve the FBE test and evaluation objectives.  The required level of fidelity depends on a number of factors including the physical environment, the mission and the sensitivity of the sensors (either real or forecast for the future).  Additionally, improved fidelity of the SNE is of no use unless the simulated entities’ behavior takes into consideration the environment, either directly or by means of an environmental effects server.The SNE used in FBE-K (March-April 2003) differed from past FBEs in many ways.  It differed in how it was generated, in how it was delivered to the modeling and simulation network, and in how it was published to the High Level Architecture (HLA) federation.  One of the most significant differences from past FBEs was our attempt to setup the exercise so that the SNE could be managed by a meteorological and oceanographic (METOC) subject matter expert with a minimum of technical support.2.  ArchitectureFigure 2.1 illustrates the manner in which the SNE was provided to and used by the FBE-K simulation.  The environmental data providers, discussed in section 3, ran the Navy environmental models whose model outputs constituted the SNE for FBE-K.  This data was delivered to the modeling and simulation network via a TEDServices gateway.  The OASES Publisher federate [1] published the model data to the HLA federation.  ATLoS used the spatially and temporally varying environmental parameters to field acoustic transmission loss calculation requests made by entities within the JSAF federates [2].  The Integrated Modeling Platform with Agent-Controlled Tasking (IMPACT) federate used atmospheric environmental parameters to model aerosol dispersion using the Gaussian Puff model.  The cloud concentrations are displayed in the JSAF Plan-View-Display and the dosing of individual entities in JSAF are tracked.3.  Navy Environmental ModelsThe data required to construct the SNE was acquired from three primary sources: the Naval Oceanographic Office (NAVOCEANO), the Fleet Numerical Meteorology and Oceanography Center (FNMOC) and the NRL divisions at the Stennis Space Center (NRL-Stennis), specifically the Oceanography Division.The majority of the ocean-related parameters used in FBE-K came from NAVOCEANO, located at the Stennis Space Center in Mississippi.  NAVOCEANO is the principal source of tailored oceanographic support to the joint DOD forces operation in the littoral zone.  NAVOCEANO maintains a suite of standard Navy databases of historic data into which a comprehensive set of non-real-time oceanographic, hydrographic data from in-situ surveys are injected.  NAVOCEANO also processes data from several satellites and manages the Navy’s oceanographic data fusion initiatives.FNMOC, in Monterey, CA, is the principal operational processing center for automated numerical METOC analyses and predictions for the Department of Defense (DOD).  Their global and regional models treat the coupled air-ocean environment as a totally integrated system and pay particular attention to the air-ocean interface.  FNMOC receives global environmental data through links with DOD and the National Oceanic and Atmospheric Administration (NOAA) data-distribution systems.  Their operation products are distributed on Navy and joint command-and-control systems via the Navy theater METOC centers, which then develop value-added products and services tailored to specific military operations in their areas of responsibility.  Their products tend to be run over large areas, such as global models or large regional models, e.g. the Mediterranean.The Oceanographic Division at NRL-Stennis, located in Stennis, MS, is the major center for in-house Navy Research and development in oceanography.  They operate worldwide experimental programs to validate their numerical models.  When their models are sufficiently mature, they are transitioned to NAVOCEANO, to FNMOC or to one of the six Navy regional centers all under the guidance of the Commander, Naval Meteorology and Oceanography (CNMOC).The atmospheric regime was modeled as well as the ocean regime during FBE-K.  The Coupled Ocean Atmosphere Prediction System (COAMPS) is an analysis-nowcast and forecast tool applicable for any given region of the earth [3]. It was developed at NRL-Monterey and is run operationally at FNMOC. COAMPS forecasts parameters up to 48 hours out, at one to three hour increments.  Modeled parameters include precipitation, atmospheric pressure, air temperature, relative humidity, vapor pressure, latent heat flux, sensible heat flux, solar radiation, infrared flux, wind velocity, and wind stress. COAMPS is currently running operationally in a nested configuration, with the outer grid using a 27-km grid spacing and the inner grid a 9-km spacing.The Modular Ocean Data Assimilation System (MODAS) is one of the current Navy standard tools for the production of three dimensional forecast grids of ocean temperature and salinity, and derived quantities such as density, sound speed, mixed layer depth, sonic layer depth, depth excess, deep sound channel axis, and critical depth.  Developed by NRL-Stennis and run by operationally by NAVOCEANO, MODAS was designed to combine observed ocean data with climatological information to produce a quality-controlled, gridded forecast as its output [4].The Navy Coastal Ocean Model (NCOM) was developed at NRL-Stennis. The 1/8° global NCOM is run daily at NAVOCEANO to produce nowcasts and forecasts of the ocean temperature and salinity throughout the water column.  The atmospheric forcing data used is for NCOM is the Navy Operational Global Atmospheric Prediction System (NOGAPS).  The model also assimilates sea surface temperature and synthetic temperature and salinity profiles from the MODAS model.  Lastly, NCOM integrates the sea surface heights from the output of the operational 1/16° global NRL Layered Ocean Model (NLOM) as well as the sea surface temperatures from the output of the 1/8° MODAS two-dimensional nowcasts.In addition to using the outputs of models that predict the atmospheric conditions (COAMPS) and models that predict the temperature and salinity of the ocean volume (MODAS and NCOM), information about the ocean surface was required.  The primary use of this data for FBE-K was to estimate the impact of the surface roughness of the ocean on the transmission of acoustic energy.  The Navy’s Wave Action Model (WAM) is a spectral wave prediction model developed by the WAMDI Group [5] and run operationally by NAVOCEANO.  Typically, WAM produces a directional spectrum of energy density in 25 frequency bins and in 24 15-degree wide directional sectors from which significant wave height, average wave period and average wave direction can be computed [6].  In FBE-K the significant wave height, defined as the average height of the highest one-third of the waves in a particular region, was used to estimate the surface roughness by the ATLOS federate.In section 6.2 we will return to the subject of the environmental data models when we discuss our approach to constructing the SNE for FBE-K.4.  Model Data Delivery  Procuring the model data needed for a simulation can be time-consuming task, particularly if the need (as in FBE-K) is for a reliable delivery of data from an external agency over an extended period of time.  The Navy fleets have a requirement for timely METOC data such as the model data just discussed.  Logically, then, it would be very practical for a DOD simulation to make use of the same model data delivery mechanism used by the operational fleet.Model Data Delivery to the FleetThe centerpiece of the shipboard suite of METOC equipment is the Tactical Environmental Support System (TESS), which provides tailored meteorological, electro-magnetic propagation, oceanographic, acoustic, and satellite products in direct support of Fleet air and surface planning and operations and antisubmarine warfare (ASW) operations.  Specifically, TESS provides the capability to assess the effects of the environment on fleet sensors, platforms and weapons systems.  Data sources include in-situ sensors, geostationary and polar-orbiting satellites, U.S. and foreign weather broadcasts, and three-dimensional weather and oceanic data fields prepared ashore.The Navy Integrated Tactical Environmental Sub-system (NITES) is a modular, open-architecture software sub-system of TESS that is integrated as a segment of theNavyC4I system on board all ships and at all major Navy/Marine Corps commands and staffs, both ashore and afloat.  NITES integrates TESS-derived products into command and control tactical decision aids for use with strategic and tactical computer systems on smaller ships and sites. During FBE-K the ships of the 7th fleet used NITES to receive delivery of METOC model data, such as COAMPS output.  Some of the ships received the data through the Navy’s TEDServices system.  TEDServices, a very recent follow-on to the Navy’s Tactical Environmental Data Server (TEDS), a METOC information storage and management system created under the sponsorship of the Oceanographer of the Navy (N096).  TEDServices was created to replace TEDS and is currently under development.  Each of the ships using TEDServices during FBE-K had installed on-board a TEDServices gateway and a tactical decision aid, such as the latest version of NITES, NITES II Object-Oriented Redesign (OOR).  NITES II OOR and other tactical systems using TEDServices were tightly integrated with the TEDServices gateways and directly accessed their databases through a public application programming interface (API).Model Data Delivery to the M&S NetworkWe, in the modeling and simulation portion of FBE-K, also chose to use TEDServices to receive as much of the METOC data as was possible.  We did not have a TEDServices gateway available to us and our systems were set up to ingest the model data from files, as opposed to making direct calls to a TEDServices gateway.  We were able to access a remote TEDServices gateway at NRL-Stennis via the Secret Internet Protocol Router Network (SIPRNet) using the TEDServices “thin-client”, a java-based application for accessing data in remote TEDServices gateways, developed just in time for our use.Additionally, TEDServices was prescribed by the office of the Oceanographer of the Navy (N096) as the delivery mechanism for NCOM model data for FBE-K.  TEDServices was also a useful source of COAMPS model data.  WAM model data was not available.  We received the WAM data, run by NAVOCEANO, but provided to us through NRL-Stennis.5.  Modifications to Environmental ServerLarge Objects over Connectionless RTINorthrop Grumman Information Technology (NGIT) delivered OASES V1.3 to the Defense Modeling and Simulation Office (DMSO) at the end of February 2003.  Development was performed in the months leading up to FBE-K by NGIT to correct difficulties that prevented OASES from being used in Fleet Battle Experiment – Juliet (FBE-J), which was part of Millennium Challenge 02.  OASES’ subscribers were not successfully receiving large gridded environmental datasets published to the RTI running in connectionless mode.  A successful solution to the problem was designed through the collaborative efforts of NGIT, NWDC and NRL-DC.  The approach chosen was to spatially subdivide the large gridded datasets and publish the segments one at a time.  The implementation of this design was performed by NGIT and incorporated into OASES V1.3.  A description of the problems encountered and techniques used to overcome them is described in another SIW paper [7].Ingestion of 4D Model DataFBE-K was the first Fleet Battle Experiment in which all of the model data was delivered in netCDF format.  Historically, most METOC data had been provided in a format called Gridded Binary (GRIB).  OASES, our environmental data server for the modeling and simulation network, was designed, as its predecessor, the Total Atmosphere Ocean Server (TAOS), to read GRIB.  We, at NRL-DC, first encountered METOC data files in netCDF format when we were using TAOS during FBE-Hotel (August-September 2000).  At that time, we needed to ingest data from the Estuarine Coastal Ocean Model (ECOM) that were in netCDF format [8].  Extensions to TAOS V1.2 were developed by NRL-DC to ingest model data to add this capability.  NGIT further developed this capability and incorporated it into OASES V1.3.At the time of delivery of OASES V1.3, support for 4D model data in netCDF format was limited to model files whose representation of time stamps matched those of ECOM.  At the same time that OASES V1.3 was being finalized, NAVOCEANO was standardizing the format of their netCDF data files across all the Navy environmental models that it runs and also ensuring consistency with the Cooperative Ocean/Atmosphere Research Data Service (COARDS) conventions for the standardization of netCDF files [9].  The two representations of time were sufficiently different that OASES V1.3 was not able to ingest NAVOCEANO netCDF data files.  Fortunately, the TEDServices developers were able to add an additional variable to the netCDF model data files produced by NAVOCEANO prior to making them available for ingestion by OASES.  An ASCII representation of a portion of a sample netCDF file provided by TEDServices developers is shown in Figure 5.1.  The variable “date” is the representation of time that is parseable by OASES V1.3 and the variable “time” is the original representation.netcdf 2DNCOM_SALINITY_1048288794890 {dimensions:	lat = 49 ;	lon = 65 ;	depth = 34 ;	time = UNLIMITED ; // (1 currently)variables:/* snip */	float time(time) ;		time:long_name = "Valid time" ;		time:units = "hour since 2003-01-31 00:00:00" ;		time:time_origin = "2003-01-31 00:00:00" ;		time:FORTRAN_format = "e13.6" ;	int date(time) ;		date:long_name = "Date" ;		date:units = "DateHour" ;/* snip */data:/* snip */ time = 0 ; date = 2003013100 ;}Figure 5.1.  Multiple Time Representations in NetCDF-Formatted Model Data Files.Simultaneously, development was begun at NRL-DC to extend OASES’ capability for reading 4D netCDF model data to include the format used at NAVOCEANO.  This development was successfully completed and tested prior to the start of FBE-K and allowed a greater variety of environmental model data to be ingested and published to the FBE-K federation. OASES could now ingest model output from the Navy’s Wave Model (WAM) produced by NAVOCEANO and provided to us by NRL-Stennis during FBE-K.Efforts to ingest a variety of netCDF data files from a variety of environmental models uncovered some logic errors in the implementation of the OASES  C++ classes NetcdfDecoder, OperationalForecast, and ForecastSequence.  The OASES Ingestor failed to properly ingest netCDF files that contained a single environmental data variable and 4D netCDF files that contained only two time stamps.  Modifications to the OASES source code were made at NRL-DC to correct this behavior.  Additionally, the build procedures for the OASES applications were modified by NRL-DC to facilitate the compilation of the OASES federated applications (Publisher, Time Federate and Subscriber) with the Run Time Infrastructure STOW (RTI-s) chosen by NWDC for FBE-K.Ingestion of COAMPS Model DataThe IMPACT federate required information concerning the SNE, specifically surface air temperature, relative humidity, wind speed and cloud cover, which are available from the COAMPS Model.  They were prepared to use pre-distributed, archival data for this purpose in the event that difficulties were encountered sending these environmental parameters from OASES to IMPACT.  In the last weeks leading up to the FBE-K exercise the decision was made to attempt to publish atmospheric data from OASES to IMPACT.  This was the first time that the attempt was made to publish a SNE covering multiple environmental regimes, both ocean and atmospheric regimes, for an FBE. The COAMPS model data was received from NAVOCEANO via TEDServices as individual 4D netCDF-formatted data files with one parameter per file.  It was possible to ingest individual files owing to the successful extensions made to OASES to support the NAVOCEANO netCDF time representation, but difficulties were encountered when trying to simultaneously ingest COAMPS data files of different environmental parameters.  The ingestion process consists of an analysis phase and an ingestion phase, both of which are separately invoked by the user.  The first phase worked with a heterogeneous mix of COAMPS data files, but the second phase failed.  This type of problem had not been encountered with other OASES input files and the cause of the problem has not been identified.  It was possible to work around this problem by running the OASES Ingestor separately on each group of data files into a single OASES database.Another difficulty encountered during the ingestion of COAMPS model data was the variety of variable names for the z-dimension for different environmental parameters.  The z-dimension was labeled “pressure”, “distance” or “sigma” depending on the parameter.  In some cases the z-dimension was absent.  The implementation of the netCDF decoder in the OASES V1.3 Ingestor uses an ASCII file to identify the mapping of the x, y and z dimensions to netCDF variable names for each model supported by OASES.  We chose to edit this file every time we ingested a COAMPS data file with a different name for the z-dimension.  An alternative would be to create separate models, e.g. COAMPS_sigma or COAMPS_distance.  Perhaps the best solution would be to modify the OASES Ingestor source code so that the user could enter a list of several possible names for the z-dimension in the mapping file and the OASES Ingestor would look for a variable in the netCDF file that matched one from the list. The OASES database that resulted from ingesting the COAMPS data was verified with the OASES visualizer to verify successful ingestion of all the COAMPS data.  The COAMPS data was then published with the OASES Publisher during the exercise with the ocean surface and ocean volume environmental parameters.  Unfortunately, the IMPACT federate did not appear to be receiving the COAMPS data from OASES and reverted to the predistributed, archival atmospheric data they had available.Operation of Environmental Server6.1. OASES Concept MapIn Figure 6.1 we show an OASES concept map which graphically illustrates the relationships between the OASES components and their corresponding configuration files that we used to support FBE-K. At the upper left we show that the source environmental data files must be inserted into a (user named) data directory. This insertion should be supported with OASES’ Live Mode, but we did not try to use that. In order to execute the OASES Ingestor, both the data directory path-name and an OASES database directory path-name (user provided) must be inserted into the OASES Ingestor configuration file. The OASES Ingestor may then be executed to ingest the environmental data into the OASES specific database. In order to then publish the environmental data onto the RTI, the database directory name, a federation configuration file pathname, and a specification of the classes and attributes to be published must all first be inserted into the OASES Publisher configuration file. Upon execution of the OASES Publisher, the OASES Publisher will wait to get a simulation time update from the OASES Time Federate. To start the OASES Time Federate, the names of the database directory federation configuration file names must be placed into the OASES Time Federate configuration file. The version 1.3 of OASES delivered to DMSO has examples of the configuration files, but individual OASES users will generally need to modify most, if not all, of them for their own use.6.2.  FBE-K OASES use caseIn setting up environmental support for FBE-K, we set out to use OASES in conjunction with TEDServices to provide data to ATLOS and IMPACT. To ensure that we could guarantee a minimum level of support, and then work to make discrete improvements, we defined six "levels" of service. Ideally, any of these service levels would be administered by the FBE-K METOC Subject Matter Expert (SME). These service levels were:1) Run ATLoS with MODAS (no OASES);2) Use OASES to serve MODAS data to ATLoS; 3) Use OASES to serve NCOM data, received via ftp from NRL-Stennis, to ATLoS;4) Use OASES to serve NCOM data, received via TEDServices from NRL-Stennis, to ATLoS;5) Use OASES to serve NCOM and WAM data to ATLoS, NCOM having been received via TEDServices, WAM via ftp;6) Use OASES to serve NCOM, WAM, and COAMPS data to ATLoS and IMPACT, NCOM and COAMPS having been received via TEDServices, WAM via ftp.Service level (1) was a backup in the case that we couldn't manage to use either OASES or TEDServices. Prior to 4/22/03 we had levels of service 1-4 established. Prior to the beginning of FBE-K on 4/24/03 we had established level 5, ingesting and publishing with OASES, but were unable to confirm ATLoS using WAM data due to delayed insertion of that capability into ATLoS. By the end of FBE-K, we were able to establish service level 6, as far as ingesting and publishing all data with OASES. We attempted but were unable to confirm IMPACT receiving.Figure 6.1: Concept Map for OASESIn using OASES to serve environmental data FBE-K, we needed to make it possible for the METOC SME operator, in this case a retired Navy METOC officer, to operate OASES. Since our candidate operator was unfamiliar with command line Linux, we built a “Poor-Man’s Graphical User Interface (GUI)”, illustrated in Figure 6.2, to enable him to operate OASES.6.3.  Poor Man’s GUIThe Poor Man’s GUI is made up of icons on the Linux desktop, where each icon is an alias (“shortcut”) representing either a data folder or a short executable script. Since for each mix of data ingested and published by OASES the configuration files are essentially unique, there are three horizontal rows of icons representing the three combinations of data we used: NCOM; NCOM and WAM; NCOM, WAM, and COAMPS. The lowermost row in Figure 6.2 represents the ingesting and publishing of NCOM (or MODAS) data. (Since both the NCOM and MODAS data were received in the same netCDF format, it was possible to ingest and publish them the same way). Before beginning a new round of ingestion and publishing of data, running instances of the OASES Publisher and OASES Time Federate were terminated. Then, going from left to right in Figure 6.2, the received data was first cumulatively stored in an archive folder. On a daily basis a copy of the newest data was placed into a separate folder for ingestion. The existing database created by previous ingests could optionally be purged and the new data then ingested. Running the OASES Visualizer provided a final data integrity check before executing the OASES Publisher. Finally, after the OASES Publisher was started up, the data publication could be initiated by starting up the OASES Time Federate.Figure 6.2: “Poor Man’s GUI for FBE-K OASESThe ingestion and publication of the NCOM / WAM combination and the NCOM / WAM / COAMPS combination could be done similarly. The one exception to this rule was that OASES would not ingest multiple COAMPS data files from a single directory, and we had received each parameter in a separate file. This remains to be fixed.We were able to use this set of desktop icons to train the METOC SME operator to execute the procedure of downloading, ingestion, visualization, and publication of the environmental data.There were some shortcomings in this approach, with the two basic points being:1) OASES will most likely need configuring for each experiment, by hand / command line (currently, no single, uniform GUI for this);2) Error detection can be difficult and the data-stream is currently not sufficiently error-free for SME-only operation.7.  Difficulties and Future EffortsAll of the environmental data were received in a netCDF format. In order to ingest a new format there are mapping files for OASES that needed to be modified. While OASES had previously ingested ocean data in netCDF format, netCDF does not itself constitute a sufficiently well-defined standard for OASES to map the data to its internal variables. NAVOCEANO is currently promulgating a NAVOCEANO-netCDF standard, in which format we received the data. The NAVOCEANO-netCDF standard is much more suitable for making a stable mapping file for OASES to properly map received data to its internal variables.We received COAMPS data in the netCDF format relatively late. Some confusion resulted from our desire to get COAMPS data surface conditions (e.g. surface winds) and not realizing that the vertical dimension was given in three different ways: sigma coordinates, millibars, and meters. While we were eventually able to use OASES to ingest these, we learned that it is much easier for OASES to get the surface conditions in a uniform vertical coordinate. (Note also that there is a 1-week turnaround time for requesting that a COAMPS variable be published before having it provided.)Several improvements need to be made to the OASES Ingestor.  One was mentioned earlier: allowing the user to specify multiple possible variable names for the dimensions of a netCDF file for a given model.  Another is support for netCDF files that do not contain an “unlimited” or “record” dimension.  Some netCDF files received from NRL-Stennis and used in preparing for participation in FBE-K could not be ingested because their time dimension was not specified as being “unlimited”.A longer-term concern of ours is how to handle multi-resolution environmental model data.  Support in OASES for curvilinear grids will not be sufficient in the future when we want to publish datasets that are the result of merging model output with different spatial resolutions (such as high resolution COAMPS model data nested within lower resolution COAMPS model data) or from merging the output of different environmental models.  A more general and more flexible grid than a curvilinear grid would be needed.  OASES has support for the Operational Multiscale Environment model with Grid Adaptivity (OMEGA) [10] for atmospheric data.  Perhaps this type of grid could be used with datasets that are the result of merging the output of different environmental models.  For this to happen, data provisioners would have to support the creation of such datasets and it is not clear that they would choose to base them on the OMEGA model.It seems reasonable that the merging of model datasets should logically be done before being ingested by OASES so that consumers of OASES data need not choose between different (and possibly overlapping) fields of data.  This task of merging datasets would have to be done by those sufficiently familiar with the models to know which portions to preserve in regions of overlap and how to resolve the values at the boundary.While the job of merging this type of model data would not fall to TEDServices, it would be reasonable to anticipate that TEDServices could in the future allow a consumer of environmental data, such as OASES, sufficient flexibility to request such a merged dataset from a menu of models.Many modeling and simulation consumers of the SNE might profit from being able to extract data from OASES on demand (user-pull), rather than receiving large datasets for the entire area of interest on OASES’ time schedule (server-push).  There already exists support in OASES for such queries, but there appears to be little precedent for its use in any major modeling and simulation events.  Use of this capability needs to be explored.Lastly, much effort was devoted to configuring the OASES server so that it could be operated solely by the METOC SME.   In section 6, we discussed ways in which we tried to facilitate the use of the command-line interfaces to the OASES modules by writing shell scripts that were in turn invoked using icons on the desktop.  TAOS, the predecessor to OASES, had a single, all-encompassing GUI, called the Operational GUI, that allowed the user to manage the separate OASES modules from a single interface.  The development of such a GUI for OASES would significantly increase its usability by a METOC SME, and would therefore represent a very significant improvement.8.  AcknowledgementsThis effort is being funded by the Composable Mission Space Environment program of the Defense Modeling and Simulation Office, led by Philomena Zimmerman.  The authors would also like to acknowledge the assistance of the TEDServices team, including John Shea, Roy Ladner, Todd Lovitt and Chris Drance, NRL-Stennis researchers, including Lucy Smedstad, James Dykes and Rick Allard, and the OASES developers at NGIT, particularly Robert Reynolds.References[1]	R. A. Reynolds, et. al., "The Ocean, Atmosphere and Space Environmental Services (OASES) System," Simulation Interoperability Workshop, Paper 01S-SIW-047, March 2001.[2]	T. Foreman: “Enhancing ATLoS,” Simulation Interoperability Workshop, Paper 03F-SIW-062, September 2003.[3]	R.M. Hodur, J.D. Doyle: “The Coupled Ocean/Atmosphere Mesoscale Model Prediction System (COAMPS), Coastal Ocean Prediction,” Coastal and Estuarine Studies 56, pp. 125-155.[4]	D.N. Fox, W.J. Teague, C.N. Barron, M.R. Carnes, C.M. Lee: “The Modular Ocean Data Assimilation System (MODAS),” J. Atmos. Oceanic Technol. 2002, pp. 240-52.[5]	WAMDI Group: “The WAM model – a third generation ocean wave prediction model,” J. Phys. Ocean, vol. 18, 1988, pp 1775-1810.[6]	R. Allard, J. Christiansen, T. Taxon, S. Williams, D. Wakeham: “The Distributed Integrated Ocean Prediction System (DIOPS),” 7th International Workshop on Wave Hindcasting and Forecasting, 2002.[7]	R.A. Reynolds, C.G. Scannell: “Supporting the Transfer of Large Environmental Data Objects Over a Connectionless RTI,” Simulation Interoperability Workshop, Paper 03F-SIW-088, September 2003.[8]	B.N. Kim, A.F. Blumberg, S. O’Neil, C.G. Scannell: “In-Stride Computations of the Marine Environment in Support of FBE-H,” Simulation Interoperability Workshop, Paper 01S-SIW-108, March 2001.[9]	 HYPERLINK "http://pdas.navo.navy.mil/coards_netcdf.htm" http://pdas.navo.navy.mil/coards_netcdf.htm[10]	D.P. Bacon, Z. Boybei, T.J. Dunn, Y.L. Ho, M.D. McCorcle, S.E. Peckham, R.A. Sarma, S. Young, J. Zack: ”The Operational Multi-Scale Environment Model with Grid Adaptivity (OMEGA). Part I: Model Description,” Preprints to the Tenth Conference on Numerical Weather Prediction (Portland,OR; July 18-24, 1994), American Meteorological Society, Boston, MA, pp. 538-540.Author BiographiesCHRISTOPHER G. SCANNELL is an Electronics Engineer with the Naval Research Laboratory.  He has worked in the Acoustics Division and the Information Technology Division researching distributed simulation applications, virtual reality applications and parallel processing paradigms.  He has a BS in Physics from Georgetown University, a BSEE from the Catholic University of America and an MS in Electrical Engineering from Johns Hopkins University.JOSEPH B. COLLINS is a Research Physicist with the Naval Research Laboratory in Washington, DC. He received his Ph.D. in Physics from Brown University in 1986. He has been working on developing natural environmental support for modeling and simulation for the last few years.Figure 2.1.  SNE Architecture.