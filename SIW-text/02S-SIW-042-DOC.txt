HLA Lessons Learned from the RDEC Federation Calibration ExperimentTim BentleyKarin LarsenAngela RodenQuality Research, Inc. HYPERLINK "mailto:Tim.Bentley@qr.com" Tim.Bentley@qr.com HYPERLINK "mailto:Karin.Larsen@qr.com" Karin.Larsen@qr.com HYPERLINK "mailto:Angela.Roden@qr.com" Angela.Roden@qr.comJoey FannAEgis Technologies Group, Inc. HYPERLINK "mailto:jfann@aegistg" jfann@aegistg Gilbert GonzalezScience Applications International Corporation HYPERLINK "mailto:Gilbert.Gonzalez@saic.com" Gilbert.Gonzalez@saic.comKathryn RooseSimulation Technologies, Inc. HYPERLINK "mailto:Kathryn.Roose@rdec.redstone.army.mil" Kathryn.Roose@rdec.redstone.army.milGreg TackettUS Army Aviation & Missile CommandResearch, Development, and Engineering Center HYPERLINK "mailto:gtackett@rdec.redstone.army.mil"  HYPERLINK "mailto:gtackett@rdec.redstone.army.mil" Greg.Tackett@rdec.redstone.army.milJames Van BebberCarmel Applied Technologies, Inc HYPERLINK "mailto:Vanbebber@catinet.com" Vanbebber@catinet.comKeywords:CGF, DIS, DREN, FCS, FOM, HLA, IDEEAS, LAN, MAN, OTB, RTI, WAN ABSTRACT: The Calibration Experiment (CalEx) was conducted in October 2001 as a demonstration of the analysis capabilities of the AMC RDEC Federation.  CalEx was a distributed exercise over the Defense Research and Engineering Network (DREN) with multiple RDEC sites, Army Research Lab (ARL) and Simulation, Training, and Instrumentation Command (STRICOM) participating in a high-level architecture (HLA) exercise.  The focus of the experiment was in the area of robotics and indirect fire metrics centered around sensor/shooter timeline issues.  Two scenarios were developed with a goal of collecting and analyzing the data to help feed the decision process for Future Combat Systems (FCS).  This paper will focus on the lessons learned in planning, managing and executing the HLA CalEx experiment.  The lessons learned will include discussions on DIS vs. HLA experiment planning, HLA experiment data collection, HLA tool availability, HLA RTI and gateway technology, simulation interoperability and integration planning, scenario generation, and HLA messaging and network transmission processing.  This paper will also briefly discuss some of the networking issues encountered during the integration and testing of CalEx.1. IntroductionThe AMC RDEC Federation (referred to as the Federation for the remainder of this paper) is a distributed engineering and engagement level modeling and simulation environment.  The Federation is a persistent HLA-based collaboration of US Army RDECs, Army Research Lab (ARL), and STRICOM. The participants include the Aviation and Missile Command’s (AMCOM) aviation and missile simulations and data collection tools; the Tank, Automotive, and Armament Command’s (TACOM) ground vehicle and armament simulations; the Communications and Electronics Command’s (CECOM) C4I and sensor simulations as provided by Night Vision Lab; ARL vulnerability/lethality assessment models, human engineering models, HLA utilities, and Dismounted Infantry Simulation; and STRICOM simulation support technologies such as Computer Generated Forces OneSAF Testbed (OTB). The collection of federates participating in any individual event of the Federation is based upon customer needs and technical objectives. The usable product of the Federation is a distributed, collaborative, composable modeling and simulation environment with robust modeling and simulation (M&S) capabilities and an architecture sufficient to support analysis of the Objective Force.  The initial objective of the Federation is to develop an HLA compliant test bed to support FCS analysis and experimentation.  Key efforts include the linking of each RDEC/Laboratory’s high-resolution models and establishing a federated data collection/analysis capability. This distributed collaborative M&S environment is capable of supporting system-of-system and cross-functional area tradeoffs and assessments.  1.1 Calibration Experiment BackgroundThe first integration of the Federation was demonstrated at the SMART Conference in April 2001 in Orlando, Florida.  During this conference, all Federation players came together and successfully demonstrated the integration between sites and did some preliminary analysis using data collection tools.  But, the vision of the Federation was for all players to be able to play distributed from their own facilities.  During the second test of the Federation called the Calibration Experiment (CalEx), which this paper discusses, the goal was to successfully demonstrate the capability of the Federation to operate in a distributed environment over a Wide Area Network (WAN) and expand upon the capabilities of the Federation demonstrated at SMART.  Another major goal was to be able to conduct data analysis on the results obtained. Planning for CalEx started in May 2001 and the experiment was conducted in October 2001.  The first meeting for CalEx was a discussion of lessons learned from the SMART Conference.  One of the major lessons learned from SMART was to get the Federation Object Model (FOM) definition, terrain and scenarios defined as early in the process as possible.  It was decided at the first post-SMART planning meeting to base our FOM definition on RPR 1.0 with extensions.  The Federation also decided to use the same Fombler’s Ford terrain area and base the initial scenarios on what was done at the SMART conference.  Changes to the scenarios were made to accommodate new capabilities and metric objectives for the CalEx.  During the SMART conference, two separate networks were maintained for DIS and HLA traffic.  For CalEx, it was decided that HLA would be the primary means of communication and DIS systems would be connected to the network via a gateway.  This paper will discuss the architecture of the CalEx, HLA challenges, RTI and gateway technology, HLA data collection and distributed challenges encountered during this experiment.  This paper will not go into the specific details of the network configuration or all of the networking challenges encountered during the Calibration Experiment but it will give a brief description to put the networking challenges in context.  The networking details are covered in a separate paper [1].2. Architecture OverviewSeveral factors drove the architecture design for the Calibration Experiment.  The first was the premise that the respective subject matter experts in materiel technologies should own and operate the representations of those technologies in the federated architecture.   Previously, each organization has maintained platform-level simulations of the overall battlefield systems with their respective subsystems modeled in higher fidelity, paying only minor attention in general to the representations of the subsystems of other technologies, assuring only nominal performance.  This approach has been analytically dangerous because it ignored interdependencies between subsystem technologies that could bias results of the experiment.  But farming out the responsibility for subsystem representations to the right organizations could be accomplished by breaking apart platform-level representations to represent systems in a distributed fashion.  This led to a server-based approach for CalEx.  The following servers were the first to be integrated using this technology:  missile server, mobility server, and vulnerability/lethality server.  The Calibration Experiment also had goals of collecting metrics in the area of indirect precision fires and robotic analysis. See Figure 2-1 for a picture of the final CalEx architecture  with the various participants indicated.Another decision made was to play more than one CGF emulation in order to take advantage of the strengths of each model and gain an understanding of the issues and challenges involved with simulation interoperability.  An OTB version generated by Ft. Knox was the primary CGF for the experiment with Interactive Distributed Engineering Evaluation and Analysis System (IDEEAS) (developed by AMCOM) used to generate some of the blue forces during one of the scenarios.  IDEEAS was modified to be a native HLA simulation during the experiment.  This allowed a capability to be added to publish target acquisition data through a FOM extension in order to support the indirect precision fire metric of the experiment.  Figure 2-1 CalEx Simulation Architecture						3.  Network OverviewFigure 3-1 provides an overview of the systems and the network that was used during CalEx.  The systems used included 44 PC(s), 8 SGI(s) and 2 Sun(s) that were distributed over seven geographical locations to include:  AMCOM, ARL, CECOM – I2WD, CECOM – NVL, ARDEC, TARDEC.  The operating systems used to support the PC(s) included a mix of Linux, NT and Windows 2000.The DREN was used to provide the Wide Area Network (WAN) support. The DREN is fundamentally a high performance ATM private virtual network that is an overlay on the AT&T commercial grid. The Metropolitan Area Network (MAN) support was provided by ATM switches, routers and firewalls that were located at each base. The Local Area Network (LAN) at each site supported a minimum of fast ethernet service.4. Calibration Experiment PlanningA detailed test plan was written for CalEx.  This test plan covered the following:The experiment objectivesDetailed description of each system participating in the experiment Preliminary architecture for the integration of the systems.  Description of each scenarioDescription  of the terrainExercise test information including the names and phones numbers of all participants and a schedule of  activitiesOnce this test plan was finished, many detailed activities took place leading up to the final integration and testing runs.  This section will provide more detail into the architecture decisions made based on the experiment objectives. 4.1 FOM Definition ProcessOne challenge in planning CalEx was deciding what data should be passed between the applications and then capturing that information in a FOM.  It was decided that the Real-time Platform Reference (RPR) FOM would be used as the starting point since it already contained most of the message definitions that were needed.  However, several extensions were added to the RPR FOM in order to collect data not supported by RPR. The following is a list of some of the extensions added to the RPR FOM:AMRDEC FOM ExtensionsVulnerability Server informationMobility Server informationLethality Server informationWhile defining the FOM extensions, the data collection team was defining measures of effectiveness (MOEs) to be used to quantify the results of the exercise.  It is very important to involve the data collection team early in the exercise process in case any FOM extensions might help in organizing and ensuring that all data needed for after action review is being collected. Extensions added for CalEx that directly supported the defined MOEs.4.2 Time Tagging DataSome of the MOEs developed for CalEx created a necessity to evaluate when certain significant events occurred and to build timelines of activities.  In order to do this the data being collected must contain a time stamp indicating when the data in the message is valid.  The DIS protocol contains a vehicle for capturing a time stamp in the header of the PDU before it is sent out.  However, HLA does not have a built in mechanism for accomplishing this task.  An approach for encoding and transmitting time stamps within a HLA message was developed for the RPR FOM and discussed in the Guidance, Rationale, and Interoperability Modalities for the Real-time Platform Reference Federation Object Model [2] documentation.  Time stamp data is encoded and placed in the user tag portion of HLA messages.  This approach helps to ensure that data can be mapped between HLA messages and Distributed Interactive Simulation (DIS) protocol data units (PDUs), which is critical if an exercise is to utilize both HLA and DIS compliant simulation.Another decision that needed to be made relative to time tagging data was how the time would be kept during the exercise: absolute or relative.  Absolute time stamps were chosen in order to reduce the confusion of using relative time stamps and tying them back to a particular event.  However, in order to use absolute time stamps the clocks on each of the machines used in the exercise had to be synchronized.  The method chosen to sync all the machines was to use Network Time Protocol (NTP).  A program called “nistime” was used which implemented NTP.  Nistime is a program that can be freely obtained from the Internet and then set to automatically set a computers time based on one of several stratum one timeservers.4.3 Data Transfer (Best Effort vs. Reliable)In an HLA exercise there are two ways that message delivery can be configured: best effort or reliable.  The approach DIS exercises are built upon is best effort.  This configuration works well in the DIS environment where object updates are sent at regular interval.  Therefore if one update is dropped another one will be sent not too long afterwards and adjustments can be made at that time.  Also, for events that occur only once (i.e. munitions detonation), some exercises can deem the loss of those messages as acceptable.  However, since the main goal of CalEx was to collect and analyze data there was a need to make sure the data of interest was received.  Therefore reliable message delivery was considered for critical data events.  But when using reliable delivery significant latency can be experienced, and during CalEx it was determined that latency could not be tolerated, especially when dealing with object updates.In order to balance the need for reliable data collection with latency problems the FOM was configured to use both best effort and reliable message delivery.  HLA allows for each object and interaction to be independently configured as to the type of message delivery mechanism it would use.  Therefore, messages such as object updates were set to use best effort while others such as weapon fires and munitions detonation were set as reliable.4.4 Integrating DIS ApplicationsDuring the planning stages of CalEx, several simulations that were needed to support the objectives were identified.  However, not all of the simulations chosen were HLA compliant.  Therefore, DIS compliant simulations were used.  In order for the DIS simulations to participate a DIS-to-HLA Gateway was utilized.  The Gateway used in CalEx was the MAK Gateway.  A description of the use of the Gateway and experiences encountered are provided below.When dealing with DIS applications in an HLA exercise, the use of new messages, or FOM extensions, does not translate to the DIS applications.  If the message does not map to a DIS PDU then DIS applications cannot make use of the additional data, while maintaining the protocol standards.  The handling of extension messages in a DIS-to-HLA Gateway is dependent on the gateway architecture.4.5 Experiment Planning Lessons LearnedPlanning and coordination play an important part to being successful in a large distributed exercise.  The Test Plan was a very valuable document in establishing a baseline during the integration of CalEx.  One lesson learned was that as the schedule deviated from what was published in the test plan, the test plan should have been updated more often and distributed to all participants of the experiment.  The Federation did not do a good job of replanning as events occurred which caused changes.  However, even the best planning cannot accomodate unforeseen events.  The Federation was in the middle of integration activities when the September 11, 2001 attacks on the World Trade Center occurred.  This caused a disruption in testing for almost two weeks, and severely hampered end-state connectivity due to heightened network security measures.Defining the FOM early is a key element to a successful experiment.  By investing a significant effort up front to define the data to collect, and hence defining the FOM, integration and exercise runs go more smoothly.  Having one person responsible for collecting all FOM inputs and then publishing the FOM to all players worked very well during CalEx.  This eliminated confusion as to the latest version of the FOM. During CalEx, the Federation maintained a secure Internet site with all the latest information and documents related to the experiment.Another lesson learned during CalEx resulted from the use of time synchronization.  The use of the Nistime program to synchronize computer clocks makes using absolute time stamps easier.  However, caution should be used when using multiple platform types (i.e. SGI, PC, etc.) because the amount of drift in the clocks can vary.  Therefore, a balancing act must be done between how often the clocks should be synchronized, which adds traffic on the network, with how much the clocks drift.The Federation experienced a problem with network latency.  Therefore, using a mixture between best effort and reliable was necessary.  The only problem was that since entity state information was received as best effort, some state change information may have been lost in network transmission.  But, this did provide the best compromise between the need for reliable data collection and latency problems.5. Data Collection for CalExThe data collection and analysis for CalEx was led by AMCOM.  AMCOM used two tools to collect and analyze data during the exercise, Data Collection and Analysis Tool (DCAT), and the MAK logger.  A third tool, Data Collection Tool (DCT), was considered but required modifications to the FOM that did not add any additional metric objectives.  Therefore, DCT was not used.  In addition to RDEC Federation members, Aegis Technologies provided additional post experiment data analysis results.  This section will give a brief description of all three tools and discuss lessons learned from the experiment. 5.1 DCATDCAT is a real-time application that collects data for analysis from either a DIS exercise or an HLA  federation execution.  The data collected is stored as DIS PDUs for further analysis.  To support HLA, DCAT is currently taking the HLA data packets and translating the data into PDU format before it is stored into a database.  DCAT has the ability to allow a user to perform real-time data analysis for an exercise by using a built-in MOE developer tool.  In addition, the MOE developer tool will allow the user to perform After Action Review (AAR) experiment analysis and debugging analysis.  This information can be displayed in chart or text format.Before the CalEx experiment, DCAT collected the following PDUs: start/resume, stop/freeze, detonation, fire, signal and entity state.  The DCAT product underwent changes so the metrics for the CalEx experiment could be met.  DCAT was modified to capture the designator PDU, action request PDU and acquisition event interaction.  Since one of the metrics consisted of analyzing an interaction, it was decided that DCAT would participate as a federate in the HLA federation execution.5.2 AEgis Analysis Station ToolIn conjunction with the data collection activities of CalEx, the AEgis Technologies tool, Analysis Station, was utilized to evaluate recorded scenario data.  The Analysis Station is a highly configurable tool for controlling, analyzing, reviewing, and documenting HLA federation executions.  Based on a set of core functionality, Analysis Station also allows for the implementation of add-on modules to capture and display federation data in a variety of formats.  This feature allows the user to tailor the Analysis Station functionality to the specific federation data management requirements.The core software components of the tool consist of the Simulation Engine module, Database Engine module, and Logger/Playback module.  The Simulation Engine module provides basic federation execution functionality, which allows the user to configure, execute and monitor an HLA federation.  The Database Engine module provides the capability to store specific federation data to a standard database.  And the Logger/Playback module allows the user to capture and replay execution runs.  To support this functionality, public interfaces to Simulation and Database Engine modules are provided via 1) the Analysis Station Module API, and 2) standard SQL calls. The SQL interface uses standard database queries and updates to provide functionality in lieu of adding additional modules to Analysis Station.  Due to time constraints, this direct database access was the approach chosen for the CalEx Analysis Station implementation.  To facilitate the data capture, Analysis Station utilizes a series of configurable XML files to specify how the FOM data is stored in the database tables.  Analysis Station’s Microsoft Access connectivity was utilized for this particular experiment.  Federation data captured included object (entity) instances and updates; weapon fires; weapon detonations, and object kills were specified for capture.  Four (4) log files from the actual CalEx scenario run were used in this process. The results produced by Analysis Station provided insight into the CalEx federation interoperability and performance.  The resulting database tables provided pertinent data related to the operation of the scenario including object updates, engagements, and damage assessment. These results were then compared against the initial scenario data and exercise observations to confirm the outcome of the simulation events.  It is envisioned that further data study with Analysis Station may be accomplished by using the created database tables to populate customizable charts, maps and spreadsheet displays.5.3 MAK Data LoggerThe MAK data logger is an application that allows the recording and replaying of simulation data from a DIS or HLA exercise. The Microsoft Windows version of the MAK data logger was used to record all of the data that was passed during the CalEx federation for each record run.   The data was logged to assist federates that were unable to participate in an exercise and to help federates in resolving problems or issues with their simulation after the record runs.  Aegis was able to take the Mak Logger results and play them back into the Analysis Workstation.5.4 Lessons Learned in Data CollectionThe CalEx experiment brought to light several key issues for data collection.  First and foremost, it is important for the data collection team to be heavily involved with the experiment planning team.  It is also a plus to have the FOM defined as early as possible when the data collection tool will be participating as an HLA federate.  These two factors will allow the team to know up front what data needs to be collected to meet each metric and how the data will be transmitted.  In future experiments, it would be beneficial to have at least two data collection and two analysis tools.  The additional tools would allow a system of checks and balances, especially for mission critical data.  6. RTI and Gateway IssuesCalEx proved to be a stress test for the RTI 1.3NGv3.2 and the MÄK Gateway.  The integration of the federation over a general purpose WAN like the DREN, the size of the federation, and the Defense Modeling and Simulation Office (DMSO) RTI version used, were major contributing factors to the main problems encountered.6.1 CalEx Experiences in using the RTI 1.3NGv3.2Running the RTI over the DREN proved to be quite a challenge for the integration team.  Unreliable connectivity and highly varying latency caused significant impact on RTI performance and reliability.  The RTI is like a distributed operating system that creates TCP connections between all federates joining the federation.  These connections are reliable, which require robust and stable network connectivity.  If these connections are broken due to short periods of network disruption or latency, the RTI does not have a fault tolerant mechanism to automatically recover from these connection failures.  This problem will make the federation hang, causing messages to queue up and eventually triggering individual federates or the federation to crash, forcing a recycle of the federation [3]. The RTI can also communicate using best-effort multicast for discovering the rtiexec process and sending/receiving FOM data.  This protocol does not create connections between federates but intermittent connectivity causes data loss, which prevented federates from discovering some entities, and causing incomplete scenario execution and data logging.      The MAN/LAN configuration at each site also affected RTI performance by creating unnecessary latency and blocking reliable traffic.  For example, most sites had several layers of network equipment between the originating nodes to the DREN connection, thus adding latency.  Some were also behind firewalls, which normally are configured to restrict reliable traffic.  In order for reliable traffic to go through a restricted firewall, specific ports need to be open.  This is not necessarily easy because the RTI, if not configured with specific ports, will arbitrarily select port numbers to establish its reliable connections between systems.There were other problems the RDEC federation experienced during CalEx related to RTI 1.3NGv3.2 that have been fixed with RTI 1.3NGv4.  For example,Federates would fail to join successfully if there were large numbers of federates trying to all join at once.   A resigning federate or removed federate can cause problems for subsequent joining federates in a federation with a large number of federates.Concurrent joins, resigns, and removes can cause federation failure.When a federate that owned objects crashes and is subsequently removed with the rtiConsole its objects become zombied.  Ownership of these objects cannot be transferred by other federates or the Management Object Model (MOM).6.2 Gateway Experiences during CalExThe MÄK HLA gateway version 3.4 was used to bridge legacy DIS 2.04 simulations to the Federation.  This is the same gateway originally developed by IST and previously available through STRICOM that has been upgraded to support RTI 1.3NG and RPR-FOM 1.0.  The production version of the gateway is only supported for Windows 2000 and NT.  The RDEC federation used the Windows version and a Linux 6.2 beta version for CalEx.The gateway performance was affected by unreliable network connectivity and latency.  During periods of network instability the gateway would freeze.  No data could be sent or received, remote entities were removed, and gateway commands could not be processed.  Eventually, the gateway would start responding again, data would start flowing, and all the remote entities were regenerated.  This continued to happen until the federation crashed and the entire federation had to be reinitialized.  The problem continued to occur when one or more sites’ TCP connections were broken due to network disruption. After the problem site was removed from the federation, the execution run was very stable and the gateway would not freeze again.     A limitation of the MÄK gateway is the inability to add new DIS experimental PDUs and HLA objects.  Modification to the gateway can only be done by MÄK at a cost to the user.  One partial solution to this problem is to use the DIS Data PDU, which can be mapped into an RPR-FOM HLA object or interaction class. Because of all the performance problems encountered, half way through integration, the Federation tried upgrading to RTI 1.3NGv4 but the Linux version of the gateway, which was a beta version, did not work with this version of the RTI.  The Windows version of the gateway worked fine with v4.  However, time did not allow us to change all the gateways to the Window’s version.  Therefore, the Federation decided to continue operating with v3.2.  6.3 Lessons LearnedIntegrating a federation over a general purpose WAN, like the DREN, presents unique challenges for the RTI.  These are some of lessons learned that can help overcome these challenges:Networks should migrate from the multicast Distance Vector Multicast Routing Protocol (DVMRP) tunnel technology to the use of a router based Protocol Independent Multicast (PIM) technology. DVMRP tunnels had to be used during CalEx due to the unavailability of routers at all sites.Network latency between sites should be kept to a minimum.  More experimentation is needed to determine the exact number but at a minimum latency should be below 50 ms roundtrip.Federates should avoid being behind firewalls, Access Control Lists, or any other network filtering agents that add latency and complexity to the network architecture .Each site should minimize the number of switches, hubs, and routers the HLA traffic must go through before reaching the main DREN connection at their local site.All systems participating in the exercise should be configured at a minimum with 100 BaseT full duplex NICs.Each site should have a network engineer that is part of the integration team.If multiple federations are being executed with one rtiExec process, assign a different multicast base address for each federation.  This can be configured in the RTI rid file.Perform as much testing as you can between sites and with the entire federation prior to the actual exercise.Although it is not significant, the gateway does add another layer of latency, therefore using a native HLA interface should always be the preferred option.  Also, if you have requirements to add experimental DIS PDUs and RPR-FOM class objects, then consider using an open source gateway you can modify yourself.7. Distributed Simulation ChallengesDuring the Calibration Experiment, many challenges were encountered in accomplishing the goals and objectives given the distributed nature of the exercise both in terms of networking and also in terms of communication among the various players.  Since this experiment was the first test of the Federation in a distributed environment using the DREN, many integration and testing events were scheduled prior to record runs.    This was key to accomplishing the objectives of the exercise.7.1 Scenario GenerationTwo scenarios were created for the experiment.  One focused on indirect precision fires and the other on robotics.  The scenarios were an expansion from the Fombler’s Ford scenarios which were executed for the SMART conference.  The following were some of the lessons learned from the scenario generation process:Start early and ensure that all players have the scenarios files as soon as possible to ensure adequate testing.  During CalEx, scenarios changed too late in the process causing delays in testing.When playing distributed, make sure the scenarios can be played out in a reasonable amount of time.  The CalEx indirect fire scenario was almost three hours in length and maintaining a stable network for this amount of time was difficult.In a distributed environment, ensure that all players understand their role in the scenario.  During CalEx, not enough attention was paid to the details of each sites role in the scenario.Make sure that the scenarios are closely mapped to the metric objectives of the experiment and that as objectives change that the scenarios change accordingly7.2 Terrain SelectionThe Fombler’s Ford scenario was chosen for CalEx.  Since the Federation played this terrain during the SMART conference, little change was needed in the terrain files and open flight files already existed for this terrain.  But early in the scenario generation process, the team noticed strange behavior using the CTDB file which had been generated for OTB.  Visually, no problems could be seen with the terrain but vehicles seem to start and stop and get stuck at various places in the terrain.  It was determined through using visualization tools that the terrain had many holes.  These holes were causing the vehicles to get stuck and it was also a reason why the indirect precision fire scenario took longer than expected. Therefore during this conversion process, the holes in the terrain were fixed for the ELE file by interpolating between points since ELE is an elevation type of format.  Not enough time existing to fix the CTDB file.During CalEx, the Federation also experienced correlation problems between OTB and IDEEAS.  This was due to the fact that the terrain that was selected crossed UTM grid zone lines and also occurred at an area in the world where the grid lines were converging.This identified a deficiency in IDEEAS that must be corrected before using the simulation in cross-grid locations, and suggested some additional integration work that must be done to rectify converging grid lines.  Another lesson learned from the terrain process is that one site should be in charge of creating and distributing the terrain files in a distributed exercise.  This site should take input in the beginning of the planning process as to the terrain formats needed by various sites but in order to maintain control of the terrain, one site should remain responsible.  7.3 Integration TestingA key to conducting a successful simulation exercise is the amount of preparation done by all the participants in the exercise. This is especially true when the HLA architecture is used to pass simulation data between each of the federates, as opposed to older data architectures, such as DIS. The DIS standard is extremely rigid in the definition of the types of data that may be passed, and does not adapt well to changing requirements. HLA adapts well to changing data requirements, but at the cost additional integration time to insure the data passed between senders and receivers is coherent to both parties. While the data types are generally well defined in the FOM, often the subtle implementation details for use of the data must be extensively tested between the federates.Extending the lesson of ensuring the quality of the data passed within the federation, it is also imperative to conduct the integration tests at the earliest feasible time in the project schedule, ideally as soon as the Federation Data requirements are defined within the FOM. All participants should be a part of the integration tests as soon as is feasible for each federate. Additionally, the specific physical network configuration and network protocols to be used during the conduct of the experiment should be fielded and tested as an integral part of the federate integration test process.7.4 Exercise ManagementThe integration testing provided important lessons learned in conducting CalEx. The timing and order of entry for each federate in the exercise was shown to play a critical role in the stability of the HLA federation. While this order may vary in other HLA federations with differing architectural and data systems, it was found that the CalEx federation was most successful in completing experiment runs if the data logging and data collecting federates were the first to join. This is likely due to these federates subscribing to all classes available in the FOM, thus their early entry into the CalEx federation allows them to sequentially register instances of object classes as other federates join the execution process. Otherwise, if these two federates join later in the execution process, they must discover all the instances of objects that have joined before them. The latter discovery process seemingly overwhelms the RTI executive process, and the federation execution becomes unstable.Key in this management process is to ensure reliable lines of communication between all the Federation participants. These communications systems should include at a minimum conferencing (or teleconferencing) capabilities, e-mail accessibility, central data repository systems, and distinct points of contact who have responsibility for the individual federate systems and other systems necessary for the conduct of the exercise (such as networking). During CalEx, a dedicated audio telephone conference line was established, with defined times for all participants to join the conference call. Additional telephone lines were installed at each remote federate site to allow sites to discuss specific integration issues not of utility to all federation participants.8.0 Recommendations8.1 HLAThe following questions are posed as possible modification to the RTI to make it more robust when operating over a general purpose WAN like the DREN: The RTI should be upgraded to make it fault tolerant to broken reliable connections. Could an RTI with no reliable connections be developed?  Currently the MÄK RTI does provide this option.  This would limit what RTI services could be used because some services like Time Management require reliable communications. 8.2 NetworkingThe following are some network recommendations:Continue integration and testing to determine if the Federation can work over the DREN by identifying the choke points and establishing procedures for mitigating their effects.  The Federation also must consider other alternatives besides the DREN. Each site must optimize their local network configuration and avoid operating behind a firewall.  The simulation WAN, MAN, and LAN used for an exercise should be isolated from administrative network traffic and all general purpose networks (i.e. Internet).The sites must use routers that support multicast. 8.3 ArchitectureThe following are some architecture recommendations:Several of the RDEC simulations are still DIS, which creates a dependency on gateways.  More of these simulations need to develop their own native HLA interface.  The RDEC federation must start developing its own FOM that is more geared towards engineering analysis and evaluation in support of Simulation Base Acquisition (SBA).  The RPR-FOM is very limited in this domain area.The RDEC federation architecture should be based more a client server architecture which supports composability of new systems and environments.  This is already being implemented with the use of the Vulnerability, Mobility, Missile and MP-ERM servers.Opening the architecture of the DMSO RTI for review of network requirements. Specifically, descriptions of the IP ports used and the mechanism by which the RTI processes chosen ports should be available, which are currently considered proprietary and unavailable to the simulation community.8.4 Exercise ManagementCritical to running an HLA exercise over the DREN is having a specific set of procedures that cover the steps required to manage the federation execution from beginning to end.  The execution procedures should address how communication will be established between sites to coordinate federation management functions.  For example:Which site and system will start the rtiExec process?Which site and system will run the fedex process?In what order will federates join the federation?How will federates be removed from the federation if they are not responding?How will the federation be recycled when it becomes unstable?What tcp and multicast ports numbers will used by the federation?Execution procedures must be defined and agreed by all parties.  A reliable, user-friendly and effective communication strategy must also be decided upon and implemented in order to facilitate the communication essential to execute an HLA exercise over the DREN [4].Federation management tools that would allow a battlemaster to control the federation from one workstation are needed.  This would include starting and removing the rtiexec, fedex and each federate participating in the exercise.  9. ConclusionsCalEx was successful in understanding to a greater level of detail the issues and problems which can be encountered when trying to operate in a distributed HLA environment.  Some of the issues the Federation was able to solve and some it was not.  Networking proved to be an area where much more research and experimentation is needed. But although the Federation was not successful in collecting the metric data planned due to the networking issues encountered, the overall exercise was successful in the lessons learned which will provide value information  as we more forward to planning and exercising future HLA experiments.  The authors which to thank the Army Material Command  for their continued support of the AMC RDEC Federation10. References[1] Roose, Kathryn; Larsen, Karin; Lorenzo, Max; Tackett, Greg; VanBebber, James:  “Network Challenges and Observations Noted During an HLA Distributed Simulation Exercise” Spring 2002 Simulation Interoperability Workshop (02S-SIW-059)[2] “Guidance, Rationale, and Interoperability Modalities for the Real-time Platform Reference Federation Object Model” Version 1.0, Draft 2, September 1999. [3] Andel, LT. Todd; Caudill, Daniel; Zeh, James; Buell, Christopher; Givens, Bret; O’Quinn, David; Subr, Robert: “Lessons Learned in Virtual Strike Warfare Environment #7”, Fall 2000 Simulation Interoperability Workshop (00F-SIW-056)[4]	Gonzalez, Gilbert; Carbia, Ivan; Colon, Victor: “Lessons Learned From The Special Operations Forces STOW-A HLA Exercise” Interservice/Industry Training, Simulation and Education Conference, November 2000.Author BiographiesTIM BENTLEY is a Senior Software Engineer for Quality Research and holds a MS degree in Electrical Engineering from the University of Alabama in Huntsville.  Mr. Bentley has been involved in the development of distributed simulations and data collection tools since 1995.  He is currently a member of the team responsible for developing DCAT in support of the U.S. Army Aviation and Missile Command Research, Development, and Engineering Center (AMRDEC).KARIN LARSEN is the Software Engineering Operations Manager in the Exercise and Analysis Modeling Simulation and Training Group at Quality Research.  Ms. Larsen has been involved in the software development of military systems since 1983 and supports the U.S. Army Aviation and Missile Command Research, Development, and Engineering Center (AMRDEC).   Ms. Larsen received a BS degree in Computer Science from the University of Missouri in 1983.ANGELA L. RODEN is a Software Engineer for Quality Research. She is currently a member of the team responsible for developing DCAT in support of the U.S. Army Aviation and Missile Command Research, Development, and Engineering Center (AMRDEC). Ms. Roden received a BS degree in Computer Science from the University of Alabama.JOEY FANN is a Senior Simulation Engineer for the Professional Training and Education Group of the AEgis Technologies Group.  In this role he has served as a technical trainer for both government and commercially sponsored training events, and has participated in the development and integration of several HLA simulation integration efforts.  His primary professional interests are focused in the areas of software engineering, distributed simulation and technical training.  He received a BS degree in Computer Science from Lipscomb University.GILBERT GONZALEZ is a Senior Systems Engineer for SAIC.  He has been involved in simulation development and distributed simulation technologies since 1987.  Mr. Gonzalez received a BS degree in Computer Engineering from the University of Central Florida.KATHRYN J. ROOSE is a Principal Engineer for Simulation Technologies in Huntsville, AL.  She received a M.S. in Computer Science from the University of Alabama in 1984.  Ms. Roose has 20 years experience in system and network management, and in developing software applications for the U.S. Army and NASA.  She is currently providing support for the APEX Laboratory at the U.S. Army Aviation and Missile Command Research, Development, and Engineering Center (AMRDEC).  GREG TACKETT is the Distributed Simulation Manager for the U.S. Army Aviation and Missile Command Research, Development, and Engineering Center (AMRDEC).  He received a B.S in Physics from Mississippi College in 1982.  He sits on the Defense Modeling and Simulation Office (DMSO) Architecture Management Group (AMG) and the Distributed Simulation Working Group (DSWG).JAMES VAN BEBBER is the Branch Manager for Carmel Applied Technologies Inc., Redstone Arsenal office. He holds BS degrees in Electrical Engineering (1995) and Business Marketing (1987) from the University of Alabama-Huntsville. Mr. Van Bebber has worked as a simulation software engineer and systems administrator in support of U.S. Army Aviation and Missile Command Research, Development, and Engineering Center; and PEO Aviation since 1995. Figure 3- SEQ Figure_3- \* ARABIC 1 CalEx Network Architecture Overview