Implementation of the Next Generation RTI	Stephen T. Bachinsky	J. Russell Noseworthy 	Frank J. Hodum	SAIC	Object Sciences Corp.	SAIC	5400 Shawnee Road, Suite 110	11715 Fairfax Station Road 	3259 Progress Drive, Suite A	Alexandria, VA 22312	Fairfax, VA 22039	Orlando, FL 32826	703-333-5428	703-658-5090	407-281-4949 x15	sbachinsky@std.saic.com	jrn@objectsciences.com 	fhodum@std.saic.com	Keywords:High Level Architecture, Runtime InfrastructureABSTRACT:  The Next Generation Runtime Infrastructure (RTI 1.3NG) was developed using a process that identified the requirements of an RTI, analyzed the key architectural elements, and leveraged the experience gained from previous RTI implementations and other distributed computing systems.  The ability to configure and evolve the internal system components was a driving principle for this design.  This flexibility was deemed vital to the support of the disparate operating conditions of various federates and federations, as well as to adapt the RTI 1.3NG to future technologies and techniques.This paper describes the design constructs and processes used in architecting and implementing the Defense Modeling and Simulation Office’s (DMSO’s) High Level Architecture (HLA) Next Generation Runtime Infrastructure (RTI 1.3NG). The software engineering techniques used to achieve such characteristics as scalability, high performance, reliability, and configurability are examined. Discussions on the time synchronization algorithm, process and threading model, data distribution techniques, and distributed communication mechanisms are provided.IntroductionThe Next Generation Runtime Infrastructure (RTI 1.3NG) provides an implementation of the Defense Modeling and Simulation Office’s (DMSO’s) High Level Architecture (HLA) interface specification (version 1.3).  The RTI 1.3NG builds upon experiences learned with the government sponsored RTI’s (e.g., RTI 1.0, STOW RTI, RTI 1.3) using a requirements-based design approach.  This development activity focused on the evaluation of factors that contribute to the requirements of an RTI based on use cases from the modeling and simulation community.  The software architecture used for the RTI 1.3NG implementation was not constrained by any previous implementations. Instead, it relied upon a formal analysis and design process with an understanding of the previous RTI prototyping and development efforts [].One of the intents of this paper is to share some of the implementation techniques, difficulties, and tradeoffs that were encountered during the design and development of the RTI 1.3NG.  Developing an RTI that correctly implements all of the services of the HLA interface specification is straightforward, if each service is examined in isolation.  The difficulty lies in creating a software architecture that can manage the subtle relationships between the service implementations and their effect on overall system stability and performance.These discussions concerning the RTI 1.3NG design and development are not intended to be inclusive of the entire system.  The RTI offers a broad range of capabilities divided into six service groups and one support service:Federation Management,Declaration Management,Object Management,Ownership Management,Time Management,Data Distribution Management,  andManagement Object Model.There are many interesting implementation strategies that can be used to provide the core behavior of these service areas.  Where possible, the RTI should be configurable to be able to strategize these different implementations.This paper provides some insight into the objectives used to guide the RTI 1.3NG design and development activities.  These objectives were not formal requirements, but they did provide general guidance. In Section 3 an overview of the RTI 1.3NG software architecture is provided, with additional detail into the implementation of several of the service groups.  Finally, the paper concludes with additional discussion of  the initial development efforts.	Implementation ObjectivesThere were several key principles that helped shape the design of the RTI 1.3NG software architecture:Functional compliance,High performance,Configurability, andPortability.These items were used to assist the investigation of the critical design elements of the software architecture.  They are described in the following sections.Functional ComplianceThe RTI 1.3NG implementation was developed according to the AMG HLA 1.3 Interface Specification [].  This is the same specification that was used for the previously released DMSO RTI 1.3 implementation.The HLA Interface Specification defines the services provided by the RTI and the behavior required by any federate attached to the RTI.  In addition, the HLA Interface Specification contains API’s for several programming languages (C++, Ada95, Java, and CORBA IDL).A requirement of the RTI 1.3NG was to ensure compile-time compatibility with the existing DMSO sponsored RTI 1.3.  This allows existing federate applications to be easily integrated with the RTI 1.3NG.During the design and development process, a number of minor ambiguities in the HLA Interface Specification were encountered.  These ambiguities made the proper RTI implementation behavior unclear.  In these cases the existing RTI 1.3 was examined for implementation guidance.  Most of these issues were subtle and a refinement or clarification was provided to the IEEE standardization process of the HLA Interface Specification.In order to ensure functional compliance with the HLA Interface Specification, an automated distributed test system was created.  This test system exercises the various RTI services under arbitrary conditions and configurations.The test system contains a library of self-validating scripts that utilize the HLA Interface Specification API to examine the behavior of each particular service.  The test script library continues to grow as new configurations or conditions need to be tested.  Initially, the nominal and exceptional invocations (i.e., invocations that result in an exception being thrown) of each service were captured in the test script library.  This resulted in a library of over 1000 individual tests.  The system provides the ability to perform regression tests on the RTI 1.3NG.  Its regular use helps ensure that the RTI 1.3NG continues to perform correctly throughout its lifecycle.Prior to the release of the RTI 1.3NG the software will undergo examination by the DMSO sponsored RTI verification tool.  The verification tool invokes various services on the particular RTI implementation being verified. This is similar to the automated distributed test system developed for the RTI 1.3NG.  However, the verification tool is based solely on proofs derived from the HLA Interface Specification. It therefore examines the adherence of an RTI implementation to the formal specification.  The development test tool examines the functional operation of the software in various abnormal states. Testing the RTI under these two views of the system has helped to ensure proper operation.High PerformanceRTI performance is a multi-dimensional space that includes, but is not limited to, such things as:End-to-end update and interaction latency,End-to-end update and interaction throughput,Bandwidth utilization (both the maximum and the mean),Memory requirements for the static code library as well as for runtime growth,Elements of scalability (e.g., the number of federates, federations, objects, regions, etc.).Elements of dynamism (e.g., the rate of change of publications, subscriptions, regions, etc.).Federates and federations will need to operate within certain regions of this performance space based on their particular operating conditions.  Although there are a number of factors that contribute to overall system performance in very complex ways, an RTI implementation is typically examined by attempting to isolate certain factors using the standard benchmark measurements [].These standard measurements are useful to compare RTI improvements and understand characteristics of different vendor implementations.  Additionally the benchmark measurements can provide an initial basis for evaluating exercise performance when used in conjunction with the Federation Developers Planners Workbook [].It is important to recognize that performance needs to be examined from a complete system perspective, especially since the federate application shares critical resources with the tightly coupled local RTI software.  An RTI implementation and benchmark test program can be optimized for particular operating conditions.  However such optimizations may yield limited performance under other operation conditions.The RTI 1.3NG implementation is intended to support a broad range of users and domains. Therefore its performance is optimized for operating conditions which are believed to be typical for most users.  For example, the execution of the most commonly used services (e.g., object update) needs to minimize the amount of processing time, potentially at the expense of less used services (e.g., set synchronization point).During the RTI 1.3NG design and development process we defined critical data paths that were used to carefully examine the operations needed to perform the most commonly used services.  The implementation of these critical data paths avoids unnecessary memory copying or resource contention.  Furthermore, the execution along these critical data paths was organized to utilize the State design pattern.  This avoids repeated conditional tests.ConfigurabilityA key premise of the RTI 1.3NG design was that a rigid implementation would not satisfy the diverse operating characteristics of all users.  Neither would it easily be able to leverage new techniques and technologies.  The analysis and design process defined appropriate abstractions throughout the software architecture that enable internal components to be substituted as necessary.  There are two benefits in developing these abstractions:The RTI can be configured to provide traits matched to a federate or federation’s characteristics;New components can be developed to examine different algorithms or support various configurations.Through the Strategy design pattern, one of several component implementations is created and used by the RTI 1.3NG to provide the desired behavior.  This configuration is typically specified through parameters in the RTI Initialization Data (RID) file, but can also be dynamically configured if necessary based on external conditions.  Examples of configurable components are the threading model and the data addressing/routing mechanism.The threading model component configuration enables the user to switch between:a single threaded implementation,a single federate thread with an RTI thread pool implementation, anda fully reentrant federate implementation (see Section  REF _Ref439670392 \r \h  \* MERGEFORMAT 3.1).Likewise, there are many different mechanisms that can be used to implement the Data Distribution Management (DDM) services (e.g., static segmentation, destination based routing, source based routing, etc.) [].  The ability to select different data addressing and routing algorithms will enable the community to learn how to effectively benefit from the different DDM techniques.PortabilityA major challenge for the development of the RTI 1.3NG is the diverse characteristics of the platform configurations that the software is expected to support.  Currently, the existing RTI 1.3 implementation supports seven different operating systems (OS’s): Microsoft Windows NT, Sun Solaris, SGI IRIX, Linux, Hewlett Packard UX, IBM AIX, DEC Digital UNIX.  Furthermore, for a given OS there may be several versions, compilers, compiler versions, and build options which must be supported.The RTI 1.3NG software is expected to be compatible with the operating systems listed above, as well as additional OS’s such as real-time OS’s (e.g., VxWorks).  Although many of the OS’s are UNIX variants, there can be a large number of differences in operating system interfaces and behavior.  For example, several operating systems are moving from a 32-bit to a 64-bit architecture.  This can cause very insidious software problems if incorrect assumptions are made within the RTI implementation.There are substantial differences in the behaviors of UNIX, Windows NT, and real-time systems.  These differences need to be accommodated by the RTI software.  Additionally, the RTI software must be built with a large variety of C++ compilers.  While a C++ standard has recently been adopted, compiler implementations will continue to have varied levels of adherence for quite some time.Development of the RTI 1.3NG has followed a dual build strategy involving Sun Solaris and Windows NT.  These operating systems were chosen because they are heavily used by the simulation community and are two of the most diverse platforms that the RTI 1.3NG must support.  During development, the RTI 1.3NG was routinely built on each platform. The goal was to identify platform-specific dependencies and idiosyncrasies early in the development process.  Early identification allowed ample time for any necessary corrective actions.  This was found be more effective than developing the software exclusively on one platform and then porting it the other.  To overcome the challenge presented by the requirement that the RTI 1.3NG run on many diverse software platforms, the RTI 1.3NG is architected on top of a special layer of software. This software layer captures the low-level services associated with distributed communications and process control, isolating details of the operating system from the rest of the RTI software.  This layer within the RTI 1.3NG implementation is built with software from the Adaptive Communication Environment (ACE) [].Using the open source software model, ACE has been ported to a wide range of platforms.  Over the last five years, many software architects and developers from around the world have improved ACE.  As a result, ACE has become a high quality product that has been heavily tested in a wide variety of situations.Design OverviewThe complexity associated with the RTI 1.3NG software architecture design and analysis was managed by decomposing the system into collections of objects, called packages.  These packages concentrated on the key activity areas of the RTI.  This enabled focused research into design and implementation issues.  Following this initial decomposition, the relationships and interactions between the various packages were reexamined to ensure proper decomposition.Good object decomposition is important to the design and development of any object-oriented software system.  To a software system as complex as the RTI 1.3NG, proper object decomposition is vital.  A poorly decomposed architecture will typically lead to frequent system re-designs, low occurrence of software re-use, and a system which is difficult to understand (and hence maintain).Initially, the RTI 1.3NG was decomposed into the following packages:Presentation Layer — efficiently supports multiple federates and federations within a single process;Process Model — encapsulates the different threading models, in conjunction with a strategy employed by the Presentation Layer;Data Management — performs publication, subscription, ownership, and routing of federation data;Time Management — supports the HLA services used to synchronize federate event processing according to a federation specified representation of time;Network Abstraction Layer — isolates the internal RTI components from issues related to operating system calls and the RTI interconnection mechanisms.Figure  SEQ Figure \* ARABIC 1  RTI 1.3NG Software ArchitectureThese packages continued to be expanded and refined during the development phase.  An illustration of the RTI 1.3NG software architecture is shown in Figure 1.  The core of the RTI is buffered between the standard HLA API that connects federates to the RTI, and the network abstraction layer that provides access to the underlying communication services.The internal components of the local RTI software are characterized based on whether they were associated with the process, a federation, or a federate.  For example, a FED database component would be “per federation” and a subscription database component would be “per federate”.  Support for multiple federates and federations was designed to be efficient, (e.g., avoiding replication of state).Any implementation of an HLA RTI is a complex distributed system that can be implemented or configured in many different ways, each resulting in unique characteristics.  There are many tradeoffs to be considered when implementing or configuring a distributed system capable of supporting the diverse operating characteristics found in the DoD Modeling and Simulation (M&S) community.Although the RTI 1.3NG implementation may not have a large number of configuration choices initially, the architecture is poised to support future configurable components.  Descriptions of the key areas of the RTI 1.3NG architecture are provided in the following sections.Process ModelSince RTI software is typically linked together with federate software, forming a single executable program, there needs to be a mechanism to efficiently control the overall process.  The federate software requires access to some of the same computer resources (e.g., processor, memory, I/O devices) that are used by the local RTI software.  Being able to optimize the handling and scheduling of execution tasks requires an understanding of the process model used by the federate and RTI software.The process model interface is not currently considered to be part of the HLA Interface Specification.  Thus, the manner in which computer resources are shared between the RTI and a federate may vary between RTI implementations.The Application Programmer’s Interface (API) used for the existing RTI 1.3 implementation is a single service called tick.  The tick service is used both to provide the thread of execution to the local RTI and to signal that the federate is in a state to receive callbacks from the RTI.  Optional minimum and maximum time values can be provided to tick.  These time values specify the desired duration the local RTI spends in servicing the tick invocation.One drawback with this process model API is that the federate does not know how often it should tick the RTI.  This information depends on operating conditions and state internal to the RTI itself.  Furthermore, it may be difficult for the federate to tick the RTI at an arbitrary rate.  This is because the federate needs to be ready to handle RTI callbacks whenever invoking tick.  Despite these issues, a key benefit of the tick API is that it provides an interface that is easily compatible with a large number of existing simulations.Requirements of the RTI process model include providing callbacks to the federate, and scheduling events internal to the RTI.  These events may include things such as servicing timers, I/O read/write lock changes, or signals that may be captured by the RTI.  The RTI process model handles these events according to a scheduling mechanism that may be a simple first in, first out (FIFO) queue or could use a more complicated algorithm based on Quality of Services (QoS) metrics.Software applications are developed with different threading strategies.  These strategies are (hopefully) optimized for the application operating characteristics (including factors such as the communication mechanisms used).  There are several different threading models that can be supported with an RTI / federate process:Single threaded application,One (or more) federate thread(s), with an RTI thread pool,Fully multi-threaded application with a completely re-entrant federate.The RTI 1.3NG implementation is able to support several of these threading models by specializing some of its internal components.  If the federate chooses to use a single threaded implementation, the federate must tick the RTI to perform internal operations including the necessary inter-federate communications.  A single threaded implementation is useful when the application wants to avoid context switching associated with multiple threads which can impact performance characteristics in certain situations.The RTI 1.3NG can be configured to contain a thread dedicated to processing incoming requests asynchronously.  This model separates the client and server roles of a local RTI into separate threads, each independently schedulable.  In this configuration, one thread handles the invocations the federate makes on the RTI.  Another thread handles any data or requests received through the external communication devices.  It is anticipated that this process model will perform better in most circumstances because it allows the operating system to efficiently schedule the fundamentally independent client and server activities. Federate and RTI activities are depicted in Figure 2.  The illustration indicates the locality of threads with respect to the upcall and downcall operations. Figure 2  RTI Downcall and Upcall Thread(s)The federate thread (or threads) is (are) always used for downcall operations and the federate callbacks using the thread passed to the tick service.  Optionally the RTI can be configured through the RID file to use an asynchronous thread for the RTI upcalls.  The upcall processing for the federation data will operate in thread specific storage independent of the downcall processing.  A thread contention area is the callback command queues that hold the information associated with invoking callbacks on the federate.  Since the execution of these commands is triggered by the federate tick call, it is this thread used to enter the federate software, and not the asynchronous upcall thread (or threads).As previously observed, two execution paths are associated with the RTI.  One path arises from the federate invocations of RTI services.  These typically result in communication with other federates.  The other path arises from the processing of messages received by the local RTI from other distributed RTI system components.When the local RTI processes incoming messages a corresponding command object is factoried.  If necessary, this command will be inserted into a queue for later callback to the federate. A single command executor handles all federate callbacks based on the configuration of the local RTI.  When multiple threads exist within the local RTI, certain data structures require guards to prevent concurrent access.  Operating systems provide locking mechanisms, such as mutexes, semaphores, or condition variables for this purpose.  These constructs must be used judiciously since excessive locking can degrade performance and possibly cause deadlocking.  When configured for a single threaded implementation, the RTI 1.3NG does not use (or even instantiate) these guards.  This avoids unnecessary performance impact.In the case of concurrent federate threads invoking services on the same local RTI (i.e., the same instance of an RTI Ambassador), the initial RTI 1.3NG implementation uses a coarse-grained locking mechanism.  This allows only a single invocation at a time.  Additionally, during federate callbacks some of the RTI services will be locked.  This model will provide behavior similar to the existing RTI 1.3 implementation, as well as supporting multiple threads within the federate and RTI process.  As RTI concurrency is better understood within the RTI 1.3NG implementation, finer-grained locking may replace these course-grained locks.Data ManagementHLA simulations require federation developers to describe the data types exchanged between federates with a publish and subscribe paradigm.  Distributed applications requiring interoperability exchange information using a common description of their HLA Object and Interaction classes.  Federates notify the federation of their intent to produce Object and/or Interaction instances (publishers or producers).  They also notify the federation of their interests with respect to Object and/or Interaction classes (subscribers or consumers).HLA objects are characterized by a set of attributes whose values may change over time.  Some of an object’s attributes may be inherited from a superclass, which resembles inheritance in object-oriented programming.  HLA interactions are one-time events described by a set of parameter values. Interaction parameters can also be inherited.  The object and interaction classes used by a federation are defined in the Federation Object Model (FOM).It is important to note that the HLA object model should not be equated with an object model from object-oriented programming languages. While the HLA object model was deliberately designed to have characteristics similar to an OO programming object model, it is data centric. HLA objects have no behavior associated with them.Specification of publications and subscriptions within a federation can be accomplished on a class-only basis.  This means that the federate publishes and subscribes to a particular federation object or interaction class (i.e., its attributes or parameters).  One federate publishes and sends data belonging to a particular data type defined in the FOM and a set of federates subscribes to and receives the data belonging to that data type.The class-only specification is extended to allow federates to define arbitrary characteristics about the data instances.  These characteristics refine the publication and subscription specifications on an instance basis.  The instance based producer/consumer mechanism is referred to as the Data Distribution Management (DDM) service group [ NOTEREF _Ref439511481 \h  \* MERGEFORMAT 2].The data characteristics used for DDM are captured in normalized multi-dimensional spaces whose dimensions and values are specified by the federation (routing spaces).  Federations that would encounter scalability issues in a class-only mechanism can define their FOM and Routing Spaces to minimize the exchange of unwanted information.A high performance RTI needs to optimize the downcall and upcall operations associated with the federation data exchanges (e.g., minimize data copies, avoid queues or locks).  Federations may require significant throughput and elimination of unnecessary instructions can improve performance.On the downcall side the federation data is inspected, packaged, addressed, and delivered to an outbound communication channel that routes the data to the set of interested federates.  The upcall operation involves similar processing, where the data is received by individual inbound communication channels, inspected, and processed.Inspection of the federation data involves ensuring that the data characteristics and properties are correct (e.g., the updating federate owns the attribute being updated).  In RTI 1.3NG, the downcall operation involves operations on an abstract interface.  Various implementations of this interface represent all the possible states of the federation data. Depending on the state, the downcall will proceed or an exception will be thrown.  In this way, a comparatively slow evaluation of a conditional expression to determine the state is replaced with a comparatively fast virtual function call.The federation data is packaged in order to be delivered to the set of interested federates.  This packaging is RTI implementation dependent.  Additionally, it is potentially dependent on the mechanism used to exchange the information.  Part of this packaging may be the marshalling of the package structure that contains the federation data.  The RTI 1.3NG implementation uses the standard IIOP specification, which is a configurable representation enabling users to tailor the packing structure.A performance tradeoff between latency and throughput is configurable by bundling the data being sent to a common set of federates. The channel data can be aggregated into a larger packet, and the federation developers can tune the frequency and size of packets to increase throughput at the expense of latency.The logical addressing of data by the RTI is used to match the producers and consumers.  The HLA does not mandate the implementation or efficiency of the data routing mechanism, although better data segmentation may reduce the amount of unwanted data received by each federate.This addressing can be accomplished using a number of different techniques.  For example, the RTI used for the Synthetic Theatre of War (STOW) program implemented a static mapping of data types and Routing Spaces to communication channels.  This mapping was known prior to execution.  The RTI 1.3 implementation uses a destination-based routing mechanism.  With this scheme, consumers notify potential producers of their data interests and the producers try to reduce the number of uninterested consumers to which their data is transmitted.The RTI 1.3NG implementation recognizes the need for experience with some of the addressing and routing techniques.  Thus the implementation has planned for the ability to support future algorithms and experimentation.Time SynchronizationAttribute updates and interactions can be sent in timestamp order. A timestamp ordered (TSO) update is one that must be delivered to certain federates in order from the smallest timestamp to the largest timestamp.  A federate can only send TSO attributes and interactions if it is time regulating.A federate may or may not be time regulating. Time regulating federates limit the advancement of the global minimum federation time.  Such federates are unrestricted in advancing their logical time.  However the timestamps on any TSO attributes or interactions they send must be greater than or equal to their logical time.  Advancing their logical time signals the RTI that they will no longer send updates or interactions with lower timestamps.Time regulating federates participate in the calculation of the lower bound on the time stamp (LBTS).  The LBTS is used to pace the advancement of logical time across the federation.Time constrained federates are not allowed to advance their local logical time to a value larger than the current LBTS.  Only time constrained federates can receive TSO updates and interactions.  If there are no time regulating federates in the federation, the LBTS value for the time constrained federates is infinity.The time management algorithm used for the RTI 1.3NG implementation is based upon Mattern’s Global Virtual Time algorithm [].  The most important aspect of this algorithm is that the calculation of a new LBTS requires all packets sent since the last LBTS calculation to be accounted for before the new LBTS calculation can complete.  This accounting ensures that no message carrying a timestamp from the past (i.e., less than the LBTS) will ever arrive.In order to achieve this accounting, all TSO messages include a number, or color.  This color identifies which LBTS calculation had most recently occurred at the time the message was sent.  The RTI 1.3NG tracks the number of TSO messages sent and received as a function of color.  Once all the messages sent with a given color have been received, the new LBTS value is provided to the time constrained federates.It is important to note that the LBTS algorithm used by the RTI 1.3NG is a non-blocking algorithm.  Federates need not block awaiting a new LBTS value except when they are time constrained and are trying to advance their time beyond the current value of LBTS.  The LBTS calculation proceeds asynchronously with respect to the progress of the federation.In order to improve the performance of the RTI, more than one update (or interaction) can be bundled into a message.  A bundled message will potentially have multiple TSO messages with different timestamps.  This does not adversely affect our implementation of the LBTS calculation since the message is unbundled before it is counted.Lessons LearnedDesigning and building the RTI 1.3NG has proven to be interesting with respect to evaluating the many ways in which a particular feature or service can be implemented.  Viable implementation strategies often have unique characteristics that cause the competing techniques to be evaluated in terms of the patterns of usage, including performance requirements.  During design and development we found that proper internal abstractions within the RTI software would allow a single RTI implementation to be configured with different traits, and evolved with new or different techniques.  This framework style architecture also promotes iterative development, where initially simple implementations and algorithms can be built and system tested to refine requirements and improve capabilities.The categorization of objects in the RTI 1.3NG as either per-process, per-federation, or per-federate proved to be quite valuable.  This object decomposition closely follows the concepts set forth in the HLA Interface Specification.  Thus multiple federations each composed of multiple federates is very naturally represented in the RTI 1.3NG implementation.  The component categorization also provides a structure that does not waste resources when multiple federates and/or federations exist within a process.Although this object decomposition is somewhat unwieldy when paired with the functional API of the HLA Interface Specification, the use of polymorphism overcame some of these difficulties.  When the federate initially creates or joins a federation the RTI provides a reference to an abstract RTIambassador service implementation.  The particular concrete implementation of the RTIambassador varies dynamically based on the state of the federate (e.g., uncreated, unjoined, save in progress, etc.).Another design aspect of the relationship between the local RTI software and attached federates is that a single object is responsible for coordinating callbacks on the federate.  There are four classes of federate callbacks: receive order federation data,time stamped federation data,receive order administrative requests, andtime stamped order administrative requests.The RTI 1.3NG has implemented several queues that order and hold the callback command objects that are executed on the federate.Since the proper ordering of these callbacks in critical for semantic and sometimes operational correctness, centralizing the coordination of all callbacks is more robust than having federate callbacks occur from many points within the RTI software.  Additionally, these queues may have pending callbacks that need to be annihilated because of other operations (e.g, remove object instance).It should finally be noted that frequent regression testing of the implementation during development was invaluable.  It is expected that the regression tests will continue to provide great benefits during the lifecyle of the RTI 1.3NG.Author BiographiesSTEPHEN T. BACHINSKY is a senior software engineer / program manager with SAIC.  He received his BS and MS degrees in electrical engineering from the University of Lowell and Northeastern University, respectively. He has fourteen years of experience in simulation engineering; featuring synthesis, design, development, and analysis using various software tools, techniques, and technologies. He has led software development teams in the area of distributed simulation and infrastructure development. Recent responsibilities include the program manager for the RTI Next Generation and lead software architect of several reconfigurable, distributed, object-oriented, simulation frameworks.DR. J. RUSSELL NOSEWORTHY is the Chief Scientist of Object Sciences Corporation.  He received his BS and MS in electrical engineering from the University of New Hampshire and Rensselaer Polytecnic Institute, respectively.  He received his Ph.D. in computer systems engineering from Rensselaer Polytecnic Institute.  His research interests include distributed computer systems, real-time computer systems, and robotics.  He has 9 years of experience building large, complex, distributed computer systems, 5 years of which were using CORBA.  Before joining Object Sciences, he spent a year working in the Distributed Processing lab in Lockheed Martin’s Advanced Technology lab, where he guided several CORBA-based distributed programming projects.  Presently, he is the chief architect of the RTI 1.3NG activity.FRANK J. HODUM is a senior software engineer with SAIC.  He received his BS degree from Worcester Polytechnic Institute.  He has five years of experience in simulation design and development.  He has performed as team lead for an integrated product team in the development of a reconfigurable man in the loop simulator.  In addition, he has contributed to the design and development of a distributed, reconfigurable simulation infrastructure.  Currently he is responsible for the development of the time management portion of the RTI Next Generation. Here, “distributed communication” refers to distributed (including intra-process) object communications. Note that the CORBA IDL language binding can be used to separate the federate application and RTI component into two distinct, location-independent entities. The terms publisher and subscriber and producer and consumer represent two distinct steps in the HLA operational process.  Publication and subscription is a declarative step.  Production and consumption is an instantiation step. These federates are referred to as time constrained.  This is discussed below.PAGE  1References[] S. Bachinsky, L. Mellon, G. Tarbox, R. Fujimoto: “RTI 2.0 Architecture”, 98S-SIW-150.[] HLA Interface Specification 1.3,  HYPERLINK "http://hla.dmso.mil/" http://hla.dmso.mil/.[] R. Wuerfel, J. Olszewski: “Defining RTI Performance”, 99S-SIW-100.[] HLA Federation Execution Planner’s Workbook,  HYPERLINK "http://hla.dmso.mil/" http://hla.dmso.mil/.[] E. Powell, “The Use Of Multicast and Interest Management in DIS and HLA Application”, Proceedings of the 15th DIS Workshop.[] Adaptive Communication Environment (ACE), HYPERLINK "http://www.cs.wustl.edu/~schmidt"www.cs.wustl.edu/~schmidt.[] Mattern, F., “Efficient Algorithms for Distributed Snapshots and Global Virtual Time Approximation.” Journal of Parallel and Distributed Computing 18(4): 423-434. EMBED Word.Picture.8  