Verification and Validation, and Accreditation Cost Estimating Tool (CET)Robert O. LewisTec-Masters, Inc. Suite 2151500 Perimeter ParkwayHuntsville, Alabama, 35806 HYPERLINK mailto:blewis@tecmasters.com blewis@tecmasters.com256-721-6703 voice, 256-721-6330 faxAbstractThis paper addresses the development and use of the Verification, Validation, and Accreditation (VV&A) Cost Estimating Tool (CET). This tool is currently available and covers all types of models and simulations including HLA-based federations. The tool is a parametric cost model that considers the unique features and characteristics of each program based on its use case, calculates the effects of leveraging and risk and uncertainty, and then uses size of the software as a major variable, except for federations. Federations use a percentage of the development cost as the primary variable. The tool is able to handle unusual or extreme cases without difficulty. It captures both phase and non-phase specific other direct costs (ODCs) in an effective manner. The tool runs on NT 4.0 and WIN95 and 98, and requires no special software. It can produce an estimate in a few minutes and will be demonstrated as part of the briefing.Keywords: VV&A, Cost Estimation, Modeling and Simulation, HLA FEDEP, Legacy M&S, Federates, and Federations1.  Introduction            		The Cost Estimating Tool (CET) is a major part of the V&V Manager’s Toolkit, the first increment of which was sponsored by the TRADOC Analysis Center (TRAC) at Ft. Leavenworth, Kansas; and the second part of which is sponsored by DTC (old TECOM) Headquarters, Aberdeen, MD. The development began in the Fall of 1998 and will be concluded early in 2000. The current effort is directed only at Verification, Validation, and Accreditation (VV&A) projects, although process can be used for Independent Verification and Validation (IV&V) efforts as well with the substitution of the appropriate internal model. The CET is the third generation of costing tools and methodologies designed and developed by the author of this paper.  The first generation tool was called $ADVICE (pronounced ‘dollar advice’), which was designed for estimating and costing Distributed Interactive Simulation (DIS) projects (circa 1994). The second generation tool was integrated into the DARPA Computer-Aided Education and Training Initiative (CAETI) program (circa 1996).  Both of these earlier efforts lacked many of the improvements and features incorporated into this new tool.  The CET is able to provide much more accurate estimates than the earlier tools because of: 1) improved analysis of the models and simulations (M&S) to which the VV&A effort is being applied, 2) a more comprehensive set of internal models, and 3) a more sophisticated set of algorithms that include a multi-step tailoring process, a method for considering complexity and leveraging, and technique for calculating risk and uncertainty.2.  PerspectiveIn the past, cost estimating for VV&A programs has been largely based on coarse estimates of percentages of development cost, but this approach only works for new or recently completed modeling and simulation (M&S) efforts, and even then is not very accurate.  Unique attributes of each program tend to be ignored and each estimate done in this manner is little better than an educated guess.  This approach can yield especially poor estimates when used on legacy programs that have undergone several or many changes.  Should the initial development cost be used?  Should each modification be added to the total?  Should only the major changes be included?  This approach can produce a number two or three times higher than the cost of building a new M&S, so the idea of percentage of development cost can, depending on the circumstances, be either a very poor number or a rather good number.  Regardless, a percentage-based estimate is not good enough by itself, because it does not consider size and programming languages, complexity, use case, risk and uncertainty, unique characteristics of the M&S, amount of reuse, any previous VV&A history, and adequacy of the documentation for starters.  Further, it does not consider costs of subject matter experts (SMEs), tools, support software and hardware, communications and networking, travel and TDY, and any other extraordinary costs that may occur.  An example of extraordinary costs would be the burden of added live testing to support validation or having to spend a long period TDY at a test range.  Although these cases are somewhat rare, when they do occur, they create significant perturbations in the VV&A estimating process.  The important thing in the estimating process is to provide visibility and separate tracking for these items and not merely bury them in the overall cost, which could result in unfounded accusations of excessive cost. VV&A cost should always be reasonable and explainable.  The shortcomings of earlier cost models provided the incentives to develop a much more comprehensive cost estimating approach than has existed previously.  This new approach has to be able to cope equally well with the various types of M&S and their uses.  Thus, it has to support reuse of legacy M&S products with and without good VV&A history, legacy M&S with minor or major modifications, and new stand-alone M&S.  It also has to be able to adapt to and work effectively with other VV&A models such as that used by DTC.  Finally, it has to handle distributed simulations, most of which are rapidly becoming High Level Architecture (HLA)-based.  The new Recommended Practices Guide (RPG) being produced by the Defense Modeling and Simulation Office (DMSO) recognized this same set of problems and has tailored their latest product to provide unique solutions for each of these variations in HTML and traditional documentation formats.  The cost estimating approach described in this paper and the new RPG use the same basic VV&A process models to ensure consistency and compatibility between the cost estimates and the execution of the VV&A program. The tool also makes replanning much quicker and more accurate. 3.  Identifying the Generic Type of M&S and its Application Cost estimating is a complex process that first has to consider several things about the M&S to which the VV&A is applied. The first dimension of the problem is to identify the type of M&S and something about how it is to be used. The CET evaluates each M&S on an individual basis. The first five examples given below refer to stand-alone M&S products which can be considered federates or not.  (Federates are individual M&S products that are capable of joining HLA-based federations.) The major M&S types are described as follows:  The simplest and most economical example is a legacy product that is to be reused essentially “as-is.”  The concerns here focus immediately on the previous VV&A history and past experience from its users.  These VV&A programs are typically low levels of effort, with an occasional part that requires more significant effort.  It can be low as long as the prospective application closely resembles the original applications and the accompanying information, including VV&A history, is complete enough to support the new accreditation.  The second example is the legacy product that requires minor modifications to make it acceptable for the intended use.   In accordance with long-standing configuration management guidelines, we selected 30% change to the software as the cut-off point for defining minor changes.  Anything above this amount constitutes a major change or “heavily modified” legacy product.  M&S with minor changes typically require low-to-moderate V&V effort, depending upon which parts changed and how close it pushes the 30% figure.  The third example is the legacy product that undergoes substantial modification (>30%).  At this point, most of any prior V&V can no longer be trusted, so the V&V effort is essentially repeated with little reliance on historical data.  Nonetheless, there are some savings derived from the unchanged parts that are factored into the cost-estimating algorithm on a proportional basis. The fourth type is the new stand-alone M&S.  From a VV&A standpoint, this type and the heavily modified legacy product are about the same with a slight adjustment for reused parts in the legacy one.  Therefore, one VV&A model works for both examples with allowances for reuse, which can also apply to “new” M&S since there are numerous examples of reuse even in those that claim to be new products.  The fifth type is based on the DTC VV&A Methodology.  The DTC model has been included at the request of the second sponsor of the CET.  It is a comprehensive VV&A approach that is similar to those mentioned above and is tailored to unique attributes of the application. Its inclusion indicates the universality of the cost estimating approach used in this tool.  The sixth type is the distributed simulation.  These have undergone several evolutions in the decade of the 1990s ranging from the Aggregate Level Simulation Protocol (ALSP), to Distributed Interactive Simulation (DIS), to the current HLA-based federations.  Most of our distributed simulation emphasis in the cost estimating process is on HLA federations.  These federations are composed of several or many stand-alone M&S products that become federates when linked together.  VV&A of a federation assumes that federates come with a pedigree from previous VV&A.  Even so, when these federates are joined together, there is no assurance that they will behave correctly or provide the correct results, so a significant part of the federation development and execution process (called the FEDEP) is devoted to ensuring that this occurs.  It is not our goal to go back to square one and redo the VV&A of the federates; rather, it is to negotiate with the federate providers to do certain things to ensure their products work as required to support the federation requirements.  The basic assumption should always be that federate VV&A is not the responsibility of the federation developer.  To use a federate with an inadequate VV&A pedigree is asking for trouble during integration and afterward.  The VV&A of a federation is mostly focused on how well its overall mission is being met.  To do this requires understanding the scenario and analyzing the interactions, behaviors, fidelity, and performance of the elements represented by the federates in a total “system-of-systems” context.  Thus, even the key cost parameters for federations are different from other types of M&S, as discussed below.    4.  Key Cost Estimating RelationshipsIn our VV&A cost estimating process, all M&S except federations use the size of the software product as the most significant parameter.  VV&A estimates for federations, on the other hand, use a percentage of the federation development cost estimate as the most significant parameter.  Aside from these very different approaches, other parts of both estimating processes use many of the same process steps and factors to determine which VV&A activities to perform by phase and what their relative intensity should be.  In both cases, each activity is assigned a number referred to as “raw counts” to indicate its relative level of effort.  These are based on a significant sample size, surveys from experts, etc.  The raw counts are selected uniquely for each type of M&S application and are then tailored by several quality metrics.  Individual V&V activities in which leveraging is planned are reduced to a small percentage (10%) of the original raw counts; this is anticipated more in federation development than for any other type of M&S product because of the high degree of automated tools and amount of work done by the federation developer that does not need to be repeated by V&V.  (Leveraging is the process wherein V&V accepts and credits work done by others, e.g., the developer, as part of the V&V pool of evidence.)  Next, both estimating approaches introduce risk and uncertainty to weight the level of effort (now in “adjusted counts”) for each activity, but use a slightly different set of factors.  In both cases, the adjusted counts are totaled by VV&A step (or phase) and for the entire program.   In all cases except federations, the total adjusted counts are applied to an algorithm that converts them to a VV&A cost per line of code for the particular software languages involved, and then multiplies the resulting dollar figure by the number of lines of code.  There are several options to help refine the code counts, e.g., Function Points, Logical lines of code, etc.   The cost estimating process has to know what the average loaded man-year costs are for the VV&A staff.  In any case, the result is the cost of VV&A labor for the entire effort, which, because we know the distribution of counts by activity and phase, can produce their associated budgets in man-hours or man-weeks, etc.   The federation cost estimating process is quite similar up to the point that the process determines the total adjusted counts, which in this case are applied to a different algorithm than the one described above that used VV&A cost per line of code. In this case, the total adjusted counts are used to calculate a VV&A cost based on a percentage of the cost estimate for the federation development. Because federation development cost estimates typically include significant networking and communication costs, hardware purchase or lease, stealth viewers, support software, and numerous other non-labor costs, the number of primary interest is the loaded labor estimate, which is used for estimating the VV&A labor cost.  Although the percentage of development cost has long been used as an estimating technique for V&V effort, no V&V cost estimating process up until now accounts for the following factors in a quantitative manner: 1)  Specific task selection based on unique program characteristics, 2)  Adjustments based on program particulars such as adequacy of interim products and other quality metrics, 3)  Significant allowances for leveraging from work performed by other team members, mostly the developer and sometimes independent analysis and T&E agents, and 4)  Weighting by risk and uncertainty as well as complexity.  5.  Cost as a Function of Size or Development CostInstead of picking some arbitrary number of 5% of development costs for the VV&A of a reused simulation product or 10% for a new one, this estimating process considers the most significant program parameters in generating a cost figure that is much better aligned to the characteristics of the M&S, the needs of the program, and the amount of V&V required for credibility and accreditation.  Before going any further with a discussion on percentages of development cost as a basis of VV&A cost, several points have to be made.  For legacy products, the total “sunk” cost can be quite high and may have accumulated over many years and through many revisions.  It is, therefore, a poor number to use for estimating VV&A cost.  Unless you can identify the cost of individual versions and why they were built and then adjust these numbers accordingly (which is usually impossible), there will be serious skewing in the cost estimating process.  A much better approach in this case is to use the size of the product that will be reused, identify its software languages (which have a very large effect on cost per line of code), and determine as necessary how much is new versus reused.  This technique is even used for new stand-alone M&S, but in that case must be based on development “estimates,” not actual counts, as well as other items and issues.   The approach of counting lines of code in estimating VV&A costs for federations makes no sense.  Would you count the code in all the federates? No!  Would you count the code generated in interfacing all the federates to the federation?  Probably yes, but the result would not be a significant factor in the overall estimate and is very difficult to use.  This line of questioning can continue, but for federations an answer based on product size always comes up short.  Fortunately, the sponsor and developer have to make a rather significant planning investment in order to estimate the cost of developing the federation.  The development cost estimating process is based on many variables that contribute to the overall understanding of the effort, blended with the experience and systematic estimating process of the development team.  In this case, there is intrinsic safety associated with basing the VV&A estimate on the development estimate not found in any totally independent form of estimating.  A VV&A estimate tied to the development estimate assumes that if the development scope changes significantly, then VV&A will receive a similar adjustment.  This should work in either direction, so there are a number of self-regulating aspects to this type of estimate that protect the sponsor’s and V&V agent’s interests.  Since the problem is multi-dimensional, the developer’s estimate needs to reflect good knowledge and quantification of the following, which benefit the VV&A planning as well:The use case – this example is a new or modified reused HLA federation. A clear understanding of the user and sponsor needs and objectives of the federation. A clear delineation of roles and responsibilities of each participant in the development effort, and how the organizational interfaces with operate (including VV&A).   Relative idea of the number of federates and their entities and how they are expected to interact in their configuration, including the geographically separated federates.  This helps scope the magnitude and difficulty of the total effort.Specific answers to questions about the federation requirements, conceptual model, input data quality, and stability and appropriateness of the federates.Estimated level of effort (LOE) or cost for end-to-end execution the FEDEP for this federation.Estimated level of effort (LOE) or cost to interface the federates to the HLA RTI and simulation infrastructure (common databases, synthetic environment, networks, etc.)  Risk and uncertainty of the program and how these factors affect the cost.The estimated size of the new software and its relative complexity (this helps bound the problem and provides sanity checking.)Measure of federation complexity as measured by the different types of interactions. A list of other direct costs (ODCs) such as tools, facilities, communications, SMEs, support software, TDY, travel, etc. (The V&V agent needs similar data.)Average man-hour, man-month, or man-year cost for the staff.  (The V&V agent needs similar data.)From these factors, the developer can produce a relatively accurate cost proposal for the effort.  Because of the scope and comprehensiveness of the developer’s cost estimate, the VV&A estimate for federations can then be tied to it as a percentage of that cost.  In this cost estimating process, this VV&A percentage is not a fixed number; it is calculated based on program characteristics, amount of reuse, leveraging, risk and uncertainty, etc. in much the same way as for the other types of VV&A.  As mentioned briefly earlier, the ratio between FEDEP labor costs and VV&A labor costs is the key estimating relationship, but it is modified by the risk and uncertainty, leveraging, and complexity of the product.  Then, the ODCs for the VV&A effort are accounted for separately and usually have very little correlation to the ODCs for the FEDEP.  ODCs for the VV&A effort are usually a much smaller percentage of the total VV&A cost than they are in the federation development since VV&A usually has free use of the federation infrastructure.  6.  What Constitutes a Good VV&A Estimate?Use of terms like “good, adequate, reasonable, and relatively accurate” in VV&A cost estimating means that the activities and tasks outlined for the effort can be accomplished effectively and thoroughly, but not excessively. The term “should-cost” figure is very important since it is produced independently of other inputs, influences, and outside budget constraints.  Thus, this figure is what an adequately funded and supported VV&A effort for the particular use case should cost.  This should be the budget; then, if conditions change during the development of the product, the VV&A budget should be reviewed to ensure it still correctly represents the required effort.  Real-world constraints sometimes affect the VV&A budget.  A typical scenario finds someone on the decision-making side of the program decides that the VV&A budget should be a specific dollar amount or percentage of the federation development cost without developing a scientifically-derived budget.  Sometimes these numbers are above the should-cost figure, and sometimes they are below.  The sad part of this “shoot from the hip approach” is that it has promoted occasional criticism concerning the high costs of VV&A.  Conversely, it also results in VV&A efforts that are woefully under-funded, which in turn, fosters criticism that the VV&A effort could not do everything that needed to be done.  Either way, VV&A takes the heat for lack of a scientific cost estimating process.  The estimating principles and factors in this tool will not enable “extreme” estimates to be generated in the first place.  Validation of Some M&S Can Present a Serious Estimating ProblemIt can be argued that there are simulations that are very difficult to validate for any number of reasons, most of which are based on assumptions that either the phenomena or physical properties of the things being modeled, their complexity, or the highly stochastic nature of the outcome is too nebulous to measure accurately and consistently.  Although this is true in some cases, they can be successfully managed and supported by effective VV&A efforts as long as the sponsor recognizes the limitations and constraints imposed by the results.  Some would call this “best effort” while others would systematically divide the problem space into parts that could be effectively and reasonably validated and those that could not.  Evidence and test results would be collected for as much of the problem space as possible and subjected to more traditional forms of validation and analysis, while a team of SMEs and other experts would be convened to perform face validation and perhaps perform advanced statistical analysis on the more difficult remaining parts of the simulation or model.  The point is the V&V agent has to know where the point of diminishing returns occurs and should try to stop just short of passing it.  Because this estimating process has several very effective checks and balances built in, the sponsor can readily see what the VV&A effort is proposing to do for the assigned budget.  If the sponsor wants to increase the V&V effort in specific task areas to help overcome these difficult validation issues, so be it.  This can be accomplished in one of two ways:  1) Specific Validation tasks, LOE, and costs are added under the Validation Phase column in the Extraordinary Costs worksheet.  This is the preferred method because it does not impact other VV&A tasks, still provides a reasonable plan and estimate, and allows all of the extraordinary validation activities to be tracked, managed, and accounted for separately.  2) If the extraordinary validation activities can be rolled into the pre-defined validation activities by maximizing the adjusted counts through tailoring, this is also acceptable.  It does, however, impose more effort on behalf of the planner, who must enter data, examine the results, and tune the estimate until the correct answer is derived.    Both options above require that the planners prepare a separate estimate for this extraordinary validation support, which is another reason Option 1 above is preferred, since it is much easier to incorporate these figures into the estimate and V&V plan.  Regardless of the option used, the VV&A planner is cautioned to not be carried away with an overly ambitious validation effort.  If the developer built the M&S in the first place, but the validation looks very difficult, there may be some flaws in the assumptions concerning how to perform the validation effort or what must be done to provide essential credibility.  Full cooperation is required among all the participants to come up with a balanced, leveraged, and cost-effective validation plan and estimate.  If the sponsor studies and accepts the V&V Plan with the levels of effort proposed and the V&V agent performs the specified work, yet there still remain unreconciled validation objectives, it may be that the goals are unrealistic within the available resources.  Use of outside experts, SMEs, and additional budget to extend the validation effort are all possible options.  Option 1 above is also preferred when these shortcomings in the validation effort are discovered during testing.  It is easier to add a separate task than to rework the entire V&V plan and estimates.  This remark is not intended to be snide, but validation often continues until the agent runs out of time and money.  The fact remains that there will always be a few isolated examples of very difficult validation problems that require some serious planning, study, and collaboration among the developer, sponsor, user, and VV&A to come up with a reasonable, workable solution.  Along these lines, if the thing being modeled is so poorly understood that it cannot be validated against some referent, then the model may be a poor choice or an inadequate representation or implementation, and its use should be discouraged. When dealing with stochastic and chaotic systems, there are powerful mathematical tools that support the modeling itself and its validation; these should support both efforts.  It also appears that models of human behavior fall into this category and can be handled in much the same way as the more traditional M&S discussed thus far.  A final thought involving difficult validation problems is that all the testing effort conducted by all participants combines to form the basis for validation.  The V&V agent needs to be able to pull from all these sources those things that are most germane to the ultimate credibility and accreditation of the M&S product, regardless of its type and application.   To this end, sometimes the best solution is knowing where to stop.  It should be noted that even when an M&S is adequately validated for one application and its particular scenario(s), it may no longer give valid results when these factors change. Thus, validation never ends.  The decision to stop should be reach mutually by all the participants in the program so that everyone agrees, and no one group feels burdened by too much responsibility for the success of the program. 8.  Overview of the Cost Estimating Process and ToolFigure 1 depicts the generalized cost estimating process, which is embedded in the tool.  The following briefly describes the major steps in the estimating process:Step 1: Once the prerequisites are completed, there is a short set of questions that determines the appropriate VV&A model—legacy with or without modifications, new stand-alone, DTC, or federation.  Once these are answered, the program takes one of six internal paths tuned to each type of model application.  As additional models are added, the number of internal paths will increase accordingly.  EMBED Word.Picture.8              		Figure 1.  Cost Estimating Process Flow DiagramStep 2: The second set of questions allows the tool to perform fine tuning of the VV&A application model selected in the previous step.  In this step, consideration is made for the quality and completeness of the documentation, conceptual model, interface definitions, input data, leveraging, etc. that can affect cost of the V&V effort.  The more rework required by the V&V team, the higher the cost.  Step 3: Next, the user of the tool is required to select his/her best estimate of the M&S program risk and uncertainty (R&U) factors based on a 15-question matrix. Values selected can influence the adjusted raw counts by as much as (50%; however, those ranges are seldom experienced.  Typical increases and decreases range between 5-15%. The output of the tool at this point is expressed in adjusted counts from the previous phase as modified by the risk and uncertainty calculations. Risk and uncertainty (R&U) propagates down through the VV&A activities for each application model in a unique way.  Everywhere the R&U issue impacts a particular VV&A activity, the internal tool matrix gets a “hit.”  The user does not have to do this; it is already pre-determined.  High impact or high priority R&U issues get more hits making the weighting greater. Steps 4 and 5: Now the development cost for federations or the size and complexity factors are introduced based on the languages being used in the software.  The first resulting set of calculations is an estimated level of effort (LOE) for every task.  The tool user enters the average cost per man-hour and the tool converts the LOE to cost in whatever money system is desired.  The default is U.S. dollars.  The total is the “should cost” labor figure and is available by activity, phase, and total program.  Step 6: Almost always, a VV&A effort will have to pay for extra cost items that are not included in the labor estimate.  These are entered into the overall cost spreadsheet in two forms—phase specific and non-phase specific costs.  It is here also that extraordinary costs pertaining to any feature of the VV&A effort should be added and tracked separately.  It was mentioned earlier that if the M&S appears to be particularly difficult to validate, and the traditional validation activities in the VV&A application model do not seem adequate to support the effort, here is the place to add an independently planned and estimated adjunct validation effort.  Having it here also provides a mechanism to track its progress and costs separately from the other more predictable in-line VV&A activities without skewing the plan.  This is definitely the recommended way to handle difficult VV&A planning and estimating problems. It is not appropriate to load the normal VV&A cost estimate with these numbers unless the PM recommends this action, and is able to explain why the V&V costs are so disproportional to the average for this type of application.  When such an extreme case is being considered, the effort should be priced separately and not merely buried in the overall VV&A cost without the full knowledge by all participants and disclaimers to the VV&A effort that explain the reason for the unusual cost elements. Otherwise, VV&A gets an undeserved reputation for fostering high cost efforts, and has no way to deny the allegations if such costs are anonymously folded into the bottom-line cost.  Every effort should be made to protect VV&A from these types of accusations.  After extra costs are delineated, the total cost of the VV&A program is calculated.  Step 7: The final tailoring occurs when and if the sponsor has a number in mind for VV&A that disagrees with the “should cost” figure derived from the CET.  The tool user can now adjust the VV&A activity matrix to reach the budget number, if directed to do so.  The R&U values can be changed, the leveraging can be changed, tasks can be raised or lowed in scope and LOE, etc. to converge the numbers.  However, if the VV&A tool user has to go more than 15% to reach a match by reducing the VV&A effort, the true risk to the program will go up at least that much.  In such a case, the tool developer urges the tool user to recheck all the values, call the help line if necessary for confirmation and discussion, and then take the results to the sponsor for final in-depth discussions and resolution.  Having the extraordinary costs as separate accountable and trackable items is a very effective way to negotiate the best value, least-risk VV&A effort regardless of the budget.  9.  Saving the Best Part for LastThe tool is available free of charge to anyone who wants it by contacting the author at the address on the first page.  The operational version (V1.0) is currently available.About the authorRobert O. Lewis is a senior analyst at Tec-Masters, Inc. in Huntsville, AL.  He has developed three cost tools over the past six years and is currently supporting the Defense Modeling and Simulation Office (DMSO) in the production of a new VV&A Recommended Practices Guide (RPG).  He has recently performed both IV&V and VV&A on the National Missile Defense (NMD) Program.  He has been very active in the Computer Simulation Conferences and Simulation Interoperability Workshops in the past and has authored more than 20 papers in the past five years.  He contributed to the current RPG, IEEE 1278.4, and several other VV&A publications including DA PAM 5-11, and the VVT&E process for DARPA’s Computer-Aided Education and Training Initiative (CAETI).  He has taught 60 short courses over the past 16 years and wrote a popular textbook on IV&V published by John Wiley & Sons. The VV&A models included in this tool, except for the DTC model, were co-developed for the TRADOC Analysis Center (TRAC), our initial sponsor, and the Defense Modeling and Simulation Office (DMSO) produced Recommended Practices Guide (RPG) currently under development.  The use of these models in the CET should not be construed to represent views of TRAC, DMSO, or any other organization or agency, private or public. The DTC model is the property of the Development Test Command and was supplied to TMI for inclusion in the CET.  Modifications to its model were done with the approval of DTC.  The HLA Federation Development and Execution Process (FEDEP) VV&A Overlay used in this tool was generated to support cost estimating and has not been approved or authorized by DMSO at the time of release of Version 2.