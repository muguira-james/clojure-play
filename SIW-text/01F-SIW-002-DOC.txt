Distribution,Use and Reuse:Questioning the cost effectiveness ofre-using simulations with and without HLA.Jean-Louis IGARZA and Christian SAUTEREAU(NATO/ RTA/ Modeling &Simulation Coordination OfficeDGA/ DSP/ Centre d’Analyse de Défense, France)33 1 55 61 22 77, 33 1 42 31 90 69igarzaj@rta.nato.int, sautereau@cad.etca.fr Key-words : simulation support environment, development methodology, distributed simulation, HLAABSTRACT : The idea of simulation support environment (SSE) was born in the 80’s. SSEs generally provides simulation developers and users with a development methodology and a generic toolkit for designing, elaborating and running stand-alone constructive simulations. At the present time, different products are available: either COTS or GOTS. Utility of SSEs is rarely questioned, but, so far, it seems that they have not been very successful, or widely used. They intrinsically suffer from some limitation, since they confine the user in the strict context of a dedicated development environment and restrict them for using specific hardware/software combinations. Nevertheless, they are generally recognized as providing an actual capability for reusing simulation components in different applications.In 1995, the HLA was invented and promoted by the US DoD. Since then, the HLA standard has raised much enthusiasm and probably also some reservations. Nevertheless, HLA was largely adopted, either to mandatory or voluntarily approaches. The HLA is generally considered by the M&S community as a very satisfactory approach of interoperability and reuse. This second capability has been developed with the HLA at a different level than SSEs, since HLA is supposed to support the reuse of complete simulations, whereas SSEs allow the reuse of simulation components within a specific environment. Six years after its creation, the HLA has reached a satisfactory level of maturity thanks to experienced developers and users. The acceptance of a new version of HLA as an IEEE standard confirms this fact. Nevertheless, using HLA has been proven to be sometimes difficult and requires the selection of a good project leader, smart developer teams and  to adopt a high level methodological approach. So, in some cases when manpower and funding are scarce and when distribution is not specifically required for the foreseen application, developing stand alone applications based on a well suited SSE can be preferred to an HLA based distributed approach. As an example, in the operational analysis domain, the use of distributed simulation is rarely required. In some other cases, a SSE could even strongly support the development of HLA compliant federates. Hence, both uses of SSEs and HLA are not incompatible, they are even complementary: it can be demonstrated that SSEs are useful for developing HLA federates and, conversely, that a HLA federation is not the only way for reusing simulation software.The purpose of the presentation is to describe both reuse strategies (reuse of simulation components versus reusing whole simulation federates) and to try to assess their cost effectiveness in some applications. Some advice and recommendations will be provided.Introduction1.1. ContextIdeas and recommendations expressed in this document are strongly influenced by the background of both authors and people they worked with during some fifteen years, in the French Center for Defense Analysis (CAD, Centre d’Analyse de Défense, a technical center of the French Ministry of Defense). Authors experience lies mainly in the operational analysis domain. Therefore, their knowledge relates largely in pure software and “non real time” simulation, now referred by the M&S community to “constructive” simulation. It will appear from the following statements that other applications domains of simulation like “live” or “virtual” are not discussed. It is the responsibility of the readers to imagine how general ideas apply to their own business domain, but since the importance of software in the simulation domain is growing, it is hoped that expressed recommendations may help many people.The following statements reflect only personal feeling of both authors and are neither the official view of NATO, nor of the French MoD.1.2. Purpose of the paperFor more than ten years, the general philosophy of “re-use” and “re-usability” is largely accepted by the M&S community and, more generally, by national and international defense organizations. A clear demonstration of this assertion can be found in both M&S Master plans of the US DoD (1995) and NATO (1998), since “Interoperability and Reusability” are mentioned as primary objectives in both documents. From the experience of the last ten years, the requirement of interoperability between simulations is rarely discussed. But some authors have expressed some reservation or even a concern about the possibility to actually put in practice the reuse paradigm.Curiously, reuse of M&S was rarely discussed until recently, as if people were convinced that it’s obvious and easy to reuse simulations partly or globally. Conversely, past experiences have demonstrated that reuse could be difficult and not always cost-effective (see, for example reference (3)). Nevertheless, the intention of both authors of the current paper is not to negate the reusability idea, but to question the efficiency of the way we are currently trying or plan to practice it. Some recommendations are made to help derive more benefits from reusing what have been developed in the past.1.3. Definitions: reuse and re-usabilityThe following definition is proposed from the glossary of the NATO M&S Master Plan:Reuse:“The use of M&S resources, (e.g., models, simulations, databases, algorithms, tools) for purposes beyond those for which they were originally developed. Reuse can occur within an organization or in different organizations, or in different application areas.”From this definition, we can derive that “Reusability” is the capability to reuse M&S resources according to the above-defined meaning.Two comments. First, as expressed in this definition, the reuse concept is very general, since it refers not only to complete simulations, but also to what is composing them. Second, the organizational issue is clearly mentioned. Both remarks are suggesting that different types of reuse can be considered.Simulation Support Environments (SSEs)DefinitionThere is neither official nor widely accepted definition for a Simulation Support Environment, but from a general understanding, a SSE can be defined as “a collection of methodologies and tools which allow to design, develop and run simulations on some types of computing platforms”.To be more specific, SSE tools should provide very general functionality that avoids developers to “reinventing the wheel” every time they build a new simulation. The SSE idea stands on the premise that 30% to 60% of a simulation code is dedicated to the implementation of very general services such as graphical user interface, logical time management or entities management. All those very general services can be grouped and offered to developers under the form of service sets (time management, object management, visualization management, data collection management, interoperability management, etc.), which can be used and reused from one simulation application to another one. Other parts of the simulation code are exclusively devoted to what is the noble aspect of the simulation: modeling entities, behaviors and interactions.The SSE concept is really not a new idea: first products developed and/or used by both authors were written in FORTRAN computer language in the seventies… But, curiously enough, even if the great benefits of using such concepts and tools are obvious, SSEs have not been so widely successful, nor largely adopted. Reasons for that will be mentioned later.Currently, many different SSEs are co-existing. All are specific to different communities of users. They can be either commercial (COTS), made available by government organizations (GOTS) or even free software. In some cases, they also offer to simulation developers some basic sets of low fidelity components (such as aircraft or missiles models) allowing them to rapidly develop simple but typical simulation applications becoming familiar with the SSE use.Adopting either commercial or government products have advantages and drawbacks to be shortly discussed further.A typical example: the ESCADRE SSEReaders familiar with the ESCADRE SSE or, more generally, with SSE concepts can omit this paragraph 2.2. and go to paragraph 3.In French, ESCADRE means “Environnement de Simulation en Conception orientée objet et Ada95 pour le Développement et la Réutilisabilité des Etudes”, that can be translated into “Simulation Environment based on object oriented design (OOD) and Ada language for development and reuse of studies”. ESCADRE has been introduced in previous SIW papers (reference 5 to 8) in more details: it is shortly described as a typical example illustrating what is a SSE and keeping this paper self sufficient. The ESCADRE SSE provides simulation developers and users with a methodology and a toolbox for developing and running constructive simulations for operational analysis, feasibility studies of future systems and their design, etc. The ESCADRE toolbox offers to users common services such as object and interaction management, logical time management (events scheduling and continuous state-variables integration), and a graphical user interface based on X-Window/Motif (largely available on commercial platforms) etc.The current version of the ESCADRE tool set is written in Ada95 and provides only an Ada95 API for ESCADRE based applications. Developers use the framework to build new simulations using building blocks. To fully benefit from the process, they have to construct and manage repositories of object classes and interactions, allowing them to customize new and legacy applications to specific requirements.ESCADRE has been regularly upgraded and used since 1987 for building simulation applications, by French government organizations and some industry of defense companies. Some tens of current simulations are based on ESCADRE and as the user community is continuously enlarging, it seemed obvious in 1997 that a new ESCADRE version supporting the HLA should be profitable in the near future. Then, the first version of ESCADRE supporting HLA became available in November 1999 and the first ESCADRE-based federate was certified HLA compliant by the US DMSO in June 2000. The most recent ESCADRE API provides now a user-friendly interface with RTI services. The ESCADRE methodology has also been modified to comply with specific object oriented programming features such as the inheritance paradigm or, more generally, the HLA concepts.Historically, the initial requirements that led to the development of ESCADRE were the following: the need for rapid development of study simulations from frequently imprecise, inaccurate and quickly-changing specifications in relation with requirement evolution,the need for simulations that were flexible, reusable (wholly or partly), easily maintainable and portable (in order to take advantage of the continual progresses in computer science and hardware).The origin of the ESCADRE history lies in the mid-80s, when the simultaneous emergence of object-oriented analysis methods and of the Ada83 language fostered the creation of the SSE. It was designed to cover the entire simulation life cycle from design to implementation. ESCADRE became operational in 1987 and has been improved many times since then, thanks to its constant use. It has demonstrated its portability, mainly thanks to the quality of the Ada language: it was available on DEC computers (VAX and Alpha, running under the OpenVMS operating system), Unix workstations (Sun/Solaris, IBM-RISC 6000/AIX, SGI/Irix, HP/UX, PC/Linux) and on PCs running under Windows NT.The ESCADRE main advantages are that it offers a very natural approach, yields easily reusable modules, facilitates software maintenance by allowing encapsulation of the various aspects of an abstraction and hiding implementation details.2.2.1. The ESCADRE methodologyThe ESCADRE methodology is based on an object-oriented analysis and software design, a variant of the methodology advocated by Grady BOOCH in 1985 (see book references in 4 or 5). This results in application architecture very close to the specific structure of the actual problem. The designer is identifying the main actors in the scenario to be simulated (aircraft, missiles, etc.), the existing organized interactions (hierarchical or horizontal) and the antagonist scope for detection and monitoring using their sensors. The grouping of the actors into object classes confers flexibility in the dimensioning and constitution of the scenarios, while the structuring, modularity and hierarchical arrangement of classes foster validation of the simulation's components and their reuse in other applications.Th original methodology has been significantly modified, during the ESCADRE lifetime, for example, when the OO inheritance and HLA paradigms were introduced, but the original philosophy and concepts have been kept over time.2.2.2. ESCADRE tool boxESCADRE is based on an Ada95 software library. It allows coding of both "class" objects components and interaction object modules, modeling the behavior of the simulated actors and their interactions. ESCADRE is generally considered as user-friendly. Main generic services provided to users by ESCADRE in each step of the simulations life cycle are the following:Pre-processing:Data preparation services: management of 2 categories of files: the first type records technical attributes attached to the simulated weapon systems, the second kind is related to the description of operational parameters and general features of scenarios. All these data are managed using libraries of files, closely reflecting the overall structure of the application. A ‘random seeds manager’ is also used to initialize the seeds of random generators (all usual stochastic variables are available).Background manager: it provides a tool to construct natural environment databases (based on common data standards such as DLMS for terrain) when preparing runs. At runtime, the background manager provides also efficient access to the adapted environment database (such as altitude matrix to compute line-of-sight) or associated visualization features (such as contour lines, vegetation, roads, rivers, etc.) according to the level of details to be displayed.Run-time servicesThe ESCADRE engine manages objects and their inter-actions, as well as the logical time (events and continuous state variable computation). Execution can be monitored either on a pre-defined period of time or event by event.A simulation controller is available: it provides execution supervision, on-line graphical display monitoring, on-line queries to the actors and interactive monitoring of their behaviors as implemented in their programmed models. A log of main events is displayed and recorded in a journal file. Different tracing thresholds (which can be modified on-line) are offered.A data logger (recording relevant information) is also available. Selected output variables are gathered and processed during the run of the simulation in order to provide statistics for off-line exploitation of simulation output.Post processingESCADRE offers a statistical processing tool for statistical computations and display of results under textual or graphical form (such as bar or pie diagrams).A graphical visualization "re-player", a journal viewer and editor (text file) are also available.General featuresThe three phases (pre and post processing, run-time) use the same textual or graphical. ESCADRE is potentially multi-lingual: both menus in French and in English already exist and, for other languages, a simple translation of the menu titles in this new language has to be achieved and recorded in a file. The language can be selected by initializing a single variable when starting the simulation. The ESCADRE supporting documentation is available either in French or in English (thank to Singapore users who kindly took care of the translation from French to English).2.2.3. Conclusion on the ESCADRE SSEIn use for fourteen years and recently supporting the HLA standard, ESCADRE has demonstrated its timelessness and should stay in use for many years to come. The ESCADRE methodology and toolbox are typical of similar developments in many countries. Among these, without mentioning commercially available products, one might mention the US DoD J-MASS (Joint Modeling And Simulation System), undoubtedly one of the most ambitious products. Similarities between all SSEs and their key concepts vindicate for a larger use of this kind of product.Benefits of using SSEsThe main advantages of using SEEs appear to be obvious and are listed below:They save time (mainly) and possibly some money,They allow users of a common SSE to share the same culture, to adopt a common discipline in their familiar environment,Models of entities and interactions are natively interoperable within the same SSE framework (maybe, using a neologism such as “intra-operability” is more accurate),They allow developers to concentrate more on “noble” tasks such as modeling of military systems, the primary interest of military customers,Finally, SSEs are supposed to favor reuse in a way that has to be more thoroughly discussed.But, the main and great advantage, rarely emphasized in the past, is the following one. It is illustrated by an attractive image first introduced by Dwayne Nuzman, from the US Army AMSAA, some years ago:Effects of continuous evolution of the state-of-the-art can be compared to folks trying to climb an escalator going down. On a similar way, continuous evolution of information technology tries to attract your current software downstairs. You are continuously fighting to maintain it upstairs, trying to stay in track with the technological progress. This process is extremely time-consuming; in fact, it is difficult and expensive to update applications trying to keep them on the top. Relying on an efficient SSE able to be improved in consistency with the state-of-the-art is the single solution. The history of ESCADRE illustrates this process, since its capability to evolve and to integrate new but useful features such as new graphical visualization tools or HLA functionality has been demonstrated.SSEs are protecting applications from rapid obsolescence provoked by technological progress in introducing evolution advantages. As a result, they can be considered as efficient “technology filters’.Some drawbacks of SSEsAll the above listed advantages should not mask some SSEs’ drawbacks that have to be recognized. At this point, we shall underline the difference between commercial SSEs and governments ones. Usually, government SSEs are provided free of charge for official use, but may have usual characteristics of free products, unless a support team is funded; for example, limited support, some limitations in functionality or lack of adequacy for some specific purposes. A real political will is required to impose a government SSE and, more important, to support it, taking into consideration that new or evolving budgeting constraints shall not prevent to do it.Commercial SSEs should not normally suffer from those drawbacks, but the experience has shown that they suffer from other limitations:They are generally costly: expensive developers’ licenses and runtime fees are current practices,Developers’ teaching and training can be time consuming and costly,Their timelessness is limited by both the evolving state of the M&S market, the health of the vendor companies and possible changes in distributor policy,Sometimes, they have demonstrated their poor capability to evolve, to be adapted to specific requirements, so, from this point of view, the selection of a good SSE is risky One important issue is that they naturally confine the user on dedicated platforms (hardware and operating system), because the portability does not seem to be a concern for vendors; rarely are the SSEs available on all current platforms; another side effect is the possible reluctance of some contractors to use a product developed by competitors and consequently a de facto monopoly of vendors,But, for both authors, the main issue is a general lack of adapted methodology: provided tools are generally very good, but, frequently, the only advice given to developers is to rely on some OO methodology and on the Unified Modeling Language (UML). Unfortunately, that is not sufficient to design and code an application all the more than many SSEs are difficult to use.Not all products suffer from these drawbacks, but experienced users can recognize some features of their favorite toolbox!How reuse is supported by SSEsFirst, generic tools themselves are reused: remember the magic number 30 to 60% of the code! This is already a great benefit.Complete simulations can sometimes be reused in their totality, but SSEs favor mainly reuses of components: models of entities and interactions. Algorithmic parts can also be reused, but this can be sometimes difficult, unless both good modularity and clean interface are provided.A general condition of good reusability is the obligation for a component to be as far as possible self-sufficient and independent from other components. In that meaning, the inheritance concept is somewhere risky because it can hide some dependencies. That fact should motivate designers and developers to document as far as possible those dependencies. A good philosophy should be to minimize the number of inheritance levels and also to limit the use of multi-inheritance as far as possible.Generally, components are reused within a unique SSE, but for interoperability reasons, it would be nice if components developed under a specific SSE could be reused again in another simulation developed under another SSE. Unfortunately, even if it appears as a seductive approach, the experience has proven to be difficult and for some obvious reasons:Coding languages are not always compatible (without the noticeable exception of Ada (and sometimes C++) which can interface with other 2nd generation languages such as FORTRAN, COBOL or C),But, the main difficulty lies in the underlying concepts, for example, the “Object” or “Interaction” paradigms that can be very different from one SSE to another, even using the same vocabulary! For example, between ESCADRE and J-MASS the interaction paradigms are very different and this is not the only difference.The ESCADRE experienceThe ESCADRE experience has demonstrated that good components can be reused many times. More frequently, those components are “object classes” (called “actors” in ESCADRE), but interaction classes (called “properties” in ESCADRE) are also reused if they have very general features. Components in ESCADRE are generally offered as Ada packages (the preferred self-sufficient compiling units in this coding language). This example of reuse capability shows its own constraints and generally occurs within a limited community for the following reasons:First, the need to protect sensitive military knowledge,Second, the integration of some confidential industry models provided by different companies, coexisting and cooperating within the same stand-alone applications can only be achieved within neutral government centers,Third, the requirement to establish shareable component repositories, which is an unavoidable investment to establish an effective reuse policy, whatever that policy may be.Within the French center for defense analysis, the ESCADRE component libraries are organized in technical and/or operational domains, each of them having a designated custodian. Custodians are responsible for the documentation and the validity of components they offer. The responsibility of developers when re-using components is to adapt them to their own requirements and to re-validate them when integrated in a new specific application. After having used them, they shall return new versions they developed back to the custodians for new possible reuses…When a new version of ESCADRE is announced, another responsibility of custodians is to update the components they offer, in consistency with the new version. Such updates are just technical, with the purpose to allow components to run under the new version of the SSE, just as they are, without significant changes. When really new features or tools are provided within a new version of ESCADRE, it is the responsibility of re-users to use them (or not) in their future application. Generally, two versions of ESCADRE are simultaneously maintained to facilitate smooth transitions for developers and users. Obviously, this policy shall be replicated in component repositories that should also provide two generations of components.Provisional conclusionRe-using components in the same environment has been proven to be affordable and useful. But, the ESCADRE experience has demonstrated that such a reuse policy is only viable in small communities, due to confidentiality restrictions, some political constraints and, mainly, communication and cultural issues.The reuse of components is efficient only if some investment is available, in providing support to SSE users and establishing component repositories with an adapted configuration control.Furthermore, the high quality of available components is an essential pre-requisite for an efficient reuse. More specifically, three conditions are imperative:Readable, documented and efficient code,Verification and validation of stand-alone components,Re-validation when reusing code in a new simulation context.These are the three primary conditions for a success.The High Level ArchitectureIntroductionThe High Level Architecture has been described in sufficient details in already published and excellent documents. Related information can be freely accessed either on the US Defense and Modeling Simulation Office (DMSO) site or, for SISO members, in SIW tutorial presentations and/or former papers. So, it is postulated that people reading this paper are sufficiently knowledgeable in HLA. The HLA has two main objectives: technical interoperability of simulations and their re-usability. Usually, the objective of interoperability is the main concern of the M&S community when discussing the HLA. This paragraph is mainly focused on features of HLA supporting the reusability objective.Finally, it is important to underline that the HLA reuse concept is generally addressed at the application level and not at the component level in comparison with the Simulation Support Environment idea, even if developers are generally interested in re-using only a part of a simulation application.Misunderstandings about HLA and some false and real drawbacks,HLA has been frequently advertised in the past and information has been made widely available. Nevertheless, it is quite surprising to realize how HLA is misunderstood and wrongly criticized.Some frequent misunderstandings have to be recalled and if possible avoided in the future. For instance, many times, HLA is believed to be just another SSE, maybe a more ambitious and very general one, but just a SSE. Some people were confident that the logical time within their application could be managed by the RTI time management: it was a frequent feeling that the RTI was a standardized simulation engine! It should be recognized that some words or used sentences were confusing, when separated from their context. For example, the “Kaminsky directive” of September 1996 induced a real confusion in France, stating that: “… I designate the HLA as the technical architecture for all DoD simulations”. After that firm declaration, some new French development contracts stated that new applications should be developed under the HLA, without any clear interoperability requirement, nor real reuse motivation! Probably, that the “architecture” concept as defined in the information technology community is not largely well understood. Just to provide another example, a Fall 2000 SIW paper stated that the HLA prevents the use of “information hiding” and “encapsulation” when coding simulations, while those practices are recognized as very important in software engineering! Hopefully, SSE developers are continuously practicing it, building either HLA federates or stand-alone simulations using SSEs supporting HLA or not. Examples of similar errors are unfortunately not so rare. They show that many criticisms directed toward HLA are not well founded and they suggest that an efficient learning and a full understanding of HLA is far from easy.But, unfortunately (just as in many other human activities), HLA has also demonstrated its own real drawbacks. The main and only real issue about HLA is its complexity: HLA is “high tech”, but using it has a price. The counter-part is the difficulty in designing, establishing, integrating, testing and running HLA federations when comparing to more traditional practices for development of stand-alone simulations. Without a good methodological approach as suggested by the FEDEP, a skillful and multi-disciplinary development team, efficient management of the project, little success will be obtained. In France, some teams experienced HLA, then stopped and came back to a DIS approach, which seemed easier, even if far more limited. In some cases, people have declared that “HLA simply does not work” trying to hide their own incapability.What such failures mainly demonstrate is the requirement for better teaching, better training, better-adapted methodology and debugging tools. There is also a clear need to leverage the capability of the M&S community in terms of abstraction and software engineering.It is possible also that HLA has been too widely advertised: even if the issue of “technical interoperability versus substantive interoperability” has been raised for sometime, Maybe, HLA presenters have sometimes underestimated the importance of using reference FOMs or data standards, probably equally important to reach the “Interoperability Graal”.But, the main general issue does not really concern the HLA standard but its supporting software (the RTI). No Simulation Interoperability Workshop was held in the past, without papers denouncing “the poor performances of HLA for real time federations”. People have a very short memory: DIS and ALSP times are not so old. Both authors believe that the performance issue has to be globally considered and related to the overall complexity of the distributed simulation paradigm. A new era has been reached: we have to realize that distributed simulation can be developed and run only by very professional teams and no more by lab scientists with some basic knowledge of computer science. Furthermore, there is no scientifically established evidence that distributing simulation can perform better than some stand-alone ones: in the analysis domain many people consider that it is exactly the opposite.Thankfully, there is a published scientific approach, reference (9). The following sentence is extracted from this paper: “…the diagnosis of overload problems in large, distributed systems is a long standing and widespread issue. Similar problems were encountered with applications of the ALSP, an approach similar to SIMNET/DIS approach but focused on event-oriented time-managed war games”. It is sometimes surprising to realize how knowledgeable experts suffering every day from gaps and poor performances of the Internet, vehemently complain about a postulated poor performance of more sophisticated systems such as an HLA federation. Another mystery: why are people paying more attention to some failures than to optimistic papers reporting successful HLA uses?Finally, a very general and useful practice is often forgotten when distributing simulations. Either using HLA or a different standard, good performance can be better achieved in respecting the following rules:Strongly coupled entities should be implemented on the same node,Only loosely coupled entities should be distributed on distant nodes.Main benefits provided by the HLA approachIn discussing drawbacks or difficulties related to the HLA, it is right to equally mention the tremendous advantages brought by the HLA to the M&S community. Those benefits were not so apparent at first, nor largely advertised.The firstly apparent benefit of the HLA approach is the promotion of the object orientation (OO) approach that was previously appreciated by a relatively small M&S community. The OO approach is now largely recognized as well adapted to the simulation activity, but it was not so widely known from the M&S community before the birth of HLA. Significantly, this fact illustrates a better recognition by the developer community of the importance of a more structured approach and of a better methodological approaches.As another example, the HLA paradigm incites developers to better separate services (which in HLA federations are provided by the RTI) and models (that can only be implemented in federates). This separation was not so clear in some formerly developed applications. Generally speaking, the HLA paradigm encourages the use of best computer science practices in the simulation activity: declaration, information hiding enforced by publication/subscription mechanisms, modularity, separation between low-level services and algorithmic aspects, etc.Compared to preceding standards DIS and ALSP, HLA was the first to promote and successfully implement the mix of different time management algorithms, which was an obvious weakness of the former interoperability standards. This has been a significant technical achivement even if not easy to design and to implement. Also important, from the performance point of view, is the Data Distribution Management. Even if a significant effort has still to be achieved on such a difficult issue, DIS and ALSP never approached this aspect. Some other interesting features could be discussed such as Ownership Transfer which provides an elegant solution to solve the issue of multi-level fidelity.In conclusion, HLA clearly reflects of the current state-of-the art. It has strongly incited the M&S community to upgrade its methodological and technical level and, even if it was not clearly expressed in the declared objectives of the approach, HLA has facilitated a significant step forward in the overall M&S community.The HLA reuse philosophy and its consequencesAs previously stated, in the HLA context, simulations are reused in their totality even if a small part is of interest in building a federation. Obviously, this can only happen if repositories of simulations are created and maintained at a high level. In the HLA concept, information related to available simulations is mainly recorded as Simulation Object Models (SOMs) under a standardized format (called HLA Object Model Template or OMT). SOMs represent a concise way to summarize capability of simulations and quickly became familiar to HLA practitioners.The first obvious consequence of the HLA reuse paradigm is that it forces users to build distributed simulations and not stand-alone applications which are technically more simple to deal with. Distribution is no more a choice, with respect to constraints due to practical considerations or requirements of protecting some specific information contained in separate models.Secondly, reuse can only occur when a large choice of simulations is available: this can only happen in a large community of users such as the US DoD or within NATO, not in smaller communities. Furthermore, within large communities, benefits of the HLA reuse can only be obtained after an initial investment to update the legacy simulations to HLA compliance. In smaller communities such as the French defense M&S community, when a new requirement appears, generally the issue is rarely to reuse simulations since the choice is scarce, but very often to undertake a new development.In conclusion, the HLA reuse philosophy will be efficient only if two important conditions are satisfied:First, the establishment of large repositories of models and simulations, which provides a real choice of resources,Second, the investment for updating legacy simulations. This investment can be important because operational simulations were not always developed according to the good practices of modern software engineering.In addition, HLA re-use practice supposes that when designing and implementing new simulation applications for which a requirement of interoperability exits, they are built in accordance with the HLA standard. But, this should be far easier than adapting legacy simulations. In any case, using an SSE supporting the HLA will be very helpful for this activity.How to accommodate both philosophies: some recommendations It is evident that, both reuse philosophies are sufficiently different to be compatible and even complementary. The following recommendations are based on initial HLA experiences of both authors and their ESCADRE practice during the last fourteen years.First criterion: Economy Reuse is purported to save time and money. There is no doubt regarding this criterion for reuse based on an SSE. For practical reasons, little experience is available on reuse based on the HLA in small communities and only one from one larger community (the US DoD).Updating legacy simulations for achieving HLA compliance can be costly for some obvious reasons such as the following:They were very rarely designed and implemented satisfactorily according to the reuse purpose,Even if this first condition was satisfied, they rarely support object orientation and other general features facilitating the transition to HLA (such as modularity, clear separation between specific models and general services).So, there can be some doubt that being dogmatic in requiring the HLA compliance for every current simulation is not cost-effective. Contrarily, requiring HLA compliance for newly developed simulations is achievable, prudent and cost-effective. One can believe it should be easier to adapt new applications for their integration in a new federation providing they were designed initially with this purpose in mind. This objective of HLA compliance will be better and affordably achieved if new developments are based on an SSE offering both a good methodological approach consistent with the HLA principles and a high level and user friendly tool-kit interfacing with low level HLA/RTI services.Accommodating HLA and SSE reuse concepts: the Based Object Model (BOM) approachSome new SSEs exist that were designed with the HLA philosophy in mind. They are so new that initial feedback has not been published. A preliminary assessment recommending using those products or not should be premature and unfair. It would probably not help their real implementation and their safe evolution. In addition, some attempts have recently been made to marry the HLA philosophy and the former component approaches, since many SSEs were born before the invention of HLA. References (5) to (8) report on such an experience, which has been judged as successful.But, a special mention should be made on the Based Object Model (BOM) methodology, which is a clear recognition of the importance of unifying both component and HLA approaches. The BOM concepts were mainly refined within a SISO study group (see references 11 & 12). Unfortunately, there is no real experiment of this concept so far and, at a first glance, the BOM concepts are not so simple to understand. According to past experiences about reuse of simulation components, the idea of identifying a set of object classes and interactions closely coupled should not facilitate the reuse philosophy as previously described in paragraphs 2.4 and 2.5. Past experiences have proved that components are easy to reuse when they are self-sufficient and as much de-coupled as possible from other ones. It is not the case with the BOM philosophy, which can favor the coupling of interaction classes and the object classes initiating or reacting to them. Maybe future experiments will show that the independence condition is not so important. Let’s wait and see.Final recommendations for a reuse policy in the operational analysis domainUnfortunately, as this paper suggests, there is not a definitive and miraculous policy to prescribe. However, one recommendation can be made: behave flexibly and not be dogmatic.When a new requirement appears in a specific application domain, it is impossible to start from scratch: it would be stupid not to use past experience. Even if the reuse policy can be expensive, we are forced to comply otherwise we will not progress. The first fee to pay for reuse is the investment in creating and maintaining good repositories of simulations and also of simulation components. The high quality of their development is also a prerequisite. It should be supported by the best software engineering practices favoring reuse:Object orientation, modularity, readability, portability of source code,Adapted documentation, in particular availability of conceptual models (CM), with the strong requirement that the CM of the overall application is reflecting the overall structure of the simulation and is composed from CMs of individual components,VV&A of components and, after their integration, of the full application, keeping in mind that the V&V process is never finished and that every new reuse provokes the beginning of a new V&V step forward.In any case, there is not a preferred reuse approach either based on the systematic use of HLA federations or of stand-alone applications. The decision should be taken on a case-by-case basis.Our recommendation is that when having to develop a new application a cost effectiveness study should be carried out. As an example, if a new functionality is required in a current simulation named “A” and if this functionality already exists in another named “B”, two solutions should be compared:First, implementation of the new functionality in A using the dedicated documentation provided by B,Second, establish an HLA federation based on A and B.If simulation B is well documented (as previously described), there is a high probability that extending the capacity of A to integrate the functionality provided by B is cost effective. This process should be far easier if the design and implementation of A is based on an efficient SSE.The first solution (extension of A or B capability) can not always be applicable, either for performance reasons or as previously mentioned confidentially reasons. In such a case, HLA provides a safe and unique solution to preserve confidentiality, supposing that some additional security precautions be taken to reinforce the subscript/publish/interact mechanism. One will notice that concomitant uses of an SSE and HLA allows developers to have a real and cost-effective choice in reusing simulations and their components..Author BiographiesJean-Louis IGARZA is presently Chief Scientist in the NATO/RTA/MSCO (Modeling and Simulation Co-ordination Office) since October 2000. He was formerly head of the Simulation Department of the “Centre d’Analyse de Défense” (CAD, French Center for Defense Analysis, MoD). He has a Ph.D. in Applied Mathematics (Paris University, 1968) and a background in Statistics. The main part of his career has been in Operational Analysis (air domain). In the recent past, he taught “Statistics and Probability” at Engineer Schools, and is now teaching “M&S” at Versailles University.Christian Sautereau is presently Head, Simulation Department of the “Centre d’Analyse de Défense” (CAD, Center for Defense Analysis, French MoD) where he promotes object oriented methods in simulation. He is presently the project leader of the ESCADRE SSE, that he created in 1987. During 1970-1987, he was instrumental in the M&S of a number of weapon systems, in the Conventional Armament Department of CAD. He was Deputy Head of this department and became after that position “Scientific Adviser” of CAD. He graduated from the “Ecole Nationale des Arts et Métiers”, Paris, France in 1968 and received a DEA degree in mathematical Statistics from University of Paris.References:“US DoD Modeling and Simulation Master Plan”, DoD 5000.59-P, October 1995“NATO Modeling and Simulation Master Plan”, Version 1.0, AC/323 (SGMS) D/2, 7 August 1998Dale K. Pace : “Simulation Conceptual Model Development Issues and implications for reuse of Simulation Components”, paper # 00F-SIW-019, September 2000, SISO Workshop,Christian Sautereau, Philippe Chervi "ESCADRE: A design methodology and a tool kit for building technico-operational simulations", “Simulation” review of the SCS, September 1994,Jean-Louis Igarza, Christian Sautereau, Philippe Annic, Dominique Canazzi, Emmanuel Berry: “Development of a HLA compliant version of the French ESCADRE SSE (simulations support environment): lessons learned and perspectives”. paper # 98S-SIW-028, March 1998, SISO Workshop,Dominique Canazzi, Philippe Annic, Jean-Louis Igarza, Daniel Girardot: “ESCADRE HLA: an operational SSE for HLA compliant simulations development” paper # 98F-SIW-088, September 1998,Jean-Louis Igarza, Major Theodore Dugone : “The WARRIOR/ELYSA Experience: A FEDEP Use Example” paper # 00S-SIW-142, March 2000, SISO Workshop,Dominique Canazzi, Philippe Annic, Jean-Louis Igarza, Nathalie Le Rest: “ESCADRE-5.1 : a SSE For Low Cost HLA Compliance”, paper #01S-SIW-052, March 2001, SISO Workshop,Duncan Miller & Steven Boswell: “A general Framework for Modeling federation performance”, paper # 01S-SIW-070, March 2001, SISO Workshop,Robert Lutz: "A comparison of HLA Object Modeling principles with traditional OO modeling concepts", paper # 97F-SIW-025, Fall 1997 SISO Workshop,Paul Gustavson, John Hancock, Christopher Stapleton: "The Base Object Model (BOM) primer: A distilled look at a Component reuse methodology for simulation interoperability", paper #01S-SIW-086, Spring 2001 SISO Workshop,“The BOM Methodology Strawman(BMS) Specification” prepared by the BOM SISO Study Group, 15 May 2001.PAGE   EMBED Word.Picture.8  