Integration of SIGSIM Real-Time Thermal and Atmospheric Modeling Library into Paint the NightBrian Miller, Max Lorenzo, Don TidrowCECOM Night Vision and Electronic Sensors Directorate10221 Burbeck RoadFort Belvoir, VA 22060bsmiller@nvl.army.mil,  HYPERLINK mailto:lorenzo@nvl.army.mil lorenzo@nvl.army.mil,  HYPERLINK "mailto:dtidrow@nvl.army.mil" dtidrow@nvl.army.milRuss Moulton Jr., Chris FinkJRM Technologies Inc.11913 Main Street,Fredericksburg, VA  22408(540) 368-8106 HYPERLINK "mailto:rmoulton@jrmtech.com" rmoulton@jrmtech.com, cfink@jrmtech.comKeywords:ABSTRACT: US Army Night Vision and Electronic Sensors Directorate is currently completing the integration of the SIGSIM thermal and atmospheric modeling library into the Paint the Night (PTN) multispectral sensor simulation.  SIGSIM models the spectral signatures and atmospheric effects of a set of defined materials based on sensor and environmental inputs, and maps the results to parameters suitable for consumption by an OpenGL based simulation.  This allows PTN to simulate multiple spectral bands using a single terrain database and target models, as well as represent real time environmental effects.  This paper will: discuss the capabilities and limitations of SIGSIM and its PTN implementation; outline the changes made to PTN, terrain databases, and target models; show synthetic imagery generated by PTN with SIGSIM.  1. IntroductionThe U. S. Army’s Communication and Electronics Command (CECOM) Night Vision and Electronic Sensors Directorate (NVESD) develops sensor simulations to aid in: sensor design, prototyping, and analysis; search and target acquisition (STA) model development; evaluation of tactics, techniques and procedures; and automatic target recognition (ATR) training and analysis.  To meet this goal NVESD has designed and built a real-time multispectral sensor simulation known as Paint the Night (PTN).  In order to keep pace with modern sensor design, it has become necessary to retool the signature modeling capability for Release 2 of PTN.  PTN’s previous multispectral signature implementations were cumbersome and provided little flexibility for non-traditional sensor bands, and non-standard environmental conditions. These non-traditional bands are those outside the long-wave infrared (LWIR) and mid-wave infrared (MWIR) wavebands including short and near infrared.  They also may include sub-bands of the traditional bands.  This is being accomplished through the implementation of the SigSim Real-Time Thermal and Atmospheric Modeling Library, developed by JRM Technologies, within PTN.  SigSim theoretically models the spectral signatures of a set of defined materials based on sensor and environmental inputs, and maps the results to parameters suitable for consumption by an OpenGL™ based simulation.  Because SigSim is predictive the simulation is not limited to specific wavebands, where measured data is available or limited to a precalculated set of environmental conditions.2. Previous Signature ModelPTN is an OpenGL based polygon renderer synthetic image generator (SIG) based on SGI IRIS Performer.  While the OpenGL lighting model is intended for the modeling of light sources and reflected phenomenon, it is effective to use its real-time hardware based rendering implementation to produce thermal scenes. Previous versions of PTN have used a simple encoding scheme to reproduce the thermal phenomenology in an IR scene as OpenGL material properties. A diagram of the lighting model is shown in figure 1.  EMBED PowerPoint.Show.8 Figure 2. SEQ Figure \* ARABIC 1. OpenGL Lighting ModelThe following is the OpenGL lighting model in its mathematical form:where EMBED Equation.3  and  T(u,v) is the texture modulation as a function of the texture coordinates u,v. Ia, Id, and Is are the ambient , diffuse and specular light intensities respectively. (a, (e, (d, and  (s are, respectively, the ambient, emissive, diffuse, and specular materials properties of the object, and ( is the shininess. Vectors l and o are the direction vectors from the surface to the source and observer respectively.In this scheme total thermal emission is mapped to the OpenGL emission parameter, (e , the IR band reflectivity to OpenGL specular parameter, (s . Solar loading effects are mapped into the spectral diffuse parameter, (d.  These parameters are precalculated for each scene element, such as grass, trees, roads, etc. for a predefined spectral band, ambient air temperature profile and scene temperature range.  These parameters are stored in a material database for use by the SIG.  In most cases the calculation of parameters are based on empirical data collected by Night Vision or available in open literature.  All signatures are modulated by textures to add detail to the models and increase realism.  Target vehicles are handled in a slightly different manner. The OpenGL emission parameter, (e, specular parameter, (s, and spectral diffuse parameter, (d, are used to represent the portions of the signature that are attributed to thermal emission, IR reflectivity and solar loading respectively, but the signature is based on the texture which is calibrated thermal imagery.  The proportional variation of the OpenGL material parameters allow the signatures to vary appropriately in response to the light source.  For example areas exposed to the sun will appear brighter due to the sun’s heating effects while an area not exposed to the sun will remain at its nighttime temperature.  These material properties are encoded and used directly from the target models.This method has some key limitations.  Every different sensor, characterized by a change in waveband or effective temperature range, requires a different precalculated database of OpenGL parameters.  In addition every specific environmental scenario would require a different database.  Also, it is difficult to find empirical data to derive the parameters and vehicle textures in the non-traditional wavebands.   And finally the simple mapping scheme breaks down as the wavelengths approach the visible band and the material becomes more reflective.3. PTN Release 2 Signature ModelThe primary change to the signature model for PTN Release 2 is the incorporation of a predictive signature model, the SigSim model library, into the PTN SIG.  In addition some minor changes were required to terrain databases to make them compatible with Release 2.  More extensive changes were required for Target models to allow them to take advantage of SigSim capabilities.3.1 SigSimImplementing the SigSim Model seeks to resolve the limitations of the previous signature model by replacing the empirically based precalculation step with a real-time predictive model.  To achieve this SigSim performs the following tasks in real-time:  (1) calculates the temperatures of scene elements based on the meteorological conditions provided by the SIG (2) calculates resultant radiometric values from the temperature data and material radiometric properties for the waveband specified by the SIG; (3) maps that radiometric data into OpenGL material and lighting parameters; (4) makes OpenGL parameters available to the SIG.To accomplish this SigSim requires three types of input on which it bases its predictions: a sensor definition, the environmental conditions, and material system definitions for each scene element.The sensor definition defines the waveband and temperature limits of interest.  The waveband tells SigSim over what wavelengths the sensor will be collecting data.   Since the calculations are in radiance and the output will be in a gray shades the resultant radiance values need to be mapped to an appropriate gray shade scale. This is calculated based on the temperature limits.  In addition a sensor gain factor may be applied, which affects the radiance to gray shade mapping as well as a maximum light level value for visible and near IR waveband sensors.The environmental conditions specify both lighting and meteorological conditions.  SigSim uses date, time, latitude and longitude to determine the sun position and intensity.  It also provides for the input of illumination from the moon, stars and urban area.  Meteorological inputs are daily minimum and maximum temperature, wind speed, humidity, rain rate and temperature, and visibility.  These are used in the thermal calculations.The material system definition is the most complicated input.  A separate system definition should exist for each scene element that may result in a unique signature in any of the desired wavebands or environmental conditions.  This system definition includes the thermodynamic properties of the system’s underlying bulk material and radiometric properties of the exposed material.  For example we can define a section of armored vehicle hull as our system.  The bulk material is steel since it drives the thermal calculation of that surface, while the exposed material is paint, which drives the radiometry at the surface.  The thermodynamic properties are: conductivity, specific heat, density and thickness.  The radiometric properties are emissivity, absorptivity and reflectivity, and are wavelength dependent.  In addition to properties the system definition specifies the boundary conditions of the problem.  For example if we are dealing with our vehicle hull example and the armor covers the crew compartment, we can assume the interior surface of the material is exposed to a constant air temperature, and the external surface is exposed to a ambient air temperature at ambient air velocity.  If that same armor was located over the engine compartment the system definition would be different.  The interior temperature would be higher and an additional radiative flux from the engine might need to be included, but the exterior conditions and the material properties are the same.Figures 3.1 illustrates a typical thermodynamic problem for a system where the material maintains a constant temperature at a fixed distance below the surface, that distance is called the diurnal depth.  This would most likely apply to a ground or road scene element.   Figure 3.1 Thermodynamic Schematic EMBED Word.Picture.8  Figure 3.2. Radiometric Schematic Based on the environmental and material properties the heat transfer equation is solved for the temperature at the exposed surface T1. From that temperature an emissivity can be calculated for the desired waveband.  Figure 3.2 illustrates the radiometric problem for the same system.  The reflected energy can be is calculated based on the impinging energy, the wavelength dependent reflectance values, both specular and diffuse, and angle of between the energy source and the surface normal. The waveband dependent emission and reflection are mapped to the proper OpenGL material and lighting parameters.3.2 Terrain DatabaseEstablishing which geometry each material system definition applies to is necessary for the SIG to apply the OpenGL material properties generated by SigSim correctly.  To accomplish in PTN, a system definition name is attached to the material object.PTN is a Performer™ based application and uses Performer Binary Format (pfb) as its runtime format.  PTN stores the system definition name in the pfMaterial USER-DATA field.  This provides a convenient location for the name since the pfMaterial object stores the OpenGL rendering parameters.  In addition, a single pfMaterial may be assigned to multiple sets of geometry.In general each terrain element, such as a grass field, an asphalt road and an oak tree, is a separate geometry in the terrain database and little modification beyond adding the USER-DATA field is required.Textures are still used to add detail and realism to the scenes and are handled similarly to previous releases of PTN.  SIGSIM does not directly account for textures, this requires all textures to have the same mean in order to result in uniform signatures.3.3 Target DatabaseTargets are handled the same way as terrain in PTN Release 2, tagging the geometry with different system names. However, the vehicle implementation is more complicated since a single vehicle may comprise many systems and the logical breakdown of those systems may not correspond to any breakout of the geometry in the existing model file.  This requires some significant rework of target models to incorporate the material tags.  As mentioned before since SigSim does not recognize textures, texture means must be the same in order to get proper signatures.  This presents a more difficult challenge for vehicles, since a single texture may cover multiple systems.  The texture must be broken up and the means of each region be adjusted separately and then the texture recombined.NVESD uses the Alias Wavefront Maya modeling package and additional custom software to do this vehicle modeling.  PTN ImplementationOn simulation startup and when a SigSim related parameter (waveband, temperature, time of day) is changed, the SIG makes a call with that information to the SigSim library.  SigSim performs the necessary calculations and returns the OpenGL material and lighting parameters.  The light parameters and position are adjusted by the SIG.  The SIG maintains a list of pfMaterials so it may quickly update them as necessary.LimitationsThe SigSim thermal model is steady state. This results in the instantaneous effect of environmental changes.  While this is a good approximation for most scene elements, some have significant thermal lag, which cannot be well represented with a steady state model.The thermal model is one-dimensional.  The one-dimensionality is particularly evident on vehicles where a point heat source, such as the engine or exhaust is likely to occur.  In this case heat does not just conduct from inside to outside, but out from the hot spot, perpendicular to the surface normal.  This limitation can be overcome to some degree by texture.SigSim, as a predictive model, is only as good as the data that is input.  The raw data required by SigSim is more readily available than sensor data, but careful development of the system definitions is critical to getting realistic results. PTN Release 2 implements SigSim Version 3.0.  Future releases of SigSim and PTN should reduce these limitations.  4. Results EMBED Word.Picture.8  Figure 4.1.  Synthetic Imagery in the long-wave IR.  Diurnal cycle from 0200 hours in the upper left to 2200 hours in the lower right.Figure 4.2.  Synthetic Imagery in the mid-wave IR.  Diurnal cycle from 0200 hours in the upper left to 2200 hours in the lower right.Figures 4.1 and 4.2 show a simple scene consisting of a terrain, several different road types, a few trees of a single type and a truck target, all generated using PTN R2.  Figure 4.1 is the diurnal cycle of that scene in the long-wave IR.  This illustrates a significant improvement in the realism of PTN,  showing a more realistic diurnal cycle.  The previous signature model showed did not allow difference in scenes when the sun went down.  Once the light source was removed the imagery remained constant.  Predictive thermal modeling and a more sophisticated OpenGL mapping scheme allow us to model the variable ambient air temperature such that the scene at 0200 appears significantly cooler than the one at 2200, as it should.Figure 4.2 shows the same scene in the mid-wave IR.  No changes were necessary to the database or the vehicle model to achieve this effect, only the modification of the waveband limits in the SigSim input.   Variation is seen between the long-wave and mid-wave scenes due to the variations in the emissivity and reflectivity of the materials in the respective wavebands.5. ConclusionsThe  integration of SIGSIM Real-Time into Release 2 of PTN is a significant step toward achieving more realistic multispectral scenes that incorporate reflective, ambient and system dependent effects, and ultimately improving NVESD’s capability to design and evaluate sensors and sensor related technologies.6. References[1] 	Lorenzo, M., Jacobs, E., Moulton, R., and Liu, J., “Optimized Mapping of Radiometric Quantities into OpenGL,” Proceedings of SPIE Vol. 3694, p. 173-182 (1999)[2]	Incropera, F., DeWitt, D: Fundamentals of Heat and Mass Transfer, Wiley, New York 1985.[3]	Moulton, R., “SigSim Programmers Guide and API”, JRM Tech Inc. (2001)BRIAN MILLER is a Mechanical Engineer with the CECOM Night Vision and Electronic Sensors Directorate. He has his B.S.M.E from Virginia Tech and his M.M.E from Catholic University.MAX LORENZO is a team leader in the CECOM Night Vision and Electronic Sensors Directorate. He has a B.S. in Geology from The College of William and Mary.DON TIDROW is an Electrical Engineer with the CECOM Night Vision and Electronic Sensors Directorate. Don is currently the lead developer for the Paint the Night sensor graphics visualization system.. He has a B.S.E.E. from Kettering University.CHRIS FINK is the chief technical architect and code developer of the JRM’s Hyper-Spectral Scene Simulator, and he developed the latest SigSim 4.0 models and software for BRDF, spectral reflectance, and spectral atmospherics and meteorology prediction, and integrated them into the Signature Synthesis Manager (shader) for the BRL-CAD ray-tracer.  Dr. Fink holds a Ph.D. in Theoretical High Energy Physics from Florida State University, a Master of Science Degree in Physics from Florida State University, and dual Bachelor of Science Degrees in Physics and Philosophy from the University of Wisconsin. RUSS MOULTON JR. is the chief architect and software developer of JRM’s SigSim 4.0 spectral signature synthesis library, including the steady-state and 1D transient thermal solvers and radiant emittance libraries.   He also developed JRM’s SenSim 3.0 Windows-based advanced EO/IR Sensor Design and Visualization Tool.  Mr. Moulton received his MSEE in Digital Signal Processing from the University of Pennsylvania Moore School of Electrical Engineering in 1989, and graduated summa cum laude from the US Naval Academy in 1984 with a BS in Physics and minor in Electrical Engineering.   EMBED Equation.3  