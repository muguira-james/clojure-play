Enabling UAV to C4ISR integration using M&S and gaming technology(05F-SIW-113)Jan TegnérClaes Bäckström Qi HuangSaab Systems ABNettovägen 6SE 17588 Järfälla, Sweden+46 8 580 840 00 HYPERLINK "mailto:jan.tegner@saabsystems.se" jan.tegner@saabsystems.se,  HYPERLINK "mailto:claes.backstrom@saabsystems.se" claes.backstrom@saabsystems.se,  HYPERLINK "mailto:qi.huang@saabsystems.se" qi.huang@saabsystems.se  Keywords:UAV, C4ISR, Gaming, Interoperability, Data link, Link-16, HLA.ABSTRACT: The Swedish Armed Forces are going through a rapid transformation with interoperability and network centric capabilities as main focus. National data links will be replaced by NATO data links, such as Link-16, and support for coordinated joint surveillance and combat missions are needed. Integrating support for unmanned vehicle systems, e.g UAV, and Close Air Support missions are some of the major challenges ahead as well as support for civil security tasks. To handle a kill chain from detection and classification to engagement, a system of systems approach is needed with a distributed tactical picture, decision support, resource allocation and UAV support. This paper describes several R&D efforts to support UAV integration and discusses future possibilities to enhance the functionality. The Dial-a-Sensor (DIAS) project focused on information handling in a user perspective when using an UAV for surveillance, SAR and anti-terrorist missions. In the project an UAV control station was integrated with a beta release of the Battlefield 2 game engine which provided CGF functionality and visualization.  The UAV-S2E project focuses on the sensor to engagement function chain according to STANAG-4586 using formal chain of commands, decision support and indirect fire to support peace keeping operations. In the project live C4ISR systems are integrated using simulated data links and simulated UAVs, short distance missiles and other CGF components.1. Introduction1.1 Background Technical evolution of unmanned vehicles has been rapid the last ten years and the extensive use of UAV during Operation Iraqi Freedom has made unmanned vehicles an important piece of next generations network enabled defence system. The army has been pioneers regarding unmanned vehicles, but there is an increasing interest within the navy, the air force and civilian authorities to use unmanned vehicles for both military and civilian purposes. It is likely that the new user groups will have different requirements on unmanned vehicles than the army has.While the technology has been in focus, there has not been enough work on how doctrines, systems and personnel should adapt to the new technology to take full advantage of the possibilities unmanned vehicles give. NATO is developing a standard STANAG 4586 [1] for UAV control systems, but unmanned fighters might be required to handle Link-16 to be able to interact with other fighters in the future.   1.2 Outline The outline of this paper is as follows.Chapter 2 describes the Dial-a-Sensor project, which focused on information handling in a user perspective when using an UAV for surveillance, SAR and anti-terrorist missions.Chapter 3 describes the UAV-S2E project, which focuses on the sensor to engagement function chain according to STANAG-4586 using formal chain of commands, decision support and indirect fire to support peace keeping operations.Chapter 4 discusses future UAV evolution. Chapter 5 discusses use of tactical data links and tactical interaction between UAV, C4ISR systems and other platforms.Chapter 6 “Summary and conclusions” sum up and concludes the paper.2. Dial-a-Sensor projectThe Dial-a-Sensor project is a part of the government funded General Control Station for Unmanned Vehicles (GKOF) program. The main goals of the GKOF program were to: Show that it was technically possible to implement the subsystems of GKOF.Create a platform for technology development.  Analyze the possibilities of the new technology and limitations from a C4ISR point of view. Besides the Dial-a-Sensor project, the GKOF program has included live flight test with UAV, development of Portable Remote Sensor data Terminals (PRST), participation in STANAG 4586, automatic picture analysis, decision support for UAV, VSM UGV and Skylark experimentation. The GKOF program started in 2002 and will be terminated during 2005. Besides Saab Systems, which was prime contractor for the Dial-a-Sensor project, Saab Aerosystems, Saab Bofors Dynamics, Aerotech Telub, EMW, Carmenta, STIBI and the Swedish Defence Research Agency (FOI) participated in the project. Rescue services in Linkoping, Amphibious Combat School, Navy Combat School, Swedish Naval Tactical Command and Amphibious Forces participated as users in the experimentation and the Swedish Crisis Management Agency (KBM) participated as observer. Several other authorities, like police, airport, rescue services etc has been involved in the requirement phase.2.1 The main objectives for Dial-a-Sensor projectThere is a need to be able to distribute information from unmanned vehicles and their control station to other users. The ability to control the vehicles and their sensors remotely is crucial in a network based defence. Technically there are no limitations to distribute sensor data, but there is little knowledge in to whom, how and when sensor data should be distributed to increase efficiency. In Dial-a-Sensor project a methodology experiment was performed where several users at different hierarchical level was able to interact with a UAV. The main questions to be answered were:How shall an information request be made to a unmanned vehicle?How shall the information be presented for the requesting user?  Figure 2.4.1 Exercise facilities2.2 The scenarioUnited Nations have an ongoing mission in X-land. All personnel and equipment to support the mission are shipped through airport and harbour in the city of Nykoping in the border country Sodermanland.  SHAPE  \* MERGEFORMAT Figure 2.2.1 Skavsta airport and harbour in Nykoping.The airport and harbour is protected by a UN troop, consisting of a Swedish Battle Group, in co-operation with local authorities. The battle group have a unit with unmanned vehicles (UAV, UGV, USV and UUV) at their disposal.2.3 Game configurationsDepending on the role, the level of technical support, time frame, geographical area and protection the situation for the personnel is totally different.RoleCharacteristicsStaffNo technical limitations, long perspective (days), large geographical area, indoor shelter, several people.Field personnelLittle technical support, short perspective (now), small geographical area, no shelter, 3G cellular phoneMission coordinatorSome technical support, medium perspective (hours), place of event, semi-protected (car).Table 2.3.1 Role characteristics.The end user may have different possibilities of controlling an unmanned vehicle, its payload and information received from the unit. In STANAG 4586 [1] four different levels of UAV interoperability are defined: Indirect receipt of secondary imagery and/or data.Direct receipt of payload data.Direct receipt and control of payload.Direct receipt and control of payload and flight control of UAV.Direct receipt and control of payload, flight control and ability to launch and recover UAV.In the study test personnel was able to interact with the unmanned vehicles corresponding to STANAG levels of interoperability 1, 2 and 4.With the lowest interaction level the test personnel was able to send commands to a GKOF system, which controlled the unmanned vehicles and returned a report and pictures when the mission was accomplished.  With the medium level of interaction the test personnel has voice, text, picture and/or video interaction with the operators of the GKOF system and may change or refine the objectives during the whole mission.Figure 2.3.1 Low interaction levelWith the highest level of interaction the test personnel has direct communication with autonomic unmanned vehicles. Test personnel controls the unmanned vehicles using loiter points and the payload using commands, i.e. zoom, rotate etc. To analyze all configurations with different roles and interaction levels nine games were required. Each game configuration was defined in a play card.Game config.Test personInteraction level8Field personnelHighVehicleUGVEventSuspected bomb bag at empty hangar at airport.Stress factorNoActorsUGV operator & interpreterOne terroristTask test personMark position for suspected bomb bag and building in report. Estimate type of bomb, possible consequences, level of threat etc.Task playerPlace bomb at building.Expected reactionOrder to unmanned vehicle unit. Report ready to higher command within 20 minutes. Table 2.3.2 Play card for game configuration 8To measure the outcome of each game configuration several variables was measured:Performance – standard report usedWork load – standard form usedSituation awareness – standard form usedBehaviour – protocol from observing domain expertCommunication – logPlayer comments – Final  interview2.4 Technical descriptionThe main systems included in the exercise was PRST terminals used by rescue centrals and mission coordinator, a 3G cellular terminal used by live field personnel, the GKOF system used for sensor control and communication and Battlefield 2 which were used for simulating friendly and opposite forces, UAV/UGV simulation and communication interface,  sensor simulation and video distribution. Figure 2.4.1 Systems included in exerciseTo be able to control unmanned vehicles remotely a plugin was developed for BF2 which allowed the GKOF systems to send and receive DLI messages [1] to BF2. The GKOF system could also forward DLI messages between BF2 and a PRST terminal or a 3G cellular terminal. Figure 2.4.2 Remote control of UAV/UGVTo simulate the sensors of the unmanned vehicles, i.e. simulated video and IR camera, the video was produced using BF2 and was then distributed, so that it could be presented by the GKOF system and PRST and 3G cellular terminals. Figure 2.4.3 Sensor video distributionThe PRST system in a higher command centre has a multi screen solution with a large conference console as main console. The PRST system is intended to control unmanned vehicles and its sensors, to show available unmanned vehicles in a map, to present their state. It is possible to present sensor coverage, calculate distances and capture photos from streaming video for later analysis.There is also a portable PRST terminal for mission coordinators who works in the field. Sensor data is then received in real time through a video server in the network.The field personnel were using a 36 cellular phone as terminal which could present a map and real  time video from the unmanned vehicles sensors. The terminal could also be used to control the sensors remotely.Figure 2.4.4 3G cellular phone terminalThe GKOF system acts as a layer between unmanned vehicles and C4ISR systems. It has a plug-in based map and database application. Currently there are plug-ins for telemetric and sensor handling to UAV and UGV, report handling, image handling and video handling (playback and live). Multiple clients with different configurations can be connected to the server and there is also a web service function to support network enabled capabilities. GKOF has following functionality:: video capture, digitizing and processingimage handling and analysisdatabase handlingtelemetry data and map handlingreal time reconnaissance reportspost-processed reconnaissance reports including imagery and videomission order handlingtactical situation awareness to/from C4ISR systemsmultiple mission handlingFigure 2.4.5 GKOF Interfaces The simulated environment was produced using a beta release of Battlefield 2 (BF2) with the new Dice game engine.  BF2 has a client-server approach, where the server is responsible for synchronization between the clients. The clients and the server provide HMI for their users. BF2 supports dynamic changes of natural environment and includes simple generic hierarchic models which can be parameterized to implement different kinds of vehicles, aircrafts, ships, submarines and different kind of weapons. There is also an embedded AI functionality with support for both the strategic level and the human behaviour level. The UAV and UGV was implemented using the included generic model, new maps and visual skins for unmanned vehicles and humans were developed in Open Flight format. The visualization components in BF2 were also used to generate sensor images and video. In figure 2.4.6 below the top pictures show two scenarios when unmanned vehicles is used for civilian crisis management, i.e. aircraft crash at airport and traffic accident with truck with dangerous cargo involved . The pictures in the middle shows a terrorist attack in the harbour in Nykoping and the pictures at the bottom shows picture from UGV with bomb bag and a picture from an UAV in the terrorist scenario.Figure 2.4.6 Sample images from Battlefield 22.5 Results from Dial-a-SensorWith low interaction level it was hard for the higher command centre and the mission coordinator to get a concise communication with the UAV/UGV operator when only text messages was used. There was frustration over that nothing happened, since they got no feedback during the mission. With medium interaction level all participants felt they had good situation awareness and could through the UAV/UGV operator control the sensor if needed. One disadvantage is that mission coordinators and the staff at the higher command centre needs to be able to distance themselves from the actual events to be able to take neutral decisions. It was easier to get a common understanding of the situation when higher command and mission coordinators could use the same information as personnel at lower levels. With the highest level of interaction none of the participants believed they could control a sensor without loosing the focus on their main tasks. It requires special trained personnel to handle and control sensors in an efficient way. It is useful for decisions maker to know what a sensor could be used for, but not necessarily how it is done.3. UAV-S2E projectThe UAV Sensor to Engagement (UAV-S2E) project is a SAAB internal R&D project. The project goal is to demonstrate a functional chain from detection to engagement using C4ISR systems, UAV systems and missiles. In the project Saab Systems provides C4ISR functionality, Saab Aerosystems provides UAV functionality and Saab Bofors Dynamics provides SSM functionality.3.1 Sensor to engagementIn the project a live C4ISR system delivered to the Swedish amphibious forces was reused and functionality for supporting UAV was added. The C4ISR are able to receive track data and reports from mobile radars, reconnaissance patrols, air defence systems and distributes a correlated situation pictures to adjacent systems.Figure 3.1.1 System of system layoutDecision support functionality has also been added to the C4ISR system, to help operators to optimize the use of available surveillance and engagement resources.The UAV control station receives surveillance orders from the C4ISR system and besides reporting back results from the mission the UAV control system may send real time target data to a Missile Planning & Control System (MPCS) to support indirect fire against enemy targets using ECOM robots.Figure 3.1.2 ECOM robot system3.2 The scenarioThe scenario used in the UAV-S2E project is based on scenarios described in the Swedish Armed Forces Headquarters report “Future ground target combat – International Operations”. [2] In the initiation phase he C4ISR system receives an intelligence report that enemy rocket artillery has been sighted in a small village. Figure 3.2.1 Enemy rocket artilleryThe C4ISR operator allocates surveillance and engagement resources to the mission. In this case an APID rotary UAV and a robot unit is available. If no local resources are available or if the resources are controlled by other C4ISR system, for instance if air support is needed, the operator may request resources from HQ. The operator sends orders to both the UAV unit and robot unit to prepare for a mission.In the surveillance phase the C4ISR operator sends a mission order to the UAV Planning & Control system to send an UAV to the village to confirm the intelligence report and to retrieve additional situation information. The C4ISR operator receives pictures, video and other information in real time from the UAV during the surveillance mission. The targets are automatically tracked by the UAV Control system.  Figure 3.2.2 CybAeros APID rotary UAVIn the engagement phase, when the targets has been identified, the C4ISR operator sends a mission order to the robot unit to engage the enemy targets with support from the UAV unit. The robot unit regroups and launches the robots. Situation picture based on UAV information is received from the C4ISR system.In the reaction phase, which is the final part of the engagement phase, target data from the UAV system is transmitted in real time directly to the MPCS system to guide the robot to the targets.  In the post operative phase the UAV scans the target area to determine the result of the attack.3.3 Technical descriptionThe project will have two major demonstrations:Fall 2005 – with simulated weapons and UAV and recorded live sensor video. Fall 2006 - with live UAV.In the 2005 demonstration the tactical support system MSS/PE, developed by Saab Aerosystems, was used as UAV Planning & Control system. MSS/PE is also a part of the Gripen fighter training system.Figure 3.3.1 MSS/PE System LayoutThe UAV itself is simulated but uses a live video tracker, which is fed by recorded live sensor video. The use of recorded data decreases realism in the MSS/PE system since the sensor data is not affected by the movement of the simulated UAV, but on the other hand realism is increased in the C4ISR system since the distributed sensor data has higher quality than it would have if it was generated by Battlefield 2 or some other simulation product. Figure 3.3.2 IR sensor video over target areaThe robots are simulated in the scenario, but since Saab Bofors Dynamics uses simulation when developing their new robot systems the software in the robot models are principally the same as in the live robots. The robot models are fed by recorded live tracker video.   The platform data for the UAV, the robots and units are distributed using HLA/RPR-FOM [3][4]. Since recorded sensor data is used it is not required for performing the scenario, but it allows the scenario to be displayed using a God’s eyes view.In the Fall 2006 scenario a live UAV will be used, preliminary the APID rotary UAV will be used since it has been granted restricted flight permit by the Swedish Civil Aviation Authority (LFV). The UAV should be equipped with video camera and IR sensor. Communication between C4ISR system, MPCS and MSS/PE will in larger extent be using live communication interfaces. 4. Discussion on future UAV evolution The UAV technology so far has been focusing on army needs, since the army has been leading the evolution. For navy and air force use the requirements will be different. Within the air force there is a slight resistance towards unmanned fighters, especially among pilots. With a pilot on the ground controlling the UAV using a joystick, latency may be crucial in combat situation even though the manoeuvring performance is higher without a pilot.An unmanned fighter needs a high level of autonomy to be able to handle SAM attacks etc. on its own without ground operator intervening. Normally the unmanned fighter should receive missions order with for instance a position, a route or an area to surveillance instead of being controlled in real time. In the Dial-a-Sensor project one of the outcomes was that the operators was overloaded if they had to control the UAV in detail. Figure 4.1 Neuron UAV and Gripen fighterIf a fighter pilot should be able to communicate with an unmanned fighter, he needs to be able to communicate with it in the same way as he communicates with other pilots. This implies that the unmanned fighters need to be equipped with Link-16 communication equipment to be able to exchange J-messages with ground control and other fighters [5]. , It may also be necessary for the unmanned fighter to perform speech recognition and voice synthesis to be able to handle voice communication with other fighters. However, if speech recognition and voice synthesis should be performed in the manned fighters instead, this would radically decrease the need of bandwidth since the voice could be transmitted as data instead of digitalized voice.From the C4ISR point of view handling a Gripen fighter and a Neuron UAV would principally be transparent (depending on configuration) and, thus, reduce complexity in the C4ISR system. Using the new Link-16 simulation standard [6] developed by SISO Tactical Data Link Study Group [7], interaction between ground control, fighters and unmanned fighters could be studied virtually in a cost effective and safe environment to evaluate the impact on doctrines,  tactical behaviour and technical needs.  Medium and long distance missiles with sensors may perform surveillance missions on their way to their target and act like an expendable UAV. Since current Link-16 terminals are too heavy and too expensive, this is currently not an alternative. Even though a separate link is used to the missiles, J-messages may be used between C4ISR systems and missile guidance system and/or between C4ISR systems and the missile guidance system. The Link-16 simulation standards may be used to evaluate the use of J-messages even though a different physical link probably will be used in reality. The question whether to use the STANAG 4586 standard for UAV interfaces, the STANAG 5516 for Link-16 exchange or both, depends on the level of autonomy of the UAV and whether C4ISR systems, fighters and other system may communicate directly with the UAV or all communication is passed through the UAV control system.  5. Summary and ConclusionsUAV technology has evolved rapidly, but there is a need to analyze how the new technology should be adopted in an optimal way and how the technology inflicts on doctrines, tactical behaviour, technical needs, chain of commands and HMI.Gaming and simulation technology is a powerful tools which may be used during the whole lifecycle of  UAV systems, from analysis to training.There is a need to study how unmanned fighters should interact with other fighters and ground control and whether Link-16 may be a solution.6. References[1]	STANAG No. 4586, Standard Interfaces of  UAV Control System (UCS) for NATO UAV Interoperability. Draft version 2.4, September 26, 2001.[2]	Framtida markmalsbekampning – Internationella Insatser, ATK00148S, Swedish Armed Forces Headquarters. (in Swedish)[3]	IEEE 1516 Standard for Modelling and Simulation (M&S) High Level Architecture (HLA),  HYPERLINK "http://www.ieee.org" www.ieee.org[4]	SISO Real-Time Platform Reference FOM v2draft14,  HYPERLINK "http://www.sisostds.org" www.sisostds.org[5]	STANAG No. 5516, Edition 3, Tactical Data Exchange – Link 16.[6]	SISO-STD-002-V2.0 Draft Link-16 Simulation Standard. Tactical Digital Information Link – Technical Advice and Lexicon for Enabling Simulation (TADIL-TALES).  HYPERLINK "http://www.sisostds.org" www.sisostds.org[7]	SISO Tactical Data Link Study Group,  HYPERLINK "http://www.sisostds.org" www.sisostds.orgAuthor BiographiesJAN TEGNÉR is Technical Manager at the Training & Simulation department at Saab Systems in Sweden. He currently works with C4ISR to Simulation integration issues including simulation of tactical data links. Previously he has been involved in the development of several C4ISR systems for the Naval and Air Defence domain and simulators for Air Defence systems. During the last years he has mainly been working with R&D in the field of Modelling & Simulation. Jan Tegnér is elected member of SISO Conference Committee and head of the local organizing committee for the Euro-SIW 2006 in Stockholm.CLAES BÄCKSTRÖM is a cognitive scientist working at Saab Systems. He currently is project manager for the Dial a sensor R&D project with eight participating military industries investigating how Unmanned Vehicles should be used by the end-user. He is also working with a joint Saab Australia & Sweden C4I R&D initiative where maritime, land and intelligence systems are interconnected. His research interest is human factors, especially in combination with neuropsychology, sensors and robotics.QI HUANG is a senior scientist at the Training and Simulation Department of Saab Systems. He is currently working as project manager for the UAV Sensor to Engagement (UAV-S2E) project. He holds a PhD in Robot Control System from Royal Institute of Technology, May 2001. His research interests include robotics, artificial intelligence and decision-making support for C4ISR systems. He has previously worked for ABB Robotics and Transman Robotics.AcknowledgementsSpecial thanks to colleagues at Saab Systems, AeroTech Telub, Saab Bofors Dynamics, Saab Aerosystems, Swedish Defence Research Agency and DMOC at Kirtland AFB for support, ideas, feedback and discussions which made this paper possible.  