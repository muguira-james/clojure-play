Critical Needs for Future Defense SimulationsCapabilities Needed for M&S Users Neale CosbyInstitute for Defense AnalysesStreet addressAlexandria, VA zipPhone number here HYPERLINK "mailto:ncosby@ida.org" ncosby@ida.org Rick SeveringhausDynamic Animation Systems, Inc.12015 Lee Jackson Hwy ste 200Fairfax, VA 22033703-503 -0500, 757-412-4577 HYPERLINK "mailto:rick.severinghaus@d-a-s.com" rick.severinghaus@d-a-s.comKeywords: Provide key words hereABSTRACT: This is an expansion of last year’s paper. “The M&S Void: Virtual Simulations for Individual and Small Teams.” It is our proposition that the field of modeling and simulation needs a re-look. If predictions are half right, the war on terror will be a long one. Thus, we should take the long view of modeling and simulation for the future. Our vision: through the use of defense simulations, develop capability to understand, predict, and improve the influence of individual people in settings important to national security. We will attempt to outline the crucial challenges ahead in moving this vision forward. Last year we focused on the individual/small team needs. This year we will address challenges in implementing embedded operational/learning capabilities within simulations/simulators. Individuals insert influence thru behaviors, actions, and communications. How this is to occur in an operational and asymmetric threat environment that includes such things as robots and robotic teams, complex terrorist cultures, and communications channels connecting individual warriors in the field to theater and  national command authorities is just not clear. Just as clearly, existing military simulation capabilities are not oriented towards expanding our knowledge of how to function in such environments. As current combat operations ongoing around the world have adapted to new environments, military leadership needs also to adapt a new mindset with respect to the understanding and use of simulations. The premise of this paper is that opportunity exists to harness defense simulation technology to improve greatly situational awareness, at the individual, team, and tactical levels. Developing such capability, beyond requiring significant cultural change, will require investment of significant resources – both for research and for simulation and technology development. The payoff can be solid advancement in quality of both individual Service and joint learning experiences using simulation science and technology. A key to realizing this potential is to integrate the science of individual and team Situational Awareness, decision making theory, and the modeling capabilities of the international defense simulation community. A number of technological initiatives and solutions will be discussed, with the objective of generating momentum leading to new high priority advanced research program(s). Introduction"In an age when new electronic marvels are being introduced almost daily and thus the gadgets in current military use are out of date, it is easy to forget (and it has often been forgotten) that command, rather than being simply an assortment of technological marvels around which organisations and procedures are built, consists of a series of processes - each of them as old as war itself - by which the technological means at hand are pressed into service. [1]”Van Creveld’s assertion is well worth serious consideration. It speaks to a core issue percolating beneath the surface within most technology based defense organizations – as we move forward in technology enhanced military systems,  does technology drive organization, or does organization drive technology? There is much evidence supporting either view, but the more hazardous approach is to let the former drive military readiness. The point made in our previous paper was that “in today’s dynamic world, we need to be able to immerse commanders at every level into believable decision-making situations, especially at the point of the spear. And it must be remembered that the decision-making will be made more and more by individuals and small groups in the field, using only the organic sensors at hand, supplemented only by partial situational awareness provided by the latest carryalong technology box. In training our forces, the trick is to provide decision-makers at all levels what they really need from simulation —insight.” [2] That point, and that paper, argued the need effectively from the point of view of a node on a network, be it small or large.  In the context of this paper, it is the large view we take – a view which leads us to the role of networks, and the actors in them, in the processes which comprise decision making and command and control of complex organizations. If we set out to identify and improve the influence of individual people in settings important to national security, we must first identify two things. What we mean by ‘improving influence’ and what we mean by ‘settings important to national security’. In the context of this paper, we can state our meanings in this way:By influence of individual people, we mean providing people, through improved communications networks,  increased individual and shared situational awareness to enable better participation in, and decision making for, the tactical, operational, and strategic operations in which they find themselves.By ‘settings important to national security,’ we define the term broadly, meaning settings of any sort in which individuals actions and / or decisions can have significant effects on either subsequent actions or outcomes.  Of course, “significant’ is a relative term, but we hope it will become clear in the reading of this paper. Setting the StageIt should be the job of technology to adapt to the human elements it serves, not the other way ‘round.  Yet 3+ decades of technology developments have largely taken the approach of providing more data automatically that used to be provided manually, push it thru a GUI (now called the HSI – Human Systems Integration), and force the user to adapt to it.  In simplistic terms we have practiced ‘man to man defense’ in our approach to the injection of technology, including simulations, into an operational world. For each new ‘wonder box’ of high tech automation, we have typically assigned an individual to man ‘the box’, and employed a variety of decidedly not hi tech tools to transport data and information across ‘boxes’. There are notable and significant exceptions, of course, but the bulk of technology injection has followed this traditional path.  What technology, and supporting models and simulations, should do is identify, track and analyze specified problem sets in at least 4 dimensions (e.g., x, y, z, and time at the tactical level) and present information (not data) to decision makers.  In this concept, an important corollary is to define in a new way the role of “operator”.   An “Operator” in a world of fielded advanced distributed simulations and tactical decision aids is one who understands deeply the underlying technology and algorithmic engines, to the degree necessary to be able to alert decision makers when, and to what degree, the data and information provided by the technology is degraded or not reliable. Developing and delivering the right mix of simulations to serve this view of the world presupposes knowledge of what information is to be delivered and in what manner, which in turn presupposes knowledge of the types and kinds of decisions which must be made.   However in a world increasingly dominated by ambiguity, it becomes problematic which approach or approaches should be taken for the development of models and simulations. The crucial challenges aheadFrom our research, the impacts of communications networks constitute one of the primary challenges facing us today.  Much research over the past decade reinforces the notion that 3 aspects of communications need much more emphasis:human aspects of C2,the impacts of organizational networks on communications infrastructure, and the complexities of the human- technology interface – meaning, the relations among humans (of limited cognitive capacity) and increasingly complex and robust tactical/operational/strategic decision aids. Human Aspects of C2It is a fundamental  premise of this paper that the models and simulations of the defense establishment must change – soon – to adapt to the needs, capabilities, and limitations of the ‘human element’, and not continue as before -  a decades long procession of increasingly complex systems to which the human element has had to adapt.  As shown through research, “It would appear that many command enhancement initiatives (including research programmes) are, in reality, driven by technology. This situation is perhaps understandable, in so far as the promise held by these systems must clearly be assessed, and, wherever possible, realised. However, this approach potentially results in solutions looking for problems. The occurrence of such situations is considered somewhat paradoxical, given the relative lack of fundamental understanding about the very human process of command which technology aims to support.”[3] The authors of this 2001 research effort go on to state, “These problems originate largely from a failure to understand adequately the subtleties, and inherent strengths of the manual command process. Technology is thus clearly a double-edged sword. Such issues highlight the pressing need for better consideration of the human aspects of command in the development of digital support systems. Past failures confirm the now urgent requirement for human factors to be brought into the very heart of the requirements, design, development and evaluation processes inherent in the procurement of future digitized command support systems.” [4] The logical conclusion of this is that both M&S systems and actual C2 systems must take into account the needs of those making the decisions; easy to state, but much harder to achieve in practice. The impacts of organizational networks on communications infrastructureThe challenges we have in mind are daunting. To illustrate, take, as an example, the scale of ‘network’ that exists on board a US aircraft carrier. As with many military organizations, there are group structures, one or more network structures, myriad small group affiliations, and numerous communications paths all interacting dynamically.“The complexity of operations aboard a large, modern carrier flying the latest aircraft is so great that no one, on or off the ship, can know the content and sequence of every task needed to make sure the aircraft fly safely, reliably, and on schedule. As with many organizations of similar size and complexity, tasks are broken down internally into smaller and more homogeneous units as well as task-oriented work groups. 6 [5] In the case of the Navy, the decomposition rules are often ad hoc and circumstantial: some tasks are organized by technical function (navigation, weapons), some by unit (squadron), some by activity (handler, tower), and some by mission (combat, strike). Men may belong to and be evaluated by one unit (e.g., one of the squadrons), yet be assigned to another (e.g., aircraft maintenance).”In order to keep this network alive and coordinated, it must be kept connected and integrated horizontally (e.g., across squadrons), vertically (from maintenance and fuel up through operations), and across command structures (battle group--ship--air wing). As in all large organizations, the responsible officer or chief petty officer has to know what to do in each case, how to get it done, whom to report to and why, and how to coordinate with all units that he depends upon or that depend upon him. This is complicated in the Navy case by the requirement for many personnel, particularly the more senior officers, to interact on a regular basis with those from several separate organizational hierarchies. Each has several different roles to play depending upon which of the structures is in effect at any given time. 7   [6]    Furthermore, these organizational structures also shift in time to adapt to varying circumstances.” [7]   “For a variety of reasons, no two aircraft carriers, even of the same class, are quite alike. Even if nominally the same, as are the recent Nimitz-class ships, each differs slightly in equipment and develops a unique personality during its shakedown cruise and first workup and deployment.  While it is true that each ship is made up of the same range of more or less standardized tasks at the micro level, the question of how to do the job right involves an understanding of the structure in which the job is embedded, and that is neither standardized across ships nor, in fact, written down systematically and formally anywhere. If they left the yards physically different, even such apparently simple matters as spotting aircraft properly on the deck have to be learned through a process of trial and error.”  [8]  The complexities of the human-technology interfaceWithin just over a decade, a “science of networks” has emerged from its sources at Cornell University, MIT, and the Santa Fe Institute.  Fundamentally, this new “science” addresses collections of components that are “doing something” (e.g., sending data, or making decisions). These collections, being connected in some manner, form a network, have a definable network structure, and, in the case of human networks, have behaviors and relationships among components. And, they exhibit varying degrees of component connectedness, and 2 forms of dynamics – “of” the network (how the network structure itself evolves), and “on” the network (meaning what is happening – data flows, decisions - on the existing network structure). What the science tells us is that groupings of components within the overall network, the behaviors of components, and the varying distance (in time, level of effort, or degree of connectedness) among nodes are all important to the outcomes that occur. All of these characteristics, and others, are important to us in this sense – the science has developed well enough to have important things to say about how military organizations function as collections of overlapping and interlocking networks of systems, people, and procedures, and processes. Which means, to represent by modeling and simulation some one or more aspects of military capability that rely on networks to function implies a requirement to understand the organization, and How it Operates, before the code writers swing into action to recreate a system’s reality in lines of C++ code. [9]Critical Decision Making – principles for presentation.What’s needed from defense simulations today are models which can take into account the messy decision making processes of commanders and troops in the face of incomplete, conflicting, and sometimes wrong information in an atmosphere in which the rules and constraints upon which decisions are based are neither clear nor static.  This condition alone wreaks havoc with the defense establishments’ huge installed base of simulations based on deterministic rules for obtaining outcomes. The playing field today just does not support use of such models.  In terms of designing decision support aids, the challenges are multiple.  Kallmeier (V. Kallmeier, S. Henderson, B. McGuinness, P. Tuson, R. Harper, S. Price & J., 2001) lists the following eight challenges to effective team decision making: The evolving nature of conflict. Novel situations demand innovation, and analogical reasoning to transfer knowledge and experience from one situation to another.Operational imperatives. The emergence and adoption of knowledge dominance strategies for conflict resolution highlight the criticality of shared understanding amongst members of a command and control structure. Such understanding must include shared situational awareness, team awareness, command intent, and metacognitive aspects.Asymmetric threats. Such threats demand the maintenance of multiple perspectives amongst team members.The discontinuous battlespace. Highly fragmented nature of contemporary conflict (brought about in part by the collapse of the strategic-operational-tactical hierarchy) requires non-linearity and the capability for dynamic visualization as integral parts of the decision process.More open doctrine. Increased openness and delegation of responsibility leads to the requirement for both team adaptation, and for better preparations as a foundation to team decision making.Distributed team formations. For geographical distributed forces, maintaining Shared Situational Awareness can become problematic, and degrade critical teamwork behaviors, to the detriment of operational readiness. Ad-hoc teamworking.  Teams operating in contemporary conflict settings often comprise composite forces, consisting of rapidly assembled and deployed personnel who may have had limited opportunity to train and work together previously.Multi-national and coalition teams. Many operational forces and teams are now composed of units from many different countries, each of whom may bring cultural and linguistic barriers to effective team communication and co-ordination.Kallmeier was addressing problems in the “real” domain, but each item listed is just as applicable to the domain of models and simulations. The major thread running through all of these challenges is the same – how is an organization “organized” to optimize information density, distribution, and presentation to enable timely, effective, coordinated, and correct decisions among multiple C2 nodes connected across one or more networks. “Human decision making depends largely on mental models of the situation within which the decision is to be made. These mental models usually take the form of enactive (mental) imagery. There is currently a largely implicit assumption that the best mental model in this context is an information-rich picture. This assumption leads to the provision of IT that focuses upon the delivery of increasing quantities of data. This can be observed in the continuing quest for greater bandwidth provision to Command Posts (CPs).  However, this assumption does not appear to be valid. All models are simplifications, and simpler models often give greater insight than ‘richer pictures’ – ‘seeing the wood for the trees’. The question of what sort of mental model best supports tactical decision making is highly significant and, critically, it is a human rather than a technical issue.”[10]It’s all about the rate of information transfer… not about replicating reality to the nth degree, based on sets of blueprints.   The precursor to success in this is hard thinking to determine what things should be displayed to the decision maker, in what format(s), when, and how. [11]Towards improved defense simulationsSo, to return to our question, how to harness defense simulation technology to improve greatly situational awareness, at the individual, team, and tactical levels, what should be done? What we have is an “object” focused defense simulation industry working on replication of reality.  What we need is a “process” focused leadership community working development of decision aids… encompassing “development of effective strategies for supporting and enhancing command team decision making [that] must rely on holistic approaches, which place equal emphasis on understanding and exploiting people, process, organisation and technology as the building blocks of change.” [12] To start down such a path, we need to recognize the differences between M&S focused on objects, and M&S focused on process capture: “.. the powerful methods of object-oriented modeling and programming are primarily focused on objects, not processes. ….While hierarchical representation of objects is rather widely valid and natural in combat modeling, straightforward hierarchical modeling of processes is only sometimes feasible.  More generally, the relevant processes have a more complex relationship to each other, with connections across branches of the hierarchical tree and, in some cases, with iterations or cycles of data flow.” [13] And we must put a searchlight beam on the complex problem of modeling systems capability in a way to bring out the strengths and weaknesses of existing, contemplated, and proposed decision processes. A first step in this is recognition of the need to consider organizational change as an essential element of improving decision processes – and therefore the influence of individuals. Ambiguity and Shared Situational Awareness In the book, “Six Degrees:  The Science of a Connected Age”, Duncan Watts goes to great lengths to demonstrate the impacts of the existence of ambiguity on and within the networks that make up organizations.  In military ones, ambiguity is typically a fact of life, at least in the sorts of scenarios that the defense M&S community continually tries to model.  In discussion of the role of ambiguity on organizational design, he makes a strong case that hierarchical organizations are not well suited to coordinated, effective, and timely decision making. He argues that “the problem of coping with chronic ambiguity is, therefore, equivalent to the problem of distributed communication. Firms that are bad at facilitating distributed communications are bad at solving problems, and therefore bad at handling uncertainty and change.” [14]   He further argues that in hierarchical organizations, “as soon as any ambiguity enters the picture, the chain of command is immediately saturated by the demands of processing endless requests for information and guidance.”[15]   Space does not allow in this report delving in detail into the implications for military organizations, but we would assert this rings true for many military agencies and organizations.  And that implies something very specific about the development of models and simulations – with respect to the ability to facilitate effective decision making, it is the communications simulation and modeling that must be robust, if we expect military leaders to practice decision making skills in a realistic manner.  “Shared SA arises out of the explicit co-ordinating interactions between individuals (and their communication/information systems). The effectiveness of shared SA is therefore a function of: • team structure and organisation; • team members’ training; and • supporting technology, including digitization. 33. Battlespace digitization is widely regarded as a means to enhance shared SA by increasing the availability of detailed information to all friendly units. That said, it is important to understand that awareness of concrete details, such as tank positions, forms only one part of the contents of SA and will not be relevant to all individuals. Other, equally important SA contents include abstract interpretations, expectations and intentions. Thus, the provision of an abundance of low-level data across a network will not necessarily enhance shared SA. Considerable thought must be given to how digitisation can best be used to accommodate real SA requirements. Novel techniques may be required, for instance, to enable individuals to share their changing intentions with each other. As yet, very few studies have actually been conducted examining the nature of shared SA and how it can be supported or enhanced.” [16] One such study conducted by the Army Research Institute provides a good example of the complexities of issues that must be explored and addressed. To best see what we mean, it is perhaps best illustrated by use of an example.  Quote from Meliza [17]An exampleAn example of the integration of information distribution, Shared SA, and network structure and organization is useful, taken from the book, “Hope is not a Method,” is useful here: “Eight Minutes To Three Minutes: Organizing Around Information” [18] The problem: “engaging an unseen target with a mortar … [a] complex, difficult process” in support of tank unit operations.  [19] p. 160.The components: observer, fire direction center, unit command center or TOC, the mortar itself, crew and ammunition, and the communications network, with friendly tanks operating in the area.Eight minute standard: mortar crews and tanks organized in separate organizations (read “stovepipes”) with integration by human interfaces “- a forward observer assigned to the tanks; a fire direction center to compute and check the data,; command posts to check databases to ensure, as best they could, that no friendly forces were in the target area; and command posts to establish communications channels and coordinate all these actions.”[20]Three minute standard: tank crew uses laser range finder to ID the target and compute range and azimuth precisely, and position precisely with onboard GPS.  Output (GPS based target position) is passed directly to the mortar crew, compute firing data using onboard computers. Simultaneously, output goes to task force database to verify friendly and enemy positions, and target verification sent automatically to the mortar crew’s computer. “All of this done, the crew set the correct explosive charge, armed the fuze, and fired the rounds, hitting in less than three minutes (including the sixty-second flight time of the rounds)-with fewer steps, faster communications, and less error.”[21] p. 161. In General Sullivan’s words, “the 3-minute organization was formed around information … which could unleash a capability the mortar crew had that the tank crew needed.  It could exist because of technology – a GPS system, laser ranging devices, digital communications, onboard computers, and so on – that greatly reduces human error. But it all came together because of the organizational concept (emphasis added).”[22] It goes almost without saying that the “organizational concept” is the purview of the military – and not of the myriad vendors, large and small, who provide the technology, or ‘digitization,” as the British like to call it.   Yet, today the vast majority of research, development and procurement of such digitization technology is technology driven, and NOT organizationally driven – meaning in this context warfighting organizational concepts.  In an acquisition world  biased very much toward stovepipe, systems oriented acquisition, it is no wonder that the result is marvelously complex and detailed simulations of systems and environments, and a hodgepodge of patch-quilt communications ‘architectures’ developed after the users of delivered simulations finally have time to figure out how they are really to be deployed - meaning, again, in accordance with some organizational concept which is the purview of only the military, the customer. Our conclusion from this example: what is missing from much of the defense simulation industry development approach is an a priori essential focus on understanding the organizing principles – e.g., warfighting principles – for which a simulation or set of simulations is to be designed.   One might hope, given that General Sullivan published his book in 1996, that the US Army now possesses a simulation system to allow its forces to practice and gain competency in coordinated mortar fires using the organizing principle just described. The key to realizing this potential is to integrate the science of individual and team Situational Awareness, decision making theory, and the modeling capabilities of the international defense simulation community.Technological initiatives and solutionsWe have stated that military leadership needs to adopt a new mindset with respect to the understanding and use of simulations. The premise of this paper is that opportunity exists to harness defense simulation technology to improve greatly situational awareness, at the individual, team, and tactical levels.It is instructive to think of simulations in terms of their relationships to each other. Consider, for example, Figure 1, in which the relationships among four general types of simulations are portrayed in terms of a pyramid. The four types are:IllustrativeDescriptivePrescriptivePredictiveThe descriptions which follow are not technical, but are definitions made to illustrate the needs of the defense modeling community. SHAPE  \* MERGEFORMAT Figure 1.  Modeling Pyramid - Domains and progressions( 1 ) Illustrative simulations are those whose primary purpose is to create in the user a mental model of something – a system, an operation, a single piece of equipment. These simulations show you a ‘picture’ in text, video, icons, graphics, or other means, of typically, first principles.Typically, illustrative simulations are focused in building mental models among the user audience, mental ‘pictures’ of the modeled “thing” and the environment and context(s) in which the modeled item is used.( 2 ) Descriptive simulations are those whose primary purpose of function is to represent realistically one or more components. These simulations provide a description of a modeled “something” based on modeling inputs. In terms of decision making processes, these models help users develop mental situation models to help them visualize current conditions during performance of tasks for which the simulation was designed.(3) Prescriptive simulations are those that prescribe or enforce compliance with a rule set or modeled functionality. Simulations of this type tell you, the user, what to do in some modeling domain. Operation of these types of simulations typically draw upon the operator’s training, skillsets, and situational awareness to address and “solve” problems using data sets input to the simulation. (4) Predictive simulations, lastly, are those simulations designed with a primary purpose of providing the user some method ‘seeing forward’ whether in engineering design, campaign analysis, or projection of future states of modeled objects. These simulations attempt to provide the user with an ability to know what to expect and to base decisions on the outputs of the simulations. The more complex variations of this type encompass multimode, multi-user connections, with communications channels designed to foster shared situational awareness and to provide sufficient information to support effective decision-making.  In general, these can be thought of as 4 levels, or generations, of simulation. The reason for describing types of simulations in this manner is to get one thinking in terms of patterns of simulations. If one can make a reasonably non-controversial assertion that the bulk of defense simulation development has occurred along a program/project centric trajectory, it can then be argued, at a very high level, that this trajectory of simulation development has also grown within programmatic stovepipes. The problem with this approach, which developed for a variety of very defensible reasons, is that, as the real world, in which defense establishments must operate, got more complicated over the past two decades, the simulation infrastructure which has evolved is no longer an effective one for dealing with ambiguous threats, . Now that may be a controversial assertion!  However, the issue here is, what simulation infrastructure is needed now for the defense establishment to best support individual and team decision making when faced with Kallmeier’s eight challenges? In terms of the pyramid, what’s perhaps needed is development of some organizing principles, applicable across an chosen enterprise (e.g., US DOD, or UK MoD), to guide future development in simulation technologies.A typical pattern of simulation development has been 1 – 2 – 3 – 4 (black/solid arrows):  Basic simulation to illustrate 1st principles, physics, and/or system basics, followed by a descriptive simulation to introduce users to process and procedure and systems’ responses to operator actions, and third, a prescriptive simulation to “teach” or “train” a target audience proper tactics, techniques, and procedures for use of the modeled system. The development of simulation products to train operators on acoustic theory, equipment operations, and employment of specific equipment sets is an example of this progression. The problem with this pattern of simulation development is that the resulting products reinforce, repeatedly, patterns of equipment employment and decision making which are linear biased towards constrained situational awareness. This result was by no means intentional, but occurred due to the natural tendency for operators to be best at operating what they have in hand and thinking about “the Problem” in terms of the information presented to them from the simulation “box” in front of them.  What can occur then in the pattern of progression from 3 to 4 is the emergence of new problems quite unforeseen by designers tasked with developing predictive simulations (e.g., “tactical decision aids”) for operators trained in the 1 – 2 – 3 – 4 pattern. In some cases, the complexity of the fourth generation simulation has left operators unable to properly employ the simulation’s capabilities. The reasons are not entirely clear, but are supported by recent studies. “A study by Leibrecht, Lockaby, and Meliza (2003) found that the job of a unit can become more complex as the unit attempts to make greater use of digitization. That is, certain problems only become evident when a unit has made progress applying automation. This provides further evidence that concerns which are not apparent early in the automation integration process may become problems as the process matures.” [23]Another typical pattern of simulation development has been 1 - 3 - 4 (blue/dashed arrows) in which the trajectory has been to first build an illustrative model for generating a good mental model and context for the user, and then to provide a prescriptive model for accomplishing a specific task, or achieving a specific set of outcomes, requiring the user to know and employ appropriate mental and situation models to achieve satisfactory performance.  Finally, a predictive tool – a simulation or analysis engine – is provided to the user to enable decisions to be made, based on the outputs of the provided tool. There have been some notable successes using this pattern of simulation development, but even these tend to channel human decision makers into patterns of decision making constrained to the output of the simulation box. We argue here that this simulation pattern does not help in making discontinuous leaps in tactical thought, such as changing the information flow to effect a 2/3 reduction in response time to a Call for Fire as described above.Other patterns of simulation development can be imagined using the pyramid construct in use here.  But, in an attempt to get to the crux of the matter, consider a simulation pattern of development, 1 – 2 – 4 (red/dotted arrows). A development trajectory along this path would be something like this:  first, an illustrative simulation describing some problem domain, providing users an appropriate mental model of the problem set, and a view into the environment in which the user will have to perform. Next, a descriptive simulation (or simulation set) is developed, one which provides sufficient representation of component capability to allow users to understand process, systems’ capabilities, and  responses to operator actions. And lastly, a predictive simulation is built, based not on an extension of some deterministic third generation simulation built to enforce procedure or methodology compliance, but on a examination of the potential patterns of organizational interaction that may be brought to bear to address the problem set illustrated by the first level simulation.  This is by no means an easy tasking.  Every argument to this point in this paper has emphasized the complexity of the human decision-making ‘space,’ and we have attempted to provide convincing argument that the human decision making effort is a decidedly human process, and somewhat messy at that. Moreover, and this is the key point, if we are to serve the needs of decision makers having influence on important matters, we must focus on the patterns of interactions among humans – not machines – in designing simulations meant to improve performance in an ambiguous and oft-changing environment.As Watts tells us, coping with chronic ambiguity is a problem in distributed communication. He further argues that one should “think about organizations as networks of information processors, where the role of the network was to handle large volumes of information efficiently and without overloading any individual processors. …. Whether searching for a distant target or retaining connectivity in the face of failures, may network problems boil down to the transmission of information in connected systems.” [24]As a way to find an approach to address the issues described in this paper, we can consider Figure 1 in terms of families of simulations. Figure 2 illustrates the concept. SHAPE  \* MERGEFORMAT Figure 2.  Patterns of simulation developmentFigure 2 groups illustrative, descriptive, prescriptive, and predictive simulations into sets of models and/or simulations serving various needs.  The groupings are based on each of the four faces of the pyramid as being one pattern of model/simulation development.   In this view, the 1 – 2 – 3 – 4 pattern described earlier becomes the 1 – 2 – 3 face of the pyramid, labeled as “A” in Figure 2.  The concept offered here is that patterns of simulation development take place on one of the faces of this pyramid. It is also argued that simulations developed on “A” are not suitable for extension to provide effective predictive simulations - because the pattern of simulation development results in object based, deterministic models that do not lend themselves well to addressing higher level decision making skills of the kind described in this paper.Similarly, a development pattern on “D” results in a family of models well suited for the practice of doctrine specified tactics, because the development pattern assembles just the models and simulations needed to exercise a set of tactics defined in the requirements documents for those models and  simulations.  Similar assertions can be made for the other faces of the pyramid; these are summarized in Table 1.M&S Family/ Pyramid FaceDomainsModeling/SimInputsOutputsUsesValueSkills & Techniques Trainers/ A(1-2-3)Individual, small teamSystem stimulation data, environment data Physics and/or emulation  basedSystem outputs + data/info displaysEquipment and physio-motor skillsDevelops competency on equipments and systemsProcedures Trainers/ C(1-3-4)Individual, small team, some large teamSystem stimulation data, environment data Physics and/or emulation  basedSystem outputs + data/info displaysSituation Models, Procedures and team skillsDevelops competency on equipments and systemsTactics Trainers/ D(2-3-4)Small, large teamOPFOR entities, System stimulation data, environment data, specific comms interfacesSystem outputs + data/infoDisplays, communi-cationsMental Models, Situation Awareness, and team coordination skillsTactical Decision Aids, exercise of doctrinal use of operational guidanceDecision Trainers / B(1-2-4)Individual, small teamBehaviors, Concepts, command guidance, Comms network flowsdata/infodisplays,decision alternatives Situation ContextsSituation awareness, team coordination, and decision skillsExercise of situational awareness, complex Decision processesTABLE 1.  M&S FamiliesTable 1 of course offers only a high level view, and the validity of the contents within each column can, and probably should, be discussed at length. However, the core message is this: simulation development across the past few decades has fallen into established patterns, none of which lend themselves well to the exercise of critical decision making skills needed by leaders and operators in the field to address significant ambiguity in operational situations. Where “good” decision making requires individual and team situational awareness, real time reachback to superiors for “real time” guidance on command intent, and flexibility in execution of response, existing DoD simulations are in need of much improvement.  In the context of Figures 1. and 2.,  the best development pattern is on “B” – in which models and simulations are designed to illustrate and describe appropriate scenarios, without requiring the design fidelity required to exercise basic skills or proficiency in operation of equipments. Summary The objective of this paper has been to address issues and challenges in implementing operational/learning capabilities within models and simulations to improve greatly situational awareness and decision making, at the individual, team, and tactical levels.  The challenges include behavior modeling, addressing communications, both flows and flexibility, modeling of human interactions in information sharing, identifying and modeling the “networks” in which teams operate, and modeling of patterns of human decision making.  Additionally, much improvement is needed in the modeling of “ambiguity” – of intent, of non-military influences on forces in the field, and of human responses to imposed pressures.  The goal of such modeling should be focused on a) creating models that facilitate development of mental models and situational awareness, and b) creating simulation environments in which decision making can be practiced in creative and unorthodox ways. RecommendationsFour recommendations are offered as logical steps towards addressing these challenges.Research into methods for building families of models that capture the science of networks – models that reflect human patterns of interaction in a team environment, and that provide for, and allow, communications paths to change as  the operational context changes.Develop methodologies for representing ambiguity in the actions and responses of  human and organizational entities in domains of interest. As an example, group modeling of native population actions/reactions to conduct of security patrols by deployed peacekeeping forces.Research into new and different techniques and  processes for collection, analysis, and display of  information contributing to situational awareness and understanding of options available to decision makers. Basic research into the patterns and processes used by teams and individuals in their employment of digitized and automated information displays and decision support tools. By this is meant research into how humans best relate to such displays and tools. Each of these four recommendations are based on a single fundamental assertion – that the next generations of  models and simulations must recognize and take into account, as a primary design criteria, the patterns of behavior exhibited by human operators making decision in complex and ambiguous situations. The hoped for outcome is knowledge to allow design of models and simulations to better prepare forces to engage in non-combatant, stressful, and ambiguous environments. References[1] Martin Van Creveld, ‘Command in War,’ Harvard University Press, Cambridge, MA: 1985[2] Cosby, Neale & Severinghaus, Rick, ‘The M&S Void: Simulations for Individual and Small Teams’ 03E-SIW-103, Proceedings of the 2003 European SIW, June, 2003.p. 3. [3] V. Kallmeier, S. Henderson, B. McGuinness, P. Tuson, R. Harper, S. Price & J. Storr “Towards Better Knowledge: A Fusion of Information, Technology, and Human Aspects of Command and Control,” Journal of Battlefield Technology, Volume 4 No 1 March 2001.[4] Ibid.[5] 6  In formal organizational terms, we refer to this as "decomposability." The basic notion was introduced by Herbert A. Simon in "The Architecture of Complexity," Proceedings of the American Philosophical Society, December 1962, pp. 467--82, reprinted in Herbert A. Simon, The Sciences of the Artificial (Cambridge, Mass.: The MIT Press, 1981).  In Rochlin, Gene I, LaPorte, Todd R., & Roberts, Karlene H. ‘The Self-Designing High-Reliability Organization: Aircraft Carrier Flight Operations at Sea’, Naval War College Press, Autumn, 1987.[6]  7   During our interviews, one senior officer on a flag staff suggested that the several different functional and hierarchical modes of organization might be viewed as a set of "overlays" that are superimposed upon the formal organization at different times, depending upon the task or circumstance at hand. Many of the officers must shift roles numerous times during the course of a single active day of flight operations. In Rochlin, Gene I, LaPorte, Todd R., & Roberts, Karlene H. ‘The Self-Designing High-Reliability Organization: Aircraft Carrier Flight Operations at Sea’, Naval War College Press, Autumn, 1987.[7] Rochlin, Gene I, LaPorte, Todd R., & Roberts, Karlene H. ‘The Self-Designing High-Reliability Organization: Aircraft Carrier Flight Operations at Sea’, Naval War College Press, Autumn, 1987.   [8] Rochlin, Gene I, LaPorte, Todd R., & Roberts, Karlene H. ‘The Self-Designing High-Reliability Organization: Aircraft Carrier Flight Operations at Sea’, Naval War College Press, Autumn, 1987.   [9]  Duncan J. Watts,  “Six Degrees The Science of a Connected Age”,   W.W. Norton & Co. Inc., New York, NY, 2003 See chapters 1 through 4. [10]  V. Kallmeier, S. Henderson, B. McGuinness, P. Tuson, R. Harper, S. Price & J. Storr “Towards Better Knowledge: A Fusion of Information, Technology, and Human Aspects of Command and Control,” Journal of Battlefield Technology, Volume 4 No 1 March 2001.[11] Edward R. Tufte, Multiples in Space and Time, Chapter 6, ‘Visual Explanations’, Graphics Press, Cheshire, CT 1997. p. 105 – 112.[12]  V. Kallmeier, S. Henderson, B. McGuinness, P. Tuson, R. Harper, S. Price & J. Storr “Towards Better Knowledge: A Fusion of Information, Technology, and Human Aspects of Command and Control,” Journal of Battlefield Technology, Volume 4 No 1 March 2001.[13] Paul K Davis, ‘An Introduction to Variable-Resolution Modeling, in Naval Research Logistics, Vol. 42, p. 151 – 181,  John Wiley & Sons, Inc., 1995. p. 174-175.   [14]  Duncan J. Watts,  “Six Degrees The Science of a Connected Age”,  W.W. Norton & Co. Inc., New York, NY, 2003  P. 273.[15] Ibid., p. 276.[16] V. Kallmeier, S. Henderson, B. McGuinness, P. Tuson, R. Harper, S. Price & J. Storr“Towards Better Knowledge: A Fusion of Information, Technology, and Human Aspects of Command and Control” Journal of Battlefield Technology, Volume 4 No 1 March 2001.[17] Larry L. Meliza, Karen J. Lockaby, Bruce C. Leibrecht, ‘Providing Feedback on Unit Employment of Vehicular Command, Control and Communication Systems’, Proceedings of 2003 Interservice/Industry Training Systems and Education Conference.[18] Gordon R Sullivan & Michael V. Harper, “Transforming the Organization”, chapter 9, ‘Hope is not a Method’, Broadway Books, 1996, p. 160.[19] Ibid., p. 160[20] Ibid., p. 161[21] Ibid., p. 161[22] Ibid., p. 161[23] Larry L. Meliza, Karen J. Lockaby, Bruce C. Leibrecht, ‘Providing Feedback on Unit Employment of Vehicular Command, Control and Communication Systems’, Proceedings of 2003 Interservice/Industry Training Systems and Education Conference. [24] Duncan J. Watts, ‘Innovation, Adaptation, and Recovery,’ “Six Degrees The Science of a Connected Age”, W.W. Norton & Co. Inc., New York, NY, 2003. p. 273.Neale Cosby is the Director of the Simulation Center at the Institute for Defense Analyses. He has experience with research, development and analyses of training simulations. The Simulation Center reconstructed the Battle of 73 Easting in the Gulf War and is currently reconstructing the battles for Mazar-e Sharif in Enduring Freedom.Rick Severinghaus is the Human Performance Director, Submarine Learning Center, Groton, CT.  A retired submariner, he has extensive experience in submarine operations, including command of a fast attack submarine. Since retiring from active duty, has been Principal Engineer with Dynamic Animation Systems of Fairfax VA, and is active in the Simulation Interoperability Standards Organization (SISO). He is currently conducting human performance analysis projects, and is active in development of 3D immersive PC based simulations for various domain applications. He is the author of several articles, conference presentations, and technical papers addressing use of simulation and modeling to support training, mission rehearsal, and operational decision processes and the operator and command level. Within SISO, he serves as a member of the Executive Committee.DABC344321Prescriptive  Illustrative Descriptive  Predictive 21Prescriptive  Illustrative Descriptive  Predictive 