Problems of Validating Human Behaviour Models Uwe K.J. DompkeIABGEinsteinstr. 2085521 OttobrunnGermanyTel.: x49-89-6088-3061FAX: x49-89-6088-4029E-mail:  HYPERLINK mailto:udompke@iabg.de udompke@iabg.de orDr.Uwe.Dompke@t-online.deAlexander von Baeyer IABGEinsteinstr. 2085521 OttobrunnGermanyTel.: x49-89-6088-3061FAX: x49-89-6088-4029 E-mail: baeyer@iabg.deEdgar HeinekenGerhard-Mercator University DuisburgDepartment of Psychology47048 DuisburgGermany Tel.: x49-203-379-2541FAX: x49-203-379-3333E-Mail: heineken@uni-duisburg.deKeywords:Human Behaviour Representation, ValidationABSTRACT: Validation of Human Behaviour Models requires a variety of approaches to cover a broad range of scientific aspects.A multiple criteria set must be defined and will contain:Expert judgements on the military face validity (external validity)User judgements  (also face validity on the military usefulness)Judgement on the scientific theory (psychological construct validity)Measurement of the simulation output (internal validity).The validation process must start with the validation of the psychological process model by observable behaviour reported in the scientific literature and in the experience of military experts. The next step is the evaluation of the model by comparison of input and output regarding the sensitivity of the model (among others different Inputs have to cause different outputs). The paper will describe the multiple criteria set and the validation process in general. An application of this approach to an ongoing German MOD study on Human Factors will conclude the paper.IntroductionContents of the paperCharacteristics of Human Behaviour ModelsConcept of Validity Multiple Criteria Set Validation Process Application to an Ongoing StudyCharacteristics of Human Behaviour ModelsInherent NonlinearityLarge Space of Possible ResponsesAbstract, Non-readable RepresentationConcept of Validity The Concept of Validity is Used byExperimental MethodologyPsychological Test-theory2.1	Experimental MethodologyInternal Validity Changes in the Outcome of an Experiment Are Only Caused by Systematic Changes Of the Input Parameters of the Experiment and Not by Other MeansExternal ValidityThe Results of the Model Are Transferable to Situations Outside the Experiments2.2	Psychological Test-theoryThe Validity of a Test is Defined by the Difference Between What  the Test Really Measures and What it Wants to MeasureThe Quantity of Validity is Measured by a Correlation Coefficient 2.3	Kinds of ValidityValidity of Contents (Face Validity) Contents of the Items of the Test Includes the Items to be MeasuredPrognostic or Criteria ValidityResult of a Test Criteria Corresponds to the Assumed ResultsConstruct ValidityHypotheses About Construct (Not Only Specific Criteria as in Criteria Validity) Can be Supported by Test Results3.	Multiple Criteria Set to Cover a Broad Range of Scientific AspectsExpert Judgements on the Military Face Validity (External Validity)User Judgements  (Also Face Validity on the Military Usefulness)Judgement on the Scientific Theory (Psychological Construct Validity)Measurement of the Simulation Output (Internal Validity).4.	Application of the Validity Concept in German MOD Study „Human Factors“4.1	Validation Process Start With the Validation of the Psychological Process Model by Observable Behaviour Reported in the Scientific Literature and in the Experience of Military ExpertsNext Step Is the Evaluation of the Model by Comparison of Input and Output Regarding the Sensitivity of the Model (Among Others Different Inputs Have to Cause Different Outputs)4.1	Internal ValidityOutcome of the Simulation is Only Depending on the Implemented Model (No Side-effects) Internal Validity Depends on the Implemented Algorithms4.2	External ValidityIn the Model Implemented Objects with their Psychological Attributes and Criteria are Representative for the Modelled Situation in RealityExternal Validity can be Judged by Experts (Empirical Approach)4.3	Validity of Contents (Face Validity)In Analogy to Test-theory Given When Simulation Determined through Modelled Human Factors and Described Attributes of the Situation Tested by Rating of Experts4.4	Prognostic or Criteria ValidityComparison of Real Person in Real Situation with the Simulation Can be Based on Historical DataA Problem is Availability of Data Which is Suited for the Respective Simulation4.5	Construct ValidityIs in Principal for Evaluation of Human Factor Simulation SuitedThe Implemented Constructs Like Motivation, Training Etc. Have to Imply Actions of the Simulated Persons That Can Be Seen in Reality TooConstruct Validity Will be Tested by Expert Rating4.6	Multiple Criteria Validity in Human Factors StudyProof of Simulation Algorithms and Implementation (Internal Validity)Judgement by the Expert (External Validity)Judgement by the User (Face Validity)Construct Validity5.	ReferencesU. Dompke, A. v. Baeyer: Terms of  Reference Long Term Scientific Study on Human Behaviour Representation, NATO RTA/TSC(98)492, Brussels, U. Dompke, A. v. Baeyer: Prospectus Long Term Scientific Study on Human Behaviour Representation, Ottobrunn, 1998Richard W. Pew, Anne S. Mavor: Modeling Human and Organizational Behavior, National Acedemy Press, Washington D.C. 1998E. Heineken, H. Ollesch: Advantages and Limitations of Computer-based Scenarios as Learning Tools. Paper presented in CIP98, York (UK), 1998S.Y. Harmon, S.M. Youngblood: Validation of Human Behavior Representations, SIW Spring 1999Authors' BiographyUWE K.J. DOMPKE is a systems analyst and program director at the IABG Command, Control, Communications & Intelligence Division in Ottobrunn, Germany. Starting from 01. October 1999 he will become the secretary of the Institute for Technology of Intelligent Systems (ITIS) at the University of Federal Armed Forces Munich. He is the Study Director for NATO SAS-017 on Human Behaviour Representation, LTTS/48 on CGF and NATO LTSS/40 on CAX. He gives lectures at the computer science department of the University of Federal Armed Forces in Munich.ALEXANDER VON BAEYER is system analyst and program manager for human factors research at the IABG Land Systems Branch in Ottobrunn, Germany. He was and is member of various NATO Research Groups and EUCLID programs. He is Deputy Study Director for NATO SAS-017 on Human Behaviour Representation.EDGAR HEINEKEN is full professor of psychology at the Gerhard-Mercator Universität in Duisburg, Germany.  His main fields of research are: Computer simulations in Leadership Training, Virtual Reality in Psychological Research, Psychology of Memory and Cognition.First Draft Will be Completed Soon