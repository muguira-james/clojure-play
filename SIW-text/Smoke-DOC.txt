A New Variable Resolution Gaussian Puff Based Smoke ModelStephen A. KukolichLinda LoveroTom SchadyRichard SchafferLockheed Martin Information Systems Advanced Simulation Center37 North Ave., Burlington, MA 01803781-505-9500skukolich@lads.is.lmco.comllovero@lads.is.lmco.comtschady@lads.is.lmco.comschaffer@lads.is.lmco.comABSTRACT:  A new variable resolution Gaussian puff based obscurants model is described.  The model was developed as a proof-of-concept for evaluating consistency tradeoffs in multi-resolution obscurant simulation.  These evaluations are being made as part of the DARPA ASTT program.There are three elements to the model.  The first is a method for evolving obscurants represented as Gaussian puffs.  This model is designed to capture the essential features of this evolution.  The second is a method of combining puffs that are sufficiently close.  The third is an algorithm for determining when this "clustering" should occur.  The model draws on several sources.  The first is COMBIC, which is general smoke and battlefield obscurant model.  The second is SCIPUFF, which uses Gaussian puffs to model low concentrations of chemical or biological contaminants diffusing in the turbulent atmospheric boundary layer.  SCIPUFF also contributes a model of dynamic fluctuations in concentration.  Smoke-specific characteristics, such as the hot buoyant rise of recently generated smoke, and smoke munition descriptions, were taken from COMBIC.For the third element, we have developed a representational error-estimate based merge criteria, to arrive at a general method for clustering Gaussians in a multi-resolution simulation.  This allows a simulation to control the cost of obscurants, in either local areas or globally, by appropriately setting the clustering criteria.  In on-going work, we plan to measure the degree of target detection consistency that can be achieved with different clustering criteria.IntroductionJSIMS and other near-future military simulation projects may require the synthetic natural environment to service multi-resolution simulation.  This means a heterogeneous mix of platform and aggregate representations forces may be playing in the same simulated battle-space simultaneously.   Similarly the synthetic natural environment itself may need to be multi-resolution, and limited in its use of computer resources, to be comparable in cost to the simulation level it is servicing.  The smoke model described here, which is currently under development, includes tunable parameters, or “knobs”, to control the model’s fidelity, which will allow us to study consistency issues associated with multi-resolution simulation.  This smoke model may also be useful directly to simulation because of its ability to adapt to the requested resolution and desired computer resource costs.Section 2 describes this new Gaussian puff based smoke model.  Many aspects of the model are derived from COMBIC.Section 3 describes the algorithms for merging puffs.  The amount of merging that goes on can be controlled through input variables, “knobs”.Section 4 describes some preliminary consistency experiments, to begin to see whether smoke representations that have more merging of Gaussians can give similar results to representations with less merging.Section 5 concludes this paper.2.  A Simple Gaussian Puff Smoke Model2.1   3-D Gaussian puffs representing smokeHere we give a description of 3-D Gaussian puffs used for representing obscurant smoke.  The remainder of this section will include descriptions of the life cycle of smoke puffs (including their creation from burning sources), their evolution over time, their effects on light transmission, and their annihilation when they have become too diffuse to obscure a significant amount of light.  Puffs also can be replaced by other puffs through merging; this is dealt with in a following section.Figure 2.1.1 shows a sketch of smoke puffs representing a smoke plume.  The puffs are emitted from a burning source, and rise vertically because they are hotter than the surrounding air.  The puffs are also blown sideways by the wind and become larger by diffusion. Figure 2.1.1, Sketch of smoke puffs rising from a burning source.A smooth 3-D smoke plume easily can be obtained by adding together the densities from a set of overlapping 3-D Gaussians.  Although shown as ellipsoids in the sketch, the Gaussians are really continuous 3-D density functions which are most dense in the center and whose density falls off to zero as one proceeds away from the Gaussian's center position. Figure 2.1.2 1-D Gaussian with  EMBED Equation.2  ; Plot of 3-D Gaussian along a line.  Figure 2.1.2 plots the density along a single line through the center of a single 3-D Gaussian.  In this Figure, the standard deviation ( EMBED Equation  ) is 1.  The Gaussian falls to very near zero at  EMBED Equation.2  , so  EMBED Equation   gives a reasonable way of measuring the width of a 1-D Gaussian.The corresponding formula for a 1-D Gaussian is EMBED Equation  As shown in Figure 2.1.3, a 2-D Gaussian has a length proportional to  EMBED Equation.2  , a width proportional to  EMBED Equation  , and an orientation angle  EMBED Equation  .  It is very similar to the representation of a rectangular car as one might see it displayed on a 2-D map.Figure 2.1.3 Sketch of a 2-D Gaussian.Equivalently, a 3-D Gaussian is very similar to a 3-D rectangular vehicle, as both are described by: a center position vector  EMBED Equation  ; a length  EMBED Equation  , width  EMBED Equation  , and height  EMBED Equation  ; and a 3 by 3 orthogonal rotation matrix R to describe orientation.  The additional parameter needed for a 3-D Gaussian is its maximum density, c, which occurs at its center.  The formula for an n-D Gaussian is EMBED Equation  where  EMBED Equation.2   is an n-D column vector EMBED Equation  and the n by n A matrix is related to the orientation matrix R and the  EMBED Equation.2   lengths by: EMBED Equation  where  EMBED Equation   is a diagonal matrix  EMBED Equation  and  EMBED Equation   is related to the  EMBED Equation   "widths" by: EMBED Equation  .Conversely, given an A matrix, it can be decomposed back into an orientation matrix R and  EMBED Equation   widths via eigenvalue eigenvector decomposition [3].     To fully describe a smoke plume over space and time by 3-D Gaussians puffs, we need to know how to:create the puffs, i.e. have them emitted from a burning source,evolve the puffs over time, including rising, expanding, and blowing downwind,merge the puffs that have expanded sufficiently so that they mostly overlap some other puff; thus two puffs can be replaced with one puff (this is driven partly by the physics and partly the desire to save on computational resources), destroy the puffs when they have expanded sufficiently to become irrelevant to the simulation.These topics are each covered below.2.2   Burn equations and two-puff merge method in emissionTwo things are described here: the formulae for mass emission over time from a munition source, and a 2-puff technique used to give a continuous train of overlapping puffs from a continuous source.The profile for how each kind of source, e.g. a tactical smoke producing round like a white phosphorus M156 rocket, emits obscurant mass over time was taken straight from the COMBIC model [1].  Most of this information is listed in the COMBIC manual; although, explicit mass portions in each subcloud had to be derived from software.  COMBIC allows for more than one plume or puff to come from a single source munition.  The data used directly in this model was taken from the same data used for ModSAF smoke models, so at most, only the major puff and the major plume subcloud were retained.  On the time scale of DIS-like simulations, puff generation is practically instantaneous.  So the major concern here is the burn profile for plumes, which can take hundreds of seconds.The burn profile (different for each subcloud of each munition) is described by: a total mass M of a given obscurant type, a total burn duration  EMBED Equation.2  , and a burn polynomial  EMBED Equation   describing fractional rate of mass loss as a function of the fractional time  EMBED Equation   into the burn duration: EMBED Equation   EMBED Equation  , EMBED Equation  So that the integral of dm/dt over the burn duration gives the correct total mass M, the polynomial coefficients  EMBED Equation.2   must be scaled so that the integral of the polynomial  EMBED Equation   between zero and one is one.Simply because we were in a hurry to produce a quick implementation, we skipped including the exponential decay term used in COMBIC in conjunction with the polynomial term.  We plan to go back to correct this in the near future.A 2-puff technique is used to give a continuous train of overlapping puffs from a continuous smoke source.    The problem is to figure out how to emit a single puff for each given (possibly large) finite-sized time interval, satisfying two competing goals.  The first goal is to stretch out the puff along the (3-D) puff movement direction so that if only one puff is used for each long time interval, the result still looks like a continuous plume.  The second goal is not to stretch the puff more than necessary because this overstretching could cause the puff to have significant parts much farther upwind of the source than physics would allow. To accomplish both goals, two puffs are released at different times during the past time interval and are propagated to the end of the time interval to the appropriate positions.  The two puffs are then merged to yield one puff.  To derive the release times for the two puffs, the following qualitative discussions will pretend that the propagation direction is approximately straight and only consider spreading effects along that one-dimensional direction.Figure 2.2.1 shows in 1-dimension how overlapping puffs can give a reasonable representation of a spatially (or time) varying function, if they are sufficiently wide so that the resultant sum does not show the original bump positions.  Optimizing the first goal "sufficiently wide" is a  EMBED Equation.2   of about 0.5 times the separation interval, to give only a 5 percent variation in trying to represent the function 1.  However, in considering the second goal, we chose to shorten this to a minimum  EMBED Equation.2   of about 0.37 times the separation interval, which leads to worst case variation of about 22 percent in representing the function 1 -- noticeable, but not huge.Figure 2.2.1 Overlapping Gaussians can represent a spatially varying function.Figure 2.2.2 shows the extreme case of the two initial puffs having little spread compared to the distance moved due to propagation – the merged width almost entirely results from times at which the puffs are released.  Given the desired minimum merged  EMBED Equation   above, the release times should be at 0.13 and 1-0.13 times the tick interval.Figure 2.2.2 Extreme initial merging case.This two-puff method of obtaining a single release puff for each time tick gives reasonable results in three dimensions.  Provided that the different release positions are computed from the release times, results are reasonable even in the presence of a moving source and a crosswind.2.3   Fits to COMBIC resultsIn lieu of a proper physics model for the time evolution of smoke puffs, representing either puffs or plumes, we fit formulae to the results of running COMBIC.  The actual data used, the same as used in ModSAF, covered a wide range of munitions types and effects.  Proper obeisance to some of the real boundary layer physics is given far below, after a simple fit discussion.The assumed form used in each fit, one fit for each dynamic variable for each munitions type, is a power law in time, with a weak dependence on horizontal wind speed u: EMBED Equation  .The dynamic variables this was applied to included: z (height),  EMBED Equation  (spread in height),  EMBED Equation.2   (horizontal spread).  As a simplification, horizontal downwind spread  EMBED Equation.2   and horizontal cross-wind spread  EMBED Equation.2   were averaged to give an average horizontal spread  EMBED Equation.2  , though a more complex model need not make this approximation.  It was also assumed that in the horizontal direction the puff just moves with the wind, partly to avoid considering the much more complicated physics picture, and partly because the data bore this out reasonably well.  Exceptions occur at short transient times of a few seconds when the puff is still catching up to current wind speed.For the height variable, the power law form is augmented with a maximum height (above ground) because, as shown in Figure 2.3.1, puff and plume heights were observed to reach a maximum and then abruptly stop rising.  The assumed form for maximum height is a power law in wind speed u: EMBED Equation   Figure 2.3.1 early height versus time, with wind speeds a) 7 m/s, b) 9 m/s, and c) rise fit power formula at 7 m/s.Over the entire time ranges studied (on the order of  EMBED Equation.3   seconds), typical errors in fits to  EMBED Equation   and other outputs from COMBIC are typically 5 to 15 percent.  The worst errors usually arise not from the assumed time-dependence, but from the failure to adequately model the dependence on wind speed.As an example, the fit results for the major plume from a  White Phosphorus M156 munition are given below.variableC0C1C2C3zmax14.6-0.615z1.02.07-0.09220.424 EMBED Equation.2  1.390.1340.05020.882 EMBED Equation.2  9.530.09710.05841.0The time exponent for  EMBED Equation   was actually fixed at 1.0 before fitting, partly because plots showed that this fit most of the COMBIC data reasonably well.  However, physical arguments tell us [2] that the long-term exponent should be closer to the diffusion exponent of one half.  This anomaly might arise because we are using COMBIC results in a way they were not intended to be used; we use time as the independent variable instead of downwind distance, which is not a good parameter in the context of puff merges.In the context of puff merging, the time passed since release is not a good state variable either.  Alternatively, when updating each of the dynamic variables that depend on a power law, our software will invert the power law formula to determine a ‘time’ parameter from the previous dynamic variable value.  Next, the given change in time is added to this time parameter, and finally the new dynamic variable value is computed from this updated ‘time’ parameter.The extremely simple model described here does amazingly well at reproducing COMBIC results, considering that it does not include a proper picture of the boundary layer physics.  Within the boundary layer, in a proper physics model, wind speed and turbulent transport increase with distance from the ground.  For this reason, COMBIC uses a reference height of 10 meters for describing horizontal wind speed.  The simple model given here implicitly averages over all heights covered by a puff.  A puff can spread continually upwards, and thus sample longer-range turbulence at higher heights; this could partly explain the observed, unmitigated horizontal spread rate.We plan to revisit this model, looking for more physically derived formulae that are equally simple.  The first goal in this initial model was to get the qualitative features reasonably close to correct, so that effects on detection due to puff merging can be studied.2.4   Transmission attenuation, Puff destruction and SummaryHere, a very brief discussion of light transmission through smoke clouds is given.  This leads to a criterion for when Gaussian smoke puffs are no longer relevant to the simulation.In a military simulation, a major interest in smoke is its ability to obscure the detection of potential targets.  This is accomplished through preventing light transmission, and by scattering other light into the line of sight (e.g., the smoke color obscures the target color).  Both effects are algebraically related to the transmission degradation.  Transmission is simply the fraction of light that makes it from the target to the observer along the line of sight, through the smoke.At a given light wavelength, the transmission follows Beer's law EMBED Equation.2  where  EMBED Equation   is a constant depending on the light wavelength and the smoke type, and where CL is the concentration length, which is the line integral along the given line segment of the obscurant mass density  EMBED Equation.2   EMBED Equation  We are using 3-D Gaussians to represent smoke density  EMBED Equation.2  . The value of a full covariance matrix 3-D Gaussian, along any straight line is simply a 1-D Gaussian.  So the line segment integral always reduces algebraically to the difference between two special function values ("erf" function values), which can then be computed very rapidly on a computer.  Besides being natural solutions to the diffusion physics, this speed issue is the major reason for choosing Gaussians to represent smoke in the first place.  Unfortunately, we do not have the space here to give the straightforward math for reducing a 3-D Gaussian to a 1-D Gaussian, though it is straightforward.The worst possible transmission (i.e. smallest transmission) through a single Gaussian smoke cloud is along its longest ellipsoid axis (which is also one of the eigenvector directions), so it is very easy to compute.  In our smoke model, when the smallest possible transmission rises above a given threshold, the smoke puff can be removed from the simulation.In our model, we obtained the  EMBED Equation   constants from COMBIC documentation.This section has described a simple and complete Gaussian puff model for modeling obscurant smoke, including generating puffs, evolving them over time, and using them to compute transmission obscurance.  The following sections will augment this model by including dynamic merging of overlapping puffs, which is done to reduce the number of puffs that need to be simulated.  They will show the use of this model in studying changes in modeled smoke transmission properties caused by merging puffs.3.   Merging Puffs for Speed3.1   Introduction and Merge equations                                         The reason we want to merge puffs is simply simulation efficiency.  If fewer puffs are used to represent a given smoke distribution, more smoke or other phenomena or entities can be simulated with the available computer resources.  The first subject to be discussed is simply the equations for computing a new Gaussian from two Gaussians being replaced. The following subsections will discuss various merge criteria, including adjustable thresholds, for controlling when merging takes place. In addition, the variety of algorithms needed for the efficient application of merge techniques will be described. In replacing two 3-D full-covariance Gaussians with one Gaussian, we chose to follow the simple "moment"-based method described by Sykes et. al. [2].The zeroth, first, and second order moments for a single Gaussian are defined by the following integrals: EMBED Equation.2   EMBED Equation.2   EMBED Equation.2  where EMBED Equation.2  All of these quantities are easy to compute from the basic variables used above to describe a Gaussian.The matrix  EMBED Equation.2   is related to the Gaussian A matrix we have used above by: EMBED Equation  Via eigen-decomposition, also described above, each can easily be computed from the other.The merge equations simply describe how to obtain the moments of the new Gaussian from the two Gaussians that it will replace. EMBED Equation.2   EMBED Equation.2   EMBED Equation.2  where: EMBED Equation.2  .3.2   Merge CriteriaSome merging follows very naturally from the physically derived diffusion of Gaussians, and this merging frequently does very little damage to the representation of the smoke density.  Other merge criteria can be far more brutal because the intent is to trade in fidelity to gain simulation speed.  Consequently, two different criteria are given here; each of which reflects one of these different reasons for merging.  Each merge criterion also has an adjustable threshold, which serves as a "knob", so that the fidelity changes caused by merging can be controlled externally.Our measures of fit error were based on the integral over all space of function differences squared, rather than based on density, because differences between density functions can be negative at some points in space. EMBED Equation  Being a proper Euclidean distance measure, analogous to distances between 3-D position vector, it satisfies the triangle inequality EMBED Equation.2  Using this distance measure, we can define the error in how well a merged Gaussian represents the original unmerged Gaussians as the distance between these two smoke representations: EMBED Equation  This proper error measure is somewhat hard to compute and maintain because it would require retaining all of the original unmerged Gaussians, as well as the merged Gaussians, defeating the purpose of merging.  However, inspired by the triangle inequality, we can easily maintain an upper bound estimate of this error, which is recomputed during each merge, so that the original Gaussians can be discarded.  Suppose Gaussians  EMBED Equation   and  EMBED Equation   are merged to form EMBED Equation  . Then our upper bound estimate for the error  EMBED Equation   is given by the following recursion: EMBED Equation  where the recursion is: EMBED Equation  where  EMBED Equation   and  EMBED Equation   are the upper bound error estimates for  EMBED Equation   and  EMBED Equation   respectively.  If  EMBED Equation   or  EMBED Equation   happens to be an original unmerged Gaussian, then the corresponding error estimate is zero.  Otherwise, we can assume that the above recursion was applied when the merged Gaussian was formed.For conveniently controlling or monitoring merging in a simulation we need to put the above error estimates into formulae which are dimensionless fractions.First, we define a local error fraction estimate, which pertains to how well a merged Gaussian represents the Gaussians it comes from: EMBED Equation  Unfortunately, at this time, we do not have a proof that this is an upper bound on something, but we suspect that some definition of the "true" denominator would give such a proof.Next we define a global error fraction estimate, which is very useful in monitoring how much error there is in the representation of all of the unmerged Gaussians by all of the current merged Gaussians. EMBED Equation   EMBED Equation   EMBED Equation  Our two merge criteria are now:#1 Local Merging:  If, as a result of a particular merge, the local error fraction estimate for the resulting merged Gaussian does not exceed a user input threshold, then the merge may proceed.#2 Force Merging:  When the total number of Gaussians being simulated exceeds a specified limit  EMBED Equation.2  , then do forced merges until the number of Gaussians is reduced to the required limit.  A forced merge looks for the merge that will give the smallest resulting  EMBED Equation   value.The total merge procedure consists of first evolving the current value of  EMBED Equation   for each Gaussian, then applying merge criteria 1 and 2 above, and finally computing the global-error-fraction for monitoring the process. Through the local-error-fraction-threshold and the limit on the number of Gaussians  EMBED Equation.2  , the user can control how many merges are done.  With a small threshold value, the first merge criterion can be quite friendly to the smoke representation, because it says that it is okay to merge any pairs which would result in a small representational error.  The second merge criterion can be quite brutal to the representation because, while it chooses the best pair to merge based on induced error, it does not care how large that error becomes.3.3 Time propagation for approximate fit errorSuppose we were to maintain both the merged and unmerged Gaussians, and evolve both representations in time.  As the Gaussians expand, the measured difference between the merged functions and the unmerged would decrease over time.  Here we will outline a very simple model for estimating how  EMBED Equation   should evolve over time.A merged Gaussian and the unmerged function it represents will be approximated by two uniform density spheres, sphere 2 and sphere 1 respectively, each with the same center position and mass M, but each with a different radius.  The above described distance measure gives a measure of the error of the sphere 2 density in representing sphere 1: EMBED Equation  where  EMBED Equation   and  EMBED Equation   are the respective sphere volumes, and EMBED Equation  .Given  EMBED Equation   at time  EMBED Equation.2  , and equating this to fit-error, and after estimating volume  EMBED Equation   from the  EMBED Equation.2   values, the above formula gives a way to compute an estimate volume  EMBED Equation   for describing an estimate of the unmerged function density.If each spherical volume is assumed to evolve as a power law in time,  EMBED Equation.2  then given  EMBED Equation.2   and thus  EMBED Equation   at a later time  EMBED Equation.2   (evolved from  EMBED Equation.2   using the normal time evolution methods), as well as the volumes  EMBED Equation   and  EMBED Equation   at the earlier time  EMBED Equation.2  , then the unmerged volume  EMBED Equation   can be computed at the later time, EMBED Equation  This can be plugged back into the above fit-error formula to obtain an estimate for EMBED Equation  , the desired output, at the later time  EMBED Equation.2  .  The time exponent (a) for volume expansion can be estimated from available Gaussian  EMBED Equation.2   evolution data.3.4 Need efficient data structures for finding relevant GaussiansWhat have not yet been described are efficient algorithms for finding which Gaussians make up the best pair to merge.  More research is needed to flesh-out the outlined ideas presented here.SCIPUFF [2] uses a quad-tree to find spatially close Gaussians, which then make up good candidate pairs for merging. It may be possible to expand on this somehow also efficiently to produce candidate pairs even where each member of the pair accidentally occurs on opposite sides of high-depth quad-tree boundaries. This is desirable so that good potential pairs are not missed and so that merging proceeds in an optimal order, as if the quad-tree optimization were not present.It might be a good idea to consider the size of each Gaussian, not just the center positions, by storing large Gaussians at quad-tree nodes which have a box size comparable to the Gaussian size, rather than always storing Gaussians in the quad-tree leaves.This same quad-tree (or oct-tree in 3-D) also is needed to find efficiently the Gaussians which can impinge on a given ray transmission line segment.In addition, the quad-tree-like data structure, a heap [3] is needed for dynamically queuing and sorting the best pairs to merge.  The purpose of the heap is to have a "queue" which can have elements inserted or removed at anytime and which can be requested at anytime to yield the element with the minimum key value.  In the case of merging, this element would be the Gaussian pair with the minimum merge error value (which is different depending on whether a local merge or a forced merge is being done).  To represent these Gaussian pair elements, one only needs to augment each Gaussian puff object with two fields: one to represent which other Gaussian each wants to pair with, and another to represent the list of Gaussians which want to pair with it.  This would preferably be accomplished through a class inheritance-like technique to avoid getting one large cluttered Gaussian structure. This "back pointer" list includes both the current mutually accepted "dance" partner, and Gaussians not on the "dance floor" (heap) because they want to pair with Gaussians which already have a better partner with which to pair.  When a merge occurs (which takes a pair off the dance floor), all of the elements on the back pointer lists of the two Gaussians being merged need to be reprocessed, to search again for their best desired partner.This section on merging has described merging algorithms which take into account a measure of representational error, i.e. how well the merged Gaussians represent the original unmerged Gaussians, in choosing the best Gaussians to merge.  Both local and forced merging methods can be controlled through externally settable thresholds, i.e. "knobs".  More work is needed to complete these merge algorithms with a spatially based technique, so that searching for Gaussians, either for merging or for ray transmission calculations, is very efficient.4. Preliminary Consistency Experiments4.1 Experiment Design Our goal was to find out how much merging of Gaussian smoke clouds was possible while preserving consistent results.  We decided that comparing ray intervisibility results through smoke clouds would be a good indication of the effect of merging the Gaussian smoke clouds. We set up an experiment template that would allow the user to compare intervisibility results between smoke clouds that were merged with a very low resulting error versus smoke clouds that were merged with more error allowed.The user inputs two points that describe the southwest and northeast corners of a three-dimensional box. The user also inputs a number of intervals in the <X,Y,Z> directions.  This information is used to form a grid of points. One grid of points contains source locations, and the other grid of points contains target locations.  The user also inputs another set of points that describes the 3-D area in which the smoke is to be detonated.  The number of smoke clouds and a time interval are input as well.  The smoke is detonated randomly within the designated area within the time specified.  A time to wait before performing intervisibility checks is specified along with an optional random seed. After the time allotted is over, a series of intervisibility checks is performed pairing each of the source points with each of the target points.  Various information is recorded into files, including scenario information so that scenarios may be reloaded, total resulting error and maximum Gaussians, and histograms describing the intervisibility results.Each test is done with two subtests.  The first subtest is done typically with a low local error fraction and high number of maximum Gaussians in order to do merging of Gaussians that overlap and produce little resulting error.  The second subtest is done typically with a higher local error fraction and a lower number of maximum Gaussians in order to test the results of merging Gaussians with less overlap. Each subtest drops the smoke clouds during the specified interval, periodically merges the clouds according to the conditions specified, performs intervisibility checks at the allotted time and records the results.  Each subtest can be repeated as desired to show the reproducibility of the results.  Additionally, more tests can be specified which would be done with the same bounding corners of all the boxes, but different smoke detonation times and different smoke locations would be randomly selected in order to provide various testing conditions. The figure below shows the view from the ModSAF PVD during a subtest.Fig. 4.1.1  A sample subtest of Gaussian smoke experiment.We performed a number of tests, keeping the allowed local error fraction and maximum number of Gaussians consistent for subtest1, but increasing the local error fraction for subtest2.  For each increased local error fraction, we did five tests.4.2 ResultsOur preliminary experiment results appear promising. We overlaid the histogram results of subtests 1 and 2 for both the lowest allowed local error fraction we tested (0.1), as well as the highest error fraction (0.9).  We show here the runs which produced the median results for each group.Fig. 4.2.1 Overlaid histograms showing consistency of results for subtests 1 and 2 with varying error fractions.As expected, the lower error fraction runs produce more consistent results, but the higher error fraction runs look favorable, particularly when the reduction in the number of Gaussians used is taken into consideration.  We tried to develop a method of determining how "near" the histograms produced by subtests 1 and 2 were for each test.  We used a dot product for each pair of histograms and plotted the results for each test. We overlaid a graph of the average results at each error level.Fig.  4.2.2  "Nearness" plot of comparison between subtests 1 and 2.Our preliminary results are not monotonically decreasing, but we do see the expected trend.Further studies need to be done in order to obtain conclusive results. These experiments will study the effect of varying the maximum number of Gaussians, and the effect that the proximity of the Gaussians has on the resulting merged Gaussians, as well as gather more raw information so that overall statistical trends may be discovered. This information will be used to determine the feasibility of using the Gaussian puff approach for smoke clouds.5. Summary and Future WorkWe have presented a new smoke model. Its primary purpose is to provide variable fidelity for studying the consistency effects of multi-resolution representations of the synthetic natural environment on simulation.The current version of this model is primarily based on numerical fits to COMBIC model outputs.  This does a very good job of capturing the qualitative characteristics of smoke evolution.  However, cross-checking this model against other smoke models may be appropriate.The currently implemented merging algorithms are sufficient for conducting small merging experiments.  However, for conducting larger experiments, or real simulations, much faster search algorithms are needed.This model does not yet contain the statistical descriptions of smoke density fluctuations.  Incorporating this feature would allow a single ray-transmission calculation to yield a probability distribution of transmissions rather than just one transmission number.  This could vastly improve the representational capabilities of this model at minimal extra cost.The preliminary transmission experiment results look quite promising.  Using the representation-friendly "local merging" criterion the resulting transmission histograms appear to be very similar to each other even with moderately large thresholds.An important area for future work is to address combining aggregate sensor and unit representations with this smoke model.  This may allow us to increase the error thresholds while still maintaining consistency. This smoke model could be used as a multi-resolution model, by using the same underlying model with different error thresholds.6.   AcknowledgementThe research reported in this paper was sponsored by the Defense Advanced Research Projects Agency and the US Army Simulation, Training and Instrumentation Command.  The work was performed as part of the Advanced Simulation Technology Thrust program under contract N61339-97-C-0033.References[1]  D. W. Hoock, R. A. Sutherland, D. Clayton: Combined Obscuration Model for Battlefield-Induced Contaminants, Atmospheric Sciences Laboratory, TR-0221-11, White Sands Missile Range, NM 88002-5501, 1987. [2]  R. I. Sykes and D. S. Henn: "Representation of Velocity Gradient Effects in a Gaussian Puff Model" J. App. Met., Vol. 34, pp 2715-2723, Dec 1995.[3]  W. H. Press, B. P. Flannery, S. A. Teukolsky, and W. T. Vetterling: Numerical Recipes in C, Cambridge Univ., New York, 1988.