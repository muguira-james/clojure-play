Analysis Simulation Visualization Toolkit(CAMPVIZ – Campaign Visualization Toolkit)Mr Chris WertmanBooz-Allen & Hamilton4301 North Fairfax DriveSuite 200Arlington VA 22203703-908-4441Wertman_chris@bah.com Mr Daniel ShedlowskiTechnical DirectorCenter for Army Analysis (CAA)6001 Geothals RoadFort Belvoir VA 22060-5230703-806-5508shedlows@caa.army.milKeywords:Analysis, Visualization, Modeling & Simulation. ABSTRACT: Within the analysis community, analysis of real world situations often require the utilization of multiple simulations to portray all aspects of the situation which are of interest. These simulations often operate under differing sim-to-real time ratios. For example, missile trajectories and intercepts may be detailed physics based models requiring several runs over multiple days to assess TBM launches. At the same time, force-on-force analysis models may provide a representation of six months or more of combat in a matter of hours.      Combining these various simulation outputs is a tedious process requiring the analysis of reams of tabular products from each environment, then manually "merging" them to provide a coherent picture and tell a coherent story. The Center for Army Analysis (CAA) decided that this was no longer an acceptable process for the highly detailed and interlinked simulation analysis they needed to provide for their customers. As a result, they contracted to build a visualization tool which would accept the output of multiple simulation environments, then allow that data to be merged in time and space, significantly advancing both analysis and presentation capabilities of the battlespace. .1. BackgroundThe Center for Army Analysis (CAA) is the primary analysis support center for the army staff and its various elements.   In this task, the center utilized a number of simulations and models to evaluate aspects of  force structure, force composition, and force performance in a variety of scenarios.  As noted by Neff, etc,[1] analysts typically employ a specific simulation to evaluation a specific, often narrowly focused problem statement then merge the results from multiple simulations to provide a complete assessment of a complex scenario.  This is the case at the CAA, where more that a dozen models and simulations might be used to evaluate a particular scenario, such as northwest Asia.  Additionally, these models are not explicitly designed to interact with other simulations, making it difficult to determine relationships between activities and outcomes in one model and their impact to other activities and outcomes in other models.  Another characteristic of these simulations is that most of them provide output in the form of tabular reports of data, which while useful to analysts, is not conducive to presenting results to clients or members of the army staff.  Based on all of this, the CAA recognized a need to provide a visual representation of their analysis.  This would aid their analysts in viewing relationships between their various simulations, but also support their presentation of results and findings.2. IntroductionThe CAA and army staff, recognizing the difficulties  and shortfalls noted above, approached the staff at the Warfighting Analysis and Integration Center (WAIC) to support their need for visualization of their simulation output.  The WAIC had supported the Assistant Vice Chief of Staff, Army for a number of years, and had a demonstrated capability for visualization of simulations.  Additionally, they had a tool which had been developed earlier, which appeared to lend itself to the task as initially defined by the CAA.  This initial contact grew to a complete statement of work which can be summarized to the following requirement:“Provide a Visualization Capability that integrates in time and space the output of CAA’s suite of campaign analysis related models and dynamically displays the key information related to the progress of the campaign over time.”While this was a simple, straight-forward sounding description of the requirement, additional detail was needed before development could begin.The CAA viewed this capability as providing the following benefits to their organization and in turn, for their clients:-Provide an integrating mechanism for CAA’s suite of campaign analysis models--Overarching (“super model”) interface.--Helps process owners to understand the big picture and their role.--A “pseudo federation of models” — integrates and displays the results of all contributing models with respect to time and location.-Provide a mechanism for presentation of results--Dynamic display of campaign progress over time.--Greatly facilitates comprehension of analysis results-Provide quality control of CAA analysis products--Identifies key points of model interfaces and data linkages across processes.--Highlights model disconnects.3.  Requirements DefinitionsThe first phase of requirements definitions was a process of education; the education of the visualization developer to the business that the CAA is involved in.  In other word, we needed to define what they do, how they do it, what tools they use, what output they expect, and what their clients expect in order to determine what visualization system they need.The first element of this description is a brief overview of the simulations used, and how the data from one simulation relates to, or is used by another.  Figure 3.1, included here is a representative example.  To trace through this briefly, the initial conditions are input to EADSIM, which calculates the effect of Theater Ballistic Missiles (TBMs) in the first phase of combat.  EADSIM is a high fidelity, physics based model, used to determine TBM launches and potential targets. The probability that they are intercepted by various blue force assets, such a Patriots, THAAD, Aegis, and the like.  From this analysis, TBMs which are not destroyed by blue force assets are called "leakers", which could have high explosive, chemical , or biological warheads. EMBED PowerPoint.Show.8  Figure 3.1 – Example CAA Simulation ArchitectureObviously, each warhead type will have a different impact on the battlefield.  These impacts are calculated and assessed in a variety of simulations.  Physical damage, as well as personnel and equipment loss may be calculated by one simulation, while another simulation calculates the environmental impact of chemical and biological strikes.The environmental affects are then used to calculate additional attrition. This data can then be used as input to a variety of combat and combat support models.  Finally, the combat models will be used to determine the actual force on force outcomes based on all of the previous input.This simulation environment is not operated like a typical federation or confederation as known to the general SISO community.  The simulations are not operating concurrently, but instead operate serially or independently.  In other words, the output of one simulation may be used as one of the initial conditions of another simulation.  Federations/confederations involving direct interaction are not appropriate since there are significantly disparate time steps involved.  The time required for simulation runs also vary significantly between the various simulations.  The detailed analysis of TBMs in EADSIM, may well require several hours to calculate all the parameters associated with a single day of missile launches.  At the same time, the combat simulation may provide the output of 180 days of combat in the same number of hours.  Based on all of these factors, and the desires of the client, a standard HLA federation configuration and operation through an RTI, was not deemed appropriate. EMBED PowerPoint.Show.8  Figure 3.2 – Visualization OverviewThe initial description of the visualization requirement was for an integrated display of all of the simulations operated by the CAA as shown in Figure 3.2.   Upon further review, the requirement was expanded to allow each of the major functional area managers to evaluate the output of their simulation, as well as associated subsets of data from other simulations using this same tool.  This required the visualization tool to provide an ability to parse output data and display according to some pre-defined processes or layers.  For example, the manager responsible for analysis or logistics issues may want to see the “deployment” and “sustainment” layers, but not concerned with TBM issues or the combat campaign representation.  This type of desired display capability is represented in Figure 3.3. EMBED PowerPoint.Show.8  Figure 3.3 – Process Layer DisplaysAdditional fidelity was levied on the system to allow the CAA wide flexibility with the visualization system, while providing visual support to analysis and presentation of analysis results.  These included:-Model Independent--Data driven--Database front end-Display Requirements--Symbology (Standard mil symbols or user defined symbols)(Time(Geographic location—map based--Data tables and graphs(Time(Associated with symbol/timeOnce all of the requirements had been defined, the contractor documented all of these into a detailed  requirements document, which was accepted and approved by all parties.  This is a critical step in insuring a common understanding between user and developer and helping to insure that the final product will meet the expectations of the user [2].4.  System Design  The system resides on a server that stores the data database, map database, and security information.  The user would access the data through a web based visualization tool.  The visualization tool software was written in Java to provide maximum flexibility and portability of the software.4.1 Database Design.  The first and probably most important aspect of the system design for this visualization tool is both the nature and structure of the database.  This importance has been described by a number of Data Logger and After Action Review (AAR) tool developers [3], [4], [5], and [6].  Critical database design revolves around where and how the data is collected as well as the amount of data that is archived	-  Is there a need to collect and store all output data from all the simulations?	-  Is every attribute associated with every data point required for replay.As noted earlier in the paper, it was determined early in the requirements description process that this tool did not lend itself to an HLA paradigm.  We did evaluate, however, the possibility of implementing the datastructure based on the Object Model Development Toolkit (OMDT) and utilizing the RPR FOM as the starting point for this effort.  It was determined quite quickly that the FOM structure was too restrictive and inflexible for needs of CAA and its requirement that the tool be totally model independent.   EMBED PowerPoint.Show.8  Figure 4.1 – Data Table RelationshipsWhile the final system was implemented in a Java based database, MS Access was used through the design phase to provide a common reference between the users and the developers.  Figure 4.1 represents the tables, data fields, and relationships between those fields that were implemented.  The concept of the database was one which would allow each of the process managers to define the detail, attributes, and data fields they wanted to reflect.  As such, there is a table specifically labeled “attributes”, which is an array that can be as large or short as the analyst desires.This information can be displayed on the visual representation tool, based on the needs of the analyst.  Another aspect which reflects the flexibility of the system for the needs of the analyst is reflected in the way symbols are defined and described.  This is described in greater detail in Section 5.4.2  Background/Maps.  Another aspect of the visualization tool was the need to reflect activities from the large view of a global perspective, down to the tactical combat perspective contained in maps with scales as low as 25,000 to 1.  This means the tool needed a map database containing all possible scales and locations which would be of interest to the CAA and its clients.  Additionally, there were circumstances in which the best representation might be a vector based map, while other occasions necessitated the representation on raster based maps (Figure 4.2).  This significantly increased the map database requirements.  Changing map scales requires modifying and sizing icons for visual display.  When and how map information would be passed from the server to the visualization tool determine the interface that must be designed between the map data base and the visualization tool. EMBED PowerPoint.Show.8  Figure 4.2  Sample Maps4.3  Visualization GUI.  The portion of CAMPVIZ, which is hosted on the user’s client machine is a web based tool, allowing anyone with a web browser, and the proper permissions to access the database.  The browser based window provides the ability to select specific database sets and subsets, as well as the desired map(s) upon which the data is to be displayed.  Controls would also be made available to allow the analyst to control the speed of the representation, the maps to be displayed, the geographic features to be displayed, as well as control of data elements to be displayed.5.  Implementation.   It was decided early in the development process that CAMPVIZ would be developed in small manageable phases, partially to meet some time constraints and also to match available funding levels.  The first phase would be a “Proof of Concept” system, which would have the basic functionality which had been discussed, but not all possible functions that had been defined in the requirements document.A graphics tool, Macromedia Director, was used by the developer during both the system design phase, as well as the development phase to assist the client in understanding the capabilities that were being proposed and developed.  Users are often unable to articulate their requirements in a way which translates effectively into a developers statement of need (Might, et al [2] ).  Since the client was not generally familiar with M&S visualization potential and constraints, this was a very effective tool to facilitate the dialog between user and developer.The software for this project was written in Java.  This included, not only the application software, but also the database implementation using JDataStore and JBuilder.  There were several essential elements associated with the initial phase of the CAMPVIZ.  They were; (1) insuring objects moved appropriately based on the simulation from which the data was derived, (2) storing and providing appropriate object state, either directly on the display or in amplifying data which could be requested by the user, and (3) providing a visual representation of each object based on specific and tailorable input from the user.  While the first task may appear to be simple, in fact this created some problems.  It required an implementation, whereby objects, that may be stationary or moving, could enter or leave the battlespace at different times.  Additionally, objects may move to specific geographic location (i.e., lat/lon) or may move a specified distance along a pre-defined path.  The path itself, was implemented as an object which was defined as a series of lines through user defined nodes.  As with any other object in the database, these paths could be displayed or not, based on the desires of the analyst.In the proof of concept phase, all of the basic functionality was implemented, however the capabilities were generally limited in scope.  The map backgrounds were only implemented on either a world scale or Southwest Asia and Northeast Asia at lower levels of resolution.  Within these regions, we only provided one or two map scales.  Manipulation between map scales was not automated, but required manual intervention.The first phase only contained enough time and resources to develop a rudimentary database and database interface.   While all the tables and relationships described earlier were implemented, data entry was strictly a manual process.  The analyst provides a spreadsheet or flat file with data (and its appropriate data name), then one of the developers input the data into the database.  Additionally, we believe the current implementation has some significant performance shortfalls, particularly in the time required to download a database of interest to the client browser.  Even with a very limited database and small sub-set of map data, it can take several minutes to download one scenario for display.The representation of objects was discussed at great length, but in the end the flexibility requirement of the client was paramount.  As such, we allowed for the utilization of all MIL-STD 2525B to be used, but also any user defined representations which could be described in terms of a closed polygon, ellipse, or line.  Additionally, the user has maximum latitude in describing the color of the object, both in terms of outline color, but also the fill color. The fill color could also be defined as translucent, allowing background features to be seen through the objects.   There is also an option available to highlight the object in some manner if critical information needed to be provided visually.  Another capability this provided was the ability to represent objects which might change size and shape over time.  An example of this would be regions of chemical or biological contamination over time. Icon or object movement was an area in which some trade-offs were made for the proof of concept version.  As was discussed during the requirements phase, various CAA models ran at different time steps.  Some of the simulations might perform updates every few hours, while others may not update for 24 or 48 hours.  Initially, there was discussion of several different movement schemes.  We discussed three different schemes; the first would be strictly time-stepped where all objects would be positioned based on their actual or interpolated location at a specific time, second is frame based or positioning an object based on a true location at it’s most recent update – regardless of current time, and finally a “smoothing” positioning which would interpolate position from time-step to time-step giving the impression of continuous movement.  The actual implementation was a frame based concept which places an object at its last reported position, regardless of the time that has passed since that update. EMBED PowerPoint.Show.8  Figure 5.1 Preferences Dialog BoxA feature that was requested and implemented for this proof of concept, as shown in Figure 5.1, was the ability of the analyst to define the frame intervals (how much simulation time had passed) from 0 hours (zero) up to 24 hours.  In conjunction with that, the time each frame would be displayed could also be controlled from 0-60 seconds.  In this way, a “flickering” movie type of display can be provided for the analyst or for their use in briefings to the Army staff.  The primary purpose, or objective, of the Proof of Concept version of CAMPZIV was satisfied by providing a system capable of representing all desired objects and object state. These representations are all independent of one another and independent of the source of the data or its representation.  EMBED PowerPoint.Show.8  Figure 5.2 – CAMPVIZ Overview6.  Next StepsThe Proof of Concept version of CAMPVIZ was delivered to CAA in October 2000 and is currently being evaluated and exercised by them.  While the system implements key concepts that were requested to sufficiently to evaluate the overall project, there are some recognized, and in some ways, planned  shortcomings.Some work has been initiated in documenting requirements for Version 1 of CAMPVIZ which will accomplish the following:Develop an automated tool to load data from simulations to CAMPVIZ databaseExpand and enhance available maps, both scales and typesExpand database structure to accommodate all current CAA modelsSmoothing of icon/symbol movement (interpolation of moving object locations for models of varying time steps)Enhance operational performance, including initial load timesThe primary object of Version 1, however will be to provide a robust, operational capability to visualize simulation output for the CAA analyst as well as their clients within the Army and other DoD elements.  At this time, the next version of the project is on hold,pending receipt of additional funding.7. References [1]	K Neff, S Vermette: “Lessons Learned While Using a Component Framework to Reconstruct a Legacy Analytic Model”  00S-SIW-014, March 2000.[2]	R Might, R Willis, F Crain, “Developing Requirements for Analytical Models and Simulations”, 00F-SIW-130, September 2000[3]	D Wetzel, K Johnson: “A Non-Intrusive HLA Distributed Data Logger” 00S-SIW-100, March 2000[4]	R Head, P Perkinson, M Thoma, A Wilson: “Developing an HLA Federation-Independent Playback Application”, 00S-SIW-146, March 2000 [5]	J Black, “Data Collection in an HLA Federation”, 99S-SIW-022, March 1999[6]	G Magee, G Shanks, “Lessons Learned from an Implementation of a Fully Distributed Data Collection Tool”, 99S-SIW-084, March 1999Author BiographiesMR CHRIS WERTMAN is an associate with Booz-Allen & Hamilton at their Ballston II Facility, in Arlington Virginia.  Mr Wertman holds a B.S. in Aerospace Engineering from the University of Oklahoma and an M.S. in Computer Information System from Boston University.  He has held numerous positions during a period of more than 20 years, developing, implementing, and using modeling & simulation in support of major theater level exercises, individual task training, system acquisition, as well as systems and force analysis.  He has provided simulation and simulation related support to OSD agencies, as well as Army,  Air Force, and Joint/Combined service clients.MR DANIEL SHEDLOWSKI is the Technical Director for the Center for Army Analysis (CAA) at Fort Belvoir, Virginia.  Mr. Shedlowski has a  BA in Mathematics, Kings College, Wilkes-Barre PA, MS in OR, Fairleigh Dickinson University, Rutherford NJ, Industrial College of the Armed Forces, Ft. McNair, Executive Excellence Program of the Federal Executive Institute, and Harvard University's John Fitzgerald Kennedy School of Government National Security Program.  He is the director of in-house development of theater force evaluation model (FORCEM). He assumed his current position as Technical Director of the CAA in 1995. He led major analytical efforts for the Deputy Under Secretary of the Army for Operations Research such as "Army Analysis Requirements for the 90's" (1990), a Manpower Requirements Determination (MRD) Methodology review (1993) “A Redesign Option for Improving HQDA Analysis Support” (1996) and “Revolution in Analytical Affairs” (1998).