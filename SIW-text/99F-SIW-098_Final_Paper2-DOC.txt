Real-Time Performance of RTI Version 1.3Ernest F. PayneRaytheon Systems Corporation c/o Air Force Research LaboratoryAFRL/VACD2180 Eighth Street. Suite 1Wright-Patterson AFB, OH  45433-7505 HYPERLINK mailto:ernest.payne@va.wpafb.af.mil Ernest.Payne@va.wpafb.af.milLt. Jesse B. ZydallisAir Force Research LaboratoryAFRL/VACD2180 Eighth Street. Suite 1Wright-Patterson AFB, OH  45433-7505HYPERLINK "mailto:Jesse.Zydallis@va.wpafb.af.mil"Jesse.Zydallis@va.wpafb.af.milLt Todd R. AndelAir Force Research LaboratoryAFRL/VACD2180 Eighth Street. Suite 1Wright Patterson AFB, OH  45433-7505 HYPERLINK "Todd.Andel@va.wpafb.af.mil" Todd.Andel@va.wpafb.af.milABSTRACT: High Level Architecture (HLA) is currently the standard protocol that is used in government simulation facilities. Simulations at the Air Force Research Laboratory, Air Vehicles Directorate, Integration and Assessment Branch involve real time, highly dynamic aircraft that mirror air combat engagements.  These engagements naturally result in extremely high network and protocol traffic because of the constant state variable changes. This traffic can affect the performance of any such simulation.  An important factor to consider when trying to reduce latency in real-time simulations is the performance of the Network Interface Unit (NIU).  A performance comparison of the High Level Architecture (HLA) Runtime Infrastructure (RTI) Versions 1.3 releases 3 through 6 is presented in this paper.  This paper demonstrates the effects of the Federate Network Interface Unit (NIU) on a real-time, highly dynamic simulation. The Integration and Assessment Branch has historically completed performance measurements of simulation protocols.  This paper presents updated measurements and tests completed on RTI Version 1.3.  This is a comparison of the effects of the RTI releases, using various machine architectures with different performance characteristics.  The measurement criteria is based on the effects of an increasing entity load with respect to time. The test bed design, measurement techniques, and results of NIU code performance will be presented.  In addition latency, accuracy and bandwidth measurements were taken using equipment developed in-house under the Simulation Network Analysis Project (SNAP) and is presented here.Keywords:HLA, NIU performance, RTI, SNAP, latency, accuracy, bandwidth, highly dynamic simulation, high fidelity, real-time simulationIntroductionAir Force Research Laboratory, Air Vehicles Directorate, Integration and Assessment Branch received funding through AMC (Air Mobility Command) via ASC/YW (Aeronautical Systems Center, Training Systems Products Group) to evaluate HLA progress and to test the effects of network loading using HLA RTI version 1.3.  During the evaluation period, multiple releases of the RTI version 1.3 became available and are incorporated into this study.  This paper shows the performance of RTI version 1.3 releases 2 through 6 with respect to each other.  It also evaluates the RTI’s performance across a network using various architectural configurations.The High Level Architecture (HLA) is no longer in its infancy with version 1.3’s release and version NG, Next Generation, soon to be on the way.  With this growth comes change which the real-time community must be ready for.  Therefore, it is necessary to evaluate the impact of the RTI on real-time simulations.  A baseline for testing was created through previous performance testing of the RTI on a real-time simulator.  This baseline included the use of a 4V4 configuration (Figure 1).  This configuration consisted of 4 highly dynamic aircraft flying against 4 highly dynamic aircraft.  The 4V4 configuration was used to determine the effect of the RTI on the performance of highly dynamic real-time simulations and networked simulations.  In this paper a highly dynamic aircraft is referred to as one that completes high-G type maneuvers.  These maneuvers break dead-reckoning thresholds, which leads to the creation of Ethernet packets to update networked simulation state variables. [1]   EMBED ShapewareVISIO20  Figure  SEQ Figure \* ARABIC 1 - HLA Evaluation Network ConfigurationMeasurement TechniquesTwo sets of data measurements were taken to support this project.  One set of data was taken through the use of direct code timing measurements.  The direct code timing measurements were used to capture execution times of the RTI functions.  A second set of data was taken though the use of the Simulation Network Analysis Project (SNAP).  SNAP is a simulation network analysis tool developed in-house by Integration and Assessment Branch personnel.  SNAP is used to accurately measure latencies and bandwidth of a simulation while remaining completely passive to the simulation.SNAPSNAP measures all latencies involved with stand-alone simulations and those networked locally or over a long-haul network.  One SNAP computer can operate alone to determine several performance factors of a single simulator; such as stick input to out-the-window (OTW) video delay, stick-to-instrument delay, stick-to-state variable update delay, stick-to-Ethernet packet transmission delay, Ethernet packet reception to state variable update delay, and Ethernet packet reception to OTW video delay.  Also, multiple SNAP computers can evaluate the performance of a networked simulation by connecting to simulators in geographically separate locations and monitoring the end-to-end delay.  SNAP can also monitor a network and give statistics on network traffic from generic Ethernet packets to HLA packets.  SNAP is capable of driving the simulator-input signals, allowing the SNAP operator to have repeatable test results.  SNAP measurements between simulators located anywhere in the world are accurate within 500 microseconds.  For more information on SNAP, refer to [7] and [8].Code TimingSimultaneous execution of several different processes on different computers is required to implement real-time simulations and to measure the NIU performance.  Therefore a common timing source is needed for consistent code timing.  Global Position System (GPS) time provides an accurate method that can be used by local or geographically separated simulation sites.  This common time is provided to all processes by a SNAP computer that was modified to continually write GPS time into SCRAMNet shared memory.  The time is accessible by every computer involved allowing each event to be accurately time-stamped.  Event timestamps are then recorded for each frame of the simulation by the simulation computers.  After the simulation run, the recorded data is written to a file.  The use of the consistent timestamp enables the reconstruction of events for each frame of the simulation and accurate measurements of specific operations of the simulation and NIU.Test-bed DesignEach simulated federate is composed of one piloted high fidelity simulation aircraft and from three to fifteen digital players.  The following subsections give an overview of the test-bed architecture and quick overviews of each component of the test-bed.  See [3] for a more detailed description of the components. Test-bed ArchitectureThe conceptual diagram of the test-bed architecture is shown in Figure 2.  The digital players are shown as three individual players, but in fact are run as a single process in one dedicated processor and “fly” in SCRAMNet.  The number of digital players ranged from 3 to 15 entities.  The access time from SCRAMNet to a digital processor ranges from less than 1 ms for three entities to approximately 3.5 ms for fifteen entities. By keeping the same test bed throughout the testing period allowed for reproducible results. EMBED ShapewareVISIO20  Figure  SEQ Figure \* ARABIC 2 - Test-bed Architecture - ConceptualSimulation ComputersThe two high fidelity simulations were run on two Encore RSX computers.  These computers ran synchronously with each other and contain one RSX 100 MHz CPU, a SCRAMNet card, an Ethernet port and are connected together by a Reflective Memory System (RMS).  The Encore simulations are not affected by the NIU code and execute exactly the same regardless of which NIU is used. There are three Silicon Graphic computers utilized in this testing.  An eight CPU Challenge XL contained R4400 processors running at 200MHz, a four R10000 processor, 194 MHz CPU Onyx10000 and a four R10000 processor, 250 MHz CPU Onyx2.  Each computer utilized here had a SCRAMNet board installed in it.  The Silicon Graphics machines were used to implement the NIUs (one NIU per processor), handle the six UTD digital players (up to fifteen digital entities per processor) and the simulated WAN.  The SCRAMNet boards were used for transfer of simulation data to the NIU computer, transfer of GPS time to all machines in all the architectures, synchronization of the NIU and digital players processes, and for data collection.  Also, each entity, whether high fidelity or digital, wrote its current state information into the data section of SCRAMNet so that the true location of the entity could be saved for each simulation frame.Ethernet NetworkAFRL/VACD’s computer deck utilizes two 10BaseT Ethernet networks. One is for developmental, non-real time uses and the other is for real-time simulation use. Each computer has two Ethernet ports installed in them.  One Ethernet port is used for remote login purposes on the developmental network and the other is used for communication between the machines on the real time network. The RTI uses the real-time network for communication.  By using this configuration, the simulation runs on a dedicated 10BaseT Ethernet with no extraneous traffic on it. SNAPThe Simulation Network Analysis Project (SNAP) equipment is connected to the Ethernet and SCRAMNet to collect network, simulation state, and code timing data.  SNAP records data passively to allow the user to determine the latencies in a simulator and the network latencies present.  SNAP measurements between simulators located anywhere in the world are accurate within 500 microseconds.  During the Distributed Interactive Simulation (DIS) experiments, the collected DIS PDUs where decoded by SNAP to determine the latency from simulation state changes to when the change went out in a PDU.  For the HLA evaluation raw Ethernet packets are collected but not decoded by SNAP because the network format of the RTI’s Ethernet packets is not readily available.  In these tests the Ethernet packets are collected as hex values and later decoded through data analysis to determine the latencies.RTI InterfaceThree multiprocessor computers were used in various combinations as a basis for testing.  Each machine varied in its architecture and performance.  The machines were set up in a way that simulated the use of networked simulators.  The federation consisted of two federates.  There are nine possible federate configurations, three for each computer.    For each computer, both of the federates resided in a separate processor on that computer, or resided in a processor on one of the other computers. Each federate NIU utilized a dedicated real-time processor.  The NIU processor busy-waited for the frame synchronization flag in SCRAMNet that signaled the NIU to update its internal simulation time with the current GPS time.  It then busy-waited again on an aircraft done flag in SCRAMNet to signal that all the federate’s local aircraft had updated their data in SCRAMNet.  The NIU processor would then:Use the state data in SCRAMNet to update the true state of the local entities.Dead reckon the aircraft position.Compare the difference between the truth data and the dead reckoned data with the thresholds.Update entity’s attributes if necessary with the rtiAmbassador.Process RTI messages by calling the rtiAmbassador tick method.Dead reckon all known remote entities.Write dead-reckoned state information of remote entities into SCRAMNet.The NIU used the Real-Time Reference FOM version 0.1.5 and was not time regulated or constrained.  MilitaryPlatformEntity objects whose attributes were all receive order, best effort, represented all aircraft and/or missiles. Only MilitaryPlatformEntity objects were published and subscribed to and no interactions were used.  The first attribute update for all aircraft or missiles would send all the attributes associated with the MilitaryPlatformEntity.  Subsequent calls would only send the aircraft and/or missile state information. The state data consisted of TimeStamp, AccelerationVector, AngularVelocityVector, Orientation, Position, and VelocityVector.The RTI Initialization Data (RID) file was modified to use the real-time network on the three Silicon Graphic machines’ selectable Ethernet port as its network device. Being able to specify the Ethernet port is a much-needed enhancement from being constrained to the default Ethernet port in 1.0v2.  The RID file was also modified to turn off UDP bundling to decrease message latency, and where available the default_heavy_weight_interval was set to 1000000 as suggested to decrease the number of publish and subscribe Ethernet packets sent onto the wire.   Some programmers testing the RTI, as a possible solution to the problem, suggested this modification.  It was noticed that modifying this value to 1000000, 1, or 0 had little or no effect.Modifying the RID file caused a conflict when joining using different machines.  This was because each machine’s second port has a different port designation.  For example, the Silicon Graphics (SG) Onyx 10000’s second port designation was “fxp1”, and the SG’s Challenge second port designation was “ep0”.  The conflict was that the files were a different size and any subsequent federate was not allowed to join.  To circumvent this problem, it was necessary to edit the RID file so it contained each external port designation with all other external ports commented out except the one belonging to the owning machine.  Future releases of the RTI should address this issue.Digital EntitiesDigital entities were used as the extra players on each LAN to load the network.  All digital entities for one federate were run as real-time process on one of SG Challenge processors.  The entities could fly a straight, level turn, or prerecorded flight path.  The prerecorded flight path used for the high-G maneuver was recorded at AFRL/VACD with a real pilot in a 1v1 within visual range engagement.The digital entities were run on the 8-processor Challenge machine. All other machines used in the testing were 4 processor Silicon Graphics machines.  When two federate NIUs were run on the same machine, the fedex would also run on that machine.  With the operating system locked into one processor, each of the two NIUs on a separate processor and the fedex on a processor, this utilized all the processors of the 4-processor machines.  The digital aircraft had to remain on the 8 processor Challenge during the tests.Network LoadingLoading the network based on increasing numbers and performance characteristics of the digital entities tested scalability.  This loading is representative of two squadrons performing air-to-air combat training.  The actual numbers and characteristics of the digital entities used for loading are explained in more detail in the  REF _Ref424223904 \* MERGEFORMAT Testing section.TestingTestDynamic EntitiesNumber of  TrimTotalIDPer SideEntities Each  SideEntities0vNone4 aircraft81v1 aircraft3 aircraft82v2 aircraft2 aircraft83v3 aircraft1 aircraft84v4 aircraft1 aircraft105v5 aircraft1 aircraft126v6 aircraft1 aircraft147v7 aircraft1 aircraft168v8 aircraft1 aircraft189v9 aircraft1 aircraft2010v9 aircraft, 1 missile1 aircraft2211v9 aircraft, 2 missiles1 aircraft2412v9 aircraft, 3 missiles1 aircraft2613v9 aircraft, 4 missiles1 aircraft2814v9 aircraft, 5 missiles1 aircraft3015v9 aircraft, 6 missiles1 aircraft32Table  SEQ Table \* ARABIC 1 - Test MatrixTable 1 shows the test matrix used during the test runs.  The test ID is used as the x-axis label in most of the following charts.  This block of tests is the same as the test matrix in [3] for each protocol.  “The block consists of ten tests, each one with an increased load.  The first test had 4 entities on each side flying trim and level.  The second test had one entity on each side performing a high G maneuver with the rest flying trim and level.  Each test then increased the number of digital entities flying a high G maneuver.  Note that there was always a piloted player flying straight and level, but its network output is insignificant compared to the output from the digital players.  Example: test 7 had 6 entities on each side at high G with one entity on each side flying trim.” [3]Federation executions for each test lasted 10 seconds, as did the tests in the previous experiments, and data was recorded both on the Encore computers and SNAP.  The Encore computers recorded the simulation’s internal truth location of each local entity and its perceived position of each remote aircraft.  The spatial accuracy as perceived by the Encore simulations could then be calculated each frame of the simulation as the difference between its perceived location and the true location of the entity in the data section of SCRAMNet.Comparisons of RTI1.3r2-r6Total Protocol Processing Time Figure 5.1 Total Protocol Processing TimeFigure 5.1 shows the total protocol processing time comparison of the different protocols evaluated in this study.  This chart shows the overall time it took the NIU to process incoming and outgoing network data on the 8-processor Challenge. [1] There is a large difference in the plots for RTI 1.0v2 and DIS.  This difference is attributed to the increased protocol communication added with the use of the RTI.  The lesser difference in the plots of RTI 1.0v2 and RTI 1.3v2 is attributed to the evolution of the protocol.  The last difference noted is in the plots of RTI 1.3v2 and RTI 1.3v6.  This is viewed as being attributed to the bandwidth and packet size change versus the great changes in the architecture of the DMSO RTI 1.3 that was previously seen.Update Attribute TimeWhen the RTI called the method “provideAttributeValueUpdate()”, the federate responded by invoking “updateAttribueValue()”.  Figure 5.2 depicts the percent of the “send time” that it took to execute the update of the attributes.  In Figure 5.1, it appears that the time to process entities increased linearly but this does not seem to be the case with this send interaction.  The expected result would create the same pattern in callbacks to the RTI. Furthermore, Figure 5.1 shows that seven entities are processed without frame time violation and should therefore be accurate but Figure 5.2 shows the percent of time decreased at seven entities. Figure 5.2 Percentage of Time to Update Attribute ValuesComparisons using Different Machine ConfigurationsHistorically, the VACD effort of RTI evaluation has been conducted using only one multi-processor computer to house the entire federation. The NIUs were locked into a single processor with the task limited to interfacing with the RTI and the simulation.  This project delved into looking at the performance of the RTI and the simulation when the federation resided on different multi-processor computers.  For consistency, the execution was carried out as before.  This portion of the evaluation involved a comparison of the RTI when the machines of different capabilities are used.  In the past, the NIUs resided in a dedicated processor on the Silicon Graphic’s Challenge.  By moving the NIUs to different machines it was determined if there was any affect on the execution performance.  In all, there were three different Silicon Graphic machines tested in six different configurations.  Following are graphs that depict the performance of the NIUs in the varied configurations.  The data was gathered using three different computers.  At most, only two computers were used to represent the federation and sometimes the federate resided on only one computer.  Figures 6.1 through 6.3 show which combination of computers were used, which computer that the NIU being evaluated resided on and what other computer was involved in the federation. An important point to remember here is that the NIU resides on a dedicated processor on each machine that it resides. This is important when one is conducting performance measurements. The first name is the computer where the local NIU resided. This is the NIU that is being evaluated.  The second name is the computer where the remote NIU resided.  For example, Onyx2-Onyx10K indicates the NIU that resided in a processor on the Onyx2 was being evaluated and the second federate was on the Onyx10000. There is also an indication of the frame time used in this test configuration. Once the plot crosses the frame time boundary, the results then become questionable and are included for information only.  The crossing of the frame time boundary basically means that you start to lose spatial accuracy in your simulation.  This is due to the fact that the simulation was dropping update packets.Machine to Machine ComparisonFigure 6.1 demonstrates the performance of the RTI when the NIUs were running on the same machine but different processors.  That is, the NIU was locked in a processor on the same machine as the other NIU.  The fedex also resided on that machine. Machine to machine means both NIUs resided on the same computer, but in different processors.This figure shows the average performance of the protocol processing time of each computer. Protocol processing time is the summation of the time to process the send and receive interactions each frame time. One frame time is 20 ms since the test was run at 50 Hz. As expected, the faster computer performed best.  The main point of interest is that each combination eventually exceeded the frame time and thereby droped frames. The dropping of frames had an adverse affect on the simulation since the networked simulators did not receive the updates when they needed to.  It should also be noted that there is no great increase in the number of entities that could be accurately processed, before breaking the frame time, by using a faster machine. The Challenge accurately processed 8 entities while the Onyx2 only processed 3 additional entities. Therefore, processing power is an answer for real-time, but not the complete solution.Figure 6.1 Protocol Processing Time by MachinePerformance Comparison of the Onyx 2 and the ChallengeFigure 6.2 Protocol Processing Time Onyx 2 to ChallengeFigure 6.2 shows the performance of the NIUs when executed with the Onyx2 and the Challenge configuration.  The Onyx2 to Onyx2 and Challenge to Challenge performance is included for a comparison.  The result is exactly what one would expect.  This is that if you include a faster machine in the loop then your simulation performance will increase and will be able to process more entities before breaking the frame time. The performance of the NIUs showed an improvement when the NIUs were on separate computers.Performance Comparison of the Onyx 2 and the Onyx 10000Figure 6.3 demonstrates the RTI performance when the Onyx2 and the Onyx10000 were used.  These were the two faster machines involved in this testing.   The individual performance of each machine, when the NIU is on the same machine is included for comparison.  The performance of the NIUs showed an improvement when the NIUs were on separate computers. In this case, the frame rate was not exceeded until the number of entities per side was 14. Figure 6.3 Frame Time Comparison Onyx2-Onyx 10000Fedex Residence QuestionWhile collecting data, it appeared that the fedex showed a preference to the first federate over the others.  The data showed a widening gap between the protocol processing time of each federate as the number of entities that were successfully processed increased, as shown in Figure 6.4.  Figure 6.4 Send and Receive ComparisonsEvery test to this point was run with the fedex residing on the fastest machine.  To control this, the NIU was started on the machine we wanted the fedex to reside on first. The results showed that there was no difference where the fedex resided.Figure 6.5 Protocol Processing Time with Fedex ComparisonEthernet DataAs in all testing reported in this paper, the attribute subscription was limited to 5 attributes plus time, to allow for GPS time-stamping, to give a total of 6 attributes which consisted of 68 bytes of data.  Figure 7.1 shows that the DIS and RTI NIUs output approximately the same number of packets which confirms that the dead reckoning algorithm in the RTI NIUs was functioning the same as the one in the DIS NIU.  This fact is important because it verifies that the simulations were working together.  The Ethernet data from the different versions of the RTI differed slightly from DIS due to the administrative packets that the RTI put on the wire.  DIS-Lite outputs less packets than all the other protocols because it adjusted the dead-reckoning algorithm to minimize bandwidth usage. [1]Figure 7.1 Total Number of PacketsFigure 7.2 shows that DIS-Lite had the lowest bandwidth requirements and the RTIs had the greatest requirements.  It was noted that with successive releases of the RTI, the bandwidth requirements have increased.  One key factor in this was the increase in the data packet size from RTI version 1.3v2 to RTI version 1.3v3 (1.3v3 through 1.3v6 remained the same).  RTI 1.3v3 saw the increase in packet size from 214 bytes to 394 bytes, as shown in Figure 7.3.  Another point to notice is that the bandwidth of RTI 1.3v6 dropped off a little bit once the testing hit 8v8 and 9v9.  This is due to the fact that the frame boundary was exceeded here and packets were lost.  That is also the reason that the total number of packets at those points was also a little less than expected.  Since frames were dropped, some packets were not created thereby showing a decrease in the number of packets and in the overall bandwidth.It is important to address the bandwidth issue encountered.  In the testing completed here the bandwidth was fairly high at a low total entity count.  For example, from Figure 7.2, at 6v6 which was 14 total entities (Table 1) the bandwidth was 776.1 Kbps.  This bandwidth is very high for that total number of entities.  If the RTI is to be used in joint exercises over long haul networks involving multiple players, improvements need to be made.  These improvements should include improving the packet efficiency and decreasing the bandwidth utilized.Figure 7.2 BandwidthIt was determined, through analysis of the hex dump of the Ethernet packets, that the increase in size was due to additional publish and subscribe information that was included in each packet sent.  A number of RID file modifications were attempted to correct this situation (changing the value of the default_heavy_weight_interval flag).  None of these changes had any affect on publish and subscribe information being passed.  The RTI help desk confirmed that this was a flaw in the software design of RTIs 1.3v3 through 1.3v6 and should be corrected in future releases.As reported in our previous paper, “a basic DIS Entity State PDU had 144 bytes of “simulation data” and was 186 bytes on the wire.  The extra 42 bytes consisted of 28 bytes for the UDP/IP Ethernet header information and 14 bytes for the Ethernet encapsulation.  The RTI NIU would output all the data for a MilitaryEntityState object on the first pass.  The initial packets to handle this transmission were 670 bytes.  Since the packet format is not published it was deduced that the 670 byte packet contains publish, subscribe and initialization data.  For each federation execution, one 670 byte packet was sent for each entity.  After the initial attribute update, the RTI NIU only sent out the data that changed, which were 68 bytes of state information.  This Ethernet packet was 394 bytes on the wire or 344 bytes of data, the 344 bytes was the total of the RTI overhead and the simulation data in the packet.  This shows that there is still quite a bit of overhead in the RTI’s Ethernet packets.” [1]Figure 7.3 Packet Efficiency“There were two different types of packets for attribute updates seen during the experiments: initialization and update.  The initialization packets contained what looked like publish and subscribe information and the actual data given to the updateAttributeValues method.  Packets containing the publish and subscribe data were only sent when the first updates for each entity took place.  These were the 670 byte packets mentioned above.  After that, only update packets were seen that contained just the data given to the updateAttributeValues method.  These were the 394 byte packets mentioned above.” [1]The size of the update packet can be estimated by using Tables 2 and 3.SectionSize (bytes)Enet Header42RTI Info68RTI Attribute Header4 * # of attributesDataSummation (Size of each attribute * # of attributes of that size)CRC4Total PacketSum of previous rowsTable 2 - Update Packet Size (RTI 1.3v2)SectionSize (bytes)Enet Header42RTI Info68RTI Pub/Sub Info180RTI Attribute Header4 * # of attributesDataSummation (Size of each attribute * # of attributes of that size)CRC4Total PacketSum of previous rowsTable 3 - Update Packet Size (RTI 1.3v6)The update packet size had the most significant change from RTI version 1.3v2 to 1.3v6 as previously mentioned.  From Table 3 it can be seen that the addition of the RTI Pub/Sub Info indeed contributed a lot to the size of the packet and the amount of bandwidth required.  In subscribing to 6 attributes it increased the size of the packets by 45.7% or 180 bytes from RTI 1.3v2 to RTI 1.3v6 (again RTI 1.3v3-RTI 1.3v6 showed the same packet sizes).  Increasing the number of attributes subscribed to would decrease the percentage of the packet that the publish and subscribe data would take but would not decrease the 180 bytes used.ConclusionsThe results presented in this paper are done in the hope of bringing to light some of the performance issues of the RTI as it impacts real-time simulations. The results should make simulation programmers and the architectural developers of the RTI more aware of issues affecting real-time simulations.  These issues are extremely important when planning to create a real-time simulation using multiple entities and multiple sites.  “Note that the results presented here are for aircraft state updates only.  No other types of objects or interactions were exchanged.” [1] For a full up training or combat simulation there would be a substantially greater amount of data transferred.  This increase in data would result in greater bandwidth utilization thereby leading to higher latencies encountered.With the introduction of RTI 1.3v3, through RTI 1.3v6, a substantial change was detected in the performance of the RTI. The packet size increased significantly resulting in an increased bandwidth requirement.  The increase in the packet size was due to the addition of publish and subscribe information included in the data packets.  The current performance will limit the number of entities possible in a real-time high fidelity federate, or lower the accuracy of the remote entities by increasing the NIU’s frame time to accommodate the processing overhead.  The processing overhead of the RTI needs to be decreased in order to support high fidelity real-time simulations.The use of faster machines with more processing power will allow a simulation to perform with lower latencies. Throughout the testing completed it has been noticed that each version of the RTI requires more processing power in order to achieve the same performance.  Hopefully in future releases of the RTI a decrease will be seen in packet size and bandwidth requirements.  References[1] Johnson, Capt. Ronnie and Wuerfel, R.: “Real-Time Performance of RTI Version 1.3” 98 Fall Simulation Interoperability Workshop. Paper No.: 98F-SIW-125.[2] Purdy, Lt SG Jr., Wuerfel, R., Barnhart, Lt D., and Ewart, R.:  ‘Network Evaluation for Training and Simulation’ AFRL-VA-WP-TR-1998-3013 - November 1997.[3] Purdy, Lt SG Jr., and Wuerfel, R.: “A Comparison of HLA and DIS Real-Time Performance” 98 Spring Simulation Interoperability Workshop. Paper No.: 98S-SIW-042.Author BiographiesERNEST PAYNE received a Bachelor of Science in Computer Engineering from Wright State University in 1995.  He has been working for the AFRL/VACD facility’s site contractor, Halifax Corporation and Raytheon Systems, since 1996.  Currently, Mr. Payne is a Senior Software Engineer involved with network interface software and with real-time software development.LT JESSE B. ZYDALLIS received a Bachelor of Science in Computer Engineering from New Jersey Institute of Technology.  He received his Master’s of Science degree in Computer Engineering (Specialization in Parallel Processing and minor in Networking) from New Jersey Institute of Technology in 1998.  He entered the Air Force and was commissioned in 1997. He has been working at The Air Force Research Laboratory’s Integration and Assessment Branch (AFRL/VACD) since January 1998. Currently Lt. Zydallis is responsible for Simulation Network Analysis Project (SNAP) project management.  He is also involved in optimizing real-time network performance and communication support for both VACD and the Joint Strike Fighter (JSF) program.LT TODD R. ANDEL received a Bachelor of Science in Computer Engineering from the University of Central Florida in 1998.  He entered the Air Force in 1989 and was commissioned in 1998. He has been working at The Air Force Research Laboratory’s Integration and Assessment Branch (AFRL/VACD) since November 1998. Currently, Lt Andel is a Simulation Network Analysis Project (SNAP) operator.  He is also involved in optimizing real-time network performance and communication support for both VACD and the Joint Strike Fighter (JSF) program. EMBED Excel.Sheet.8   EMBED Excel.Sheet.8   EMBED Excel.Sheet.8   EMBED Excel.Sheet.8   EMBED Excel.Sheet.8   EMBED Excel.Sheet.8   EMBED Excel.Sheet.8   EMBED Excel.Sheet.8   EMBED Excel.Sheet.8   EMBED Excel.Sheet.8  