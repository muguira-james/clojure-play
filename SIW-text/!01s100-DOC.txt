Application Domain Modelling for the Verification and Validation of Synthetic Environments:Developing the Training Process Definition FrameworkG. N. HoneM. R. Moulding*Computing Information Systems Engineering GroupDepartment of Informatics and SimulationRoyal Military College of ScienceCranfield UniversityShrivenham, Wiltshire, UK+44-1793-785522hone@rmcs.cranfield.ac.uk; moulding@dial.pipex.com(*contact)and Major A. K. RobinsonRoyal Logistics Corps (British Army)Keywords:VV&A of Synthetic Environments; Application Domain Modelling; Training Process Definition; Collective Training.ABSTRACT: As part of our research programme into the Verification and Validation (V&V) of Synthetic Environments (SEs), we have argued the case for modelling the application domain, in which a SE will operate, as an important way of helping to ensure that a SE is fit for purpose (e.g. 98S-SIW-063).  At the Spring 99 SIW, we presented a paper (99S-SIW-122) which elaborated this Application Domain Modelling (ADM) approach for SEs employed for training applications, and introduced a novel Training Process Definition Framework (TPDF).  This employs a sequence of analysis techniques that combine the approaches of Software Engineering and Human Factors, and was designed specifically to facilitate the early-stage V&V of training-based SEs.  The rationale for the TPDF was that, if the training process could be completely described, this would form a strong foundation upon which to define the requirements of a training SE to deliver that process.  At that time, the TPDF had only been applied to Individual and Small Team Training, but we announced our intention to develop the TDPF further, by considering its application to Collective Training.  Accordingly, within the last two years, we have applied the TPDF to the requirements analysis for a Collective Training SE-based system: a Unit-level Tactical Trainer (UTT) directed primarily at Command and Staff training.  This application has enabled us to make refinements to the TPDF, and to demonstrate the decomposition of a Collective Training process.  In particular, changes to the front-end of the TPDF, to incorporate a degree of iteration, have allowed us to minimise potential conflicts between stakeholders with disparate views, while addressing Collective Training has led to a new perspective on Task Decomposition and Composition.  This paper  reviews the TPDF and its role in the early-stage V&V of SEs. It then presents the results of its application to the UTT, and discusses the associated refinements that we propose and their attendant benefits.1. 	Introduction Fitness for purpose should be a primary objective of the validation of a Synthetic Environment (SE).  This, in turn, requires a sound understanding of the problem domain being modelled and the application domain in which the SE is to be employed.  At the Spring 1998 SIW [1], we suggested that, while considerable effort had been directed towards formalising abstractions from the problem domain, exemplified by the Conceptual Models of the Mission Space (CMMS) initiative, relatively little work had been aimed at modelling the applications domain, to support user-oriented requirements capture. Consequently, we proposed Application Domain Modelling (ADM) as an extension to any High Level Architecture (HLA) [2] federation development process. The objective of ADM was to support both verification and validation at an early stage of SE development.  In outline, we saw ADM as involving the modelling of the application process (that which employs the SE), and of the application system (that which delivers that process and within which the SE is embedded).  This gave us the “Y” model of HLA system development, now a trademark of our research programme.Effectively, we have two parallel threads, one of which produces a model of the application (in the case of this paper, military training), and the other which produces a model of the problem (or the mission space).  These threads converge to produce a highest-level model of the desired SE.In an earlier SIW, Haddix et al argued a clear view of the CMMS as intended to inform the design but not to be the design [4].   We take exactly the same view with regard to ADM, and the TPDF was developed as a means of informing the design of an SE by generating a clear model of the training requirement without dictating the nature of the training activity.  The summation of the CMMS and the ADM  (at the stem of the Y-model) will be a conceptual model of the Synthetic Representation that encompasses Operational Doctrine and best Training Practice.2.	The Training Process DefinitionFramework (TPDF)In reference [4], we offered the view that no single technique would lead to the definition of a training process, and proposed a meta-process employing a sequence of techniques.  This we termed the Training Process Definition Framework (TPDF).  As propounded, the TPDF includes the application of the Soft Systems Methodology of Checkland [5], the Hierarchical Task Analysis of Annett and Duncan [6], and three techniques originating as practitioner or research tools: Training Needs Analysis, Cognitive Task Analysis and the Systems Approach to Training.  Our view was that the TPDF stages each tended to confirm decisions made in the previous stage, thus contributing toward verification.  The original TPDF sequence is shown in Figure 1.  The main features of the TPDF can be summarised as:Soft Systems Methodology (SSM). An intellectual enquiry tool employed at the start of the TPDF, to gain a clear understanding of the application domain, together with all of its relevant processes and systems.  While not prescriptive, SSM can be used in an iterative manner with the analysis being discontinued whenever the required understanding has been obtained.  Key to the use of SSM is its ability to bring out conceptual models for candidate systems in the domain of interest, together with a root definition of such a system. Training Needs Analysis (TNA).  This is concerned with both the costs and the consequences of training, as opposed to not training; and also with the effects of modifications to existing training.   If the TNA does not indicate the presence of a “Training Gap” between the present state and the desired state, then there is no need to continue a project. Hierarchical Task Analysis (HTA) This well-established and clearly defined technique is applied in several stages within the TPDF.  For ease of representation we prefer a pictorial rather than a tabular format, and suggest confining each level to four stages: Task, Sub-task, Component, and Item.  Where an item can be further decomposed, it is then treated as a task; where no further decomposition is practicable, the lowest level is treated as an item.Training Item Needs Analysis (TINA). The TINA designation was chosen to indicate that it is carried out at the item level on the HTA product, with each item being individually considered.  This is a second level of TNA that is performed on the output from the HTA.  It delivers a set of mini-TNAs: one for each training item produced by the HTA.Cognitive Task Analysis (CTA).  Here the focus is on the carrying out of the task, rather than defining it. CTA considers the skills and knowledge that are needed, both in theory and in practice, to carry out the items specified by the set of TINAs.  As with TNA, there is no single accepted method for CTA: we chose to use the ‘KSA+E’ model after Bramley [7].  This identifies the Knowledge, Skills, Attitudes and Experience required for task performance, and relates very well to current software/systems engineering practice.  The KSA+E set becomes the required training process post-condition.Training Process Design. The previous stages result in a specification for training; that is, the ‘KSA+E’ set or post condition. The relevant subject-matter experts can now turn this into a full training process design.  The precise form will vary with the type of training, but will generally be via the definition of a number of sub-processes, which combine into a coherent whole, and admit verification that the (human) output will meet the required specification.  When completed, the training process definition can be checked back to the CTA and TINAs, as part of the verification process.3. 	The First TPDF Instantiation: Small Arms Trainer (SAT)As previously stated [4], we started by reverse engineering a particular SE that was known to work well – the Small Arms Trainer (SAT).  Having assembled the components of the TPDF, we then carried out a full instantiation of the TPDF with regard to the SAT.  The one area that was not totally realistic was the initial SSM Analysis, since few would question that soldiers need to be able to shoot.  As will be seen later, this resulted in some modification to the TPDF front-end, when we started to consider a future system.  In all other respects, we were able to treat the instantiation as if it were for a novel requirement, but with the caveat that the need for a standing army was a political decision.The HTA divided neatly into two stages, each of three levels.  The first stage brought out a recurrent item identified as “Engage Targets as Ordered”, otherwise shooting skills; the second identified items that were necessary within the skill of shooting, but which could not be further decomposed.  The subsequent TINA indicated that one item was not a “Must Train”, but that all others came into this category.  In the CTA, we were able to identify the relevant Knowledge as Declarative, Procedural or Strategic, and the Skills as Psychomotor, Procedural or Cognitive.  The remainder of the KSA+E set were a positive Attitude, supported by the Experience of being able to consistently execute good shots.The final step in the TPDF is the detail design of the training process.  Having reached this point, we took the training schedule for the real basic marksmanship training process and mapped this on to the process specification delivered by the TPDF.  The only practical difference noted was that the real programme called for a mixture of SE and live-fire training, while we had concluded that all lessons could take place in the SAT.  Having said this, the comments from a Subject Matter Expert (SME) at our School of Infantry were that if the weather disrupted the training schedule, then lessons  take place in the SAT as required.4. 	The Concept of the Unit Tactical Trainer (UTT)First, it is appropriate to define the term “Unit Level”.  This is not quite as simple as it may appear.  The current British approach is based on the concept of the “Battlegroup”, a tactical entity that can have a variety of compositional structures, but which requires a mix of infantry and armour.  This can be considered as an Infantry Battalion, which trades (say) one company for the equivalent in heavy armour (US Company, British Squadron) and now becomes a Battlegroup.  A battlegroup recently (1998) deployed in the Balkans had infantry companies from not just different battalions, but from different regiments.  It will be obvious that, at this level of command, the Battlegroup Commander and his staff must be experienced in controlling a composite (or Combined Arms) force. In British terms, a Unit is the primary administrative unit to which any soldier belongs, and to which he/she owes allegiance.  It will provide accommodation, food, pay, training, discipline, and a primary sense of identity.  It may be an infantry battalion or a tank regiment.  Colloquially, it is “Single Cap Badge”, and more formally it is “Single Arm”.  The fundamental problem with Training at Unit Level is that the unit must provide training at all levels above basic training, going up to functioning as part of a battlegroup.  The UK has five levels of collective performance standards, and Unit Level training is directed at levels One to Three.  It must do this without actually being part of a battlegroup, and thus the upper limit is generally referred to as combined arms training at Single Arm level. Levels Four and Five are conducted as  true Battlegroup Training.There are many constraints on military training, such as financial, environmental, political, operational; however, one of the most critical constraints is the sheer size of training area required for even medium-scale field-training exercises.  This is particularly so when any country has a very high population density, and is the case in the UK.   At the level of individual soldiers, sections, platoons, and even infantry companies, the low-level tactics can be exercised in the field.  At the level of tank squadrons or companies, and upward, the tactical decisions run down from the top level of command to the lowest level.  Accordingly, the “vague need” for a suitable training device appeared to be for a SE that would facilitate Command and Staff training for operations up to, and especially at, battlegroup scale, but which could be available to personnel at all command levels while at their parent units.5. 	The Application of the TPDF to the UTTFor the next part of this work, we were joined by our third author, at the time a student on the MSc  in Defence Technology course at the Royal Military College of Science (RMCS).  The focus was on the earlier stages of the TPDF: SSM Analysis, Training Needs Analysis, and Hierarchical Task Analysis.The starting point was a “vague need”, or more correctly a loosely-framed potential requirement for a Unit Level Tactical Training Device.  The scale of this need was considerably larger than that for the Small Arms Trainer used to prototype the TPDF.  There were many more interested parties, or “stakeholders”, holding views that diverged to some degree.  It was not immediately clear exactly where a Unit Level Trainer would fit into the whole spectrum of Army training.  A Training Needs Analysis carried out by a commercial organisation had proven to be inconclusive.  In short, this was a perfect test-bed for the TPDF.Perhaps the two most important stages of a SSM analysis are those concerned with the generation of conceptual models and root definitions.  Indeed, it is the successive iterations of the SSM approach that lead to a reasonably clear view of what a process should be about, and how it might achieve that objective.  The conflicting views of the stakeholders had resulted in the generation of six root definitions, each with a common core and a divergent aspect.  To select the most appropriate definition, it was proposed that the TNA should be embedded inside the SSM analysis (see Figure 2 below).  The argument for this was that, since the root definition drove the conceptual model, and that model in turn became a driver for the subsequent training process, then a simplified TNA could be used to select the most appropriate root definition. This amendment to the original TPDF implies a degree of iteration between the SSM Analysis and the embedded TNA.  In practice, this did permit the formulation of a root definition that was generally acceptable to all stakeholders.The final TNA iteration was, therefore, based on a root definition that had been shaped by previous iterations.  While not constituting any formal part of the V&V procedures, it is considered that the “Vague Need” has now been transformed into a confirmed need.  From this, a TNA that indicates the existence of a training gap, with the implication that the TPDF should continue, constitutes a confirmation of the need and thus of the SSM Analysis.  We suggest that the term “Confirmation” is appropriate here, since the SSM does not produce a sufficiently detailed specification for the term “Verification” to be employed.Figure 2    Modified TPDF Front-endGiven a confirmed need, and a TNA that indicated the existence of a training gap, the next stage in the TPDF is Hierarchical Task Analysis (HTA).  There is not, in principle, any difficulty in the formal decomposition of military tasks at this level.  Anyone with a knowledge of SIMNET will know that such a decomposition has been carried out from Brigade level down to Platoon.  Having said this, SIMNET was an existing SE-based training device, whereas the UTT is a projected device.  In the context of the UTT, the function of the HTA (as indeed of the TPDF as a whole, and of the ADM approach) is to elicit a set of requirements that are, as far as possible, verified and validated before the actual SE comes into existence.If we follow the principle of a multi-stage, four-level, decomposition (Task, Sub-task, Component, and Item), the overall HTA approach appears to be quite reasonable.  The second-stage HTA takes an Item from the first stage, and treats this as the Task being decomposed; in the example that follows (Figure 3), Relief in Place becomes the second stage task.  It can be that, even when this is only taken to the Sub-task level, the Components identified are identical regardless of the direction of relief.  This level of decomposition is identifying items that can be processed in the TINA stage of the TPDF.  It is also apparent that one component is primarily Cognitive, and the other three components have a Procedural bias; already we are eliciting data that will permit subsequent stages to be verified back to the HTA.  Not yet accounted for, however, is that the HTA has not been identified with any particular level of command, or a given scenario.Figure 3    The First Two Stages of HTA for the UTT EMBED Word.Picture.8  Figure 4    HTA - Effect of Level of Command on DecompositionIt is convention that an HTA thread will stop at the lowest level that can be described using an action verb (e.g. “Give Orders”); for Command and Staff (C&S) training, we found that the decomposition had to be taken beyond this point.  Before a commander can frame a set of Orders, there is a large range of items to be considered.  These items will vary with the level of command, and also with the scenario involved.  Figure 4 illustrates this, for two levels of command, for the Timings component within a briefing or Orders.  The Battlegroup Commander has 92 potential items, spread across 13 components, in contrast to the 5 components (and less than 20 items) of the Company CommanderIt is clear from Figure 4 that items cannot be composed in a linear (summative) manner to form the next higher node.  Rather, there must be a hierarchical composition of appropriate items and nodes, where each node “adds value” to the items which it composes.  We would also comment that while some HTA practitioners prefer to present an analysis in tabular form, others choose a graphical layout with the stages arranged vertically.  We believe that the graphical layout with the stages running horizontally is easier to search visually.  Having said this, a tabular layout does lend itself to the use of automated checking of the same nature as the RMCS HLA Checker Toolset [8].  Such a checking tool may offer benefits in the identification of identical items, or the resolution of items which may be apparently identical.  Since neither layout will automatically resolve which items should form part of any hierarchical composition, some human (SME) involvement is essential here, and this can contribute to the overall validation process.6. 	Evolution of the TPDF Front end.In the previous section we referred to the problem of generating a single root definition in the SSM stage, when there are multiple stakeholders involved. The initial proposed solution [9] was to embed the TNA into the SSM Analysis, and then to use repeated iterations to refine the root definition.  Having considered this, we now feel that, while the iterative approach is a very good way of attacking this problem, embedding the TNA is not the most appropriate option.  We now propose a further refinement which has both SSM and TNA arranged to provide an iterative loop, within a front-end section of the TPDF.  This is seen in Figure 5, below.To consider the benefits resulting from this change, we must first refer back to the reason for developing the TPDF in the first place: the concept of moving as much as possible of the V&V (and particularly the verification) to the earliest possible stage.  It is obviously not possible to rigorously verify against a vague requirement or specification, but one can refer back to the product of the previous stage to see if the current output will act to support or confirm the previous output.  In this context, our TNA stage has two functions: that of support/confirmation for the SSM Analysis, and to act as a go/no-go gate for further work.  We believe that the two functions are mutually supportive: the TNA constrains the vagueness in the SSM Analysis.Figure 5    TPDF  Front-end – Second RevisionTo take a simplified case, assume a project where the SSM has generated three possible root definitions.  The first TNA iteration then indicates that only two of these can be justified on the grounds that a training gap has been demonstrated, and that an economic or operational benefit will accrue from the relevant training.  A second pass through the SSM refines one of the “good” root definitions, and both carry through  to the TNA.  Assume that both are still justified, but one presents a better case.  Taking this through the SSM once more, again produces a consensus for a single root definition.  This, and its resulting conceptual model are now the start for the final TNA, a “go” output from which now acts to confirm (or to verify informally) the SSM output.  An alternative outcome would be that no root definition can be justified by the initial TNA, and a second iteration proves no better.  Here the gate-decision has been “no-go”, showing that the project is untenable without a major rethink7. 	DiscussionWe began the work of developing the TPDF in the area of individual and small-team training, and have taken it on to consider its use on larger teams and Command and Control applications.  Recall, however, that we started with the intention of modelling the Application Domain, with the express aim of improving V&V, and believe that our views of two years ago [4] are still sound.  By adopting a methodical approach to the formulation of the requirement for a SE (using the term broadly), we can turn a major undertaking into a series of manageable steps.   The incremental approach means that each intermediate deliverable can be subjected to independent validation, and that we can attempt to verify the consistency between the stages in the TPDF as early as possible.  Toward the end of the TPDF, it is the items in the TINA, and thence the CTA, that will form the basis for the relevant training design.  We now have a view of the TPDF as a whole, and of the relationship between its stages, as in Figure 6, below. EMBED Word.Picture.8  Figure 6    The Final TPDFIt can be further argued that it is those same items in the TINA that must be considered (when the complete training process and system are commissioned) as the headings for the performance measures against which the trainees will be judged.  In our HTA, above, we have set out a path from “Unit Training” to “Briefing”.  This briefing may, or may not, be the same as another briefing identified elsewhere in the HTA, but continuing with the decomposition will ultimately lead to a comprehensive list of those items that have potentially to be included in the training design.As an example, the further decomposition of “Briefing” will lead to “Communications” (or Comms).  Comms can be further decomposed, and in our typical pathway may identify “Own Comms”, “Relieved  or Relieving Force Comms”, and “Adjacent Force Comms”.  While “Briefing” will occur many times in the full HTA for Unit Level Training, reference to the relieved or relieving force will only occur under the heading of “Relief in Place”.  This (assuming the TINA indicates a need for training) will then be assessed under the CTA for (amongst other things) the Declarative, Procedural, and Strategic Knowledge that the Commander or his relevant Staff Officer will require in order to deliver a proper briefing.  These are among the points that an Observer-Controller, or other trainer, would require to see dealt with in a correct manner during the course of an exercise.With our work on the SAT, there was a single (objective) measure of performance as the post condition: a standard test of basic skill-at-arms.  In Tactical, or Command-and-Staff training, many of the measures will be subjective; the items to be measured will be effectively identified by the TPDF, and thus the training design can be verified for completeness against the earlier stages of the TPDF.   This will also facilitate the validation by a SME of both the training design, and the system to deliver that design.  While we have been, and still are concerned with SEs, we can see no reason why the same principles cannot apply equally to embedded training devices.Necessarily, this account of our research on the TPDF has been brief.  However, a comprehensive report providing further details of the work is available[10], and can be obtained form the authors at RMCS .8. 	Future DirectionsThe primary concern of the UTT is Command and Control (C2) training, and this has led us to consider the possible effects of the various Digital Battlespace initiatives on the potential organisation and effectiveness of command functions.  To this end, we have taken steps to establish a Digitization Laboratory which incorporates a Human Factors facility, and anticipate further exploration of the task composition-decomposition at different levels of Command, and additional investigations into the role of embedded training within digitized C2 systems.9.	AcknowledgementsThe authors would like to express their thanks to the UK Ministry of Defence (MOD) and the Defence Evaluation and Research Agency (DERA) for encouraging and funding this work; in particular, to Mrs Jenni Henderson, our MOD customer, and Dr. Robin Miller of DERA/CDA.10.	References[1]	Hone, G.N. and Moulding, M.R. “Application Domain Modelling to Support the Verification and Validation of Synthetic Environments”,  Proc. Spring 98 SIW (Paper #063).[2]	DoD. “DoD Modelling and Simulation Master Plan”, Washington, DC, 1995.[3] Haddix F., Sheehan J., Loesekann M. and  Scrudder R., “Semantics and Syntax of Mission Space Models”, Proc. Fall 99 SIW (Paper #152).[4]	Hone, G.N. and Moulding, M.R. “Developments in Application Domain Modelling for the Verification and Validation of Synthetic Environments: Training Process and System Definition”.  Proc. Spring 99 SIW (Paper #122) [5]	Checkland, P. “Systems Thinking, Systems Practice”, Wiley and Sons, Chichester, 1981.[6]	Annett, J. and Duncan, K.D. “Task analysis and training design”, Occupational Psychology, 41, 211-221, 1967. [7]	Bramley, P. “Evaluating Training”, IPD Books, London, 1996.[8]	Morales M.C. and Moulding M.R. “Improving the Verification of Synthetic Environments:  Advanced Checking of  HLA Specifications across a Federation”, Proc. Spring 00 SIW (Paper #076) [9]	Robinson A.K. “A Critical Analysis of the Training Process Definition Framework as applied to the Requirements Capture for a Unit Tactical Trainer”. MSc Dissertation, RMCS Shrivenham, UK., July 1999.[10]	Hone, G.N. and Moulding, M.R. “A Unified Approach to the Verification, Validation and Accreditation of Synthetic Environments: Training Process and System Definition”, RMCS Ref: SE027E/TR2, May 2000.Author BiographiesGEOFFREY HONE is a Senior Research Fellow with the Computing Information Systems Engineering Group in the Department of Informatics and Simulation, at RMCS.  A Cognitive Psychologist, his Doctorate was in Spatial Perception in Simulator Displays, and he has subsequently worked on networked training simulators at the DERA Centre for Human Sciences.MICHAEL R. MOULDING is Professor of Software Engineering, and Head of the Communication & Information Systems Engineering Group, at RMCS.  Over the past decade his main research activities have been in the fields of high integrity software, requirements analysis, mathematically formal specification techniques, and the verification, validation and accreditation of Distributed Interactive Simulation systems. Currently, his main activities are associated with Battlespace Digitization, and he is Chairman of a new MSc course in this topic at RMCS.KEITH ROBINSON is a serving officer in the Royal Logistics Corps.  He obtained both a BSc and MSc at the RMCS, and is currently involved in the procurement of SE-based training systems for the UK MOD.  	Subject to the agreement of UK MOD.