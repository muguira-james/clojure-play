Building a Selective-Fidelity Simulation EngineBradley C. SchrickerAT&T Government Solutions, Inc.11301 Corporate Blvd.Suite 110Orlando, FL 32817407-658-6908 HYPERLINK "mailto:bschricker@att.com" bschricker@att.comKeywords:fidelity, HLA, Selective-Fidelity Simulation, Fidelity Evaluation FrameworkAbstract: The concept of Selective-Fidelity Simulation describes the ability of a simulation system to self-adjust its level of fidelity based on resource factors such as available processing power and memory for the purpose of optimizing the fidelity and resource usage.  This author has proposed an implementation of Selective-Fidelity Simulation that takes advantage of the ownership management capabilities of the High Level Architecture (HLA) Run-Time Infrastructure (RTI) in previously published papers [1] [2].  However, a number of factors make it more reasonable to develop an application that solely assumes responsibility for the functions necessary to implement this methodology without the additional and bulky overhead that comes with the many other functions of the HLA RTI.  This paper describes the reasons for proceeding in a direction that excludes HLA from the implementation.  It then continues by explaining in detail the capabilities, components, and functions necessary to allow a simulation to select the level of fidelity at which it will perform, including the measurement of fidelity, the monitoring of resources, and the transition from one model to another.  This paper will finish with a summary of future directions and planned papers to discuss those directions in more thorough detail.                            IntroductionAs with any computer system, a careful balance between performance and resource usage exists.  For instance, failure to efficiently use as much computing resources as possible when performing numerous complex arithmetic operations can result in sub-par performance.  At the same time, an overloading of the system resources can also create issues of poor performance.  The Modeling and Simulation (M&S) community has seen this phenomenon for many years and attempted to address with such solutions as multi-resolution simulation. Far and wide, the solutions that the M&S community has proposed involve significant user input and action (or inaction, in some cases).Selective-Fidelity Simulation is a proposed method of dealing with this problem while eliminating the need for a human user to manage the balance between performance and resource usage.This paper discusses Selective-Fidelity Simulation in great detail and then goes on to describe the components necessary to implement it in the form of a single Selective-Fidelity Simulation Engine.  FidelityTo understand fully how to implement Selective-Fidelity Simulation, one must possess a thorough understanding of fidelity.  It should be noted that even though simulation professionals commonly use the term fidelity and that most individuals have an intuitive grasp for what it implies, the term does not have a single, widely accepted definition.  Even more troubling is the lack of an objective method for measuring the level of fidelity of a model.For the purpose of this branch of research, this author has defined simulation fidelity simply as: “a measurement of how well a simulation represents its corresponding referent, which is based on a real-world object or system.”  That definition introduces a second term with an ambiguous meaning: referent.  Plainly put, a referent is an abstract representation of any real-world object or system.  The concept of a referent is required to understand fidelity because it is impossible to make any direct and meaningful comparisons between a model and the real-world object upon which it is based.  A simple exercise can demonstrate why this is true.Consider any simple real-world object that might be simulated and then create a representation of this real-world object – the format of this representation is inconsequential at this point.  Now that both the real-world object and its corresponding referent exist, attempt to perform a DIRECT comparison between the two.  This exercise devolves into an arduous task, as a truly direct comparison must be carried out on a single medium, such as paper or on a computer screen – not two mediums such as ideas on paper to a real-world object.  The clearest alternative is to create a representation of the real-world object that is as close to reality as possible and make the comparison with that.  One this action is taken the comparison is no longer a direct one between the real-world object and its referent, but between the referent and a second referent.This limitation in using simulation fidelity in a practical fashion enhances the importance of understanding a referent and its role in determining fidelity.  Recall that fidelity is, “a measurement of how well a simulation represents its corresponding referent, which is based on a real-world object or system.”  Ideally, that measurement would be based on a direct comparison between the model and the real-world system that is being simulated.  However, as demonstrated, that direct comparison is not possible.  Instead, the real-world system must be represented in an identical format to the simulation.  In essence, both the referent and the model are abstractions of the same real-world system or object.To put this into practice, a referent must be an abstraction of a real-world object or system that is as close to that real-world object or system as possible, augmented with tremendous amounts of accurate detail.  On the other hand, the model can be an abstraction with far less detail, based on what the user(s) or developer(s) deem as interesting or important.  This concept can allow a meticulous comparison between a model and the best possible representation of its corresponding real-world system, the referent.  This notion is illustrated in Figure 1. EMBED PowerPoint.Slide.8  Figure 1.  Illustration of the referent and modelsIn this figure, a nebulous and fuzzy shape with no clear boundaries represents Reality, demonstrating the difficulty in clearly defining reality.  The Referent is shown as a rigidly defined figure that is located very close to Reality.  The Model(s) are also rigidly defined, but much further away from Reality, illustrating that the models do not have as much accurate detail as the referent.  In fact, to simplify the process in practice the Model(s) can be based upon the Referent instead of upon Reality [3].Selective-Fidelity SimulationSelective-Fidelity Simulation takes advantage of these definitions of simulation fidelity, related terms, and a published method of measuring fidelity called the Fidelity Evaluation Framework.  Combining these concepts provides the necessary foundation for designing a functioning Selective-Fidelity Simulation system.Fidelity Evaluation FrameworkIn general, the Fidelity Evaluation Framework is a method for objectively measuring the level of fidelity of a model.  More specifically, it is a concept that allows an individual to limit the subjectivity involved with measuring fidelity by specifying exactly where the subjectivity occurs and applying it the same way for every model.  Measuring simulation fidelity will always involve human subjectivity, as the process of determining how well a model represents reality requires opinions.  Regardless of any effort to remain impartial, no person can possibly judge the level of fidelity that a model has with respect to its referent without introducing some level of subjectivity.This is not to say, however, that a well-designed method cannot obtain a meaningful measurement.  By stipulating that fidelity must be based on a specific referent, the Fidelity Evaluation Framework allows objective measurements to be taken in a variety of ways, allowing different methods method for measuring and the application of weights to certain aspects of the referent.  This idea is illustrated in Figure 2. EMBED PowerPoint.Slide.8  Figure 2.  Fidelity Evaluation FrameworkMeasuring FidelityBy isolating subjectivity, a user or developer can obtain an objective measurement of simulation fidelity.  A simple example of how one might measure simulation fidelity is by breaking down a referent into many components and then rating the presence of each corresponding component within the model against it.  Using FidelityOnce a user or developer thoroughly understands simulation fidelity and the Fidelity Evaluation Framework, thoughts can turn toward using these concepts in practical manners, such as Selective-Fidelity Simulation.Motivation for Selective-FidelityThough it may seem intuitive, it should be noted that in most cases, a lower level of simulation fidelity usually results in a lower resource usage.  This is because, for the most part, lower fidelity models are often associated with less complexity.  As an example, consider a generic traffic simulation system that has two models from which to choose.  The first model represents vehicles and roadways as only X- and Y-coordinates that have no size or shape with no notion of a surrounding city.  At the same time, the second model represents vehicles as having volume and mass, roadways as having elevations, slopes, and embankments, and municipalities littered with buildings and pedestrians.  Clearly, because of its increased level of complexity, the second model would draw far more computational resources than the first.  While this more detailed model might increase the level of fidelity of the simulation, it can also cause the system to reach a point where the augmented fidelity can adversely affect the performance of the system.  This situation can manifest itself if the computer system lacks sufficient computational resources to effectively implement the model.In a simulation with a fixed-model representation of the referent – that is, no implementation of Selective-Fidelity Simulation – the computer upon which the simulation executes would be forced to use that fixed model regardless of any shortage or surplus of computational resources that may exist.  This can either overwhelm the computer system and result in degraded performance or allow the simulation system to run a low-fidelity model when it is capable of executing far more.  As an example, reconsider the traffic simulation mentioned above.  While running the low-fidelity model, it may execute flawlessly while producing fundamentally flawed data because of its lack of detail.  On the other hand, the higher fidelity model may cause the resource load to grow too high, causing the behaviors of the vehicles to break down, also resulting in flawed data.Implementing a Selective-Fidelity Simulation architecture can effectively eliminate this costly situation.  By having multiple models of the same real-world system, a simulation system can avoid both the underwhelming and overwhelming situations caused by overly simple or overly complex models, respectively.  In the traffic simulation example, an implementation of Selective-Fidelity Simulation would allow the simulation to automatically toggle to a lower fidelity model if the available computational resources dip below a predetermined threshold.  Using the same logic, the simulation system could also alternate to a higher fidelity model if the available computational resources rise past another predetermined threshold.  This continuous cycle would constantly force the optimization between simulation fidelity and resource use.Importance of ResourcesNumerous computational resources greatly impact the functioning of a computer system.  For any computer or set of computers responsible for maintaining a time-critical system – a classification into which most simulation systems fall – these resources can be vital for best performance.  Among the most important computational resources to be considered are processing time, physical memory, graphics memory (most applicable to virtual simulations), and swap space or virtual memory.Every one of these resources ultimately affects the performance of a simulation system.  As long as the resource load remains low, models should execute exactly as specified.  However, as that load increases, a line in the sand exists where the resources required to smoothly execute the model are no longer available.  As this happens, it results in poorer representation of the referent upon which the model is based.As an example, reconsider the traffic simulation previously discussed.  If, at any time during the execution of this system, the physical memory shoulders a full load, the operating system may need to rely on the designated swap space on the hard drive for virtual memory.  Because hard drive access is approximately 1000 times slower than memory access, this would significantly slow the portions of the implementation of the model.  A more extreme situation might be induced if the swap space were to also take on a full load, possibly resulting in a crash of the simulation system, unquestionably an unacceptable outcome.Critical Issues to be ConsideredA reliable implementation of Selective-Fidelity Simulation will depend on a number of key issues.  Those issues include, but may not be limited to:How can a simulation system monitor its own resource usage?How are the models from which the system can choose organized and executed?How can a simulation system automatically toggle its models during runtime?How should spikes and valleys in the usage of resources be handled?How often, if ever, should resource managers be polled to determine the usage?Among these issues, perhaps the most vital is determining how to monitor resource usage.  To toggle between models, an algorithm must keep track of the resource loads.  Without first developing this capability, the whole notion of Selective-Fidelity Simulation is rendered pointless.  In an ideal situation, all critical resources mentioned in the previous section could be monitored – though this would also result in a more complex Selective-Fidelity Simulation algorithm.  However, the ability to monitor any one of them could prove fruitful.In 2001, the Institute for Simulation and Training (IST) conducted a series of tests that produced an application intended to monitor various computational resources and then to take a variety of actions depending on the usage and availability of those resources.  One of those applications monitored the usage of system memory and processing power.  As a demonstration of its effectiveness, the application took action based on the loads upon those resources.  If the memory usage dropped below a certain threshold, then a linked-list structure in the program would start to grow at an enormous rate by adding elements.  However, once the memory usage grew past another threshold, nodes on that list would be deleted.  At the same time, the application would act according to the load on the processor.  If the load were below a certain point then the application would perform a series of incremental arithmetic operations to increase that load.  When that load exceeded another threshold, those arithmetic operations would cease for a period of time.  While this particular application provided nothing directly to Selective-Fidelity Simulation, it also demonstrated that a clever design could at least partly overcome the first issue.  A comprehensive understanding of how the models are organized and executed is nearly as important.  One model could be represented by a single file or by a group of files.  Another possibility is that numerous models are described within a single file.  To efficiently toggle between models this knowledge is vital.  When appropriate, the changing between models must be seamless, with as little time between them as possible.  Furthermore, all relevant state data from one model must correctly transfer to the subsequent model in such a way that the user(s) cannot discern that any transition took place at all, beyond the obvious indications of the altered level of simulation fidelity.  The occurrence of spikes and valleys in the resource usage poses another interesting challenge in implementing Selective-Fidelity Simulation.  Consider that if a processor experiences a sudden jump in its load, it may not be appropriate to toggle to a lower-fidelity model immediately.  The same holds true for sudden falls in the load upon the processor.  Without recognizing spikes and valleys for what they are, the system could continually try to adjust the simulation fidelity by toggling models, resulting in extra overhead processing and a host of other undesirable results.To further add to the seamlessness of model toggling, a determination must be made as to how often to poll for the resource usage, if at all.  Note that the act of polling, in and of itself, also requires computational resources.  Because of this fact, polling too often can actually adversely affect the behavior of a simulation system by inadvertently drawing too many computational resources.  At the same time though, polling too infrequently can make it more difficult for the system to establish a pattern in the resource usage, a necessity in Selective-Fidelity Simulation.A General Strategy for ImplementationThis section provides a general architecture to implement Selective-Fidelity Simulation.  This proposed architecture assumes that developers have already addressed and resolved the issues in the preceding section.While developers could take a number of implementation approaches, two similar methodologies stand out as the most feasible designs.  Both of these implementations involve adding software modules to the system.  The first of these implementations calls for modifying the code of the actual simulation system so that the new components incorporate directly into the existing simulation system architecture.  The second such implementation would entail the creation of separate modules that run and communicate with the simulation system through an agreed-upon communication interface.Both of these implementations possess strong advantages.  For instance, integrating these new modules directly into the system would eliminate communication as a bottleneck for the system and improve efficiency.  However, this direction does not allow easy portability since the implementation might differ greatly for every dissimilar simulation system.  At the same time, while developing separate modules would allow greater flexibility and portability, it would also add overhead for communications that would bog the system down.Regardless of which of these two approaches developers decide upon, at least two new software components must be developed and integrated into the overall simulation system to implement Selective-Fidelity Simulation.  Those two new components are called the Resource Monitor and the Model Controller.  The roles of these two components are described in detail in the next two sections.Resource MonitorThe Resource Monitor component tracks the usage of vital system resources, as described in Section 3.3.2.  While not necessarily the most efficient implementation, the most straightforward method is to continually poll the operating system at predetermined time intervals.The resource monitor would need constant and direct contact with the Model Controller (discussed in the next section).  Whenever any threshold – high or low – is crossed for a predefined amount of time – or number of polls – the Resource Monitor would quickly relay that information to the Model Controller.  The Model Controller would then initiate the appropriate action.Model ControllerPerhaps the most visible component of Selective-Fidelity Simulation, at least in terms of its effects on the system, is the Model Controller.  This module both selects and toggles the models for the simulation system to execute.  This module receives information directly from the Resource Monitor and, based on that information, either allows the execution of the currently selected model to continue or selects a new model with differing level of fidelity.  Additionally, this component toggles the models after making the execution decision.  This task encompasses the subtasks of storing relevant state data and applying that data to the new model.  Note that this process could take considerable amounts of time with higher-fidelity models.A serious point of consideration is that the Model Controller component may already largely be implemented in a simulation system, as a simulator must already load a model for execution when it first launches.  The required new capabilities would include selecting a new model, stopping the execution of the current model, storing all appropriate data, triggering the code that starts the execution of a model, and reinitializing all appropriate data stored from the previous model.  While numerous, these modifications should be straightforward.The basic architecture of the Model Controller is illustrated in Figure 3. EMBED PowerPoint.Slide.8  Figure 3. Model Controller ArchitectureIn this figure, the four main components are: the Simulator, the Model Controller, the Model Table and the Models.  In essence, the Simulator is an instantiation of a particular simulation system.  The Model Table component is a formatted table with fundamental data about each of the models available to be executed and a value indicating their levels of fidelity based upon the intended application of the simulator.  The Models component is the actual collection of available models for the simulator to execute.  When the Model Controller receives certain information from the Resource Monitor, it selects an appropriate model from the Model Table and indicates to the Simulator which new model to execute.Integration of ModulesAs mentioned in previous sections, the Resource Monitor and the Model Controller can either be separate from the simulation system code or integrated directly into it.  Regardless of which implementation is used, the communication between these two modules would follow the same conceptual path.The Resource Monitor would continually track the usage of the system resources, either by polling or waiting for a notification from the operating system.  To minimize data traffic and resource usage, the Resource Monitor would communicate information directly to the Model Controller.  The Model Controller would then either load a new model or trigger the simulation system to load a new model for execution, depending on the already existent architecture of the simulation system.This architecture is illustrated in Figure 4. EMBED PowerPoint.Slide.8  Figure 4. Resource Monitor ArchitectureIn this architecture diagram, the Resource Monitor communicates directly with both the operating system and the Model Controller – itself a part of the simulation system.  The Resource Monitor sends information to and receives information from the operating system, but only transmits information to the Model Controller because there is no relevant data that the Model Controller could pass to the Resource Monitor.  As a component of the simulation system, the Model Controller then communicates directly with the simulation system.This proposed architecture includes the components necessary to implement Selective-Fidelity Simulation, though not the implementation itself.  The rest of this paper is dedicated to explaining a more specific implementation of Selective-Fidelity Simulation using concepts of High Level Architecture and its implementation, the Run-Time Infrastructure [4] and then applying it to TES.Reasons for Moving from the High Level ArchitectureWhile the HLA RTI has proven moderately successful as a working alternative to Distributed Interactive Simulation (DIS) as a means for allowing differing simulators to interact, it has far too much capability to reasonably implement Selective-Fidelity Simulation.  The notion of transferring object ownership sparked this author’s idea of using the RTI to facilitate an implantation, but the associated overhead from the multitude of other functions included within the RTI taints the effectiveness of such a direction.Thus, it would be more practical to create an engine whose sole responsibility is to allow for a Selective-Fidelity Simulation system for a number of convincing reasons.To start, the only capability of the RTI that a Selective-Fidelity Simulation implementation would need is that of object ownership.  The RTI allows the transfer of ownership of simulation objects, thus changing which simulator assumes the responsibility of simulating that particular object.  This capability would facilitate Selective-Fidelity Simulation because it could transfer simulation objects among simulators that work at differing levels of fidelity.Another reason to disregard the RTI as a facilitator in the implementation of Selective-Fidelity Simulation is that the RTI requires the registration, subscription, and publication of all simulation objects that might have their ownership transferred from one simulator to another.  Registration essentially means that the federation is informed of the existence of a simulation object.  Subscription refers to a simulator informing the federation that it is interested in acquiring the values of specific simulation objects.  Publication pertains to a simulation informing the federation of its intention to broadcast the values of simulation object to the rest of the simulators within the federation.  This process through the set of HLA functions calls can be avoided by using a system designed specifically for Selective-Fidelity Simulation.Another important reason to go a different direction is the fact that the HLA RTI was never intended to facilitate such an idea as Selective-Fidelity Simulation.  HLA, by definition, is intended to allow interoperability between differing simulation systems.  It only makes sense that the RTI would not serve as the most efficient go-between for this implementation as it was designed for a different purpose.The following section describes what a separate Selective-Fidelity Simulation Engine would need to do to support the implementation of a Selective-Fidelity Simulation system.Capabilities and ComponentsThe Selective-Fidelity Simulation Engine (SFSE) would take on the same responsibilities mentioned earlier in this paper needed to implement Selective-Fidelity Simulation, most notably, a Resource Monitor and a Model Controller.  Additionally, much like with HLA applications, the SFSE would require each attached simulator to have basic knowledge of the other simulators connected to the overall simulation.That said, the SFSE would provide registration services that would allow each simulator within the simulation to announce its entrance into the simulation.  Much like with HLA, there must also be a publication/subscription service to allow the simulation to know what data is relevant to each of the simulators.  For similar but unidentical data types and descriptions, each simulator would handle the mapping from the overall simulation data format.  And most importantly, the SFSE would ensure that only one simulator at any given time would own, or control, the data that describes a simulation object, by implementing the Resource Monitor and Model controller functionality mentioned on the previous page.Figure 5 shows the basic architecture while Figure 6 illustrates the interaction between the SFSE and a single simulator. EMBED PowerPoint.Slide.8  Figure 5.  Basic SFSE Architecture EMBED PowerPoint.Slide.8  Figure 6.  Individual SFSE-Simulator InteractionRegistrationAll of the simulators within the simulation must register themselves.  This allows each of them to have awareness of the existence of all the other simulators.  This will allow the SFSE to correctly monitor all resources and keep track of available simulators to toggle object ownership.  Without such a registration process, the SFSE would have no way of transferring ownership of simulation objects among the simulators and thus altering the fidelity of the simulation.Publication/SubscriptionEach of the disparate simulators would likely model the same real-world systems in different ways.  This would not only include different algorithms, but could also include vastly different sets of data to manipulate.  For each simulator to seamlessly take ownership of simulation objects when appropriate, each must have a foreknowledge of all the different sets of data.  As with HLA, they accomplish this by publishing to the rest of the simulators the data and data types for which they are responsible.  Additionally, they also subscribe to the data that is vital for them to take ownership of the simulation objects and immediately begin modeling the system being simulated.  Internally, each simulator must also map from one set of data to its own, a task that, strictly speaking, is outside the purview of the publication and subscription functionality.OwnershipHLA has built-in ownership management capabilities that allow different federates within the federation to assume responsibility for simulating the real-world system.  It accomplishes this by indicating to each federate whether it is a publisher or subscriber to each individual datem.  If it is a publisher, then it simulates the data and sends it out to the rest of the federation for all other federates to reflect within their own instantiations.  However, if it is a subscriber, it only listens for data to arrive from the publisher(s) through the HLA RTI, and does not simulate the objects associated with specific data.  Each individual federate, through a shared set of ownership algorithms, controls the ownership.The ownership portion of the SFSE would function in exactly the same way with the exception that the individual simulators would not control the transfers of ownership.  Instead, that would fall upon the SFSE itself.ConclusionIntroduced in 2001, the concept of Selective-Fidelity Simulation has not yet gone through rigorous testing to prove its merit or effectiveness.  Admittedly, a large amount of work remains in the area of simulation fidelity to allow a worthwhile implementation of Selective-Fidelity Simulation.  For instance, the M & S community must acquire a more thorough understanding of a referent.  Additionally, an established and accepted example of a referent would provide a consistent measuring stick for simulation fidelity and experimentation with Selective-Fidelity Simulation.  Finally, details must be resolved in the Fidelity Evaluation Framework to even allow a meaningful quantitative assessment of a simulation system’s fidelity.  Without such work – work that would allow an objective quantification of fidelity across many different applications – a significant implementation of Selective-Fidelity Simulation cannot be achieved.Further, achieving a more thorough understanding of the roles, possible implementations, and integration strategies for the Resource Monitor and the Model Controller would significantly aid in the implementation of a Selective-Fidelity Simulation architecture.  While these tools have been implemented and used in separate test cases, as pointed out by the referenced literature, they have not been tested in tandem for any Selective-Fidelity Simulation test case, a necessary hurdle to cross.However, none of that is the purview of this paper.  This paper addresses the idea of creating a Selective-Fidelity Simulation Engine (SFSE) to assume the responsibilities of implementing this concept.  Previously, this author had suggested the feasibility of implementing this through the High Level Architecture (HLA) Run-time Infrastructure (RTI).  While such an implementation would certainly work, the RTI has far greater complexity than necessary for this application.  Thus, an SFSE designed exclusively to implement Selective-Fidelity Simulation becomes more crucial.Such an idea will need thorough testing once it is implemented.  Future papers will focus on the design and testing results of various implementations of an SFSE.References[1]	Schricker, Bradley C., Robert Franceschini, and Stephen Schricker, “Considerations for a Selective-Fidelity Simulation,” Proceedings of the 2001 Spring Simulation Interoperability Workshop, April 2001.[2]	Schricker, Bradley C., and Sonia von der Lippe, “Using the High Level Architecture to Implement Selective-Fidelity”, Proceedings of the 37th Annual Simulation Symposium, April 2004. [3]	Schricker, Bradley C., Robert Franceschini, and Timothy Johnson, “Fidelity Evaluation Framework,” Proceedings of 34th Annual Simulation Symposium, April 2001.[4]	“High Level Architecture,”  HYPERLINK "http://www.sisostds.org/webletter/siso/iss_18/art_149.htm" http://www.sisostds.org/webletter/siso/iss_18/art_149.htmAuthor BiographiesBradley Schricker is a Software Engineer with AT&T Government Solutions, Inc., currently working on the requirements analysis team of the System Engineering IPT of the One Tactical Engagement Simulation System (OneTESS) project.  He has seven years of experience in software engineering, focusing his efforts in the areas of distributed simulation, discrete event simulation, virtual environments, and behavior representation.  Mr. Schricker received his Bachelor of Science degree in Computer Science with a minor in Mathematics from Florida State University in 1998.  Mr. Schricker is currently pursuing a Master of Science degree in Modeling and Simulation from the University of Central Florida.