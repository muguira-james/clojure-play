Review of the Defense Modeling and Simulation Office Human Behavior ProgramEileen A. Bjorkman, Lt Col, USAFDefense Modeling and Simulation Office1901 N. Beauregard St, Suite 500Alexandria, VA 22315703-998-0660bjorkman@dmso.milPaul BlembergIIT Research Institute/AB Technologies Group1901 North Beauregard StreetSuite 400Alexandria, VA 22331pblemberg@msiac.dmso.mil Keywords:Human Behavior Representation, decision making models, testbedAbstract.  DMSO has reorganized on a new vector emphasizing Modeling and Simulation (M&S) support to Warfighters.   Key to this thrust are Human and Organizational Behavioral Modeling efforts.  This paper reviews those initiatives with linkages to Warfighter needs.  Additionally the paper addresses significant challenges to human behavior representation.1.  Introduction.    According to the Department of Defense (DoD) Modeling and Simulation (M&S) Master Plan (MSMP), the DoD vision for M&S is to, in part, that “. . . modeling and simulation environments will be constructed from affordable, reusable components operating through an open systems architecture.”  Part of this vision includes objectives to provide authoritative representations of both human and organizational behavior in the military domain.  These objectives further include sub-objectives to provide generic models of human capabilities, limitations, and performance; developing the capability to rapidly generate models of human behavior for specific applications, and to develop verification, validation, and accreditation processes, resource repositories, and configuration control processes for human behavior representations (HBR).  [1]1.1  The DMSO RoleThe Defense Modeling and Simulation Office (DMSO) oversees all M&S activities within the DoD.  In 2000, DMSO embarked on a new vector to emphasize support to the warfighter.  The new vision of DMSO is to lead and integrate the DoD’s M&S community and leverage M&S science and technology advances to ensure that the warfighters of today and tomorrow have superior and affordable M&S tools, products and capabilities to support their missions and to give them revolutionary war-winning capabilities. Using the guidelines set forth under the DoD MSMP and the DMSO vision, the DMSO HBR program strives to enhance reuse and interoperability of human behavior and performance models for constructive, virtual and live simulations used by warfighters and those that support them.  DMSO currently has three major initiatives to support reuse and interoperability.  The first initiative is to develop an authoritative set of components that can be used to represent human behavior.  This initiative began in FY00 and includes three parts: (1) a next generation synthetic force that is flexible in design, (2) decision-making models that are not based on optimization techniques, and (3) components for a common behavior and representation modeling and development environment.  The second two initiatives began in FY01 and are extensions of the first initiative into focused areas.  The first FY01 initiative is a Challenge Problem that will design a set of military scenarios to explore the strengths and weaknesses of various techniques and technologies for modeling human decision making processes.  The second FY01 initiative is exploring the feasibility of developing a common representation and interchange system for human behavior and performance.  Although DMSO strongly supports basic research efforts in human behavior and performance modeling by others, we feel the warfighter needs to benefit from existing work that appears to be “good enough” at this point.  Harvesting continuing basic research will help developers to refine existing representations, models, and data as more information becomes available.  After all, the Wright brothers didn’t wait until they understood everything about flight theory before they flew – they built an airplane that was flyable, even though they didn’t understand everything about why it flew or did some of the things it did.  Even after an additional century of research on the theory of flight there are still things about aerodynamics and flight control theory that are not well understood.  For example, there is no existing theory that can predict when a wing will stall; can no longer maintain lift for flying.  However, aerodynamicists can make a model of an airfoil used in a wing and determine from wind tunnel data when that airfoil will stall.  Aircraft designers then use this information during the design process; the fact that they don’t know exactly why the wing stalls when it does isn’t important, but knowing when it stalls helps them to determine performance characteristics of the aircraft such as the speeds to use during takeoff and landing.  We need to take this same approach to human behavior representation – find things that seem to work and then refine them as we get more information.  As part of this process, we are using our three initiatives to develop an HBR toolkit that supports representation of human behavior.1.2  The HBR ToolkitAlthough a comprehensive theory for describing human behavior modeling that includes cognition, decision making, knowledge acquisition, memory, and performance moderators has not yet been developed, there are many existing modeling techniques that are mature enough to use in combat modeling now.  The near-term goal is to capture these modeling techniques, along with supporting data and tools to incorporate them into a toolkit.  The ultimate DMSO goal in the HBR area is to produce a web-based toolkit that M&S developers and users can access to help populate their current M&S with authoritative HBR.  This toolkit will include algorithms; models; certified data for validating models; verification, validation, and accreditation (VV&A) procedures; functional descriptions of the mission space; integration and visualization tools; a description of “best practices” for using the toolkit; and a web-based system for accessing toolkit upgrades and technical support.    Part of the toolkit will include an evaluation of different modeling techniques as they apply to the various combat domains.  The toolkit will initially focus on capturing decision-making models since these appear to be more mature than other areas of human representation.  Future DMSO initiatives will focus on other applications as evolving concepts mature.  Decision making models are attractive to pursue for initial inclusion because they can be at least partially validated through “expert opinion.”  At this point, if a particular model produces combat decisions in a given domain that appear reasonable to a subject matter expert in that domain, the model will be included in the toolkit.  Future research will focus on collecting data and developing additional techniques to aid in the VV&A process.   The DMSO initiatives described below are aimed at developing the HBR toolkit.2.  The DMSO Initiatives.2.1  Authoritative Set of Components.This DMSO initiative began in FY00 and is seeking ways to provide: (1) a next generation synthetic force that is flexible in design, (2) decision-making models that are not based on optimization techniques, and (3) components for a common behavior representation modeling and development environment.  This portion of the program is using the same process model as the Small Business Innovative Research program.  DMSO awarded 10 small contracts spread across the three areas of research described above.  Based on the results of the initial research, DMSO plans to down-select to the most promising areas and provide additional funding in late FY01 or early FY02.  The existing contracts cover a broad spectrum of human behavior research.  These efforts include using fuzzy agent-based modeling platforms for a common modeling and development environment, developing a new architecture for synthetic forces behavior representation, automated knowledge acquisition techniques, and a variety of decision modeling methodologies, just to name a few.  The research projects also run the gamut from extending existing models to additional domains and generalizing them to developing prototype models or environments based on existing research.  The results of the initial research will be available sometime in the summer of 2001.2.2  Challenge Problem.  While analyzing the various proposals that were submitted for the Authoritative Set of Components research, it became obvious that there are many decision models already available that are either running within existing models or in prototype form.  Some of these models are highly tailored and brittle, restricting reuse and extensibility.  However, many of the proposed models appear to be highly flexible, although most have previously only been used within one domain (e.g., air combat seems to be particularly attractive to model developers, probably due to the limited time duration and number of entities in air combat).  Since so many of these approaches appeared to be “ready for prime time,” we decided to apply them in different combat domains to evaluate their potential for use in existing models.  We will use a series of challenge problems to perform evaluations of both the technical challenges of software integration as well as the semantic value of the underlying behavioral representation.2.2.1  Challenge Problem Outline.  The FY01 challenge problem will provide a prototype testbed for human behavior models.  Three problems will be selected – one each from the air, land, and maritime domains.  An operations other than war (OOTW) problem will also be accomplished if time and funding permit.  The problems will be focused, technically manageable, and at the tactical level during the first year.  The models will be used to represent both friendly and enemy forces (and any non-combatants during an OOTW problem) but will only model one type of entity during each scenario (although multiple entities of the same type will be modeled; e.g., tanks or aircraft).  Six current model technologies have been identified for integration into the testbed; additional models will be evaluated if funds are available.  The scenarios will be designed to exercise human decision making processes of particular interest to military modelers; in particular, the following processes need to be included in one or more of the scenarios:	(1)  Hierarchical decision making (i.e., passing of orders and information vertically and horizontally in real-time as a battle unfolds).  Limits may be imposed on how information can travel and what kind of information can be passed.	(2)  Use of doctrine and tactics, techniques and procedures (TTPs) as an input to the decision-making process.  These inputs will be general enough to preclude scripted behaviors (e.g., “Troops should generally try to maintain loose formation while searching for the enemy” vs “Troops shall maintain 10 ft spacing horizontally and laterally until the enemy is detected.”	(3)  Cooperative behaviors	(4)  Evolving behaviors on both sides (includes non-combatants for OOTW)Evolving/dynamic landscape/environment (Surprise)Situational awareness (SA)-based decision makingHuman performance moderators will not be a part of the FY01 challenge problem, but may be included in the FY02 challenge problem.Clear success and termination criteria (e.g., all of one side annihilated, all weapons expended) will be included in each scenario to aid model developers as they integrate their models.  Each model developer will document the process used to determine required data input to their model (e.g., weighting factors) or procedures/rules used to implement doctrine and TTPs.  The evaluation team will determine a set of standard model output and appropriate ways to capture that output; each developer will also be allowed to request additional model output specific to their model.2.2.2  Evaluation Criteria.  The underlying technology (algorithms, databases, and tools) for each model will be evaluated more than the implementation of the model, although developers will be given subjective feedback on model implementation.  There will be no attempt to compare models to each other; rather, each model will be evaluated on its own merits relative to how well it can handle each problem and the techniques required to incorporate the model into the different problems.  Sample evaluation criteria might include:	(1)  Traceability of decision making process	(2)  Speed with which model runs	(3)  Data required to implement modelTime required to “tweak” model to make it applicable to a given scenarioAbility of the model to adapt to a changing situationNote that many of the objective evaluation criteria will not necessarily have a “goodness” associated with them, even though they may be measurable.  The criteria will be used to evaluate the applicability of a particular model technology; e.g., a model that can make decisions much faster than real-time may be applicable to constructive, virtual, and live simulations, whereas a model that runs in real-time or near-real time may only be suitable for virtual and live simulations.  A model that runs even slower than real time may have some limited, specialized use in constructive simulations or as a research tool.2.3  Common Representation and Interchange System for HBRThe last DMSO initiative is an effort to develop a common representation and interchange system for human behavior representations.  This effort is modeled after the successful DMSO Synthetic Environment Data Representation and Interchange Specification (SEDRIS) program, which focused on producing a common representation and interchange system for environmental data.  [2] As its name implies, SEDRIS is composed of two parts: (1) representing environmental data, and (2) interchanging environmental data sets.   SEDRIS has a data representation model, augmented with an environmental data coding specification and spatial reference model that allows users to clearly and unambiguously articulate their environmental data.  Interchange is facilitated through the SEDRIS API, its format, and associated tools and utilities.Although the need for SEDRIS came from the M&S community, the SEDRIS development team realized that the representation would have wider application.  The challenge for SEDRIS was to provide a way to represent environmental data that applied to a wide range of potential users and was not too difficult to implement.  SEDRIS does not attempt to judge data sets or the intended use of any given data, but instead facilitates the description and sharing of environmental data regardless of the viewpoint taken by the data.  For example, consider the representation of a road.  As stated in [2], “Whether it is viewed as a linear feature in one domain, or as a series of polygonal facets in another does not (and should not) change the fact that the representation is about the same ‘thing’. Similarly, a cloud is a cloud, whether it is represented as a collection of moisture content point samples within a geographically large 3D grid, or within a weather map whose features are identified as ‘fronts’ and low- or high-pressure regions.”  An effective human behavior representation and interchange system will provide a similar capability. The first goal of the HBR Common Representation and Interchange System will be to develop a set of comprehensive objectives similar to the SEDRIS objectives.  The SEDRIS objectives are to: Articulate and capture the complete set of data elements and associated relationships needed to fully represent the physical environment. Support the full range of simulation applications (e.g., computer-generated forces, manned, visual, and sensor systems) across all environmental domains (terrain, ocean, atmosphere, and space). Provide a standard interchange mechanism to pre-distribute environmental data (from primary source data providers and existing resource repositories) and promote data base reuse and interoperability among heterogeneous simulations.DMSO initiated the SEDRIS project in 1994 with the goal to overcome the above challenges and accomplish the stated objectives.  From the beginning, the SEDRIS project has involved members from government, industry, and academia to provide an open and participative environment for all interested users.  Because a common representation mechanism will present many of the same challenges in the HBR domain, it makes sense to use the SEDRIS development process as a model.An initial workshop to investigate the feasibility of developing an HBR Common Representation and Interchange System will be conducted at DMSO during the Spring or early Summer 2001.  The workshop agenda and invitees are being finalized as this paper goes to press.3.  CONCLUSIONThe DMSO is evolving on a new vector to support the warfighter.  This effort recognizes the ever-increasing need for accurate representations of human and organizational behavior.  To accomplish this goal, the DMSO behavior program has embarked on several initiatives.  The first initiative will evolve a set of authoritative components that will represent human behavior, and includes a flexible next generation synthetic force, enhanced decision-making models, and a common behavior and representation modeling and development environment.  Additional initiatives that began in FY01 include a Challenge Problem that will explore the strengths and weaknesses of various human decision modeling techniques and technologies and exploring the feasibility of developing a common representation and interchange system for human behavior and performance. [1]  Department of Defense Modeling and Simulation (M&S) Master Plan, Under Secretary of Defense for Acquisition and Technology, Washington, D.C., October 1995.[2]   HYPERLINK http://www.sedris.org http://www.sedris.orgBIOGRAPHYLt Col EILEEN A. BJORKMAN, USAF, is the Chief, Concepts Application Division, at the Defense Modeling and Simulation Office (DMSO).  She has held a wide variety of development test and evaluation assignments, and was a tactical fighter analyst at Air Force Studies and Analyses Agency.  At DMSO she is responsible for the Human Behavior Representation program, the Smart Sensor Web program, and DMSO Community Support activities, including the Modeling and Simulation Information Analysis Center, Modeling and Simulation Resource Repository, and M&S Education.PAUL BLEMBERG is Senior Military Analyst for the Illinois Institute of Technology Research Institute/AB Technologies Group in Alexandria VA.  He is a retired US Marine Corps helicopter pilot and Weapons and Tactics Instructor.  He directly supports the DMSO Human Behavior Representation program.