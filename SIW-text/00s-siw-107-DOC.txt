TENA: A Domain-Specific Architecture for Live ParticipantsEdward P. Dunn, IIINaval Undersea Warfare CenterNewport, RI 02841401-832-5323dunnep@npt.nuwc.navy.milKeywords:T&E, live, range interoperability, trainingABSTRACT: The Test and Training Enabling Architecture (TENA) addresses the domain-specific needs of live Test and Evaluation and Training ranges within the cross-domain technical framework defined by the DoD Modeling and Simulation Master Plan.  In TENA, the High Level Architecture (HLA) is used to support interoperability between the live range domain and the larger M&S community.  TENA components include a broad domain object model of the live range and range support world, a common set of services for manipulating objects, as well as other standards, protocols, rules, and supporting software.  TENA objects are defined in traditional software engineering terms, but can be translated to HLA OMT format.  Since TENA is intended for a single domain, much of the internal object information will not be of interest to HLA federates, but directly promotes domain-specific functionality. Communication between physical instrumentation is required for local range operations, interoperability between ranges, and interoperability between ranges and other facilities. One example of domain-specific functionality is that the object model includes the assets and processes used by test and training ranges to dynamically control these communication channels.  Additional services support the access control needed for range safety and realtime substitution of instrumentation choices. Much of the information that is needed during the Federation Development phase of an HLA Exercise can be captured directly in TENA objects so that automated tools can quickly assemble an exercise of interoperable components with or without HLA participants.A prototype of TENA was built in FY99 by the Naval Undersea Warfare Center (NUWC) under the sponsorship of the Foundation Initiative 2010 (FI 2010).  FI 2010 is an interoperability initiative of the Director, Operational Test and Evaluation (OT&E), funded through the Central Test and Evaluation Investment Program (CTEIP).  The prototype includes an implementation of the most fundamental object services, objects representing typical range assets, and an interface to HLA.  In November 1999, the prototype was delivered to testers at ranges representing each service.  Tests conducted at each site will determine if the prototype will support the introduction of range-specific sensor data, displays, and HLA-compliant simulations, i.e., if software built using TENA is portable, reusable, and interoperable.This paper will briefly describe TENA, what exists in the Prototype and what remains to be developed.   The techniques used by TENA to provide an architecture friendly to the needs of its “home” domain, while leveraging HLA’s cross-domain interoperability, may prove useful outside the live range community.1.  BackgroundThe Department of Defense (DoD) rigorously tests all major military procurements.  The variety of procurements is enormous, including such diverse items as uniforms, artillery, land vehicles, aircraft, ships, submarines, communications equipment, weapons, sensors, gas masks and snowshoes.  Much of this testing is performed at specialized open air ranges (OARs) which bring unique environments, test equipment, and personnel together in support of carefully orchestrated test plans.  Additionally, combat readiness is maintained by training our forces at OARs where the environmental impact can be controlled and the training events can be carefully monitored for both troop safety and mission effectiveness.Although simulation is used extensively in the design, development and testing of military systems as well as the training of forces, live open-air testing is often required to ensure the maximum safe realism of testing or training events.  The DoD supports more than 50 test or training facilities dedicated largely to this purpose – many of them Open Air Ranges (OARs), but also including Hardware-in-the-Loop facilities  (HITLs), Installed System Test Facilities (ISTFs), and others.Major political and technical changes in the last two decades have directly effected these facilities - especially the OARs.  These changes include those listed in Table 1.Traditionally each test or training event was confined largely to one site.  The instrumentation systems at each location were highly specific to collecting and processing data associated with their mission area. Fundamentally, each site was implementing a similar data collection, processing, display and/or analysis process, however the differences in mission area, instrumentation vendors, and upgrade/procurement cycles resulted in largely unique instrumentation investments.  Although there were active efforts to share technology through organizations such as the Range Commander’s Council, the fact remained that almost every facility contained unique instrumentation and instrumentation support systems.The political and technical changes mentioned in Table 1, would together lead the DoD to set new challenges to the test and training communities to reduce the hardware, software and maintenance cost of major instrumentation systems and provide “easy” interoperability both among facilities and between facilities and simulations.TENA OverviewThe Test and Training Enabling Architecture (TENA) is one element of the Foundation Initiative funded by the Central Test and Evaluation Investment Program of the Undersecretary of Defense for Acquisition and Technology.   TENA is a software architecture that enables seamless interoperability and promotes software reuse between Test & Training Ranges and between Ranges and the Modeling & Simulation community. This section offers an overview of TENA to provide context for the discussion of the first TENA prototype. Existing architecturesAs early as April 1994, representatives from test ranges, training ranges, installed system test facilities, and interested parties have been assembling, at the invitation of the DoD, in an ad hoc group to address the changes in their industry.  This group is called the Common Test and Training Architecture (CTTRA) ad hoc group.  This group concluded that a common software architecture was key to addressing multiple community needs. CTTRA documented an internal software architecture which was representative of the majority of our nations test and training ranges circa February 1995.[1]This model may not exactly represent any one-range system, but demonstrates a dominant architectural theme of functional decomposition and data flow common to many.  CTTRA continues to meet as reviewers, customers and contributors of the Foundation Initiative project.Figure 1 shows representative systems where raw data flows, largely from left to right, through multiple stages of processing, each adding more refined user information.   These systems continue to serve as the backbone of our existing ranges, but pose insurmountable challenges when asked to “scale-up” to new requirements.Some examples of these challenges include:Minor changes in the format of a sensor data field can have a major “ripple-effect into every other block of these “classic” architectures.  Although the best software documentation practices can diminish the pain, identifying, changing, and testing all impacted software is both cost and risk intensive.Attempts to share software from one installation to another were usually unsuccessful.  The underlying assumptions about the boundaries between partitions were seldom the same from site to site (one application would compute course and speed in the “processing software”, another as part of each “display” application, both the sizes and format of shared data would differ).  The rates of data flow through the system would vary widely (whereas a submarine track might be safely updated once / second; projectiles may require 10000 samples/second or more).  This frustrates efforts to pick up an algorithm from one facility and drop it into another’s system.  Language and vendor operating environment issues add to this list to form real and substantial obstacles to cost-effective reuse of software and/or “easy” interoperability with another system.A fundamentally different approach was needed to address these challenges.TENA ElementsTENA consists of three primary elements:  A domain-specific object model, a set of object services, and a set of recommended standards, protocols and guidance (a.k.a. rules) on how to apply the architecture, including a recommended process for planning and executing exercises.  The different elements of TENA exist at varying levels of development.  A Fall 1997 report fully documented the architecture concept.  Subsequent work demonstrated how HLA could meet a major TENA requirement (interoperability between test/training facilities and the modeling and simulation domain).  FY99 focused on the definition and development of a small, but representative subset of TENA functionality (The TENA Prototype) to be applied to a real range system and tested at multiple test centers. FY00 will focus on the testing and refinement of the prototype as well as a major update to the Fall 1997 report.  The updated report will incorporate lessons-learned from testing the prototype, technical improvements since 1997, and substantial feedback from the test and training community.TENA and HLAA question that is often asked is “Why do I need both TENA and HLA?”  TENA and HLA are complementary, not competing, architectures!   Figure 2 shows the overall relationship between TENA and HLA. [2] TENA is an architecture internal to participating systems, but designed for convenient interfacing to the “outside” world, especially to the simulation community via HLA.Object Model Structure  The TENA Object Model applies conventional computer science object modeling techniques (initially Rumbaugh[3], now Unified Modeling Language-UML[4]) to the definition of essentially all information processing elements of a typical test or training range.  A very simplified view of this model is shown in Figure 3. People familiar with range systems might expect to find a model where sensors (radars, GPS, video), displays, and communication channels were prominent.  This is not the case in TENA.  In fact, in addition to its object-oriented flavor, this model differs from its known predecessors in one very substantial way.  The view of a test or training range has been literally “turned upside down”.  The instruments (although an important element) no longer drive the model.  The problem space definition is not “ How do I collect, process, and display data streams?" but rather “How do I meet my customers test or training requirements?” Objects in the top-left region of Figure 3 capture the customer’s requirements and plans.  Once established, these plans can be invoked by a large number of potential scenarios, each with a specific mission space definition (Environment, Platforms, Events) and one or more Provider Space options on how to populate the Mission Space. Only the Provider Space is covered in most existing range architectures. Expanding the scope of the traditional problem space gives this architecture enormous flexibility and integrative power.  The following pair of examples are representative of this flexibility.Example 1TENA is location transparent to the maximum extent possible.  Although we use UML as a modeling aid, each TENA object is potentially an independent software component located anywhere within the test and training range domain.  Any object visible to TENA (at any participating facility) can be scheduled for use by any other participating facility pending local permission, security, and communication capability sufficient for the needs of that particular test.  The information to make this determination is encoded in supplemental information to the object definition. Tools shared by each facility operate on this information, avoiding in most circumstances, the need for a “FOM-o-rama”-like event prior to a joint exercise.  [This is possible because the domain of open air ranges and related facilities is far more constrained than that addressed by all of HLA. Readers familiar with the FEDEP[5] process will recognize that systems that apply TENA agree on and operate within a defined “conceptual model”.  Translation to an OMT format is required only when participating in an HLA Federation.]  Figure 4 shows building a “logical range” from a collection of disparate community resources.  Our expectation is that when TENA is fully deployed it will be no more difficult to use a test resource at a remote facility than it is to use a network printer in a trusted office environment.Example 2The program manager for a new tank wants to determine if the vehicle can stay still on a 60-degree slope, without slipping down the hill.  His requirement to the testers might be: “Tell me if this tank will slip on a 60-degree incline under certain weather and terrain conditions.”  This requirement is constant for a long time, perhaps years, while the testers pass through multiple stages of the acquisition cycle from conceptual design to life cycle extensions.  The mission space elements needed to test the customer’s requirements are also constant, i.e., a hill, a tank, various weather conditions, various terrain.  The only changes over time are which provider space elements are used to execute the tests.  At early stages in the development, the mission space elements are supplied by simple models, later by more sophisticated physics-based models, wooden mock-ups, metal scale models, and finally a real tank and hill at an open air range.  TENA is designed to save the earliest requirement definitions, scenario definitions, and test results so that at each stage of development they can be compared to their predecessors using exactly the same, or at least consistent, object definitions.  TENA is designed from the beginning to be a full participant in simulation based design and development.Object ContentEach TENA object requires content definition and an implementation.  Subject matter experts define the externally available attributes and the operations (methods) an object can perform. There is a strong motivation for community agreement of object content as it enables reuse of object implementations, promotes distribution of new implementations of standard objects, and eases interoperability.  There is also a strong incentive not to lock the architecture to a specific object content definition; to allow local flexibility, innovation, and technology driven updates. Some object content definitions will be offered by the development team within the Foundation Initiative project, but we expect that the majority of object content will be defined by community working groups such as the Range Commander’s Council and the Common Test and Training Range Architecture ad hoc group. Objects are defined to support dynamic discovery.  At runtime, standard support tools can determine the capabilities of an object and apply those capabilities without requiring source code changes. The self-describing features allow integration of the object into the exercise without the need to modify, reintegrate, and recertify the large software systems used at these facilities.Object RelationshipsThe objects within the TENA Object Model are related to each other both statically and dynamically.  The static relationships are currently either standard aggregation or composition.  The dynamic relationships are more interesting.  TENA Objects are each an instance of a TENA Base Object which has capabilities beyond a standard UML object.  Specifically, relationships can be associated with any TENA Object at one of three levels: The entire object, an individual method, or an individual attribute.  These relationships are used to support both dynamic discovery and the dynamic configuration of TENA to support a specific test or exercise.Dynamic test conditions are integral to most test and training ranges.  It is common practice to have a group of sensors arrayed across a test area such that there is always at least one sensor tracking an item of interest.  TENA represents this as one mission space object having its data supplied from different provider space objects.  The representation of this is a dynamic relationship (perhaps named “Provider”) with a source as the current sensor, and a destination as the mission space object.  The relationship would be reassigned at run-time, as each new sensor became the preferred provider.  Some observers of the exercise may not even be aware of which sensor is the mission space source, while others, such as range operations personnel, may be keenly aware of not just the relationships, but of detailed behavior of the sensor(s).Another use of dynamic relationships is to associate site specific and/or test specific data with a standard object definition.  (This is conceptually similar to having multiple simultaneous “properties” associated with an object.)   Examples of site and/or test specific information which may change independently of the “stable” portion of an object include: Command Syntax, Quality of Service requirements, Archiving formats, Security/Access restrictions, Display preferences, Data Format descriptions, Cost/Usage information, and Configuration Management data.   These data would simply be stored in additional objects, each of which was the destination of a relationship originating at the “stable” source object (Figure 5).Some examples may be helpful: Configuration management data can be examined to ensure compatible versions of software are loaded before proceeding with an exercise.Automated tools can examine the quality of service required and determine if the resources scheduled for the exercise can support the predicted load.A range could execute objects it had never seen before (perhaps to support a joint exercise) simply by having a common command processing tool look for the command syntax information at the destination of the “command syntax” relationship.  This is far preferable than making even simple changes to the organic command system, which would likely require expensive software re-certification.Relationships are used to find and collect at run-time much of the information normally collected at an HLA Federation “FOM-o-rama”.  (Additional domain-specific information is used only by TENA applications.)  This allows a TENA Object to be quickly translated into a SOM and to configure TENA systems to participate in an HLA Federation.As new technologies become available, additional relationships can be added so that new applications can take advantage of the new data, while old ones run unimpeded.  The data content of these site and exercise specific “helper objects” has not been defined.  Work on establishing an XML-based description of an object’s attributes, methods, parameters, valid parameter ranges, and archiving format is planned in FY00.	Object ServicesEach TENA Object is an abstract model of a real software application.  The software applications communicate with one another strictly by use of TENA Object Services.  There is a rich set of services defined including support to add and remove objects, set and get attribute values, lock and unlock resources, invoke methods, set and get relationship information, and several variations of these basic functions.  Additional services to control distribution of data, security, data storage and retrieval, inline filtering, system initialization and other areas have been proposed, but have not been defined to the same level of detail. The Object services applications programmers interface (API) is designed to hide the implementation details of the object operations.  Specifically we want to be able to write source code once, and have it support multiple test situations. We do not want to have to change application source code in order to move data using shared memory on one test, CORBA on another, and  HLA on a third, for example.  Figure 6 shows the context of object services with respect to the application programmer.TENA Object Services make extensive use of “listeners”.  Almost every object operation (all state changes) can be trapped by the API implementation, and if another application is registered to “listen” for that operation, it will be informed.  Since all operations between objects use object services and all operations that change the state of an object can be trapped, virtually anything of interest that happens within this architecture at run time can be monitored.  This feature will be used extensively in real range applications.  Some obvious uses include:Notification to a display application that the value of an attribute has changed. (Avoids expensive polling – or recomputing raw data that hasn’t changed.)Notification to a range safety officer that an alarm has been triggered.Dynamic reconfiguration of real time exercises, i.e. changing relationships between objects, having the effected applications automatically notified of changes (and adapting) without having to interrupt real-time processing.  (Changing data sources, changing I/O channels in response to congestion, bringing additional processing resources online, etc.)Passive system debuggers and/or security monitors.TENA PrototypeTENA is a large architecture.  Its goals are ambitious.  In FY99, the Foundation Initiative was given approval to proceed with a TENA prototype.  The TENA prototype effort is  both a risk reduction effort for key TENA concepts and a practical application of a subset of TENA.  The goals for the prototype stated that it must:Represent real range systems.  This implies that, at a minimum, Environment, Sensor, Participant, Command, and Display objects must be involved.  Show the HLA / TENA Relationship. This implies that at least one Participant is populated with simulated data via an HLA federation.Apply to a “real” range.  Although this is a prototype, it must be sufficiently robust to solve a real problem at a real range, albeit a small subset of the entire TENA.Apply to multiple ranges.  The prototype must be built to support testing in multiple test environments (land, air, sea). The TENA Prototype most closely matches the evolutionary phase of the HLA RTI referred to as F.0, i.e., Do we have the right functions?  An implementation of the TENA Object Services, limited to a single process model, has been completed in Java 2.0. It has been tested on Windows 98 and NT platforms and is being ported to LINUX.  The prototype will be tested at multiple Development Test Cells (DTCs) located at Major Range and Test Facility Base (MRTFB) facilities, and will be integrated into new software being installed at the Atlantic Undersea Test and Evaluation Center (AUTEC), Andros Island, Bahamas.TestsFive DTCs, one each at White Sands Missile Range, Eglin Air Force Base, Naval Air Warfare Center - Aircraft Division (Paxtuxent River), Redstone Technical Test Center, and the Naval Undersea Warfare Center, are currently testing the TENA Prototype.  Table 2 gives an overview of the planned testing in FY00.  Bolded marks are tests that are planned to be complete before this Spring SIW.  The types of tests are designed to ensure that we can perform typical range functions across a variety of mission areas and focus on the functionality of the API.Table 2.  Test Matrix for DTC Tests in FY00Test #DescriptionNUWCPAXEglinRTTCWSMR1Move data.(((((2Discover modifications dynamically.(((((3Display TENA participant data.(((((4Display live data describing a TENA participant on a range.(((((5Display TENA participant data received from an HLA federation.(((((6Display TENA objects from multiple data sources simultaneously on multiple views.(((((7Demonstrate ability to dynamically change range environment (e.g., lat / long).(((((8Receive / display raw data from sensor.((( Additional Work / Applications to Other DomainsThe TENA Prototype is just the first step in the implementation of TENA.  Much work remains in defining objects, implementing objects, implementing services, testing in additional applications, establishing community distribution and maintenance mechanisms, and effectively leveraging work performed elsewhere.No part of this architecture is cast in concrete.  The major elements of TENA (Object Model, Services, Standards and Protocols) are highly orthogonal to one another.  This was done purposefully, to avoid a “house of cards” syndrome, and to be able to adapt the architecture over time.  The services that we have developed and prototyped may be useful to multiple domains outside of the range community.  Although they are tightly coupled to the definition of our “Base Object”, they are not at all coupled to the structure of the TENA Object Model.  Perhaps another community will like our top-level Object Model, but wish to apply a different set of services, tuned to the needs of their domain.   We expect to beg, borrow, and steal object content definitions from wherever we can find them – and encourage the working groups in the Range Commander’s Council and CTTRA to do the same.  Some may be useful across domains with little or no changes.We have defined very few “standards and protocols” at this time.  They apply almost exclusively to the implementation of objects and are meant to promote software reuse within our community.  Of course, the object implementations can be treated as a “black box” and one community could accept, for example, JavaSwing as their standard graphics software and another accept Windows without impacting other areas of the architecture. Plans for deploying TENA to multiple facilities call for increased functionality being added over time in three more major increments after this prototype: data archiving/retrieval, analysis support, and finally, automated tools for test planning and execution.  As we analyze results of our prototype efforts, we expect the Foundation Initiative project will become more actively involved in industry efforts that are clearly related to our work. We are already actively involved in the Architecture Management Group (AMG) of DMSO as the DoD’s representative from the test community. Realtime CORBA, XML, and elements of the Joint Technical Architecture (JTA) are standards that we are investigating.Current status of the TENA Prototype testing at participating DTCs will be presented at the March SIW.References[1] “Proceedings of the Third Common Test and Training Architecture Working Group”, U.S. Department of Defense, Central Test and Evaluation Investment Program (CTEIP), Virginia, 1994.[2] High Level Architecture –CD 1.01, March 1998, U.S. Department of Defense, Defense Modeling and Simulation Office, Virginia, 1998.[3] Rumbaugh, James, et al: Object-Oriented Modeling and Design, Prentice Hall, 1991.[4] Fowler, Martin et al: UML Distilled – Applying the Standard Object Modeling Language (V 1.2), Addison-Wesley, 1997.[5] “Federation Execution and Development Process (FEDEP) Model, V1.4”, U.S. Department of Defense, Defense Modeling and Simulation Office, Virginia, 1999.BiographyED DUNN is the Technical Leader for the Architecture portion of the Foundation Initiative project, TENA.  He is a Computer Engineer at the Naval Undersea Warfare Center, Newport, Rhode Island.Table 1.  Technical and Political DriverThe end of the Cold War.Reduction in Defense spending.Increased influence of software / software cost in instrumentation systems.Reduction in hardware computer costs.Increased use/fidelity of modeling and simulation.Increased awareness of environmental impacts of live testing.Focus on multi-service and multi-national military exercises.Need to test new systems with operating parameters that exceed the capacity of any one facility.Figure 1.  Common Test and Training Range ArchitectureFigure 2.  TENA - a Domain Specific Extension of HLAFigure 3.  The TENA Object ModelFigure 3.  The TENA Object ModelFigure 4.  Configuring a Logical RangeFigure 6. Multiple Protocol Framework ApproachFigure 5. Facility / Exercise Dependent Object Information