Object Models, Messages, Languages ‚Äì The Warfighter Deserves BetterAndreas Tolk, PhD.College of Engineering & TechnologyOld Dominion UniversityNorfolk, VA 23529 HYPERLINK "mailto:atolk@odu.edu" atolk@odu.edu  Charles Turnitsa, Saikou DialloVirginia Modeling Analysis & Simulation CenterOld Dominion UniversityNorfolk, VA 23529 HYPERLINK "mailto:cturnits@odu.edu saikoud@gmail.com" cturnits@odu.edu saikoud@gmail.comKeywords: Interoperability, Object Models, Messages, Languages, Explicit MeaningABSTRACT: ¬†¬†¬†¬†The world of C2 communications and interoperability grows increasingly more complex and diverse, especially as it expands to include simulations, robotic forces, SOA approaches among other new application areas. Object models, as employed in federations, afford the means for each system, while exchanging via a common lexicon, to accommodate separate definitions for the information elements exchanged. Messages, while extremely rigid and formalized, are interpreted by systems all claiming to represent doctrine, yet sometimes are not able to represent what doctrine states. Language development efforts seek to allow for the exchange of information by systems from a broad range of communities, yet while still concentrating on the terms of exchange, interpretation of the meaning of those terms is granted to the individual systems (which may each interpret their own meaning). In all these cases, by relying on terms, which may be interpreted by the receiving system, ambiguity is not only possible, it is almost guaranteed. The warfighter, who is training, planning, or operating in a dangerous world, deserves better - information exchange without ambiguity.Introduction ‚Äì Why Interoperability FailsThe interaction of simulation systems, C2 devices, and autonomous forces (drones, robots, etc) is today a complex and difficult challenge to developers, implementers, and users.  Systems are required to federate into system-of-systems architectures which were never designed for such operation.  The production and consumption of data is facilitated in such cases by technologies such as XML and web services, which allow for a similar syntax, yet the common acceptance of the semantics being exchanged remains a challenge.With each exchange of data that is made, the receiving system takes the data and interprets it and for the receiving system, once an interpretation is made, it becomes information [Turnitsa 2006].  Assume that the transmitting system (ST) had its data production methods developed to accommodate a certain standard model, and that the receiving system (SR) had its data consumption methods developed to accommodate the same standard model.  Ideally, the data (x) produced by ST would be the same as the data consumed by SR.ST(x) = SR(x)While this may be the case for the data transferred, it is not the case, as a rule, for the interpretation that the system makes of that data.  Each system is developed with a different understanding, and different implementation of a standard.  This situation will be discussed with particular instances in sections  REF _Ref172706254 \r \h 3,  REF _Ref172706274 \r \h 4 and  PAGEREF _Ref172706318 \h 6 below.  What results when this is the case is that the data interpreted by the receiving system becomes information that differs from what was intended by the sending system.  It is the interpretation of data, and the placing of it in context, that transforms data into information, and then knowledge [Turnitsa 2006].  The data itself remains the same; it is the difference in interpretation of that data that is different.  ST has a different interpretation of x than SR.  If the information of ST (i) is represented by ST as data (x), and then transmitted to SR, it is the responsibility of SR to interpret that data (x) into information based on that systems understanding of what the data means.  What should occur, if ST and SR would have the same interpretation of the meaning of x is this:ST(i) ( x ( SR(i), whereST(i) = SR(i)Unfortunately this is rarely the case, as the following sections will illustrate.  What results instead is the case where the information intended by ST is interpreted differently by SR.ST(i) ( x ( SR(i‚Äô)This situation is already a problem when only two systems are involved (ST, SR), however the problem is compounded with each new system involved in a chain of data exchanges (resulting in information interpretations).  In this case, a system may consecutively serve in the role of ST and SR, resulting in a case were we should just refer to it as system S0, where the collection of such systems (S0 ‚Äì Sn) make up the system of systems within an enterprise.  This situation is a requirement for the technical component of the Net Centric Warfare idea.  To see the immediate applicability of this problem to SISO, consider when the operation is not an actual one, but rather of training or experimentation, and the replacement of any C2 or autonomous force system by a simulation system will establish the relevancy.Seeing that the chain of data exchange and interpretation into and out of the state of information requires many such interpretations, we can revisit our earlier equation.  If we consider the equation:ST(i) ( x ( SR(i‚Äô)This can be called simply an exchange (Sx), and it results in transforming the initial information (i) into heterogeneous information (i‚Äô).  As the number of exchanges grows, the difference of i from its initial form grows with each change.  As the heterogeneous nature of each change is itself based on some permutation (i‚Äô) of the original (i), the change is exponential in nature, rather than merely multiplicative.  These results in:n * Sx(i) results in (i‚Äô n)By the time a number of exchanges (n * Sx) take place, the heterogeneity introduced to i is (i‚Äô n).  This will result in a decision based on wrong information, and turn into actions driven by a wrong decision.  In a simulation, or in training, this becomes a wrong representation.  Perhaps, in that case, wrong representation is not the end of the world, but return to the original case ‚Äì one of an actual operation.  In that case, if the wrong information leads to the wrong decision, which results in wrong action ‚Äì this is the C2 mistake that causes unnecessary compromise to a mission at best and the unnecessary loss of life in the worst case [Stewart 2006].  It is the opinion of the authors that the warfighter deserves better than this.  The remainder of the paper will discuss some particular cases where the information interpreted from data can be changed, and in which ways.  It also discusses what is meant by interpretation and understanding ‚Äì for a system.  Finally, a potential way ahead out of this problem is presented for consideration.The Problem ‚Äì Terms, not MeaningThe introduction described the general, poor, condition that exists in the interoperability domain of the systems engineering world in general, and this includes our special cases of simulation, C2 and autonomous force systems.  This section will describe what is seen as the cause for this problem ‚Äì one of homogenous exchange data being interpreted by different systems into information with heterogeneous meanings.When information resides within a system, that information is the result of that particular system interpreting data within a particular state, or context.  Each system will have different internal states, and different assumptions behind the processes and algorithms that contribute to that context.  A different system will have different processes, and different states leading to different information, even if it were based on the same initial data.Currently, as will be shown in the following three sections of the paper, the commonly practiced information exchange processes within our community (C2 and M&S) operate by exchanging data.  These data are representative terms.  As the data gets consumed by each new system, that system interprets it into some new heterogeneous information value ‚Äì quite separate from what was intended by the system that produced the data. It is theorized, and this will be exposed more fully in the final section of the paper, that by exchanging a representation of meaning, rather than terms (which may be interpreted to mean anything ‚Äì it is up to the receiving system), that information may be exchanged ‚Äì or at a minimum a receiving system can be aware of the information the sending system intended, and the reverse.Some definition of the difference between terms and meaning is appropriate.   A useful source for this definition is the theory of semiotics.  Semiotics is the theory of meaning of symbols.  Some of the main contributors of ideas in this field were Charles S. Peirce and Ferdinand De Saussure.  As a concise introduction, and to serve our purposes, we will rely on the semiotic triangle [Ogden 1923].  As can be seen from  REF _Ref172716897 \h  \* MERGEFORMAT Figure 1 - Semiotic Triangle for Systems Interoperability, a system will have some basis for referring to real world (or imagined world) referents, that the developers conceived of.  As the system is required to represent those referents in some way, then symbols are born.  These can be data elements, words, tags, or any other way that allows them to be identified individually.  As with human communication, the stronger the bond between conceptualization (behind the systems developers) and the referents, the stronger the adequacy of understanding is encapsulated in the systems design.  These referents are represented within the system, and as data elements to exchange with other systems, as symbols.  Symbols are derived to stand for the many parts of the conceptualization.  The stronger the bond (meaning it is harmonized) between symbol and conceptualization, then the more ‚Äúcorrect‚Äù the symbol is.  Finally, if there is an adequate reference (relationship between referent and conceptualization), and if there is a correct symbolization (between conceptualization and symbol), then there is a relationship whereby the symbol actually stands for the referent.For our purposes, the terms of exchange between systems are symbols.  The meaning behind those symbols is represented by the relationships between the symbol and the conceptualization, and between the conceptualization and the referent.Disjoint Terms ‚Äì Object Model Based ExchangeObject Models, and the methods for exchanging data between systems that are based on using object models, are supposed to provide some level of interoperability by ensuring that all systems produce and consume terms from a controlled vocabulary (the object model).  As the explanations and examples of this section will show, the fact that the data exchanged are terms, and the translation of those terms into meaning is under the control of each receiving system (regardless of what the transmitting system intended), means that any single term from the object model may, once transferred from one system to another, be transformed into a piece of information completely different than what was intended.  In this way, even though the term exchanged between two systems is a single term, its interpretation from data into information by the sending system is potentially very different (in meaning) from its interpretation from data into information by the receiving system.The High Level Architecture (HLA) simulation interaction standard is based, in part, on the presence of a number of different object models.  These object models are regulated by the HLA specification for the Object Model Template (OMT) [IEEE 2000].  It specifies the nature of recording information about the objects, attributes, interactions and parameters.  This template can describe both the object model of an individual simulation system, known as a Simulation Object Model (SOM), or it can describe the object model of a federation, known as a Federation Object Model (FOM). As the purpose of this investigation is to discuss the interaction of systems, and the purpose of the FOM is to facilitate such interaction, this section will be concerned with the FOM.The purpose of the FOM is to provide, for the federation, a common taxonomy of terms to discuss the objects of the federation (along with the attributes defining those objects), along with the interactions among the objects (and between the objects and the environment controlled by the simulation systems).  In this regard, the HLA FOM is a success ‚Äì it gives a standard vocabulary (consisting of terms) for the members of the federation to use to interact with each other.  These terms are the data (i) described in the introduction.  How each federate interprets that data, and then makes use of it (including matching the elements of the FOM to the individual federates SOM) is not governed by the HLA standard.  This mismatch in interpretation leads, of course, to a mismatch in information that the individual federates make out of FOM interactions supported by the HLA standard.  Some of these differences in interpretation are corrected, periodically, in a running federation by publishing updates to ‚Äúactual‚Äù or ‚Äúground truth‚Äù attribution of objects by the controlling federate [St Peter 2006].  This is one potential mitigation of the interpretation problem, however as it is not constant, there still remains the problem of information mismatch between the time periods of update.  All federates have differing internal algorithms, that make different interpretations of the received data that they get from the federation.In  REF _Ref172720146 \h  \* MERGEFORMAT Figure 2 - Federate Mismatch we can see the movement of an entity as it is represented by three different federates, interacting with the same FOM.  The first, FED1 is the controlling federate, and represents ‚Äúground truth‚Äù for the entity.  FED2 and FED3, from the figure, represent the understanding of the location of the entity within two other federates, each interpreting the location of the entity, and its path of movement, based on the FOM updates that it receives at time T0, T1, and T2.  At each time period, a hard correction is made to the location; however the period in between the time slice has the entity in totally different locations from ground truth ‚Äì which can lead to problems when decisions and actions are based on the location of that entity.The data sent out from FED1 to FED2 and FED3 is read exactly as it is put out ‚Äì the data in the interaction is the same for all three federates.  The interpretation of that data however is different, which leads to a different ‚Äúworld‚Äù being real to each federate.  To illustrate the exponential difference in meaning, consider the following.  FED1 is controlling the entity, however FED2 has a separate entity that makes a successful combat engagement with FED1 (between T1 and T2).  This is reported to FED3, once the engagement is completed, and FED3 gives the interpretation of that information to a portion of the training audience, that makes some operational decision based on the combat engagement.  The location of the shooter in FED2, however, would not have been able to engage the entity, if it had been aware of ‚Äúground truth‚Äù, so the decision made by the audience of FED3 to take action (the final steps of the OODA loop) is premised on faulty information.When dealing with simulations, this problem is referred to as the ‚Äúfair play‚Äù problem.  Consider, however, that this problem could exist for any system of systems that employs a common object model for its interactions.  Consider, for instance, in the future envisioned interactive environment of the Global Information Grid what it would mean for C2 devices, all sharing the agreed-to C4ISR Community of Interest object model that is predicted to be developed [DISA 2007].  As one C2 system exchanges data with another, then that other C2 system must interpret the data, and present information to the user of the system (or act upon it, in the case of autonomous forces).  In this case, due to faulty interpretation of data leads to false information, which drives flawed decisions and launches actions that are premised in error.The problems described here can reside in one of two places.  First, the problem can be with the federate, or system, that is interpreting the data.  Algorithmic errors might exist, or design decisions (introduced during development) might be present, that are based on assumptions divergent from the community.  These algorithms are the system processes that operate with the data of the interactivity object model as input.  This problem is discussed in section  PAGEREF _Ref172708279 \h 6 below.The second problem could be with the object model itself.  The terms of the object model can be so complex, that any algorithms (or internal processes) of a system might be forced to make assumptions.  This problem is discussed in section  PAGEREF _Ref172708289 \h 7 below.Disjoint Statements ‚Äì Messages and MessagingAs this section will show, through explanation and example, when systems rely on message standards, and messaging to exchange terms, it is potentially a worse situation than with an object model.  Messages are collections of a number of different terms, which adds to the complexity of meaning behind those terms.  As different systems (from different developers, for different organizations) have separate understanding of the meaning of the terms, as well as separate understanding of what the collection of terms that messages represent, when these messages are exchanged, the resulting translations into information is anything but a shared understanding of meaning.The common way for C2 systems to exchange data is by any of a number of different message formats.  Some of the many formats used include:Link-11A/BLink-4AArmy Tactical Data Link (ATDL)Link-16VMFThere are many more messaging formats ‚Äì the ones listed represent a small sample of the US and NATO formats commonly used by C2 systems supporting Joint Operations.The existence of so many different standards (and this is a small sample), as well as so many ways to interpret, translate, filter, and exchange the messages speaks to the potential for different understanding of the knowledge derived form the data exchanged within the particular message system itself.In US/NATO air operations, as an example, the agreed upon current standard is Link-16.  The official US standard for Link-16 is TADIL-J, or JTIDS (TADIL-J is the message standard, and JTIDS is the transmission standard), both based on Link-16 messaging, and both commonly referred to as Link-16.  The official NATO standard for Link-16 messaging is STANAG 5516, yet the NATO standard for transmission is STANAG 4175, or MIDS.  The standard operating procedure for using these ‚Äústandard‚Äù terminals and messages also differs ‚Äì the US follows its JMTOP (CJCSM 6120.01), while NATO follows ADAP-16.  There are differences in the operating procedures that are widely recognized, but until now have been accommodated with work-around procedures [Hura 2003].The problems with message exist at three levels.  The first level is information loss.  When one message format is translated to another, there formats are not equally expressive ‚Äì which is why new standards evolve (to accommodate new needs for additional expressivity).  Going from a more expressive transmitting system ST to a less expressive receiving system, SR, will result in information loss, and SR having an incomplete view of what was intended by ST.ST(i + j) ‚Üí x ‚Üí SR(i)?? ST(j)   [what happens to ST(j)]The second level of problem is one of data insufficiency.  If a receiving system SR is expecting a sufficiently rich set of data (i + j) with which to interpret into the information it is designed to operate on, and the transmitting system ST that is sending the data interprets it from a less expressive (smaller) interpreted view (i), then we see the problem of going from a less expressive transmitting system ST to a more expressive receiving system SR will result in undesired assumptions made in the information interpreted by SR.ST(i) ‚Üí x ‚Üí SR(i + j)?? SR(j)   [where does SR(j) come from]The third problem is with the nature of the messages themselves.  This problem, which is the problem of messages being semantically too complex for the receiving system., is often solved (or proposed to be solved) by employing one or more language techniques (this is the research that leads to standards such as C-BML, and MSDL).  In adopting a language based approach to bring the richer semantics of a message to a semantically simpler receiving system, a systems architect must be careful to avoid introducing either the type one or type two problems introduced earlier in this section.  More on the language problem, in general, is discussed in section  PAGEREF _Ref172706318 \h 5 below.Disjoint Patterns ‚Äì Formal LanguageFormal Languages, the third of our example methods for interoperability, is a name given to a number of techniques of data linguistics ‚Äì where rule sets are used as to interpret the structure of an exchanged statement, and the valuation of the terms in that statement.  This is very popular in several current SISO standards development groups.  The potential for disjoint meaning between the transmitting and receiving systems is here amplified from the previous two cases due to not only potentially disjoint meaning of terms, as well as potentially disjoint meaning of statements (meaning-added collections of terms), but the new amplifying dimension that the valuation of the terms within the statement must first be determined.  The rules of the languages grammar must be applied to determine what role in a statement the individual term plays, and then what it means, and in turn, what the entire statement means.The means to communicate an idea is handled via language.  For mathematics or computer science, a formal language is defined as a finite set of symbols (A) that can be collected together into a set of statements (F).  Mathematically, a language (L) is an unordered set [R√©v√©sz 1991]:L = {A,F}If a transmitter and receiver (speaker, listener; writer, reader; etc) each share the same language elements, as well as an understanding of the rules for forming F from A, then communication can occur.  Depending on the particular language theory subscribes to; the set of rules can be some system of logic, a grammar, rigid structure, or some other method.  The method does not necessarily have to be absolute; it can be probabilistic or contextually contingent.  In any case where there is either an incomplete understanding of the rules for building or interpreting statements from F (built out of elements from A), then there is some chance for ambiguity in how the receiver interprets the statement from F.If we take the capability of some specification of L to be a production function, Lp(), and then have the desired expression of the transmitting system, ST(i) as the input to that function, we will get a statement x found in F as the product of the function.Lp( ST(i) ) = FxFx is then transmitted to the receiving system SR.  For SR to interpret Fx, it must have access to a consumption function, Lc, also based in the specification of L‚Äôs capability.  The input to that consumption function will be Fx, and the output will be the interpretation of Fx into information that SR can use.Lc( Fx ) = SR(i)This is an important point for interoperability in general, and especially for efforts within SISO, as well as efforts made in support of Net-Centric Operations.  For a system to communicate with another system, it must have some intention of passing information.  It interprets (as we have seen, above) that information into data, which can be shared.  A language covers the means for performing that interpretation, as well as governing the format that the transmitted data will be in.  Having decided that it is necessary to share information, a system relying on a language method, builds a statement from F.  This is the process of interpretation (as in the earlier examples with Messaging and Object Models).  With a language, that process is controlled by construction rules (grammar, logic, etc).  Once the transmitting system, following the construction rules, forms a statement (Fx), it then grants control over its interpretation to the receiving system.  For language to work, it must be understood by the communicating community, so the receiving system must be aware of the construction rules.  If this is the case, then the receiving system can take the statement Fx, and turn it from transmitted data, back into interpreted information [Kate 2005].There are two possible problems with a language method.  The first of these is when the implementation of the particular language method in the transmitting system and the receiving system are out of harmony with each other.  If this is the case, regardless of how well documented or rigid the language method is, there will be some misinterpretation of information either into our out of the language ‚Äì and proper exchange of information between the communicating systems will not take place.  This problem is addressed below, in section 6.The second possible problem is when the language method itself is imprecise.  In this case, there is some non-deterministic technique involved in either formulating the statements from F out of A, or in interpreting statements of F back into intended meaning.  In this case, no matter what the original intended message from the transmitting system, once it is given to the receiving system, the means for interpreting that message back into information from data are based on a method that, by design, allows for ambiguity.Both of these problems are present in every day communication between people ‚Äì however people are not systems.  A person can intuit meaning, and human beings are particularly good at interpreting meaning from context.  Natural language communicators (human beings) have at their disposal a number of techniques and adaptations that allow for the distilling of meaning out of poorly formed communications, and in cases where there is a linguistic heterogeneity between speaker and listener.  None of these things are presently available for automated systems to rely upon.Many of the non-deterministic techniques that can be employed as part of a language based method have to do with the imprecise use of words, especially when there is a context implied.  As an example of this, in natural language terms, consider the following statement:Richard decided to sign up for the contest on Saturday.The use of the modifier ‚Äúon Saturday‚Äù could apply to any of (1) when Richard made the decision, (2) when Richard intended to sign up, or (3) when the contest was to occur.  The receiver of that statement does not now which of these three are intended by the transmitter.  Psychology tells us that most people hearing such a statement will associate the modifier (‚Äúon Friday‚Äù) with the portion of the statement it is mentioned nearest to (in this case, when ‚Äúthe contest‚Äù will take place) [Russell 2002].  This, of course, is not a firm rule, and in fact any intended meaning is permissible within the grammar rules of the language.  If a computer system were programmed to make decisions about where to apply the modifier, in such a case, it might have a probability that the modifier applies to the third portion of (as an example) 60%, and then 20% each for the first two portions. From this example, we can see that no matter how the transmitting system intended to apply the statements modifier, the receiving system will follow the non-deterministic grammar rules when interpreting the statement into information.  If the wrong choice is made by the receiving system, then the information it interprets will be wrong (out of harmony with what was intended by the transmitting system).  This example may, because of the nature of the statement, appear to be of minor consequence.  Consider, however, a C2 statement issuing a task as part of an order to some automated forces (robotic vehicle, drone, automated sensor, etc).  If the issued statement is Support Task Force Hermes, which is scouting, in advance of the general attack at 2100Z, in zone 27.If a non-deterministic grammar method is going to be relied upon to ferret out what is meant by such a statement, the possibility for misinterpretation is readily seen to be quite large.  Again, we have several sub phrases, and a modifier (‚Äúin zone 27‚Äù).  Where does the modifier belong?  Is the support supposed to take place in zone 27?  Is the support only for the portions of Hermes that are within zone 27?  Is there a general scouting effort, and only the effort in zone 27 is supposed to be supported?  Or does the statement refer to the general attack that will occur within zone 27?  A non-deterministic grammar will have to apply stochastic methods to (in effect) ‚Äúguess‚Äù.  Without a formal declaration in the statement as to which sub phrase this modifier belongs to, we can never be sure that a receiving system will be able to ‚Äúguess‚Äù correctly.  A possible solution is described in the next section, Interpreting Meaning.Interpreting MeaningThis section will discuss the interpretation of meaning.  It is premised in the fact that the terms and or statements of the data transferred between systems are defined in such a way that the meaning CAN be interpreted.  If that is the case, then the methods for accomplishing the interpretation are discussed here.As we have seen throughout our three sample cases of information interoperability between systems, there exist with any exchange of information from one system to another, two cases of interpretation.  The first takes place when the transmitting system, ST, interprets its intended meaning into data for transfer to another system.  This may be done by adhering to a community accepted object model, by adhering to a community accepted messaging system, or by adhering to a community accepted linguistic model.  In all three cases, what ST wants to transmit is interpreted from the state of information, into the state of data.  Next that data is transmitted, and is eventually accepted by the receiving system, SR.  Once SR has the data, it then performs the second interpretation, which is a chance to transform the data received into information that the system SR can make use of.  Again, this will be accomplished by following an interpretation method of an object model, a messaging system, or a language system.The next section, below, deals with the problems (and potential solutions for) representing meaning.  For now, we will assume that the meaning that the transmitting system, ST, intends is capable of being well represented.  If this is the case, then the problem of interpreting meaning centers on having a clear, deterministic manner in which everything that is part of a transmitted statement can be interpreted in only one (unambiguous) way.  In the case of an object model, how the transmitted object elements will be used must be clear and agreed to by the community.  This will alleviate the problem of non-aligned internal processing of objects leading to a non-harmonized understanding of the objects within a system-of-systems.  As all systems likely to be used within a future net-centric environment cannot be expected to be either documented or accessible by developers for that environment, something expressively equivalent to what is suggested within the OWL-S community is required [Benbernou 2005].  This, OWL-S, states that a clear statement is made by each service (in our case, each method for input or output from a system, either ST or SR) which determines the nature of all data accepted as input, produced as output, and the internal processes that will affect that data.  In this way, if accessing systems have access to this statement, then selective acceptance can be based on expecting known processes to operate on exchanged data, in predictable methods.In the case of messaging services, interpretations performed by the receiving system SR, should have access to some statement as to the expectations and limitations of the transmitting system that produced the statement received.  This can, again, be provided for by a system that is expressively as strong as the one predicted by the OWL-S community [Kaviani 2006].  If the output of ST is known, meaning that its constraints and intents are accepted by SR, then interpreting meaning can occur without error arising from ambiguity or incompleteness.In the case of a language, interpreting meaning is achieved by having one deterministic method for assembling and disassembling the statement.  Where the precise nature of the statement must be interpreted by SR exactly as ST intended, there can be no room for error introduced by non-deterministic methods.Representing MeaningThe previous section discussed what is required to interpret meaning, but it was assumed that terms and statements would be exchanged that could be interpreted.  This section describes what is required to exchange not terms, but meaning.The representation of meaning, whether as objects in an object model, comprising elements of a message, or members of A that become elements of F from some language L, must be clear and unambiguous.  As we have seen in the preceding section, the interpretation of meaning assumes that it understands clearly the meaning of the elements it accepts as input.Elements of representation that will be used to form interoperability supporting statements are symbols for what the system intends, in its interpretation of information into data.  The system operates on some information, and exchanged data that (hopefully) will be understood by some other system as representing what is intended.  This is described very well by the theory of semiotics, where a symbol represents some concept, and that concept is representative of some referent [Ogden 1923].  If this chain is correctly constructed, then the symbol represents the referent very well.  If the chain is weak, then the representation is disjoint from what is intended.The difficulty with symbols is that there can be heterogeneity introduced in the interpretation of what the symbol stands for (this is one potential weakness in the semiotics chain).  If, however, the symbols that are employed are basic enough, and non-complex enough, so that they can represent a simple, primitive, idea that the community of use has universal acceptance of, and universal understanding of, then the chance for the semiotic chain to be broken is reduced considerably.As mentioned in the previous section, there is an assumption that the elements of exchange will be represented in an unambiguous fashion.  In that section, it was also seen as a method of interpreting meaning, that some statement describing the internal processes of the producing or consuming system would be described.  That statement describing a system must also be reducible to primitive elements of description, if there is to be any unambiguous understanding of what a system is to do with exchanged elements.The Way AheadIf the solutions for the problems in representing meaning and in interpreting meaning are followed, then this will have the impact on systems that exchanged data elements are comprised of unambiguous atomic elements, and that all methods for producing and consuming such data, as well as the assumptions present in the interpretation from information to data, as well as from data to information, will be stated for systems to understand and base connectivity path choices on.  In shorter terms, all information exchange between systems will be done by using unambiguous atomic elements.This may not necessarily mean throwing out all of the current generation of systems for C2 and Simulation, but if applied properly, it will require the description of the assumptions followed within systems.  It is realized that this is not necessarily a feasible task (given the number of systems, the sensitivity of the data and processes involved, and the heterogeneous nature of the maintaining bodies of those systems and data), however, a path towards the final goal can be taken, and this will involve exposing the apparent meaning of the system, especially where the information to be exchanged is concerned.  If at all possible, this means understanding how the data is to be used, and the specific assumptions and meaning of the data within the system.The difference between what a system intends to represent, and how that representation can be interpreted, can occur in (grossly) three different ways.  These (as illustrated in the body of the paper) are:Mismatch of TermsMismatch of Statements (composed of terms)Mismatch of PatternsThe reason for these mismatches is quite simple, once reduced to a single cause.  The transmitting system has no influence over how the receiving system interprets the (1) terms, (2) composition of statements, or (3) the ordering of statements.  It is believed that if a set of terms that all parties can agree to exists [Lepore 2006], then the expression of meaning is possible, with some surety on the part of the transmitter that the intended value of the transmission will be qualitatively understood by the receiver.As we have seen, the data exchanged is often referred by terms, and not by meaning.  If there is to be a chance to express an unambiguous level of interoperability between systems, then the exchange of meaning will have to be attained.Ongoing research at VMASC in the area of primitives of meaning, which is one proposed method of capturing (for a domain) the universally accepted terms of meaning that will satisfy the above requirement, will be reported on to future SISO workshops.ReferencesBenbernou, S., Hacid, M. ‚ÄúResolution and Constraint Propagation for Semantic Web Services Discover.‚Äù Distributed and Parallel Databases, Vol. 18 No. 1.  pp. 65-81. July 2005.DISA, Net Centric Enterprise Services Users Guide, Net Centric Enterprise Services Website,  HYPERLINK "http://www.disa.mil/nces/NCES_UG_Final_v1_1.pdf" http://www.disa.mil/nces/NCES_UG_Final_v1_1.pdf last visited August, 2007.Hura, M., and others. Interoperability: A Continuing Challenge in Coalition Air Operations, Rand Corporation, 2003.IEEE Standard 1516-2000, Standard for Modeling and Simulation High Level Architecture, 2000.Kate, R., Wong, Y., Mooney, R. ‚ÄúLearning to Transform Natural to Formal Languages.‚Äù 2005 AAAI Conference, July 2005.Kaviani, N., Gasevic, D., Hatala, M., Clement, D., Wagner, G. ‚ÄúTowards Unifying Rules and Policies for Semantic Web Services.‚Äù  3rd Annual Lornet Conference, Montreal, November, 2006.Lepore, E., and Ludwig, K. ‚ÄúOntology in the Theory of Meaning.‚Äù International Journal of Philosophical Studies, Vol 14(3), pp.325-335. 2006.Ogden, C.K., and Richards, I.A. The Meaning of Meaning: A Study of the Influence of Language upon Thought and of the Science of Symbolism, University of Cambridge, 1923.St. Peter, M.A. A comparative analysis of air-to-ground engagement outcomes in the joint warfare system (JWARS) and the JWARS ‚Äì joint semi-automated forces (JSAF) federation, Old Dominion University, 2006R√©v√©sz, G.E. Introduction to formal languages, Dover Publications, 1991Russell, S.J., Norvig, P. Artificial Intelligence: A Modern Approach (2nd Edition), Prentice Hall, 2002Stewart, F.M.  ‚ÄúFORCENet Net Centric Architecture ‚Äì A Standards View.‚Äù  2006 Command and Control Research and Technology Symposium, San Diego, June 2006Turnitsa, C., and Tolk, A. ‚ÄúWith All Your Knowing, Get Understanding: Conceptual Interoperability and the Net-Centric Value Chain.‚Äù  2006 Command and Control Research and Technology Symposium, San Diego, June 2006.Authors' BiographiesANDREAS TOLK is Associate Professor in the Faculty for Modeling, Simulation, and Visualization at the Engineering Management Department of the College of Engineering and Technology at Old   Dominion University (ODU) of Norfolk, Virginia.  He has over 16 years of international experience in the field of Applied Military Operations Research and Modeling and Simulation of and for Command and Control Systems.  He is affiliated with the Virginia Modeling Analysis & Simulation Center (VMASC).  His domain of expertise is the integration of M&S functionality into real world applications based on open standards.  He received a Ph.D. (1995) and an M.S. (1988) in Computer Science from the University of the Federal Armed Forces in Munich, Germany.CHARLES D. TURNITSA is a Ph.D. candidate at the Virginia Modeling Analysis and Simulation Center (VMASC) of the Old Dominion University (ODU).  He received his B.S. in Computer Science (1991) from Christopher Newport University (Newport News, Virginia), and his M.S. in Modeling & Simulation (2006) from ODU.  His Ph.D. research under Tolk focuses on the domain of dynamic and fractal ontology models for M&S interoperability.SAIKOU DIALLO is a Ph.D. candidate at the Virginia Modeling Analysis and Simulation Center (VMASC) of the Old Dominion University (ODU).  He received his M.S. in Modeling & Simulation (2006) from ODU.  His Ph.D. research under Tolk focuses on generative grammars and model based data engineering for M&S interoperability. EMBED PowerPoint.Show.8   EMBED PowerPoint.Show.8  Figure  SEQ Figure \* ARABIC 3 - Non-Deterministic Grammar RulesFigure  SEQ Figure \* ARABIC 1 - Semiotic Triangle for Systems InteroperabilityFigure  SEQ Figure \* ARABIC 2 - Federate Mismatch EMBED PowerPoint.Show.8  