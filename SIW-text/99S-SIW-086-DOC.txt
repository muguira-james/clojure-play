Radiometric Validation of the Cloud Scene Simulation ModelJoel B. MozerGuy SeeleySara C. GordonSusan A. TriantafillouAir Force Research Laboratory, VSBE29 Randolph RoadHanscom Air Force Base, MA 01731-3010 mozer@hurricane.plh.af.mil, seeley@hurricane.plh.af.mil, gordon@hurricane.plh.afl.mil,  susan@hurricane.plh.af.milKeywords:CSSM, clouds, IR scene, natural environmentABSTRACT:  The Air Force Cloud Scene Simulation Model generates high-fidelity cloud liquid water content fields in four dimensions that can be visualized to produce realistic two-dimensional synthetic images of clouds in the visible and infrared spectrum (8 - 12 microns) suitable for use in simulation.  We provide a quantitative comparison between imagery based on CSSM output and actual imagery of clouds taken from ground based sensors operating in those wavelengths.  A field experiment was held 27 April to 1 May, 1998 at Hanscom AFB to provide data for this comparison.  A test site with full meteorological instrumentation, balloon radiosonde launches, and TPQ-11 cloud-profiling radar provided input data for the CSSM.  A visible band spectraradiometer was used for radiometrically accurate imagery collection of the clouds over the experiment site The spectraradiometer imagery was classified, by meteorologists, according to cirriform, cumuliform and stratiform cloud types.  Synthetic cloud scenes, which were heuristically consistent with the observed clouds and other meteorological conditions, were produced using the CSSM for each of the three cloud types.  A set of candidate image-based metrics were computed for both the real and synthetic imagery.  A Multiple Discriminant Analysis (MDA) was performed on both sets of data to determine which of the candidate metrics were most effective for objectively discriminating among the three cloud types.  This technique will be extended in 1999 to include the 3-5 micron range in the infrared spectrum.  The technique will be combined with atmospheric transmission models and used to construct tables of lines of sight and lock-on probabilities for sensors operating in the visible and infrared (3-5, 8-12 micron) spectrum.  The results will be compiled using anticipated operating altitudes and standard tactics employing the sensors, and the algorithm to produce the tables will be made available for development of tables for additional sensors.  In this paper, we present the spectraradiometer imagery, the metrics, and the results of the MDA used in the current analysisIntroductionSynthetic natural environments are an increasingly important component of high-fidelity models and simulations of DoD systems and operations.  Atmospheric clouds are a crucial component in many simulations where missions occur in or through the  atmosphere, such as with an airborne or spaceborne weapon or surveillance sensor.  Despite their importance, clouds are often neglected in such simulations because of the extreme complexity and general lack of understanding of the physical phenomena involved.Accurate modeling of clouds and cloud-related effects involves the understanding of a broad range of physical processes and their interactions.  Over broad geographic areas, the problem of representing clouds is intimately coupled to the large-scale dynamics of the atmosphere.  At the opposite end of the spatial spectrum where the fine-scale features of the cloud are important, a detailed knowledge of the microphysical composition of the cloud is needed.  This is a complex situation involving knowledge of aerosols, cloud chemistry and ice physics.  Closely related to this are the optical properties of clouds, the radiative interactions between clouds and various natural and artificial illumination sources across the spectrum from radio frequencies to longwave infrared.The present study addresses the problems of modeling cloud composition and optical properties by integrating two Air Force modeling tools.  The Cloud Scene Simulation Model (CSSM), an existing high-fidelity cloud simulation model, was coupled with the Infrared Target Scene Simulation Software (IRTSS) to produce quantitative radiometric cloud scenes.  The IRTSS is capable of producing high-resolution scenes in both the visible and 8-12 micron IR wavebands. It uses a combination of OpenGL volume rendering and simple ray tracing on three-dimensional optical properties fields to produce radiometric cloud imagery.CSSM BackgroundThe CSSM was developed by The Analytical Sciences Corporation (TASC, Inc.) for the Air Force Research Laboratory to produce realistic, spatially and temporally varying cloud fields at high resolution for the simulation of cloud effects on DoD operations and systems.  The CSSM generates three-dimensional synthetic fields of cloud liquid water content.  The CSSM is based on empirical fractal techniques coupled with cloud macrophysical models that utilize information regarding the ambient meteorological conditions.  The free parameters of the CSSM core algorithms have been chosen based on extensive investigation of the statistics of cloud liquid and ice water content in real clouds [1], [2].The core algorithms of the CSSM are based on the fractal Rescale and Add (RSA) method [3].  This algorithm relies on a multidimensional array of random numbers, which can be produced using a random number seed.  From the random number array the RSA method generates a multidimensional lattice of values that possesses inherent fractal structure as a function of lattice position.  A number of parameters determines the behavior of the function.  These parameters include the lattice resolution, summation limits, lacunarity, and Hurst parameter, which may be assigned different values for different cloud genres and different directions.  The different directions refer to the three spatial directions and time.  In addition, the fractal algorithm is applied in three ways, to obtain the horizontal cloud distribution (and cloud top), the cloud base, and the internal water content.  Therefore a total of 48 parameter values control the behavior of the RSA algorithm for each cloud genre.ApproachSynthetic-cloud scenes were compared to real-cloud scenes using a set of image metrics selected for their capabilities to quantify properties relevant to cloud scenes.  Metrics were selected with the use of a multiple discriminant analysis (MDA).  Selected free parameters of the CSSM were tuned to improve the agreement between the real- and synthetic-cloud scenes.The process used to arrive at a more radiometrically realistic CSSM could be applied using any set of real-cloud scenes.  Thus, the methodology developed for the current study can be used to tune the CSSM to specific sensor systems, based on statistics-derived sensor imagery.  Follow-on work will include producing cloud-related probability tables for aggregate simulations.Research MethodsThe research was carried out in four steps.  Real-cloud scenes were collected for use as a basis of measuring synthetic-cloud scenes.  Metrics were studied and selected for their capabilities to capture the relevant cloud properties in the real-cloud scenes.  Synthetic-cloud scenes were generated using the CSSM and IRTSS.  These synthetic scenes were quantified by the metrics and the CSSM was tuned to obtain better agreement between the metrics due to the real and synthetic scenes.Field Data CollectionImages were collected using a Real-Time Imaging SpectroRadiometer (RTISR) built by Surface Optics Corporation of San Diego, California for the Army Research Laboratory. The RTISR collects a cube of radiometrically and spectrally calibrated images at an update rate dependent on the ambient light level up to a maximum of 15Hz. The RTISR uses a zoom lens and a retractable tele-extender lens to provide fields-of-view of 29(x22( down to 1.9(x1.4(. The collected light then passes through a circular variable filter spanning the range of 390nm to 950nm over which 20 or 30 images may be collected per image cube [4].Data were acquired were from 27 April through 01 May 1998. The image cubes consisted of sets of 20 images collected at 16nm intervals over a wavelength range of 396nm to 700nm. The update rate depended on the ambient light conditions but was typically 1Hz. This relatively slow update rate was not significant for the data collected. Horizontal views of the sky, clouds, and the horizon were collected with a field-of-view of 29(x22(. Images of the ground targets were collected with a field-of-view of 14.5(x11(.Since the images were rectangular and extended below the horizon, a 128x128 pixel region was cropped out of each image.  This resulted in two sets of 73 images, one in the near ultraviolet wavelength range (396 nm) and one at the red end of the visible range (684 nm). Selecting Image MetricsA large number of image-based calculation methods was considered in choosing cloud image metrics.  The metrics, based on image analysis techniques from Parker [5], Laws [6], and Wilks [7], can be grouped according to the mathematical tools used.  Several metrics were based on coefficients of a fast Fourier transform (FFT).  Fractal dimension was also considered as a metric.  This is a measure of the degree to which an image is self similar (contains smaller copies of itself).  The remaining metrics use a convolution process to enhance selected image features.  The pixel values in the resulting convolved image are combined into a single value that defines the metric.Metrics that rely on a convolution process include energy metrics, wavelet metrics, and the metrics based on a grey level co-occurrence matrix (GLCM).  The energy metrics are found by combining values of all the pixels in an image that has been convolved with a kernel designed to detect edges, levels, or ripples.  The wavelet metrics are based on a Daubechies wavelet transform and reflect the energy at different spatial scales in the image.  A GLCM image stores the results of comparing pairs of pixels separated by a given number of pixels.  The GLCM metrics quantify different properties of the resulting GLCM image.Metric values for real clouds were studied to identify the most useful metrics from among those considered.  The selection criterion was that a good metric be capable of distinguishing between cloud types.  No single metric was expected to capture the complicated textural differences between cloud images.  Therefore, the goal was to identify a small number of metrics that could be used in combination to measure cloud images.  A  multiple discriminant analysis (MDA) was used as a tool to objectively evaluate groups of metrics.  We employed an MDA method using the DSCRM function from the IMSL libraries by Visual Numerics, Houston TX.Each of the real-cloud images collected was classified by a meteorologist as cirrus, cumulus, stratus, or clear sky.  Then the MDA was implemented to classify the images using a given group of metrics.  The metric groups were judged in terms of the percentage of images correctly identified.Using the MDA, the following metric combination was selected: summation of angles of pixels, E5L5, FFT, and skewness of GLCM.  The summation of the angles of edge pixels metric uses two 3x3 convolution masks to measure the magnitudes of the horizontal and vertical edge components for each pixel in the image.  The angle of the edge at the pixel is the arctangent of the ratio of the two components.  The metric value is the sum of these edge angles for all pixels.  The E5L5 metric is an energy metric based on a 5x5 convolution kernel designed to detect edges and levels.  The FFT metric is found by combining selected FFT coefficients from the low frequency range.  The skewness metric is a measure of deviation from the mean in a GLCM image.  Note the four metrics quantify different characteristics of cloud images, namely, edge features, low frequency content, and spatially independent grey level features.The four metrics correctly classified 88% of the 684 nm images and 82% of the 396 nm images. If these two sets are combined into one set containing 146 images, this metric combination correctly classified 76% of the images.Image ConstructionSynthetic cloud images were produced using the CSSM and the AFRL Weather Impact Decision Aids (WIDA) program's Infrared Target Scene Simulation Software (IRTSS).  The three-dimensional grids of liquid water content generated by the CSSM were transformed into grids of extinction coefficient data using the Fastmap [1] optical properties tool. Fastmap uses look up tables that map cloud type and liquid water content to optical and graphical quantities. Once the transformation of the data to extinction coefficient has taken place, rays are traced from each grid cell to the sun. The aggregate optical depth is computed and the direct solar beam is attenuated according using Beer's Law. The resulting field is then volume rendered using OpenGL texture mapping facilities. There is no treatment of diffuse sky radiation. 512x512 pixel images in the visible band were generated with a view vector looking vertically up into the generated cloud deck. The images had a resolution of approximately 9.75 meters/pixel. CSSM TuningA single cloud type was used for CSSM tuning and the number of fractal parameters that were subject to independent adjustment was reduced from 48 to six.  This was done by limiting parameter type, and independence of different directions.   By varying each of the six remaining parameters individually, the sensitivities of the radiometric properties of synthetic clouds to these parameters could be observed.  To assess sensitivity, an error was defined to measure discrepancies between the metric values of real and synthetic clouds.  CSSM tuning was accomplished by comparing the errors associated with different fractal parameters so that error-reducing parameter values could be identified.Synthetic stratocumulus clouds were generated by the CSSM for comparison to real cumulus clouds.  The reason for choosing CSSM stratocumulus clouds rather than CSSM cumulus clouds stems from the fact that the cumulus cloud generation is a special case of the CSSM that uses a parcel method to produce internal water content.  Since stratocumulus clouds are physically similar to cumulus clouds and the CSSM stratocumulus computations rely more directly on the RSA than the CSSM cumulus computations, CSSM stratocumulus clouds were chosen.  The developers of CSSM reported that two “key” parameters, the Hurst parameter and the lattice resolution, cloud be used to “control  the character of the resulting cloud field” [1].  Therefore, these parameters were under primary consideration for the current study.  The effect of lacunarity was also explored.  To further reduce the number of  parameters to be adjusted, the different directions were handled by making experimental changes to all directions simultaneously by a single factor.Wide ranges of values were chosen for experiments with each parameter.  This choice was made in order to get some experience with the sensitivity of radiometric values to parameter values.  Specific values are shown in the table below.  Values given are for the horizontal components of the fractal algorithm and values in bold are the original parameter values.  Note that setting the lacunarity to 1.0 is useful for this sensitivity study but is not a sensible choice for other purposes.  The reason for this can be seen in the details of the fractal algorithm, which are given in [8].Internal Hurst parameter0.15, 0.3, 0.6, 0.75, 0.9Internal lattice resolution0.3. 0.6, 1.0, 3.0 9.0Internal lacunarity1.0, 2.0, 3.0, 6.0, 9.0Horizontal Hurst parameter0.15, 0.3, 0.6, 0.75, 0.9Horizontal lattice resolution2.0, 4.0, 6.0, 9.0, 12.0Horizontal lacunarity1.0, 2.0, 3.0, 6.0, 9.0Experimental stratocumulus parameter valuesFor each collection of real clouds under consideration a measure of error was defined based on the best three-metric combination for the given collection.  For each metric i a mean (i and standard deviation (i among the real clouds was found.  These quantities were used to compute a measure of error for the given metric and synthetic cloud.  For example, the error in the metric si for a given synthetic cloud is (si - (I)/ (i.  The overall error for a synthetic cloud was defined as the L2 norm of the errors due to the selected metrics.  The standard deviation in the synthetic-cloud errors was considered when comparing error values.An outcome of comparing synthetic and real clouds was that errors did not change significantly with variations in the internal fractal parameters (that is, internal Hurst parameter, internal lacunarity, and internal lattice resolution).  Changes in horizontal parameters, on the other hand, did produce changes in errors that were significant relative to the standard deviations among the errors.As the horizontal Hurst parameter is increased, the error decreases.  By changing the horizontal Hurst parameter from 0.3 to 0.9 a 24 - 44% reduction in error is realized (depending on which real-cloud collection is used to measure error in synthetic clouds).  The results of experiments with the horizontal lattice resolution weakly suggest that an error reduction may be realized by increasing this parameter value.  While the average of the synthetic cloud errors showed this error reduction trend, the standard deviation among the errors was nearly as large as the trend.  Error can be reduced by decreasing the lacunarity value.  Setting the lacunarity to 2.0, instead of 3.0, lowers the error by 11 - 36%.  When the three error-reducing parameter changes were made together the error reduction was greater than could be achieved by changing any of the parameters individually.  Therefore, the new recommended parameter values were horizontal Hurst parameter = 0.9, horizontal lattice resolution = 12.0, and horizontal lacunarity = 2.0.In summary, when the fractal parameters were considered individually the error was most sensitive to the horizontal Hurst parameter and the horizontal lacunarity.  It was interesting to note that increasing the horizontal Hurst parameter and decreasing the horizontal lacunarity are both associated with not only reducing the error, but also with a smoothing of small-scale features without a significant change to large-scale features.  Increasing the horizontal lattice resolution, which is weakly associated with error reduction, also smooths small-scale variations.ConclusionsThe CSSM was tuned to generate clouds that are radiometrically realistic in terms of 396 and 684 nm images.  The methodology developed to achieve this is applicable to imagery from other sensors.  For a given sensor, the metric selection process would be repeated so that correct metric values could be established.  The chosen metrics would then be applied to CSSM imagery, determining the initial synthetic-cloud error.  Changes in this error due to adjusting individual CSSM parameters would be observed to select parameter changes that reduce error. The ability to construct radiometrically realistic and physically consistent synthetic scenes of the battlespace, including clouds is key to incorporating natural environment effects in constructive simulations.  We have begun a project that builds on the capability described in this paper to generate cloud-related stochastic data for use by such simulations.  Specifically, we are developing methodologies to generate probability-of-detection statistics for a given combination tactical target, weapon system, and mission constraints as a function of cloud parameters.  These cloud parameters will include cloud coverage, cloud altitude, and cloud type.The concept for this capability is that  a statistically representative set of simulated battlespace environment scenarios can be generated for a wide variety of cloud conditions using the (properly tuned) CSSM.  Simulated missions would be executed in these simulated environments using IRTSS technology developed in the present work, to generate through-the-sensor scenes, given sufficient information about the weapon sensor and other mission parameters.  After a large number of such simulated missions, the results will be presented in the form of aggregate cloud impact statistics for use in future aggregate simulations.  For example a statistical relationship between  the probability-of-detection of a theater ballistic missile by an Airborne Laser (ABL) and the percent sky coverage of cirrus clouds at the ABL operating altitude could be determined through this methodology.  This work is supported by the DoD Modeling and Simulation Executive Agent for Air and Space in FY99.References[1] Cianciolo, M. E., Raffensberger, M. E., Schmidt, E. O., and Stearns, J. R.: “Atmospheric scene simulation modeling and visualization” PL-TR-96-2079, TASC, Reading, MA, 1996.[2] Turkington, R. B., Cianciolo, M. E., and Raffensberger, M. E.: “Atmospheric scene simulation modeling and visualization”  TR-08607-1, TASC, Reading, MA, 1998.[3] Saupe, D.: “Point evaluation of multi-variable random fractals” Visualisierung in Mathematik and Naturwissenschaft, H. Jurgens and D. Saupe (eds.), Spring-Verlag, Heidelberg, 1989.[4] Gillespie, P., Rollins, M. and Tofsted, D.: “Evaluation of WAVES using image statistics”U. S. Army Research Laboratory, White Sands Missile Range, NM 1995.[5] Parker, J. R.: Algorithms for Image Processing and Computer Vision, John Wiley & Sons, Inc. 1997.[6] Laws, K. I.: “Textured Image Segmentation” Ph.D. thesis, U. Southern California, Los Angeles, CA 1980.[7] Wilks, D. S.: “Statistical Methods in the Atmospheric Sciences” Academic Press, Inc. 1995.[8] Cianciolo, M. E. and Rasmussen, R. G.: “Cloud scene simulation modeling, the enhanced model” PL-TR-92-2106, TASC, Reading, MA, 1992.