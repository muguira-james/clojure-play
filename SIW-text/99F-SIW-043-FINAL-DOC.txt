Dynamic Terrain: From Run-Time Modifications to Pre-Exercise TailoringDavid BakemanDr. Dale MillerDr. Steve AdelsonKent CaubleLockheed Martin Information SystemsAdvanced Simulation Center3605 132nd Ave SE, Suite 400Bellevue, WA 98006425-957-3214dbakeman, ddmiller, sadelson,  HYPERLINK mailto:kcauble@lads.is.lmco.com kcauble@lads.is.lmco.comSteve HaesTRW/BDMUS Army Topographic Engineering Center (TEC)7701 Telegraph RoadAlexandria, VA  22315-3864shaes@tec.army.milKeywords:Terrain Data Base, STOW, J9901J9901, ECN, shapefileShapeFiles, DTSimAbstract: The Synthetic Theater of War (STOW) virtual simulation systems are participating in USACOM's Joint Experiment 99 (J9901J9901), a discovery-oriented experiment for evaluation of future sensor and weapons systems (circa 2015) in defense of theater ballistic missiles.  . The STOW 97 Southwest Asia terrain database was selected as the venue for this experiment.  . While this data base has relatively large extents (5 by 7 degrees), it does not contain sufficiently many road networks, forested areas, or urban areas to support the requirements of the experiment, which requires for large numbers of commercial vehicles and opportunities for concealment from space and airborne sensors. The requirement was established to add thousands of kilometers of roads and tens of thousands of square kilometers of forest canopies and urban areas to the existing terrain data base. However, these features do not exist in the real world, and adding them to a terrain data base containing only geospecific features was contrary to the STOW data base paradigm. Moreover, production and compilation of the original data base was extremely time intensive, and replicating these activities for addition of these non-geospecific features would provide no technology advancements.  . Instead, the Dynamic Terrain and Objects (DTO) paradigm was selected for adding these new features during exercise initialization. However, the quantity of changes was massive as compared to the DTO changes previously used during either exercise initialization or at run time. The capability was added to the STOW DTO system to define the feature additions using a Geographic Information System (GIS), export them to a standard GIS format, and import them into the DTSim for distribution using Environmental Change Notices (ECN). Because of the massive number of changes, the distribution of the ECNs would have required many hours of initialization, and therefore the capability was developed for each run-time application (JointSAF, OpenScene, DTSim) to save its modified data base. These modified data bases were then distributed to all federates of the experiment. This development added considerable robustness to the STOW DTO capability, and stressed the STOW RTI by identifiying memory leaks (hundreds of megabytes) to implement these changes to the data base.J9901J9901 OverviewThe U.S. Atlantic Command (USACOM) is conducting its first modeling and simulation experiment dealing with attack operations against critical mobile targets.  . This experiment is known as J9901J9901.  . Critical mobile targets are defined, for this experiment, as theater ballistic missiles (TBMs), their launchers, known as transporter erector launchers (TELs) as well as their infrastructure, which includes refueling and re-arm sites.The experiment is focused on an operator's ability "to intuit the location of the critical TBM sites before launch" and identify not only the TEL itself, but also the storage sites.  . The weapons and sensors being used in the simulations are based on projected capabilities in 2015. Working with the intelligence community, academia and others, USACOM has tried to create databases of future weapons and sensors for both the red and blue forces.The test events are based on modeling and simulations using the Synthetic Theater of War (STOW) model developed by the Defense Advanced Research Projects Agency, and the Simulation of the Location and Attack of Mobile Enemy Missiles (SLAMEM) model, developed by Toyon Research Corp.STOW has been modified for this event to use various circa 2015 attack systems. The data on these projected future systems have been input into the STOW database to prosecute the attack against the critical mobile targets.The simulations feature one geographic area of operations the Persian Gulf region.  That area is being used due to the detailed terrain database the TEC already maintains.See [1] for additional details on J9901.Requirements For Massive Feature AdditionsThe Southwest Asia (SWA) theater has been selected for the J9901J9901 experiment. A terrain database, 500 km by 775 km in extent, already existeds and will bebecame the basis used for the experiment. The database spans a region of 5 degrees of longitude by 7 degrees of latitude (46 to 51 degrees east longitude, 25 degrees to 32 degrees north latitude). It contains all of Kuwait, southeastern Iraq, southwestern Iran, northeastern Saudi Arabia and the island country of Bahrain. The terrain ranges from mountainous in the northeast to low hills and sand dunes in the southwest. The SWA terrain also includes the northern portion of the Persian Gulf. In order to present a more varied terrain, the decision was made to construct a geotypical terrain database for the experiment. In addition, the experiment will dynamically add roads, urban areas and forests in otherwise arid areas.Urban AreasThe existing database contains a scattering of major urban areas; : Bahrain City, Dhahran, Kuwait City, Basrah, and Ahvaz.  . Geographically, all of these urban areas are within 150 km. of the coast. This concentration in a strip is caused of course by the inhospitable mountain terrain to the northeast and by the desert areas to the southwest. This distribution, however, can allow Blue to artificially concentrate their sensor tasking.  . In order to expand the distribution of possible urban operating areas, 7 additional areas were created at various locations.  . Each urban area consists of 3 different abstract representations:  : a small urban center which is impenetrable to all sensors, an intermediate urban center which degrades sensor detection by 70%, and an urban outskirt which degrades sensor detection by 30%.The total area contained within the added urban areas is 2,138.345 square kilometers.Forested AreasThe terrain is notable for its lack of vegetation. Therefore, two forested areas will were be added. The first extends from the boundaries of the Kuwait City urban area due west to 46 degree East longitude, the western boundary of the SWA terrain database. The forest will occupiesy from 28 degrees to 30 degrees North latitude. The forested area will provides a substantial maneuvering area for Red TM elements. The second forested area will merge with and abut the Zagros mountains in the northeast.  . There will beare periodic gaps or holes in these regions in which sensors will be able to detect vehicles that are in the open or on a road.  . Since there is no necessity to model individual trees or different densities of cover, forested areas will beare homogenous.The total area covered by the new forests is 47,583.6 square kilometers.Road DensitiesIn order to present a reasonable backdrop of traffic movements, the STOW99 team created additional roads.  . The Most of the original database contained only the roads from a 1:1,000,000 map product.  . The additional roads were added by digitizing the roads found on 1:500,000 map products.The increased road density was critical for creating realistic route alternatives for Red TM elements to move and blend in with other military and civilian background traffic.The total length of new roads added to the database is 5,267.44 kilometers. This incidentally amounts to a little more than a 17% increase in total road length for the entire database.DTO Architecture ReviewDynamic terrain (DT) technology development has provided the means to damage or destroy buildings and bridges, crater roads and runways, and emplace anti-tank ditches, vehicle survivability positions and infantry trenches. The challenges of supporting these environmental modeling capabilities in a distributed simulation environment were:‚Ä¢	Rreal-time operation,‚Ä¢	Arbitrating simultaneous changes to the terrain from multiple applications (e.g.e.g., bulldozer simulator and cratering munitions),‚Ä¢	Serializing changes,‚Ä¢	Communicating changes (abstractly and/or polygonally),‚Ä¢	Minimizing network bandwidth requirements, and‚Ä¢	Addressing the needs of a large scale distributed simulation on an arbitrary TIN terrain surface.The solution is based on communicating DT changes via an interaction called an Environmental Change Notice (ECN), which contains all necessary state and feature and polygonal change information. Separate applications assess the collateral effects of warfighter activities (or internal environmental dynamics), modeling the consequences and requesting the indicated changes via ECNs. An application known as the DT Scribe arbitrates and serializes requested changes. In effect, the DT Scribe is the owner of the terrain "object" of which multiple DT simulations can request state changes. Each federate (e.g.e.g., JointSAF, OpenScene ModStealth, DT SimDTSim) includes a DT Agent which then integrates each change into its client's run-time data base in real-time. Run-time induced changes to the terrain surface and cultural features are thus managed, peer-to-peer, in a distributed manner (as illustrated below).The DT Architecture has the following essential components (see Figure 1):Full distribution of the capability to describe changes, called Environmental Change Notices (ECNs), to the world. The Obstacle Editor/JointSAF, crewed simulators, and DT Simulator are examples of applications creating ECNs. ECN generation requires that all share the same geometry of the world or that the DT Rrepolygonization Sservice be used.Dynamic Terrain Simulators (DT SimDTSim) may serve several purposes. One may provide modeling of global weather effects on the terrain. Another may determine collateral damage to structures, while yet another DT Simulator may simulate the repair of DT events such as runway craters.A Dynamic Terrain Scribe (DT Scribe) orders, records, and distributes all changes to all appropriate DT Agents, and provides for reliability mechanisms and logging of DT events.Dynamic Terrain Agents (DT Agents) at each interested simulator convert the ECNs from the DT Scribe to the local run-time data base format.Dynamic Terrain Repolygonization (DT Repoly) service converts high-level parameterized ECNs into ECNs containing specific data for all potential DT Agents (i.e.i.e., ECNs that contain complete geometry and attribution for all data bases being modified by DT Agents).The Dynamic Terrain Data Base (DTDB) provides an authoritative representation of the synthetic environment for terrain changes. The DTDB is used by the DT Repoly service and the DT SimDTSim to make DT changes.The distributed DT Architecture incorporating the essential components is shown in Figure 1. All DT changes are created by peers. Although changes refer to different types of events, cover different geographical extents, and may be created and updated at different rates, no change directly takes priority over another, either for distribution over the network or for inclusion in the run-time database of any module. Changes are accepted or rejected by the scribe using a sequencing mechanism, which will accepts the first change received and assigns a world state sequence number for the change. As long as a change contains the proper sequence number indicating it is derived from the current state of the world, it will be accepted, and the sequence number will be incremented.The ECN API describes both a set of ANSI C functions to send and receive ECNs and a set of ANSI C data structures which describe all of the currently implemented ECN data abstractions. To facilitate the sending of ECNs, the API provides functions, which allow an application to create and populate an ECN of unrestricted size. When the ECN API function to send an ECN is called, code in the API breaks up ECNs into the appropriate size for the communications infrastructure (e.g.e.g., limited by maximal PDU length in DIS; see Figure 2) and generates the appropriate header information, including all of the information required by the DT Sscribe. Subsequently when an ECN is received, the ECN API, in conjunction with the DT Agent API, verifies that the ECN in question was received in the proper order and extracts each of the ECN abstractions, assembling any fragments as necessary. The ECN API, however, does not fill in any of the data in the actual ECN. This data must be provided by the application making the ECN request. This means that an application, which wishes to make changes, which contain attributes not supported by its own local environmental data, must make use of the DTDB. (Conversely this also means that any application which contains in its own local environmental data all of the required information needed to implement the an ECNs it wants to send may send that ECN without using the DTDB.)EMBED Word.Picture.8	Figure 2: ECN fragmentationUse of GIS for Definition of New FeaturesIn order to minimize development, a commercial software tool capable of editing and formatting geographical information was needed. The ArcView¬Æ GIS(Geographical Information System) (GIS) tool met these requirements and was available. ArcView is a popular GIS tool with more than 200,000 users worldwide. ArcView is designed to manage, display, query, and analyze spatial information.One of the main formats of data used by ArcView are is the shapefileShapeFiles.  . A shapefileShapeFile stores nontopological geometry and attribute information for the spatial features in a data set. The geometry for a feature is stored as a shape comprising a set of vector coordinates.  . Because shapefileShapeFiles do not have the processing overhead of a topological data structure, they have advantages over other data sources such as faster drawing speed and edit ability. ShapefileShapeFiles handle single features that overlap or that are noncontiguous. They also typically require less disk space and are easier to read and write than formats containing topology.  . ShapefileShapeFiles can support point, line, and area features. Area features are represented as closed loop, double-digitized polygons. Attributes are held in a dBASE  format file.  . Each attribute record has a one-to-one relationship with the associated shape record.An ESRI shapefileShapeFile consists of a main file, an index file, and a dBASE table.  . The main file is a direct access, variable-record-length file in which each record describes a shape with a list of its vertices. In the index file, each record contains the offset of the corresponding main file record from the beginning of the main file. The dBASE table contains feature attributes with one record per feature. The one-to-one relationship between geometry and attributes is based on record number.  . Attribute records in the dBASE file must be in the same order as records in the main file.In order to provide a reference framework for creating the desired additional features for j9901J9901, shapefileShapeFiles were needed for the existing cultural features.  . The fFollowing is a description of the steps that were required to create the shapefileShapeFiles.The STOW UE-98-1 database roads are a fusion of Interim Terrain Data ITD (ITDInterim Terrain Data), Planning Interim Terrain Data (PITD) Preliminary Interim Terrain Data) and Digital Chart of the World (DCW) (Digital Chart of the World) products. The fused roads were extracted from the S1000 Global Coordinate System (GCS) (Global Coordinate System) database using the S1000 API sample program. The resulting text file contained vertex locations in Lat/Longgeodetic coordinates and attribution for road width, texture idID, Simnet mobility type and a attribute index number.  . The text file was then run through Unix awk scripts to reformat the data to the ESRI (Environmental Systems Research Institute - makers of ArcView) "generate" format. The ESRI generate data format consists of two files; one with geometry and the other with attribution. The generate files were then read into ArcView and immediately saved as a "shapefileShapeFile". Other components of the STOW UE-98-1 database were imported into ArcView in a similar manner to allow deconfliction of new features with old features (e.g., buildings and fences).Another benefit of using ShapeFiles was the fact that source code that reads a ShapeFile is readily available. This was a benefit to both the DTO group and also to the SLAMEM group. The SLAMEM group is another participant in the J9901 exercise and it was important that there be consistency between the database information used by both the Synthetic Force (SF) and SLAMEM contingents. Since the source code to read ShapeFiles was readily available it was an easy task for SLAMEM to create code to convert ShapeFiles to their own database format. This not only allowed them to be consistent with the new roads, canopies and urban areas, but to also be consistent with the existing roads. Technology Advancements for DTOIn order to support the J9901 effort DTO required a range of advancements and bug fixes. These included the ability to import industry standard ShapeFiles, the ability to create cut and fill roads, and the ability to save the results of ECN changes. On top of all that is the robustification of all components of DTO to support one hundred times any previous quantity of ECN data.Figure 3: This image was taken from an ArcView view representing the SWA database as shapefileShapeFiles before and after the creation of the new roads, canopies, and urban areas.Another benefit of using shapefiles was the fact that source code that reads a shapefile is readily available.  This was a benefit to both the DTO group but also to the SLAMEM group.  The SLAMEM group is another participant in the j9901 exercise and it was important that there be consistency between the database information used by both the SAF and SLAMEM contingents.  Since the source code to read shapefiles was readily available it was an easy task for SLAMEM to create code to convert shapefiles to their own database format. This not only allowed them to be consistent with the new roads, canopies and urban areas, but to also be consistent with the existing roads. Technology Advancements for DTOIn order to support the J9901 effort DTO required a range of advancements and bug fixes.  These included the ability to import industry standard shapefiles, the ability to create cut and fill roads, and the ability to save the results of ECN changes.  On top of all that is the robustification of all components of DTO to support one hundred times any previous quantity of ECN data.New Paradigm for Data Base EditingTypically a database is generated from a variety of sources which are then brought together into one common format where it is edited to eliminate errors in the source data and to customize it.  Then the base format is recompiled into the various formats required by the participants in an exercise.  In this case the base format is S1000 with the desired formats being CTDB (utilized by the Joint SAF), MSO (utilized by the Joint SAF and DTSim to quickly identify Multi-State Objects), and GDE (utilized by the OpenScene Performer Image Generator to generate the 3D visualization for the stealth).  The process of acquiring the source data, correcting it, and compiling it into the various desired formats is time consuming and difficult.  So when there is a desire to change the database this must be validated carefully.The changes desired for J9901 are particularly difficult in this regard because they do not represent ground truth. That is they do not represent additional information or higher than previous resolution data about the area as it exists in the real world.  In fact they are changes chosen to affect particular training exercises involving certain kinds of cover.  This means that if the normal DBG steps were used that the original data would have to be "corrupted" by this exercise specific non real world data, not to mention the difficulty and time involved in the process.  This problem provided an impetus to create a means of editing a database that was both cheaper in time and effort to accomplish.The DTO architecture can be used to create many changes to the database surface during an exercise.  These changes include but are not limited to the following craters, anti-tank ditches, fighting positions, concertina, dragons teeth, Multi-State Objects, and also roads, canopies, and urban areas.  Thus DTO provides much of the same capability that Data Base Generation has in the past.  Previously, however, this capability was limited to occurring during or at the start of an exercise.  While this provides a capability that doesn't even exist for DBG, namely the ability to affect changes during an exercise, the quantity of change required would have required a startup time of multiple hours for each participant. The desire here was to provide the ability to make massive changes to the database but to not have to incur the time penalty during the exercise.  The solution was to implement the capability to save each of the different types of databases after the changes had been affected.  The resulting databases could then be distributed before the exercise in the same way as databases were distributed in the past.  The J9901 experiment will use many different CGI systems based on the Joint SAF along with one DTSim and several stealths.  All of these applications are Joint SAF library based and require CTDB databases.  The DTSim also requires the MSO and S1000 database formats and the stealth requires the GDE database format.  All of these formats have been used in conjunction with DTO in the past so they already have DT Agents to incorporate changes.  That meant that the only requirement to support database editing was to have the ability to save the database and any changes to a new database for each of the formats.The changes required to save the CTDB and MSO databases were added to their support libraries allowing any application using those libraries to also have the ability to save new versions of thedatabases. It is interesting to note that in saving the CTDB format any new road topology required is also calculated from any changes to the existing topology.  The CTDB maintains a network of nodes and edges which provide a framework for the planners to use to follow roads.  Since any new roads would also have to connect to any old roads that they might intersect all of this new topology must be computed.  Since the new roads being added to the database for this exercise are significant (approximately 5267 meters) it was determined that this should not happen until all of the new roads had been added.  That is why the topology is only calculated at save database time.  Furthermore it is also important to note that on a 4 processor SGI the entire SWA database was saved along with all changes and the recomputation of not only the new topology but all of the old topology as well took only an hour and a half.  This gives a conservative estimate of an ability to calculate almost 400 meters of road topology per minute.The support to save the state of the GDE database format was added to the OpenScene Performer Image generator.  While support for saving the S1000 was added directly to the DTSim parser interface.New Paradigm for Data Base EditingTypically a database is generated from a variety of sources which are then brought together into one common format where it is edited to reconcile errors in the source data and to customize it. Then the base format is recompiled into the various formats required by the participants in an exercise. In this case the base format is S1000 with the desired formats being CTDB (utilized by the JointSAF), MSO (utilized by the JointSAF and DTSim to quickly identify Multi-State Objects), and GDE (utilized by the OpenScene ModStealth Image Generator to generate the 3D visualization for the stealth). The process of acquiring, fusing, deconflicting, and compiling the source data is time consuming and difficult. Changes to  the database made using the Data Base Generation System (DBGS) and recompiling must be validated carefully.The changes desired for J9901 are particularly difficult in this regard because they do not represent ground truth, i.e., they do not represent additional or higher resolution information about the area as it exists in the real world. Rather, they are artificial changes chosen to affect particular training exercises involving certain kinds of cover. This means that if the normal DBGS steps were used, the original data would have been "corrupted" by this exercise-specific non-real-world data, not to mention the difficulty and time involved in the process. This problem provided an impetus to create an easier means of editing a database.The DTO architecture can be used to create many changes to the database surface during an exercise. These changes include craters, anti-tank ditches, fighting positions, concertina, dragons teeth, Multi-State Objects, and the newly developed roads, canopies, and urban areas. Thus DTO provides much of the same capability that DBGS systems have in the past. Previously, however, this DTO capability was constrained to occur during or at the start of an exercise. While this provides a capability that doesn't even exist for DBGS (the ability to affect changes during an exercise), the quantity of changes required would have required a startup time of multiple hours for each participant. The desire here was to provide the ability to make massive changes to the database yet avoid the time penalty during the exercise. The solution was to implement the capability to save each of the different types of databases after the changes had been affected. The resulting databases could then be distributed before the exercise in the same way as databases were distributed in the past. The J9901 experiment used many SF systems based on the JointSAF along with one DTSim and several stealths. All of these applications are based on JointSAF libraries and require CTDB databases. The DTSim also requires the MSO and S1000 database formats and the stealth requires the GDE database format. All of these formats have been used in conjunction with DTO in the past and had existing DT Agents to incorporate changes. That meant that the only requirement to support database editing was to have the ability to save the database and any changes to a new database for each of the formats.The changes required to save the CTDB and MSO databases were added to their support libraries allowing any application using those libraries to also have the ability to save new versions of the databases. It is interesting to note that in saving the CTDB format any new road topology is recalculated. The CTDB maintains a network of nodes and edges which provide a framework for the planners to reason about roads. Since any new roads may connect to old roads, the complete road topology must be recomputed. Since the new roads being added to the database for this exercise are significant (5,267 meters), it was determined that this should not happen until all of the new roads had been added. Therefore the topology is only calculated at the time the database is saved.  (A natural extension to this capability is to recalculate the topology during an exercise as road changes are made incrementally by a user interfacing to the JointSAF GUI.) It is important to note that the entire SWA database was saved along with all changes and the complete (new and old) road topology was recomputed in less than 1.5 hours running on a 4 processor Silicon Graphics (SGI) Onyx RE2¬Æ. This gives a conservative estimate of the road topology calculation rate of almost 400 meters per minute.The support to save the state of the GDE database format was added to the OpenScene Image generator. Support for saving the S1000 was added directly to the DTSim parser interface.Import of GIS Data by DTSimThe new capabilities added to the DTSim all derive from the new ability to import shapefileShapeFiles a standard GIS format data containing both geometry and attribution.  . Previously the DTSim interface provided no means of creating large scale changes.  . (The DTSim gui GUI in fact is limited to interaction with a single GCS cell.  . By adding tThe new capability to read and process shapefileShapeFiles with both linear and areal information finally provides this functionality.  . Specifically tThree different kinds of shapefileShapeFiles can now be processed.  : They are road shapefileShapeFiles containing linear geometry, canopy shapefileShapeFiles containing areal geometry, and urban area shapefileShapeFiles also containing areal geometry.The linear shapefileShapeFiles used for roads consist of a set of vertices in Geodetic coordinates and a set of attribute fields.  . The areal shapefileShapeFiles also contain a set of attribute fields along with a set of vertices which describe the polgonal area.  . These vertices are stored in Geodetic coordinates (decimal degrees) with the vertices listed in a clockwise order with the last vertex matching the first.In the final analysis using DTO to facilitate the changes to the SWA database in support for J9901J9901 was very successful.  . This is amply shown by the following statistics:  : The total run time for the DTSim to create all of the Urban Areas, Canopies, and Roads was seven and a half hours.  . The CTDB format database with changes was then saved including calculations for all road topology in one and a half hours.  . The S1000 database was saved in two hours.  . The GDE database with its 1.2 gigabytes of additional data was saved in just over three hours with an additional three and a half hours to get the data through the stealth to the IG to be processed (see Section  REF _Ref458506118 \r \h 5.4.4).  . This gives a total of approximately seventeen and a half hours (about half the time to compile the just the CTDB from scratch).  . In summary with the creation of over 47 thousand square kilometers of canopy, over 2000 square kilometers of urban area, and an addition of 17% more roads, a significantly changed database was created in only seventeen hours.Road ShapefilesThe road shapefiles contain the following attribute fields used to create the needed polygons and linear features. Road Attribute Fields IDNumeric identifier aids in identifying a particular road shapeTYPEUsed to identify the type of shape file in this case a string with the value of roadWIDTHwidth in meters TEX_IDNumeric Texture Identifier PAT_IDNumeric Polygon Attribute Table Identifier MOBILMobility type (eg. paved)USAGEIndicates the usage of the road e.g. Primary or secondarySTGSSurface Trafficability Grade SEDRISSTGS_NAMESurface Trafficability Grade SEDRIS nameVERSIONString provided to indicate the version for this shapeLENGTHThe length in meters of the roadCanopiesCanopies represent forrested areas thick enough that they are not generally represented as individual trees for efficiency reasons. In the CTDB format they are represented as micro terrain polygons offset from the terrain surface, an abstract feature defined by a set of vertices enclosing the area, and a vector feature defining the perimeter of the forrested area.  In the GDE database format they are represented by polygons floating over the terrain surface surrounded by vertical polygons from the terrain surface to the  Canopy top. The following are the fields defined within the shapefiles created to describe a Canopy. Canopy Attribute Fields IDNumeric identifier aids in identifying a particular Canopy SENTINELCharacter ‚ÄòC‚Äô Identifies this shape as a canopy shape TOP_TEX_IDNumeric Texture Identifier for Canopy top SIDE_TEX_INumeric Texture Identifier for Canopy SideTOP_PAT_IDNumeric Polygon Attribute Table Identifier for Canopy Top SIDE_PAT_INumeric Polygon Attribute Table Identifier for Canopy SideHEIGHTCanopy height in MetersPENETRABLEFlag used to create penetrable bit in CTDB Abstract feature THICKNESSValue used to create thickness value in CTDB Abstract feature VEGETATIONValue used to create vegetation value in CTDB Abstract feature FULLNESSValue used to create fullness metric in treeline CTDB feature FOLIAGE_HEValue used to create foliage height in treeline CTDB feature TRUNK_RADIValue used to create trunk radius in treeline CTDB featureTOTAL_HEIGValue used to create total height in treeline CTDB feature VERSIONString provided to indicate the version for this shape AREAArea of this Canopy in square meters PERIMETERPerimeter in meters of the Canopy.Road ShapeFilesThe road ShapeFiles contain the following attribute fields used to create the needed polygons and linear features. Table  SEQ Table \* ARABIC 1: Road Attribute FieldsIDNumeric identifier aids in identifying a particular road shapeTYPEUsed to identify the type of shape file in this case a string with the value of roadWIDTHwidth in meters TEX_IDNumeric texture identifier PAT_IDNumeric Polygon Attribute Table identifier MOBILMobility type (eg. paved)USAGEIndicates the usage of the road e.g. primary or secondarySTGSSurface Trafficability Group SIMNETSTGS_NAMESurface Trafficability Group SIMNET nameVERSIONString provided to indicate the version for this shapeLENGTHThe length in meters of the roadCanopiesCanopies represent forested areas thick enough that they are not generally represented as individual trees for efficiency reasons. In the CTDB format they are represented as micro terrain polygons offset from the terrain surface, an abstract feature defined by a set of vertices enclosing the area, and a vector feature defining the perimeter of the forrested area. In the GDE database format they are represented by polygons floating over the terrain surface surrounded by vertical polygons from the terrain surface to the  Canopy top (treelines). The following are the fields defined within the ShapeFiles created to describe a canopy. Table  SEQ Table \* ARABIC 2: Canopy Attribute FieldsIDNumeric identifier aids in identifying a particular Canopy SENTINELCharacter ‚ÄòC‚Äô identifies this shape as a canopy shape TOP_TEX_IDNumeric texture identifier for canopy top SIDE_TEX_INumeric texture identifier for canopy sideTOP_PAT_IDNumeric Polygon Attribute Table identifier for canopy top SIDE_PAT_INumeric Polygon Attribute Table identifier for canopy sideHEIGHTCanopy height in metersPENETRABLEFlag used to create penetrable bit in CTDB abstract feature THICKNESSValue used to create thickness value in CTDB abstract feature VEGETATIONValue used to create vegetation value in CTDB abstract feature FULLNESSValue used to create fullness metric in treeline CTDB feature FOLIAGE_HEValue used to create foliage height in treeline CTDB feature TRUNK_RADIValue used to create trunk radius in treeline CTDB featureTOTAL_HEIGValue used to create total height in treeline CTDB feature VERSIONString provided to indicate the version for this shape AREAArea of this canopy in square meters PERIMETERPerimeter in meters of the canopy.To create the canopy the DTSim reads each shape and reorders the vertices in a clockwise manner since all of the database formats use counter-clockwise polygons. Then it must create an areal feature, a linear feature, and a polygonal feature. The areal feature is created simply by repackaging the vertices in the format desired by the create feature ECN. Then using the PENETRABLE, THICKNESS, and VEGETATION fields, it creates the attributes in the ECN format to complete the description of the areal feature for ECN broadcast. The linear feature is created by taking the FULLNESS, FOLIAGE_HE, TRUNK_RADI, and TOTAL_HEIG fields from the shape and putting them in the proper format for ECNs. Then the vertices are included with this to complete a linear feature ECN. Now in conjunction with the linear feature it also has to create the vertical polygons that form the sides of the canopy for the visual database. These are constructed by scanning along the vertices of the linear feature and creating vertical polygons clipped to GCS cell edges and database patches (each of the database formats divides its data into square tiles called patches or paging units) and sized to fit the constraints of the texture map. The horizontal canopy top polygons are created by scanning each patch contained within the area under the canopy. Then a copy is made of each terrain skin polygon which is touched by or contained within the canopy area. Those polygons that touch the perimeter are then clipped to the perimeter. Then they are raised in elevation by the canopy height and their  texture map ID changed for a forested visual appearance. These polygons are then distributed as create polygon ECNs. To create the canopy the DTSim reads each shape and reorders the vertices in a clockwise manner since all of the database formats use counter-clockwise polygons.  Then it must create an areal feature, a linear feature, and a polygonal feature. The areal feature is created simply by repackaging the vertices in the format desired by the create feature ECN.  Then using the PENETRABLE, THICKNESS, and VEGETATION fields it creates the attributes in the ECN format to complete the description of the areal feature for ECN broadcast.  The linear feature is created by taking the FULLNESS, FOLIAGE_HE, TRUNK_RADI, and TOTAL_HEIG fields from the shape and putting them in the proper format for ECNs.  Then the vertices are included with this to complete a linear feature ECN.  Now in conjunction with the linear feature it also has to create the vertical polygons that form the sides of the canopy for the visual database.  These are constructed by scanning along the vertices of the linear feature and creating vertical polygons clipped to GCS cell edges and database patches (each of the database formats divides its data into a 2D table of data with each packet of data called a patch) and sized to fit the constraints of the texture map.  The horizontal canopy top polygons are created by scanning each patch contained within the area under the canopy.  Then a copy is made of each terrain skin polygon which is touched by or contained within the canopy area.  Those polygons that touch the perimeter are then clipped to the perimeter.  Then they are raised by canopy height and their  texture map id changed to the top texture id.  These polygons are then distributed as create polygon ECNs. The following are the fields defined within the shapefiles created to describe a Urban Area. Urban AreasUrban Areas are new as offor J9901J9901.  . They were created to compensate for the fact that there are not enough structures on the database to provide the needed cover concealment from sensor detection.  . It was determined that the thousands of new structures required to provide the cover would overwhelm both the SAF SF systems and the stealth.  . So the urban are was created.  An urban area consists of a set of vertices describing the perimeter of the area and a density field.  . The density determines the amount of cover currently either concealment (LOW, MEDIUM, or HIGH are ) supported in SAFSF behaviors. The following are the fields defined within the ShapeFiles created to describe a Urban Area. Urban Area Attribute FieldsTable  SEQ Table \* ARABIC 3: Urban Area Attribute FieldsIDNumeric identifier aids in identifying a particular uUrban AreaareaSENTINELCharacter 'U' Identifies identifies this shape as an urban areaTOP_TEX_IDNumeric Texture texture Identifier identifier for Urban urban Area area TopyopSIDE_TEX_INumeric Texture texture Identifier identifier for Urban urban Area area SidesideTOP_PAT_IDNumeric Polygon Attribute Table Identifier identifier for Urban urban Area area ToptopSIDE_PAT_INumeric Polygon Attribute Table Identifier identifier for Urban urban Area area SidesideHEIGHTHeight of Urban urban Area area in meters DENSITYDensity of Urban urban Area area (i.e.i.e., HIGH MEDIUM LOW)VERSIONString provided to indicate the version for this shapeAREAArea of this Urban urban Area area in square metersPERIMETERPerimeter in meters of the Urban urban AreaareaAs with canopies the DTSim must create an areal feature, a linear feature, and a polygonal feature for each urban area shape.  . All of these are created in almost exactly the same manner as for canopies with the only two differences.  . The areal feature has only one attribute DENSITY and the linear feature for urban areas only creates the vertical polygons since there is no corresponding linear feature for urban areas yet.  . It is important to note here that Urban Area abstract features are not a part of the CTDB format 7 definition.  . This points to another reason why the use of DTO was critical for j9901J9901.  . Changing the CTDB database compiler to support new types of information would have necessitated a new version of the CTDB database format, along with modification of the CTDB compiler. Cut and Filled RoadsIn this section, we discuss our support of dynamic cut-and-fill roads.  . A similar technique could be used to create other dynamic linear terrain features, such as railroads and river/ streams.ImplementationDynamic road generation requires five steps: specification of the dynamic road parameters, intersection of the centerline with the existing terrain, construction of the roadbed polygons, integration of the road with the surrounding terrain, and emplacement of the new feature into the database.SpecificationThe dynamic road is specified through several parameters including a centerline of the road; desired road width; integration width (the distance between the road and the surrounding terrain); and texture, soil type, and other attributes to be applied to the new roadbed polygons.  . Certain parameters are constrained by convention or by the algorithm methodology (see limitations Section,  REF _Ref458480872 \w 5.3.7below).  . Assuming these criteria are met, the specification is passed on to the road generation code.IntersectionSince we desire that the road conform to the original, underlying terrain, the road centerline is intersected with the terrain polygon edges.  . This results in a terrain profile along the roadbed that will serve as the basis for the new road polygons.ConstructionEach centerline point will generate two road edge vertices, each at the same altitude elevation as the centerline point; this will create a ‚Äúflatzero-roll‚Äù road over the varying terrain. The endpoints of the centerline generate points perpendicular to the centerline segment (when viewed orthogonally), and displaced by half the road width.  . Interior centerline points will also generate two points, but these points will be placed along a vector at equal angles to the two segments joined at the point, and scaled to keep the desired width along the entire length of the road.  . A road polygon is constructed from the four points generated by two consecutive centerline points.Figure 6 shows the resulting polygons from a simple three-point centerline.  . The two endpoints each generate two points on a perpendicular vector to their respective segments; the interior centerline point produces two points at an angle and scaled to preserve the overall road width.IntegrationThe new roadbed must now be integrated into the surrounding terrain polygons.  . An outline of the road polygons, expanded on all sides by the desired integration width, is intersected with the terrain polygons to give us a terrain skin surface profile.  . We then generate polygons between this profile and the road polygons to create a smooth integration zone.EmplacementThe completed road feature now consists of the feature specification and the newly created sets of roadbed and integration zone polygons.  . To delete the terrain polygons that this road replaces, we use the terrain profile outline from the Integration step as a cookie-cutter, and remove polygons and polygonal pieces, which fall within.  . Once this is done, we simply add the new polygons to the terrain, and the road is seamlessly merged into the original terrain.LimitationsThe current implementation is limited in scope in the following ways:Intelligent road placement is solely at the discretion of the user.  . The algorithm does not checking for the ‚Äúwisdom‚Äù of road placement.  . For example, if the user desired, he could place a dynamic road directly up the face of a cliff.  . It would be a simple matter to check the potential road slope and reject the road if any segment exceeded a particular angle.  . Otherwise, the quality of civil engineering is left to the user.In a similar vein, it might be desirable in certain cases to skip the Intersection step above, and let the user‚Äôs centerline points specify exactly which points are to conform to the terrain.  . In this way, a road might go through a small hill, rather than over it.  . This sort of road placement would require intimate knowledge of the terrain skin, however, and is not recommended for the majority of our users.Curves greater than 90 degrees are illegal.  . Our method of road generation requires that consecutive segments of the centerline make turns of 90 degrees or less.  . This restriction, by happenstance, reflects the real world, since extremely sharp turns are curves, not angles.  . The user can still create such roads, as in the case of mountainous roads, by defining several centerline points to represent the curve.Roads are flat relative to the underlying terrain.  . Typically, real-world roads are raised for engineering purposes such as drainage and or banked for traction on curves.  . Since dynamic road placement actually changes the underlying terrain (as opposed to adding attributed polygons on top of the terrain), intersecting multiple raised dynamic roads would add a cumulative "bump" as one road was created on top of a previously-generated raised road.  . In the current implementation, it would be possible to allow the expert user define the roadbed rise (or lack thereof) based on knowledge that a particular road exists in isolation and is not intended to have intersecting features.The integration zone is small, and therefore cannot be used as a shoulder.  . Some users might be tempted to use the integration zone as a road shoulder, perhaps by declaring an integration width of 2-3 meters.  . However, the integration width must be kept small so that the visual anomalies between intersecting roads are minimized.  . With such a small width (currently 0.3 meters), the integration zone polygons may be quite steep in order to merge the road with the surrounding terrain.  . It is therefore recommended that users include shoulders in the road polygon textures and expand the width of the roadbed appropriately.In addition to the polygons needed to provide visualization for the Image Generator and a running surface for the SF, a linear feature is needed for each road. This is because the SF systems require this semantic abstraction to plan routes and utilize roads.Figure 7: Here is an OpenScene Performer ModStealth Image Generator view of a section of newly created road.  . The inset is the wireframe version of the same view.In addition to the polygons needed to provide visualization for the Image Generator and a running surface for the SAF a linear feature is needed for each road.  This is because the SAF systems need more than terrain surface polygons to find and utilize roads.The Joint SAFJointSAF based systems used in this exercise use both linear feature data and topological data stored in the CTDB to both display and utilize roads.  . The linear features are stored as attributed vertices contained within each patch and a set of nodes and edges for each of the GCS cells.  . To support the creation of the appropriate road data for CTDB, two operations are done.  . First, when the original road polygons are created from the shape a linear feature, an ECN is also created.  . This linear feature ECN contains the original vertices transformed into GCS coordinates along with the ECN encoded attributes.  . When the CTDB DT agent receives this linear feature as a validated ECN from the scribe it is processed in the following manner.  . It is scanned along its length and clipped to both GCS cell and patch boundaries.  . This segment must be intersected with any existing road segments and appropriate actions taken.  . This means that the both new and old segments must be cut whenever the segments intersect.  . This is done to provide the nodes and edges needed for the topological data, which is currently only, calculated when the database is saved.Robustification of SoftwareImplementation of Disk Based Memory Caches.One of the first difficulties encountered in creating the changes for j99 J9901 was running out of memory during processing.  . In previous use exercises the largest set of ECNs totaled a little over 3 megabytes of data.  . In order to accomplish all of the changes necessary for j9901J9901, over 330 megabytes worth of ECN data needed to be created.  . It turned out that there were two problems related to memory use which had to be resolved.  . The first First, was that there were several previously undiscovered leaks within the ECN library libecn.  . The second was that none of the machines available for the work possessed enough physical memory to store the ECNs, the database(s), and the ECN changes.The memory leaks were eliminated both through inspection and through the use of memory use tracking software.  . These included a the commercial tool, called Purify¬Æ, available on the SGI platform and a special version of the memory allocation libraries, also on the SGI platform.The fact that there just wasn‚Äôt enough memory on any of the machines used was a more difficult problem.  . The final solution here was to implement a scheme using mmap, POSIX functionality allowing the use of disk space as memory, to create a cache on disk.  . The need arose to create three of these disk caches.  . The first was for ECN data both for the creation of ECN requests and for the storage of validated ECNs in the scribe.  . The second was in the support library for the CTDB database format to store all DTO changes.  . The final disk cache was created within the OpenScene IG to store DTO changes for the GDE format.Improvements to the SIM DTSim to Scribe ECN Request ProtocolIn all previous DTO exercises, where DTO was used individual ECNs tended to bewere fairly small (on the order of 250 kilobytes or less).  . These ECNs also tended to be distributed in time as well.  . That is eExcept at startup, there was were always less than 250 kilobytes of ECN data being transmitted at a time.  . As mentioned earlier, to create the magnitude of change required for j9901J9901, over 330 megabytes worth of ECN data had to be transmitted through the scribe.  . This presented a problem for the ECN request data because that data is was sent using a best effort type of transmission protocol.  . The original best effort algorithm for ECN requestsworked like thisas follows.  . First the ECN was fragmented into some manageable size.  . In the case of J9901J9901 with RTI-s that size was 4096 bytes.  . Then each of the fragments is broadcast transmitted over the ECN request routing space.  . Each ECN fragment was also put on a retransmission list for rebroadcast if needed.  . If a timeout occurred or the corresponding validated ECN was received from the scribe the fragments were removed from the retransmission list.  . Two functions minor_resend and major_resend controlled any actual rebroadcast retransmission of the ECN fragments.  . The function major_resend was called periodically to move fragments from the major retransmission list to a bin in the minor retransmission list.  . The particular bin was determined by only letting a certain number of fragments exist in a certain bin.  . Then at a much higher period, typically 100 milliseconds, the minor_resend function actually rebroadcasts retransmits the fragments from its current bin and moves those fragments back to the major_ resend list.This provided a reasonable means of transmitting ECN requests in the past.  . Of course aAs already previously stated, in the past ECN requests were quite small in comparison to the J9901J9901 ECNs.  . In fact many of the canopy ECNs were over 15 megabytes with some as large as 30 megabytes.  . Using the original protocol, only a few of the early fragments would be received because the input network buffers would overload in the first 100 kilobytes or so.  . Then each time the minor_resend function was called it would also flood the input buffers of the scribe because there would be more than 100 kilobytes worth of fragmented ECN request data per each bin.  . In this way some of the smaller ECNs say (e.g., less than 2 megabytes) would sometimes get through to the scribe, but none of the larger ECNs would get there before the timeout.The first attempt to fix this problem concentrated on changing some of the parameters of the protocol.  . First the timeout was increased to 10 and then 20 minutes.  . This did allow somewhat larger ECNs to get through but the minor_resend was still flooding the network and fragments were lost before the scribe received them.  . Then the number of minor_resend bins was increased to decrease the amount of data rebroadcast when flushing a bin.  . This also further increased the size of an ECN request that could be received by the scribe but not by enoughsufficiently.The protocol used to transmit validated ECNs from the scribe to all of the DT agents differs from the SIM DTSim to scribe request mechanism in that it is NAK based.  . That is the agent explicitly tells the scribe what ECN fragments it has not yet received.  . This allows the scribe to respond by transmitting only the ECN fragments necessary, therefore greatly reducing the amount of data sent and almost eliminating resends.  . This supports ECNs of any size since the agent just keeps telling the scribe what data it hasn‚Äôt received until it has received everything.It became clear that borrowing the NAK from the validated ECN protocol and adding a twist could solve the ECN request problem.  . In this case the sim DTSim will periodically asks the scribe to tell it what fragments of a fragmented ECN it has received already.  . The scribe will then responds with a data packet containing a list of fragments it has received. Upon receiving this list, t and the sim DTSim upon receiving this list will removes those fragments from the retransmission lists.  . This allows the broadcast of very large ECNs because the number of fragments is continually being reduced.  . This change also required only minor modifications to the original ECN request protocol allowing it to continue to function in both DIS and RTI-s.Creation of Synchronization between SIM and SCRIBE for ECN RequestsPreviously a DTSim would make a request ECN and essentially assume that it would be accepted by the scribe and to be returned as a validated ECN.  . For the purposes of database editing in particular, this doesn‚Äôt work.  . That‚Äôs because multiple changes need to occur in sequence with each ECN building on the results of the previous ECN.  . Without a mechanism to sync synchronize with the scribe between changes, many changes would be rejected because the sim‚Äôs DTSim‚Äôs sequence number would not yet agree with the scribe‚Äôs sequence.The answer solution was to create a mechanism to synchronize things between ECN requests.  . This was put into place through the addition of another callback from the DT agent which would let the registered function know what ECN had just been validated and received.  . So theyThe sequence of events here is that the sim DTSim is issued a sequence id ID when it creates the request ECN.  . It then submits that ECN request and waits for the callback from the DT agent or a timeout.  . During the wait, the sim DTSim is freed up to do may perform other activities (most importantly to read and process the network buffers).  . Upon the receipt of the callback from the DT agent it compares the original sequence id ID it was issued with the sequence id ID of the validated and received ECN.  . If the sequence ids IDs match, then the last request has been validated and received and the sim DTSim goes on to process the next item.Increase in Data Transmission Sizes for Stealth to IG CommunicationThe interface between the Joint SAFJointSAF based OpenScene ModStealth simulator (stealth) and the OpenScene Image generator Generator (IG) uses the TCP/IP network protocol.  . Normally this interface is used to provide relatively small amounts of command and data packets to the IG.  . Some examples of the kind of information that passes over the interface are viewpoint position, moving model type and position data, and weather conditions.  . The ECN data also passes over this interface on its way to the database pager and its DT agent.  . The database pager feeds the appropriate portions of the disk-based database to the polygon processor as determined by the viewpoint location.  . This makes it the natural location to provide any modified database contents to the polygon processor.As with other parts of the DTO operation, the original level of data transmission for DTO data was relatively small.  . Even though an individual ECN might have been on the order of 100 to 200 kilobytes they did not come very oftenwere relatively infrequent and as such presented only a moderate burden to the communication system.  . It quickly became apparent that with the greatly increased communication needs of the j9901J9901 database editing, the SGI TCP/IP protocol was being swamped and becoming unresponsive.  . The solution here was to keep track of the quantity of data coming across the interface and at a predetermined amount to synchronize the stealth with the IG.Implementation of Disk Based Memory Cache for IGAs with the DTSim, the hardware available to run the IG did not possess enough memory to support the massive changes required by the experiment.  . This problem is was further exacerbated in the IG by the fact that the GDE format is optimized for polygon processing not foras opposed to size considerations.  . This meant that while the ECN data for the experiment amounted to 330 megabytes worth of data, the GDE equivalent amounted to over 1.2 gigabytes of data.  . This not only more than fully exhausted the memory but is also bigger than the largest mmap memory image allowed on the available systems.  . Furthermore in addition to the 1.2 gigabytes of changed data, the IG normally maintains around 200 megabytes worth of data for the current viewpoint.The solution to this memory dilemma was two partfold.  . The first part was to implement the normal memory cache as an mmap as done previously with ECN and CTDB data.  . This cache was limited to around 400 megabytes because of the other memory requirements of the IG.  . To support the full level of memory required, a disk cache was implemented as well.The disk cache was implemented to work in tandem with the in- memory cache which in this case wasis an mmap‚Äôd memory area.  . The memory cache is implemented in two parts: the working cache where incomplete changes not yet ready for display are kept, and complete changes ready to be paged in as needed.  . The disk cache was also created as a working cache and a ready cache.  . In either case a directory structure is created with the parent directory identified by the GCS cell id ID wherein there exists a directory identified by the patch row followed finally by a file identified by the patch column.  . It was necessary to create this hierarchical structure to keep from having a single directory containing several hundred thousand individual files.  . Then each file consists of a bit image of the data corresponding to the changed contents of that patch.This change to the memory caches on the IG also has several benefits beyond this project.  . That is wWith the implementation of the disk cache, an IG running on hardware with little available memory can still participate in DTO if there is enough sufficient disk space.  . A commodity that This is usually more readily available thaen increased memory, especially on the SGI systems where memory is much more expensive per byte than disk space.Network DifficultiesIt was discovered that the transmission of ECN data when using the RTI-s was causing the loss of 100 to 200 kilobytes of memory for each ECN.  . In fact this loss of memory even occurred, though to a smaller extent, when the data was only transmitted internally.   (i.e., In other words when the DTSim was run with an embedded DT Scribe so that the ECNs went through the RTI-s infrastructure but not out onto the actual network before being received locally).  . Since the J9901J9901 DTO effort resulted in 348 unfragmented ECNs, this was an unacceptable loss of memory.  . At this time we have still not resolved this issue.  . In order to continue on with the creation of the new database, a work around was used.  , viz., That is DIS was used instead of the RTI-s.  . Even though tThis meant that the ECNs had to be fragmented into smaller packets:, DIS only supports packets of 1436 bytes while RTI-s supports 4096 bytes, but the loss of memory was eliminated.SummaryIn summary tThe effort involved in utilizing DTO to create a new database for an exercise was extremely valuable.  . It yielded many benefits.  Possibly the most important being the fact that DTO proved a reliable and effective means of editing a previously created database without resorting to the full DBGDBGS process.  . This along with the nNew capabilities were developedy to create roads, canopies, and urban areas from industry standard shapefileShapeFiles will which provide an excellent database editing capability for exercise tailoring in the future.  . The side benefits of this effort also proved very valuable.  . The  DTO code is more robust than ever before.  . Additionally by virtue of the memory use enhancements and network communication improvements, DTO is now more scalable than ever before.References[1]	A. Ceranowicz et al., ‚ÄúJ9901: Federation Development for Joint Experimentation‚Äù, Proc. Simulation Interoperability Workshop, Paper 99F-SIW-120, Sept., 1999.[2]	D. Miller et al., ‚ÄúDynamic Terrain and Objects in the STOW 97 Advanced Concept Demonstration using the High Level Architecture‚Äù, Proc. Simulation Interoperability Workshop, Paper 98S-SIW-161, March, 1998.Author BiographiesDavid J. Bakeman is a senior realtime software engineer with Lockheed Martin Information Systems Advanced Simulation Center in Bellevue, WA.David Bakeman He graduated from Montana State University in 1986 with a B.S. in Computer Science.  . After graduation David worked for Hewlett Packard designing and developing real time software for digital low frequency spectrum analyzers. This included the design and implementation of two-dimensional graphical displays.  . David started working for Loral in 1993 and was originally responsible for the adaptation and implementation of the data intersection process for the VistaWorks program.  . Since joining the DTO team David has been involved in the design and implementation of the Dynamic Terrain Agent and the corresponding GDE Agent to visualize Dynamic Terrain changes.  . Since then David led the Ocean modeling team for Dynamic Virtual Worlds and served as the focal point for the integration of the Virtual Interactive Targets physics based damage assessment program into the DTO architecture.  . Most recently David was the lead for the effort to utilize DTO to make massive edits to the South Wwest Asia terrain database.DR. DALE D. MILLER is the manager of Advanced Technology Development for the Advanced Simulation Center group of Lockheed Martin Information Systems. He currently leads the projects Dynamic Terrain and Objects in a Virtual World and the Terrain Database Generation & Technology for Synthetic Environments both sponsored by DARPA and USATEC. Additionally, Dr. Miller is managing the terrain database and terrain data fusion development for the WARSIM Program. Dr. Miller received his Ph.D. in Mathematics from the University of Washington in 1976. Since then he has contributed to the areas of DIS and its successor, HLA, real-time computer graphics, computer image generator design, adaptive filtering, image processing, feature extraction, machine vision, and optical character recognition.DR. STEVE ADELSON is a senior software engineer at Lockheed Martin Information Systems in Bellevue, WA.  . He contributed to all aspects of the DTO program, with a special interest in the repoly service, which allows dynamic terrain modifications of all sizes and database tailoring at synthetic environment initialization.  . He is currently involved with implementing SEDRIS-based DT under the High Level Architecture RTI.STEVEN C. HAES serves as Manager of Advanced Simulation Programs within the Synthetic Environments Program Office of TRW/BDM at Fort Belvoir Virginia.  . He supports the STOW project for DARPA and the US Army Topographic Engineering Center with integration, test, training, and exercise support of all Synthetic Environments software.KENT S. CAUBLE is a senior systems engineer at Lockheed Martin Information Systems Advanced Simulation Center. He led the development of the automated production processes for the World Wide Terrain Data Base (WWTDB) and compiled the STOW runtime databases. Previously, he led the production activities for the STOW Southwest Asia terrain database. Prior to his involvement in data base generation technologies, Mr. Cauble was an image generator systems engineer responsible for developing new features, systems, and support systems as well as performing image generator system configuration analysis and integration planning.  ArcView is a product of the environmental Systems Research Institute, Inc. (ESRI) with more than 200,000 users worldwide. EMBED Photoshop.Image.4 \s Figure 4: This These is an images were taken from the Joint SAFJointSAF Planned View Display of the SWA database before and after the DTO changes.												     ¬Ω road width			           scaled			          road			        width											   CenterlineFigure 5: This image was taken from an OpenScene Performer Image generator showing a view of a portion of the original SWA database followed by(left) and a view of the original database with DTO changesedited data base (right) showing the visual representation of three densities of urban areas.EMBED Word.Picture.8Figure 1. DTO Architecture ComponentsFigure 4: This These is an images were taken from the Joint SAFJointSAF Planned View Display of the SWA database before and after the DTO changes.												¬Ω road width			           scaled			          road			        width											   CenterlineFigure 6: Construction of Road Polygons from the Centerline