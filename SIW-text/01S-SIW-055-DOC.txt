Leveraging Object-Oriented COTS Simulation Environments:Rapid Analysis of BCT Deployment and SustainmentDavid PayneThe MITRE Corporation1820 Dolley Madison Blvd.McLean, VA 22102-3481703-883-6366dpayne@mitre.orgKeywords:Object-Oriented, Simulation, Army Transformation, Brigade Combat Teams, Distribution Based Logistics, BCT, DBLS, ReThink, G2, Gensym, Non-HLA, Components. ABSTRACT:  Rapid simulation analysis leveraging a commercial object-oriented simulation environment is used to develop and test innovative ways to improve the deployment and sustainment of Army Brigade Combat Teams. The strong object model of Gensym Corporation’s G2 language and ReThink environment is used to support rapid development of a family of specialized simulation components representing important elements of the US military deployment and supply distribution processes. The result is a component-based, object-oriented modeling environment that can be rapidly configured using component cloning and configuration. These components are then used to model and assess the performance of current processes and to develop and assess alternatives. At a higher level, this experience offers insights into how simulation using state of the art commercial tool kits, or other strongly object-oriented component approaches, can be conducted quickly and efficiently. A tailored component suite can be built in a few days to a few weeks. Once built, such a suite can be configured and run in a few minutes to a few hours. This allows the results to impact operational decisions. This approach also provides an alternative business model for simulation, relying on a large number of rapid engagements rather than the current model prevalent in defense simulation of a limited number of large models that take a significant length of time to build and run.1. Introduction“Frankly, our heavy forces are too heavy, and our light forces lack staying power.To address these shortcomings, we have decided to undertake our most comprehensive transformation effort in over a century.  The aim of our transformation plan is to become a more responsive and versatile force-- a force that can deploy strategically to fight, if necessary, …”GENERAL ERIC SHINSEKIChief of Staff of the Army Keynote Address to the ASEAN Chiefs of Armies Multilateral Meeting, November 21, 2000Army Transformation and Brigade Combat TeamsThe October 1999 announcement by Chief of Staff of the Army General Erik K. Shinseki directed the start of a sweeping program of Army Transformation. The Chief directed then that the Army would immediately begin to design and then field a new type of unit that would be more agile than the current heavy forces yet more lethal than the current light forces. These new units, the Brigade Combat Teams (BCT), will be able to reach distant trouble spots individually in 96 hours and in division-sized strength in 120 hours [1]. Once deployed, they will be able to support a wide range of small scale contingencies as well as be able to hold their own against any opposing force in the world. The army has already begun to make this transformation a reality. The first of these medium weight brigade sized combat teams has already begun to be organized. It will soon begin to be equipped with state of the art wheeled armored vehicles [2]. Yet, these units are only interim stepping-stones to the Army of the future, which will be equipped with a new generation of light but highly capable fighting systems. This major program of change brings new opportunities, new challenges and new risks not only for the Army but also for the other services, the larger National Security Community and for American allies and partners. Simulation will be a major contributor not only to the design and evaluation of the new weapon systems but also to the development of new tactics for the employment and the deployment of these new units. Motivation Behind This Work Getting to a global trouble spot is only half the problem. Maintaining a modern mechanized force in high tempo operations then becomes a major logistical challenge. Getting a Brigade Combat Team deployed in a few days seems hard enough. But can the required logistics support be delivered reliably when needed, where needed? How much of a support force needs to accompany the Brigade Combat Teams? When do they deploy? And does this imply a prerequisite deployment that will slow the arrival of the ground combat forces? All of these are open questions which have not been as well addressed, yet, as the even the limited work done to date on deploying the Brigade Combat Teams. The US Army Logistics Integration Agency (LIA) saw this need to look at the Brigade Combat Team sustainment issue in the spring of 2000. LIA wondered if the Army’s future logistics vision of a Distribution Based Logistics System (DBLS) would work for BCT support. MITRE was asked to look into these issues, as well as look at the command, control and communications impacts of DBLS support for the envisioned BCT missions. After the initial DBLS sustainment results began to emerge, LIA further requested MITRE look at the BCT deployment process and see if DBLS process improvements might also apply there.The Distribution Based Logistics SystemThe Army’s vision for future logistics is built around the concept of Distribution Based Logistics. Distribution Based Logistics is essentially precision management of inventory in motion. This is a radical departure from management of inventory in discreet stockage locations. The Army is currently evolving from an inventory intensive stockage based doctrine to the dynamic Distribution Based Logistics approach. The Distribution Based Logistics System (DBLS) is the Army’s term for this evolving implementation of Distribution Based Logistics. Specific details of this emerging DBLS doctrine are just now being worked out. A number of old and new concepts, approaches and processes are being combined or at least explored that as a group define a workable Distribution Based Logistics System. DBLS is necessarily built around a robust global transportation network, backed up by sophisticated information management systems. DBLS is thus very dependent on the ability to dynamically observe, manage, and control material in motion [3]. However, other improvements in the distribution process implemented or proposed by the Department of Defense, the Joint staff, the Army, the Defense Logistics Agency (DLA), and US Transportation Command (TRANSCOM) offer ways to simplify the information management problem and thus ease DBLS implementation. Some of these are:Detailed Operations and Logistics (OPLOG) planning. This allows early identification of supply and support requirements as well as a very good understanding of when and where the supplies and services will be required in the area of operations. This then allows detailed planning across the distribution chain, advance notice of requirements, and provides suppliers, configurers and transporters time to acquire resources and schedule operations. Anticipatory Logistics can be achieved if this planning horizon exceeds the time required to acquire, configure and physically move the items. Configuring shipments for specific end users or uses early in the distribution process. In the context of DBLS, these are referred to as Unit Configured Loads. This reduces the need to reconfigure shipments during distribution and effectively transfers labor requirements upstream in the distribution process, reducing the so-called “logistics footprint” in the area of operations.Harmonization of packaging, pallets and containers, material handling equipment and the cargo interfaces of distribution platforms (such as trucks and aircraft). This allows throughput of configured shipments and further reduces the need for en route handling and associated labor forces.Emerging Web-based logistics control systems. These promise a lightweight of communication between end-users, their immediate support coordinators, shipment configurers and transporters. However, these information links need to be open and near real time to meet the precise coordination requirements of DBLS.In the broader sense of logistics, this quotation from my 1997 Fall SIW paper still applies: “Distribution-Based Logistics addresses the emerging problem of managing inventory in motion.  Inventory in motion and the minimization of static inventory are key elements of modern distributed supply chain management and electronic commerce.  Efficient manufacturing, distribution and order fulfillment rely on the dependable and predictable flow of components and products through the supply chain.  Just in time manufacturing and electronic commerce amplify the need to accurately forecast, track and manage material flows.”[4]Distribution is the fulfillment end of an e-commerce operation, and an all too common cause of e-business failures. An efficient distribution process design is critical to achieving reliable high performance logistics chains in both the military and commercial worlds.2. Process Modeling to Improve BCT Deployment and SustainmentMilitary operations planners, logistics functional operators and experts, logistics modelers and process designers should find this section of the paper most interesting. Other sections address the technical insights gained from using a component-based modeling environment and the simulation practice implications of this emerging approach to modeling and simulation.  Challenges Inherent in the BCT Concept of OperationsAs noted above, designing and fielding a powerfully armed rapid deployment force is only part of the problem. To be a useful implement of national security such a force must also be deployed rapidly and once deployed, sustained in the field. Many things can be built into a power projection force such as the emerging Brigade Combat Team to ease deployment and sustainment, but the deployment and sustainment distribution processes themselves have to be made as efficient as possible if the overall goals are to be achieved. As in most modern design exercises, the design of a rapid deployment force and the deployment and distribution systems that support it should be an iterative process. In the case of the BCT, this iterative approach was followed after a fashion. Prior work by the Army, especially in their logistics vision The Revolution in Military Logistics [5], and a series of Army Science board studies identified a number of desirable traits for highly deployable and sustainable forces. These were largely built into the Interim BCT design. Similarly, several supporting organizations over the last year have looked at their processes in terms of BCT deployment and sustainment, and have identified some best practices and a few enhancements. However, the rapid acquisition timeline for the major fighting system of the IBCT, that is, the Interim Armored Vehicle (IAV), precluded a truly iterative feedback loop in these related design efforts. However, a longer cycle exists for the Objective BCT design and for its major system, the Future Combat System (FCS). Hopefully, FCS and OBCT designers will take the opportunity to evolve their systems and organizations in synchronization with the designers of the future deployment and distribution systems.The implicit problems in supporting a force such as the BCT begin with translating expected and likely modes of operation into specific resource consumption requirements. Additionally, for planning DBLS support, these requirements also need to be time phased. As it turns out, successful DBLS support of a BCT appears to be dependent on a requirements determination cycle that in turn needs to be transferred to the BCT support planners as a new doctrinal way of operating. Once determined, a complete chain from sources to the BCT end users must be specified. Process enhancement can start in the course of this specification process, but several iterations of process improvement proved necessary to get to the current level of efficiency. Key concerns going into the DBLS analysis included estimation of daily support requirements, distribution platform requirements to move the daily support, detailed designs of distribution networks, identification of types and sizes of material handling equipment in the network, and an assessment of the ability of the DBLS to keep up with BCT sustainment demands under a high operating tempo (OPTEMPO).Initial Static Analysis of SustainmentSeveral challenges confronted this analysis. The operational concept for the BCT was evolving rapidly, but was still not very specific at the time the main analysis was conducted. Additionally the BCT mission envelope is very wide, ranging from low intensity stability missions to limited operations as part of a larger force in a major war. Specific supply requirements are closely tied to unit operations, so requirements had to be assessed for a range of contingencies. The final requirements used to estimate daily distribution tonnage were based on high estimates of all supplies, including bulk fuel and water, but with a low average ammunition usage.  A workbook of Excel spreadsheets was developed to estimate supply requirements based on BCT OPTEMPO and convert them to short tons (STON) required per day. The next phase of the analysis involved extending the spreadsheets to convert tons per day into distribution platform fleet requirements. But first the specific distribution networks had to be defined. A total of five of these networks were defined: a direct intercontinental distribution system, linking the configuration point directly to the BCT a network operating through an Intermediate Staging Base (ISB)  close to the area of operations, linking the configuration point to the ISB and then linking the ISB to the BCT using intratheater cargo aircraft (called the “Intermodal ISB)a network operating through the close ISB but linking the ISB to the BCT using only ground based trucks (called the “All-Ground ISB)an intermodal ISB located farther from the area of operations (out of missile range)an all-truck distant ISB.The completed workbook calculates distribution fleet sizes and mixes for all of the air and ground platforms of the strategic (intercontinental) and intratheater legs of the various DBLS networks.  The links in the spreadsheets automatically update supply as well as fleet requirements as the composition and/or the OPTEMPO of the BCT is altered. The spreadsheets do not, however, capture the dynamic performance requirements of a real time DBLS. Exploring Dynamic Performance Through SimulationThese DBLS dynamic performance requirements were explored using a commercial process modeling environment, that is, a simulation toolkit. The direct distribution case and the two close ISB cases were modeled using the Gensym ReThink environment. (The distant ISB cases could easily be modeled by adjusting the parameters of the ISB models to reflect the shorter intercontinental leg and the correspondingly longer intratheater leg.)  The technical details of these models are explained in Section 3 of this paper. For functional purposes, the ReThink tool allowed the basic DBLS cargo exchange process to be modeled once and then immediately cloned for rapid modeling of the three distribution network configurations. Similarly, the en route process and the BCT consumption process was modeled once and then cloned as needed. Instruments and charts provided as part of the ReThink environment were rapidly integrated into the DBLS analysis environment. The resulting customized simulation model is shown in the figure below.Typical ResultsGenerally, the process model demonstrated that the static predictions of the spreadsheets were valid. The direct delivery network provided the most elegant performance. Sustainment deliveries reliably kept pace with BCT consumption with a small number of rapid deliveries each day.  The Intermodal ISB also provided reliable BCT sustainment, but required a larger number of smaller deliveries throughout the day. This would likely prove a constraint to combat operations and would thus be a nuisance to the BCT commander and his operators. The All-Ground ISB simulation was the most interesting from a simulation point of view. The first insight gleaned was that the predicted number of trucks could not keep up with BCT demand in a dynamic DBLS application. A 50% increase in the truck fleet (but only three more trucks than then the six predicted statically) solved the initial problem. However, when the model was modified to realistically portray convey operations, the All-Ground intratheater delivery link could not reliably meet BCT sustainment demands even with 24 trucks (400% of the predicted fleet). This may be due to the model not yet incorporating command and control capabilities that would more closely coordinate the movement of the aircraft and truck fleets. However, it does appear to accurately capture the behavior of today’s loosely coordinated air and ground distribution networks.Typical results graphs appear in the figure below:The Enhanced DBLS Process The figure on the next page depicts the enhanced DBLS process. Important DBLS process improvements identified in the course of this analysis include:Configuring the daily BCT sustainment requirements as unit configured loads at a configuration point close to the continental United States (CONUS) launch point. This removed the necessity to reconfigure the loads en route, and thus removed the need to deploy intermediate cargo handling operations. The ISBs, when used, were simply cargo transfer points where large cargo platforms were rapidly moved from one type of aircraft to another, or from aircraft to truck.Use of some type of adapter to allow Army flat racks (large truck sized cargo platforms) to fit directly on Air Force transport aircraft. Currently, the Air Force uses a smaller lightweight pallet as the preferred cargo platform, which must be reconfigured (that is unpacked and repacked) to transfer cargo to Army flat racks or trucks. In some cases, the pallets also have to be reconfigured to transfer cargo from one type of aircraft to another. In any case, the reconfiguration process is labor intensive and requires specialized material handling equipment that must first be deployed. This reconfiguration is time consuming and ties up aircraft and scarce airport space. Throughputting unit configured loads on flat racks trades off added shipping weight to avoid deploying cargo handling units and equipment.Another process enhancement provided by the use of flat racks on the aircraft is that the Army trucks in the BCT, and most large trucks in the Army fleet, are designed to directly pick up and drop off flat racks without additional material handling equipment, such as for lifts and container handlers. It also appears feasible that the Army trucks can use their built-in flat rack handling capabilities to load and unload the flat racks on and off the Air Force transports. Specialized flat racks are being developed to transport bulk liquids. The use of these flat rack tanks is also assumed as a DBLS improvement.Web-based direct communication between BCT log planners and configuration point managers allows timely adjustment of the contents of daily support shipments.Enhancing the BCT Deployment ProcessToward the end of the DBLS analysis, the sponsor requested a similar analysis of the BCT deployment process, with a specific desire to see if any of the DBLS process improvements could be applied to enhance deployment. The DBLS analysis spreadsheets already included the weight of the major IBCT items of equipment and a rough estimate of deployment fleet requirements to move the IBCT. These estimates were improved as much as the available data allowed at the time. The result was an estimate of the number of C17 equivalent loads required to move the IBCT. At this time another set of analysis results became available that included a hypothetical IBCT deployment in support of a UN peacekeeping mission. This scenario was used for the IBCT deployment process enhancement analysis, both to independently estimate the deployment time requirements and especially to devise IBCT deployment process improvements. The DBLS ReThink model was used as a starting point to model the IBCT deployment process. Again the object-oriented, component based environment allowed major simulation objects such as ports to be rapidly cloned from the base model, modified for the deployment model, and then cloned again as needed to build the deployment network. This provided even greater modeling productivity than in the original DBLS modeling effort.  The DBLS model took around 20 staff hours to build, but the IBCT deployment model only took around eight staff hours to build using the DBLS artifacts. Once built, the IBCT model allowed rapid simulation and exploration of the major deployment process components. It also allowed on line modification of the processes with rapid feedback on the effect of the process changes. As a result, a set of process enhancements, as well as preferred processes and procedures, were identified that resulted in a ten-fold improvement in deployment time, over the results of the initial study using current practices.The figures on the next page show the enhanced deployment process developed in this analysis, and the corresponding ReThink process model. Note how the components from the DBLS process model have been reused to rapidly build the IBCT deployment process model.3. Leveraging Objects and ComponentsModel designers and developers should find this section of greatest interest. The lessons learned from leveraging the ReThink object oriented, component based, simulation environment should be of use to both users of commercial process modeling tools, such as ReThink, as well as to component based simulation environment developers who are conceptualizing or experimenting with component based simulation environments outside of the process modeling field. The techniques explained here should apply to any object oriented simulation system.The ReThink EnvironmentRethink is delivered as a layered product, that is a custom object set, built in the Gensym G2 modeling environment and language. Competitive toolkits such as CACI SimProcess take a similar approach of layering a custom object set or library over a proprietary object oriented general purpose modeling language. SimProcess, for example, is built in and runs on top of SimObject. Other available toolkits, such as Extend, are built as object libraries written in a standard object oriented language such as C++. A common feature of these toolkits is a graphic interface that allows the modeler to replicate, or clone, the standard modeling objects and then to link them together to form a runable process simulation. Usually, the links are literally lines that connect the various specialized simulation objects. In the case of ReThink, the simulation objects are called blocks and the connecting lines are called connectors. ReThink also uses mobile objects called work objects to represent the movement of work, people, or vehicles through the simulated process, following the connections from block to block. Additionally, ReThink provides resource objects, instrument objects, chart objects and report objects to round out the simulation support environment. Custom Components as Subordinate Object Classes With Reproducible DetailReThink models are built in workspaces. One common type of block object, the “task” block, serves double duty both as a simple way to represent a work step as a time delay and/or a cost, and as a container for a more detailed model in a subordinate workspace. This makes it easy to build models of subprocesses within the larger model. There is no set limit on the number of levels of detail in a ReThink model. ReThink also allows the modeler to define subclasses of the standard objects. Subclasses of the task block class also have the ability to hold detail models in their internal workspace. Moreover, all objects (that is, instances of any class), can be cloned using a pop up menu command, invoked by a mouse gesture. Cloned task objects and descendent class objects with internal detail will have that detail cloned as well. This effectively provides a complete graphical programming capability in which the mouse is the primary tool used by the modeler to generate object classes, add a model of an internal process, and then leverage the resultant detailed object as a template for reuse.  New object classes can also be given unique icons to enhance the visual appearance and usability of the model interface. This is true of block classes as well as work objects and resources. In fact, any G2 object (which include all ReThink objects) can have a custom icon.An Example of a Simulation Object With DetailIn the DBLS and IBCT deployment analysis, the most detailed as well as the most reproduced custom object is the “hub”. The prototypical hub is a generic cargo transfer process that receives custom work object classes descended from the “distribution platform” class, transfers cargo off the incoming platforms, loads the cargo onto a different distribution platform and dispatches that platform. The hub also performs a number of housekeeping tasks to ensure that the cargo terminal operation is modeled realistically. These functions include enforcing runway, taxiway and parking capacity constraints (often referred to MOG—maximum on ground), generating and then staging an assigned fleet of specific type distribution platforms, aggregating cargo as it comes into the terminal and breaking out the cargo according to departing platform capacities. The prototype hub was built by first defining a subclass of the ReThink “bpr-task” object—the class of the standard ReThink task block. ReThink provides a right-click mouse menu command to convert one instance of a class (in this case a task block object) to an instance of a new subordinate class, and automatically generates the new class definition object with default initial attributes. The developer then opens the so-called “table” of the new class object and customizes the attributes of the new class by clicking on table entries. This triggers an edit mode and the new or changed information is easily typed or copied in. The parent class by default is always the class from which the developer evoked the “make subclass” command. Alternatively, the ReThink developer can directly generate a new class definition object and then fill in the table of the new class definition. In this case, the parent class is initially undefined and the developer needs to identify a valid existing superior class as well as a unique name for the new class to make the new definition valid. ReThink (actually G2) checks for class definition validity and will not activate an incorrectly defined definition. At the top of the table is a status line that clearly indicates to the developer if the new definition is “OK” or “Not OK”, along with the problems detected.  In the case of the prototype hub class, only the new class name (bpr-dbls-hub) had to be defined and the parent class (bpr-task) identified.The next step in the development of the prototype hub object was technically optional, but important to the development of the DBLS modeling environment. This optional step is editing the object icon used to represent each object of the new class. The hub object icon was changed using the ReThink icon editor to be a hexagonal shape, rather than the square block icon inherited from the parent class. The final but most complex task was to define the detail, or inner workings, of the hub. The detail workspace is simply generated from the right click mouse menu invoked by clicking on the prototype hub object. Selecting the command “create detail” generates a workspace which is itself an attribute vale of the associated object. Terminal icons are also generated for every connection or connection stub (that is, an unconnected input or output) of the parent object. From this point on the developer builds the detail out of available ReThink bpr-block descendent objects. The standard blocks are available off a drop down menu, and any object, standard or custom, can simply be cloned from anywhere in the ReThink environment and transferred onto the detail workspace. This includes objects of the same type as the one whose detail is being built, if that makes sense in the context of the model. Resources, instrument probes, and data feeds are other special class objects provided by ReThink on drop down menus, and nay of these objects can be cloned, transferred onto the detail workspace and incorporated in the workings of the detail model. The completed hub detail is shown in the figure below. Rapid Modeling Through CloningIn the DBLS and IBCT deployment models, this technique was used to build the prototype hub object as well as a number of other specialized classes and prototype objects with specific reusable detail. These other classes included the source of supply objects, the en route objects, and the BCT area of operations objects. Custom work objects, including a large variety of aircraft and ground vehicle classes were also defined. The result was a powerful custom simulation environment built in about three staff days that then allowed complex modeling of the deployment or distribution networks in a matter of minutes to a very few hours.The resulting top level workspace serves both as a control panel for the simulation and as an animated display of the process. Work objects, such as cargo, planes and trucks, move from the sources and home bases, through the ports and through the transportation links. For the DBLS model, the BCT continually consumes supplies according to its OPTEMPO. If resupply arrives in time, the BCT supply quantity is updated. If not, the BCT goes into a negative balance state. Standard ReThink instruments and charts are used to monitor the BCT supply status and provide a continuously updating display of supply status. In the case of the deployment model, aircraft loads are sent through the deployment process and force closure percentage is displayed on a chart. Both models support excursions. Problem scenarios and process changes can be added easily and quickly as modifications to the basic model, and then immediately run to assess the effects on the key metrics. In fact, ReThink allows modification to be made while the model is running, which is useful for debugging a model or the modeled process, but of course usually invalidates the metric results of that run. The models run quickly, allowing 10 days of distribution to be modeled in about 20 minutes with animation turned on. Without animation, the run takes around 10 minutes.  The deployment model runs take about the same time, but stop when all of the BCT reaches the destination. Thus more efficient deployment processes usually run faster than less efficient processes. These run times are for discreet event simulation mode, which advances the simulation clock to the next scheduled event and produces the fastest run times. ReThink also supports real time and scaled real time (faster or slower) simulation modes. These were not used for the DBLS and IBCT deployment analyses but could be used if required, such as for exercise support.HLA Potential There was no need to distribute the DBLS or IBCT deployment models, so HLA compliance was not built into the models. For the analytical goals of the overall effort, single stand alone models were all that were needed, for the express purpose of generating numeric results.  If HLA compliance was done the required labor would have exceeded the modeling and analysis hours by several fold. This is an interesting effect of using high productivity commercial simulation toolkits for defense analysis, and is a very different paradigm from the traditional defense simulation development process. However, G2, and thus ReThink, does provide an HLA gateway product to expedite the HLA compliance and integration of G2 based models. The DBLS and the IBCT deployment models could be of use to a future federation as lightweight but low to medium fidelity models of the strategic and theater level operations going on in support of a battle or operation modeled in a some war gaming environment. The main contribution would be to model and impose resource consumption and shortages on the combatant entities, as well as to generate cues and targets for opposing strategic interdiction of the support chain. Lessons Learned for Future Component Based Simulation EnvironmentsThis project provided the following lessons that should be applicable to most component based simulation environments and modeling efforts:Plan the class hierarchy carefully. This is basic to object oriented design, but is worth repeating here.Evolve object classes from the most basic to the generic and then to the specific. This will allow for rapid future growth of new type systems and simulation objects. Building off these common generic roots will bring along the basic simulation, numerical and data collection behavior desired with no additional work.  ReThink supports multiple inheritance that further increased the leverage gained from using a hierarchy of classes. However this is not mandatory, and brings along some added complications, especially for designers new to objects oriented systems.Concentrate on providing a minimum set of basic objects. ReThink provides 14 block classes, in addition to the common parent basic block, but only four were used extensively in the DBLS and IBCT modeling environments. Three other block classes were used occasionally and the rest not at all. This implies that a simple core set of simulation objects should be able to be used to model a wide range of systems and organizations.Allow internal detail. The nested approach used in ReThink is attractive to functional users and experts who can look inside derivative objects to easily verify internal operations. For the developer, the use of the basic block idea as a graphic programming language inside the more realistic derivative objects provides for rapid and intuitive model building. Additionally, functional or process engineering experts can easily learn the graphic programming techniques, supporting development of a multifunctional modeling team.Provide mobile work objects not only to model mobile real world entities but also to carry information from one subprocess to another. One caution with mobile objects: be sure that objects can find each other easily (such as with connectors) without computationally expensive search and proximity algorithms, unless search is behavior being explicitly modeled.4. Implications for Simulation PracticeThis section is of interest to defense simulation managers, providers, and sponsors. As mentioned above in Section 3.5, rapid development of process simulations using highly productive commercial modeling toolkits presents a different paradigm from traditional defense modeling and simulation development. This section addresses some of these differences and offers this author’s assessment of their potential impacts on defense modeling and simulation practice.4.1 Rapid Development and Short EngagementsCommercial modeling environments are designed to support rapid model development. The value, and usually the cost, of the tools are directly related to the leverage they provide model developers and users. Increasingly, the developer is the user, and the application is in process reengineering or troubleshooting, usually in a consulting role.  The model is not built as an objective in itself, but rather as a means to the immediate end of solving a problem or enhancing performance. As such, the model development time is necessary evil on the route to restored efficient operations.Problem Driven ApproachSince time is literally money in the consulting trade, the customer wants the solution as soon as possible. Additionally, lost production or operational efficiency usually has a high and identifiable dollar value. So the consultant gets in fast, models the process well enough to understand it, and then uses this model to develop solutions or enhancements. The model then ends its useful life by providing a forecast of savings or efficiencies obtained with the redesigned process as compared to the current process. Reuse may or may not be a side goal, and any reuse may be by the modeler in the form of reusable components, or by the customer who might then maintain the new model of their refined processes. But often contractual or proprietary constraints prevent either the modeler or the customer from keeping or reusing the model.Contrast With Today’s Defense Simulation PracticeDefense simulations on the other hand are typically built as final deliverables in their own right. They are built according to a detailed set of requirements, which typically are designed to cover a range of specific applications. Defense simulations are typically developed by large teams over a substantial period of time. They are typically coded in a standard software language, and avoid any dependency on commercial proprietary tools or environments. The primary cost is the engineering hours required to specify, design, build and test the major software system that is the resulting simulation product. Once developed, the simulations are typically used for recurring standardized events, such as training or analysis of strategic or operational plans. Typically, the models are neither specific enough, flexible enough, nor responsive enough to be used to solve immediate operational problems in the field or fleet. Will Defense Embrace the Commercial Approach?Due partially to the success of the commercial approach to process modeling, and partially due to the complexities of modern military systems and operations, defense organizations are already using commercial process modeling to study and enhance their operations. In addition to the application described in this paper, the Army has used process models to troubleshoot their logistics management systems, TRANSCOM has used it to enhance their distribution operations, and DLA is using it to help design their reengineered enterprise operations.  These direct applications from commercial practice are opening the door to using commercial modeling toolkits for combat and operational modeling. This is especially attractive when a specific mission or operation is being planned, or a standard operating procedure or process is being improved. While large, detailed military simulations will always be needed, I believe we will see more and more analysis being done with along the lines of commercial consulting practice. Specific problems will be addressed in short, intense engagements in which custom models will be rapidly generated, validated, used to solve the problem, and then shelved. This requires new business models for both the government and the simulation providers.  These business models largely exist now in the form of GSA schedules and other omnibus contracts for consulting services. Commercial process modeling consultants are already supplying these services to defense clients. Traditional defense simulation providers should explore this opening business area, while defense simulation management agencies should assess existing policy in light of this alternative approach to modeling.ConclusionThe DBLS analysis and the IBCT deployment analysis illustrate how commercial process modeling tools and techniques can be rapidly and effectively employed to design or enhance military support operations. The use and reuse of components was a key contributor to the success of these efforts. Similar graphical programming support built upon a well designed object oriented framework could be the basis for rapid development environments for other types of simulations. Finally, the speed and power of these rapid simulation development environments, as well as the few available examples of early success, suggest that a new simulation business paradigm is emerging for defense simulations. Whether this paradigm replaces or simply augments current defense simulation business practices remains to be seen.References[1]	Shinseki, General Eric K.: “Address to the Eisenhower Luncheon, 45th Annual Meeting of the Association of the United States Army”, Washington, D.C., October 12, 1999. (http://www.army.mil/csa/991012.htm)[2]	Army News Service, “Army selects GM to make Interim Armored Vehicles”, Washington, D.C., November 20, 2000.   (http://www.dtic.mil/ armylink/news/Nov2000/a20001120iav.html)[3]	Payne, David: “DBL-A: The Distribution-Based Logistics Analyzer”, (paper 99S-SIW-017), 1999 Spring Simulation Interoperability Workshop, March 1999, Institute for Simulation and Training, Orlando, FL.[4]   --, “Choosing a Simulation Model to Analyze Distribution Based Logistics”, (paper 97F-SIW-017), 1997 Fall Simulation Interoperability Workshop, September 1997, Institute for Simulation and Training, Orlando, FL.[5] US Army Logistics Integration Agency.  Revolution in Military Logistics briefings available at http://lia.army.mil/rml/index.htm.[6]   Gensym Corporation Web site: http://www.gensym.comAuthor BiographyDavid Payne is a Simulation and Modeling Engineer in the Operations Research Department of the MITRE Corporation’s Washington Command and Control Center. He is currently working on a number of projects for several US DOD sponsors aimed at achieving Army Transformation, Focused Logistics, and Joint Vision 2020. In prior logistics and analytical jobs, he has helped develop the Army’s Revolution in Military Logistics vision, support combat units in Desert Storm and Korea, spread arms control in Germany, fix the Army’s logistical and financial information systems, build artificial intelligence systems, and field real time weapons simulations for live operational tests. Non-work interests include golf, skiing and sled dogs. EMBED PowerPoint.Slide.8  Close ISB w/ All-TrucksClose Intermodal ISBDirect(No ISB)TYPICAL RESULTSDBLS ANALYSIS EMBED PowerPoint.Slide.8   EMBED PowerPoint.Slide.8   EMBED PowerPoint.Slide.8  