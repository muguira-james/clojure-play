XMSF Profile Study Group Final ReportKatherine L. Morse, Ph.D.Science Applications International Corporation10260 Campus Point DriveSan Diego, CA  92121(858)826-6728HYPERLINK "mailto:kmorse@epsilonsystems.com"morsek@saic.com240)228-7599301)953-5000Keywords:XMSF, web enabled, SOA, FEDEPABSTRACT: IEEE 1516.3:  The HLA Federation Development and Execution Process (FEDEP)Mr. Robert LutzJohns Hopkins University Applied Physics LabLaurel, MDPhone: 301-953-5000Email: robert.lutz@jhuapl.eduMr. Reed LittleSoftware Engineering Institute/Carnegie Mellon UniversityPittsburgh, PAPhone: 412-268-5792Email: little@sei.cmu.eduMr. Roy ScrudderApplied Research Labs, The University of TexasAustin, TXPhone: 512-835-3857Email: scrudder@arlut.utexas.eduDr. Katherine L. MorseSAICSan Diego, CAPhone: 858-826-6728Email: katherine.l.morse@saic.comKEYWORDSHLA, FEDEP, Process, IEEE 1516ABSTRACT:  The purpose of the DoD High Level Architecture (HLA) is to facilitate interoperability among simulations, and to promote reuse of simulations and their components.  While the HLA provides a highly robust framework for interoperability, it has long been recognized that strict adherence to the HLA specifications is not, by itself, sufficient to ensure a The EXtensible Modeling and Simulation Framework (XMSF) provides a framework which  allows both Department of Defense (DoD) and non-DoD Modeling and Simulation  (M&S) projects to take advantage of Web-based technologies. Such a framework aids M&S applications to interoperate, as well as enables M&S development.  XMSF is defined as a modeling-&-simulation-tailored set of self-consistent standards, processes and practices employing a set of web-based technologies and services to enable a new generation of internet-distributed applications to emerge, develop and interoperate.  Because XMSF is a framework rather than an architecture, it will be comprised of profiles rather than specifications.  The feasibility of a profile standard is being investigated by a SISO Study Group (SG).  This paper summarizes the objectives, technical progress, and future plans of the XMSF Profile SG.fully consistent, interoperable distributed simulation environment.  For this reason, a generalized process for building and executing HLA federations was published in 1996 to help guide HLA users through the steps necessary to build an HLA federation.  The intent of the HLA Federation Development and Execution Process (FEDEP) was to define a generic, common-sense systems engineering methodology that could be tailored to meet the varying needs of disparate user applications.  The FEDEP evolved through several revisions between 1997 and 1999 tThrough the efforts of the Defense Modeling and Simulation Office (DMSO) and the Simulation Interoperability Standards Organization (SISO) Federation Development Process (PROC) Forum, the FEDEP evolved through several revisions between 1997 and 1999.  With the passage of the IEEE HLA standard in September 2000, planning immediately began to incorporate the FEDEP into the IEEE 1516 series as a recommended practice guide.  The purpose of this paper is to report on current FEDEP productization efforts initiated within SISO and continued through the IEEE.  The paper begins with a history of FEDEP development, and a discussion of the original productization strategy.  Then, an overview is provided of the key activities within both SISO and IEEE to build community consensus on the content of the FEDEP document, including FEDEP balloting results. Finally, the majority of the paper concentrates on the We will discuss the major changes that were incorporated in evolving from the original FEDEP Version 1.5 baseline to the balloted IEEE recommended practice.XMSF 1.  BACKGROUNDBackgroundIntroductionThe Extensible Modeling and Simulation Framework (XMSF) has several high-level requirements derived from years of experience with M&S frameworks, and the challenges of their effective deployment across diverse networks and systems.  XMSF must enable simulations to interact directly and scalably over a highly distributed network, achieved through compatibility between a web framework and networking technologies.  XMSF must be equally usable by human and software agents.  Clearly XMSF must support composable, reusable model components.  XMSF use cannot be constrained by proprietary technology or legally encumbering patents which might discourage the free, open, ad hoc development of interconnected tactical models and simulations.Rather than a single architecture, the specification of XMSF will be in the form of a collection of profiles detailing how to interoperate with XMSF compliant systems.  These profiles will enable inter- and intra-domain interoperability. A profile is a formal technical specification for interoperability of web based technologies in support of modeling and simulation.  It may define a new capability or define interoperability between two or more existing capabilities.Profile Scope and PurposeProfiles, and thus a profile standard, must enable the following two goals of XMSF:XMSF must be equally usable by human and software agents.XMSF must support composable, reusable model components.While we currently have some composable, reusable model components, their discovery and composition into a simulation is human labor intensive and error prone.  Its discovery usually involves prior knowledge about the existence of the component on the part of the simulation integrator.  The composition process usually relies on frequent interaction between the component developer and the integrator to determine the component’s capabilities and data model/interfaces.  Even then, failures in communication about the component occur frequently, resulting in multiple integration iterations.  As we move to web based and services oriented architectures, e.g. the Global Information Grid (GIG), the current process becomes more burdensome than it is now.In environments such as the GIG, the content and structure of XMSF profiles must reduce the time and errors currently involved in this process.  Doing so will rely more heavily on the aforementioned software agents.  By extension, this means that the content and structure of profiles must be more specific and rigorous to be suitable for consumption and reasoning by software agents.What can I expect it to do?How do I physically integrate with it?How do I semantically integrate with it?How can I build another one?How can I build a better one?In section  REF _Ref519655059 \r \h 2, we’ll see how these questions get recast as the set of objectives in the profile definition.  I will return to focus on structure and content throughout this paper.Study Group HistoryXMSF itself was launched in April 2002 [1].  Based on initial response, the XMSF partners held a birds-of-a-feather (BOF) session at the Spring SIW in April 2003.  The BOF concurred that there was enough support and substance to proceed with a Study Group focused on identifying the requirements and technical feasibility of developing a profile standard.  The Terms of Reference (TOR) was developed rapidly and approved by the SAC in June 2003.  The SG kickoff meeting was held at the Fall SIW in September 2003.  During that kickoff meeting, tasks were added to the TOR to develop a conops and definition.  Since that time, the SG has been working to complete the tasks in the TOR, including meeting at each intervening Fall and Spring SIW.  This paper reports on our progress.Study Group Terms of ReferenceThe tasks agreed to by the XMSF Profile SG are:Develop profile definition including objectivesDevelop profile conopsIdentify candidate exemplar test casesSurvey profiles from other domainsFirst pass culling of obviously non-applicable profilesDetermine applicability of other profilesReview exemplar test cases to identify necessary interoperability informationIdentify XMSF-specific requirementsIdentify applicable documentation mechanismsDraft XMSF profile standard/review potential change to PDG status or request for extensionThe tasks in bold italics are completed at this time.  The tasks in italics are currently underway.  The SG concluded that actually drafting the standard was out of scope for an SG.  The SG also concluded that more progress could be made by trying to document some exemplars with our preliminary content and structure rather than attempting to exhaustively define the content and structure requirements.The relationships between these tasks are illustrated in  REF _Ref503936103 \h  \* MERGEFORMAT Figure 1Figure 1Figure 1.  The subsequent sections describe the progress to date on the SG tasks.Profile DefinitionXMSF profiles are formal technical specifications for application of interoperable web based technologies to enabling composable and reusable modeling and simulation, and facilitating enterprise integration.  The objectives of XMSF profiles are to:Provide unambiguous specification of the functionality of components, and interfaces among components of the framework Ensure interoperability between existing and new web enabled technologies, both within M&S and in related domains Provide the necessary metadata to facilitate composability and reuse of components across multiple M&S application domains Facilitate development of new applications and services that are functionally interchangeable with existing applications and services Enable development of new applications and services that readily extend functionality for continuous evolution of capabilitiesFigure  SEQ Figure \* ARABIC 111.  XMSF Profile SG ProcessFigure  SEQ Figure \* ARABIC 2.  XMSF Profile Concept of OperationsThe Department of Defense (DoD) High Level Architecture (HLA) was originally developed in response to the DoD Modeling and Simulation (M&S) Master Plan, which called for a DoD-wide common technical framework that would apply to the full range of potential M&S applications.  The primary objective of the HLA was (and continues to be) to facilitate interoperability among simulations and promote reuse of simulations and their components [1]1. Early in the HLA program, a strategy was formulated by which the initial HLA components (HLA Rules, Interface Specification, and Object Model Template) would be utilized and tested in each of four different application areas.  This testing was deemed necessary to ensure that the HLA could adequately address the broad set of DoD application requirements to which it was targeted.  The development of these prototype federations (protofederations) began in early 1995, and provided the basic mechanism for HLA evolution until the release of the HLA baseline in August 1996.One of the key lessons learned to come out of this prototyping phase was the need for a common process model to guide the construction of HLA federations.  Once established, this process model would allow federation developers to focus their resources on the development of the application itself, rather than having to expend resources on redefining how HLA federations are constructed for each new application.In response to this recommendation, the first release of the HLA Federation Development and Execution Process (FEDEP) occurred in August 1996.  The development of this document was a coordinated effort between the HLA Technical Support Team (TST) and protofederation representatives.  The HLA OMT Working Group provided a forum for each of the protofederations to share their individual approaches (and resulting experiences) regarding federation development methodologies and procedures.  It was tThen, through open discussion of alternative federation development and execution strategies, that consensus was reached on a generalized process model which that could potentially support all HLA user communities.As this new process model was exercised in actual applications, users quickly began to discover ways in which the original process description could be improved.  To ensure that the FEDEP would remain current on best practices within the HLA community, the Defense Modeling and Simulation Office (DMSO) defined and established an approach for soliciting feedback from “hands-on ” FEDEP users. The primary means for obtaining this feedback was to encourage FEDEP users to report on their experiences and suggestions for future improvements via the Simulation Interoperability Workshops (SIW) held semi-annually by the Simulation Interoperability Standards Organization (SISO).  Specific proposals for FEDEP changes were then reviewed and evaluated by the HLA Architecture Management Group (AMG), and incorporated into new releases of the FEDEP document if judged to be in the best interests of the HLA user community [2]2.  Between 1997 and 1999, five new releases of the FEDEP document were produced, each building upon the enhancements incorporated in the previous development cycle.  A sampling of some of the more significant improvements are as follows:The incorporation of an executive summary.The partitioning of the compound ““Design and Develop Federation” step into two unique steps.The incorporation of a graphical model based upon a Data Flow Diagram (DFD) representation [3]3.Explicit treatment of the general topic of federation reuse.Professional editing by an experienced technical writer.The HLA Federation Development and Execution Process (FEDEP) is a structured, generic systems engineering approach to the development of distributed systems. The specific intent of the HLA FEDEP is to guide federation developers through the series of activities necessary to design and build HLA federations. Rather than dictating a "one-size-fits all" solution for all users, the FEDEP provides a common overarching process framework into which lower-level domain-specific management and/or engineering methodologies can be easily integrated. The FEDEP was originally developed under DoD sponsorship. However, with the approval of the IEEE 1516 series of specifications in September 2000, an effort was initiated to incorporate the FEDEP into the IEEE 1516 standard. The primary rationale for this effort was to improve the quality of the document through an open standards process designed to capture the ideas and experiences of a much broader user community. Initial standardization efforts were conducted under the auspices of the Simulation Interoperability Standards Organization (SISO), but responsibility for standardization was formally transitioned to the IEEE in June 2002. The IEEE version of the FEDEP (IEEE 1516.3) was successfully balloted in November 2002, and was formally approved by the IEEE Revisions Committee (RevCom) in April 2003. The HLA FEDEP is defined according to a set of seven major steps. An illustration of the seven-step HLA FEDEP is provided in Figure 2.  < Bob - FEDEP stuff>. As described earlier, the FEDEP provides a convenient top-level framework to which user communities can map their domain-specific systems engineering practices in the area of distributed simulation.  This mapping provides a viable basis for more detailed “how to” guides for constructing HLA federations specifically within that domain.  Such mappings are commonly referred to as FEDEP “overlays”.  A number of communities have developed such overlays over the past several years, such as the analysis and biomedical communities.The FEDEP has also proved to be a useful framework for just about any topic area that wishes to describe itself within an HLA context.  For instance, although the FEDEP identifies the various subprocesses that must occur during federation development/execution and approximately where and when these subprocesses occur, it purposefully does not describe them in any significant depth. Experts in specific disciplines have thus used FEDEP overlays as a means of defining how their lower–level processes operate within the broader end-to-end federation development process.  Examples of such overlays currently include VV&A, testing, and fidelity management.  In fact, the VV&A overlay to the FEDEP is currently undergoing standardization within the SISO.Other examples of types of FEDEP overlays include “case study” overlays (meant to convey how the FEDEP was implemented on a specific project) and product overlays (meant to convey how certain tools or tool classes can be used to automate FEDEP activities).  Many specific examples of FEDEP overlays can be found in the References section at the back of this paper.  An example illustration of a FEDEP overlay (borrowed from SIW paper 03S-SIW-085) is provided in Figure 3. Figure 2:  FEDEP – Top Level ViewFigure 3:  The HLA FEDEP with the VV&A 7-Step Process Model OverlayProfile ConopsThe concept of operations (conops) attempts to capture all the roles (not necessarily individuals) that develop and maintain the profile standard, develop and maintain profiles, or apply profiles in the development of simulation systems.  For each role, individual responsibilities were also identified.  The development of the conops is one step in the identification of structure and content requirements, i.e. the profile standard must enable each of the stakeholders’ responsibilities. REF _Ref519238893 \h Figure 2 illustrates the conops for XMSF profiles using a UML class diagram with port notation.  It identifies stakeholder roles, their responsibilities with respect to the profiles, and the information they share.  For example, customers specify the requirement to adhere to specific profiles and that requirement is sent to simulation/system designers.Candidate ExemplarsA set of exemplars from various XMSF prototype projects was identified to serve as “friendly victims” for the profile standard.  Notice the loop in the lower right of the SG process in  REF _Ref503936103 \h Figure 1.  This process allows for iterative refinement of the standard based on experiences from documenting the exemplars with the standard as the standard is evolving.  The following exemplars were offered:WERTI (Web Enabled RTI) [4]WSIM (Web Services Interest Management)XML Schema Based Binary Compression (XSBC)Autonomous Underwater Vehicle (AUV) WorkbenchNSS/CombatXXI web service interface (maybe)C2IEDM Data Mediation Service prototypeExtensible Battle Management Language (XBML)Of the exemplars in this list, draft profiles have been attempted for the first two.  See paper 05S-SIW-093 [5] for details on the WE RTI profile and the XMSF profile collaboration portal (www.xmsf.org).Review of Other Profile EffortsThe task to review other profile efforts was intended to determine how other technologies had applied the concept of a profile, and whether any of their concepts or techniques could be reused in the XMSF profile effort.  The technologies reviewed were:VoiceXMLMathMLCascading Style Sheets (CSS)Web Services – Interoperability (WS-I)Extensible HTML (XHTML)Extensible 3D Graphics (X3D)Security (W3C, OASIS, WS-I)Sharable Content Object Reference Model (SCORM)Scalable Vector Graphics (SVG)RDF Site Summary (RSS)Web Computer Graphics Metafile (WebCGM)Geography Markup Language (GML)Synchronized Multimedia Integration Language (SMIL)XformsAs a project for his Introduction to XML course at the Naval Postgraduate School (1st Quarter 2005), Curt Blais assigned each of these to his students to review and summarize.  The complete results may be found in a presentation on the XMSF Profile SG discussion reflector.  Further summarization of the results as they apply to XMSF profile indicate:Almost all surveyed uses of profiles describe subsetting of capabilities for the given technologyXMSF profiles will have to describe multiple technologies, not just subsets of an individual technologyHowever, subsetting may be relevant to some of the technologies XMSF profiles have to describe, so the profile standard should allow for subsetting of a given profileXMSF “The VV&A process is depicted as an overlay that naturally aligns with the FEDEP. This approach not only matches the VV&A effort to the development effort so that exit criteria between steps can be tracked and measured, but also supports easier adoption, tailoring, and leveraging within each step.  This is a new representation of the VV&A process that is designed to be more efficient than previous versions and more easily integrated into the FEDEP because (1) the VV&A and development processes move forward together, (2) have many common objectives, and (3) share many development artifacts, tools, and data. The new representation also facilitates improved incremental evidence gathering by the V&V personnel in support of the Accreditation Decision. Overall, the advantages of the new VV&A process model include integrated resource planning and estimation, easier deployment, better clarification of roles and responsibilities, and potentially more predictable and accurate results—all of which result in reduced program risk. [12]”Profile FEDEP < Bob - Examples from other FEDEP overlays>.In September 2000, the Institute of Electrical and Electronics Engineers (IEEE) formally approved the 1516 series of HLA specifications.  This new commercial standard represented a significant technical improvement over the older HLA V1.3 documents.  The approval of IEEE 1516 provided the necessary motivation for rethinking the original DMSO approach to FEDEP evolution, as is discussed in the next section.  Overlay Several approaches are being taken to discover the requirements for the content including the exemplar test cases.  Because many existing simulation capabilities are HLA compliant and the Federation Development and Execution Process (FEDEP) [2, 3] was used, in some form or other, to develop these capabilities, we chose the FEDEP as an excellent source of process guidance.  By looking at how the FEDEP would have to be extended to support the development of web enabled M&S capabilities and how the projected enabling capabilities of the profiles could support the FEDEP, we’re discovering valuable requirements for both the structure and content of the profile standard.The purpose of the XMSF Profile FEDEP Overlay is to identify FEDEP activities that may be supported through the application of XMSF profiles, and to recommend additional tasks within these activities related to profiles.  REF _Ref504629980 \h Table 1Table 1   summarizes steps and activities in the FEDEP that meet one or both of these criteria.  The following sections and subsections examine the steps and activities in detail, highlighting how they meet these criteria.  Italics are used to indicate  amplifying information and additional tasks..In its current preliminary state, theThe overlay serves as guidance for developing the XMSF Profile Standardprofile standard by illuminating steps in the FEDEP that the Profile Standardprofile standard may support, essentially providing requirements for the Profile Standardprofile standard.  Each of the subsequent sections describes applications of profiles to one of the above steps in detail.  Much of the text is taken verbatim from the FEDEP for clarity.  Italics are used to identify where profiles are applied or affected.  Not all steps, activities or recommended tasks are represented, only those that interact with profiles in some way.  Table  SEQ Table \* ARABIC 1. Summary of XMSF Profile FEDEP OverlayTable  SEQ Table \* ARABIC 1.  Summary of XMSF Profile FEDEP OverlayFEDEP StepStep 1 - Define Federation ObjectivesStep 2 - Perform Conceptual AnalysisStep 3 - Design FederationStep 4 - Develop FederationStep 5 - Plan, Integrate, and Test FederationStep 6 - Execute Federation and Prepare OutputsStep 7 - Analyze Data and Evaluate ResultsFEDEP Activity3.1 – Select federates3.2 - Prepare federation design4.2 - Establish federation agreements4.3 – Implement federate designs4.4 - Implement federation infrastructure5.2 - Integrate federation7.2 - Evaluate and feedback resultsXMSF Overlap with FEDEP Activity3.1 – Use profiles to identify federates3.2 - Evaluate applicability of profiles to federation design4.2 - Apply existing profilesEvaluate requirements for new profiles4.3 – Update/ extend existing profiles4.4 - Ensure that existing profiles are adhered toDocument information for new profiles5.2 - Integrate existing systems/simulations via existing and/or new profiles7.2 – Simulation /system users provide feedback on usability of simulations/ systems to simulation/system developersSimulation/system developers update profiles as necessaryTable  SEQ Table \* ARABIC 1.  Summary of XMSF Profile FEDEP OverlayStep 3 – Design FederationActivity 3.1 – Select federatesThe purpose of this activity is to determine the suitability of individual simulation systems to become members of the federation. This is normally driven by the perceived ability of potential federation members to represent objects, activities, and interactions in the federation conceptual model.  Profiles may be used to identify candidate federates.  The profiles may be stored in registries where tools may support automated processes for identifying federates and evaluating their applicability to representing required entities/object and events.Recommended tasks:Determine if an existing, reusable federation meets or partially satisfies the federation requirements.Identify candidate federates, including predefined federation participants.Analyze the ability of each candidate federate to represent required federation entities/objects and events.Activity 3.2 – Prepare federation designOnce all federates have been identified, the next major activity is to prepare the federation design and allocate the responsibility to represent the entities and actions in the federation conceptual model to the federates.  This activity will allow for an assessment of whether the set of selected federates provides the full set of required functionality.  Profiles may be used to assess what applicable functionality individual federates provide.When the federation represents a modification or extension to a previous federation, new federates must be made cognizant of all previously negotiated agreements within that earlier federation and given the opportunity to revisit pertinent technical issues.  Some portions of these agreements may be captured in profiles.Recommended tasks:Analyze selected federates and identify those federates that best provide required functionality and fidelity.In its current preliminary state, the overlay serves as guidance for developing the XMSF Profile Standard by illuminating steps in the FEDEP that the Profile Standard may support, essentially providing requirements for the Profile Standard.  Each of the subsequent sections describes applications of profiles to one of the above steps in detail.  Much of the text is taken verbatim from the FEDEP for clarity.  <Bob – should I include text summarizing each step in addition to the description of each activity?>Step 3 – Design FederationActivity 3.1 – Select federatesThe purpose of this activity is to determine the suitability of individual simulation systems to become members of the federation. This is normally driven by the perceived ability of potential federation members to represent objects, activities, and interactions in the federation conceptual model.  Profiles may be used to identify candidate federates.  The profiles may be stored in registries where tools may support automated processes for identifying federates and evaluating their applicability to representing required entities/object and events.Recommended tasks:Determine if an existing, reusable federation meets or partially satisfies the federation requirements.Identify candidate federates, including predefined federation participants.Analyze the ability of each candidate federate to represent required federation entities/objects and events.Activity 3.2 – Prepare federation designOnce all federates have been identified, the next major activity is to prepare the federation design and allocate the responsibility to represent the entities and actions in the federation conceptual model to the federates.  This activity will allow for an assessment of whether the set of selected federates provides the full set of required functionality.  Profiles may be used to assess what applicable functionality individual federates provide.When the federation represents a modification or extension to a previous federation, new federates must be made cognizant of all previously negotiated agreements within that earlier federation and given the opportunity to revisit pertinent technical issues.  Some portions of these agreements may be captured in profiles.Recommended tasks:Analyze selected federates and identify those federates that best provide required functionality and fidelity.The purpose of this activity is to … Figure  SEQ Figure \* ARABIC 3.  Mapping of Profiles to FEDEPResulting Mapping to FEDEP REF _Ref504636949 \h Figure 3 summarizes the profile and profile standard inputs and outputs as analyzed in the preceding sections.  This summary takes the form of a visual overlay onto the FEDEP.  Notice that the original FEDEP inputs and outputs have been removed.  This is only for visual clarity.XMSF-Specific RequirementsHaving performed analysis of the definition, conops, other profile efforts, and the FEDEP overlay, we can now be more specific about requirements for the content and structure of profiles.We found that a very handy way to organize our thoughts on this subject is to tie them to the objectives in the definition, i.e.Provide unambiguous specification of the functionality of components, and interfaces among components of the framework Web Services Description Language (WSDL)Use formal specification technologiesUnified Modeling Language (UML)DoD Architecture Framework (DoDAF)Ensure interoperability between existing and new web enabled technologies, both within M&S and in related domainsDefine XML schema for tagging standards (protocol, data, metadata) and other profilesReferences to Federation Object Models (FOMs) and Base Object Models (BOMs)References to established metadata standards (namespace)Identify other interoperability technologies and standardsHLADefense Information Standards Repository (DISR) replaces the Joint Technical Architecture (JTA)Session Initiation Protocol (SIP) [9]Provide the necessary metadata to facilitate composability and reuse of components across multiple M&S application domains Work with appropriate DoD namespace managersShould we define our own metadata tags to support searching?As extensions to WSDL to support searching?For HLA-compliant simulations, should we try to codify federation agreements?See recommendations of data/metadata subgroup of Composable Mission Space Environment (CMSE) workshop, 04S-SIW-050 [7], and the RAND reportBPEL4WS (04S-SIW-009) [8]Facilitate development of new applications and services that are functionally interchangeable with existing applications and services WSDLEnable development of new applications and services that readily extend functionality for continuous evolution of capabilitiesResource Description Framework (RDF) and/or Web Ontology Language (OWL) to describe semantics?At this point, each of these technologies needs to be investigated in further detail to determine specifically if and how it can be applied.  Applications of some of these can be seen in [5].  Working with the other exemplars should provide insight into the applicability of others.  Furthermore, while we have performed analysis based on individual requirements sources, we have not made any effort to synthesize them all into a consistent set. The next section describes the author’s investigation into the general applicability of the UML with a brief foray into WSDL.Applicable Documentation MechanismsXMLSince unambiguous interpretation is the first objective of the XMSF profile definition, documentation mechanisms have to focus on technologies that support automated methods for searching, composability, and integration.  First and foremost, this implies XML.  It became clear fairly early on that whatever the content of the XMSF profile standard, it will be specified with an XML schema.UMLUML is “…a family of graphical notations, backed by a single meta-model, that help in describing and designing software systems, particularly software systems built using the OO style [6].”  The UML development community focuses on the metamodel, including answering questions such as, “How can code be generated from the metamodel?  Users such as the XMSF Profile SG tend to focus more on graphical notations, including answering questions such as, “How can we increase our understanding of the modeled system through the diagrams?”While the SG decided not to restrict which UML diagrams might be used in a profile, we did identify those that are potentially the most valuable, given the exemplars reviewed so far.  They are described in each of the following subsections with examples from either real exemplars or fictitious, but realistic, exemplars.  To reduce visual clutter, the UML diagrams themselves are grouped at the end of this section.Sequence DiagramsSequence diagrams capture the behavior of a single scenario, showing a number of example objects and the messages that are passed between these objects within a use case.  They are good for representing expected/necessary interaction between services, e.g. protocol representation.  They may be used to represent DoDAF views OV-6c, SV-5, SV-6, and SV-10c.   REF _Ref519666974 \h Figure 4 is a sequence diagram illustrating one aspect of role based access control.Use Case DiagramsUse case diagrams describe typical interactions between the users of a system and the system itself.  These may be at too high a level to be value adding for XMSF profiles.  They may be used to represent DoDAF views OV-5 and SV-4.  REF _Ref519667198 \h Figure 5 is a use case diagram of an exercise viewer.State Machine DiagramsState machine diagrams show the lifetime behavior of a single object.  These would be applicable only to stateful services.  They may be used to represent DoDAF views OV-6b and SV-10b.  REF _Ref519668623 \h Figure 6 is a state machine diagram of HLA services.Activity DiagramsActivity diagrams describe procedural logic, business process and work flow.  In fact, they look a lot like flowcharts.  Such content may be better represented using BPEL4WS.  They may be used to represent DoDAF view OV-5.  REF _Ref519668739 \h Figure 7 is an activity diagram showing initialization of an exercise viewer.Timing DiagramsTiming diagrams focus on timing constraints for a single object or a group of objects.  They could be useful for representing time sensitive services, e.g. ones that have timeouts.  REF _Ref519668898 \h Figure 8 is a timing diagram for a dead reckoning timeout.Class DiagramsClass diagrams describe the types of objects in the system and the various kinds of static relationships that exist among them.  The represent object methods, state, inheritance, and associations.  Their port notation may also be useful. They may be used to represent DoDAF views OV-7, SV-4, and SV-11.    REF _Ref519669292 \h Figure 9 is a class diagram for a weapons of mass destruction (WMD) service.  The content of class diagrams might possibly be better represented in WSDL, or we may need both for different purposes.   REF _Ref519669303 \h Figure 10 shows the WSDL associated with the class diagram in  REF _Ref519669292 \h Figure 9.Deployment DiagramsDeployment diagrams show a system’s physical layout, i.e. which pieces of software run on what pieces of hardware.  Although the specific hardward and operating system are less relevant in a web environment, they may be applied for representing physical distribution of services. They may be used to represent DoDAF view SV-1.  REF _Ref519669312 \h Figure 11 is a deployment diagram for a command and control viewer with role based access control.UML Diagram ExamplesFigure  SEQ Figure \* ARABIC 4.  Sequence Diagram Example – Role Based Access ControlFigure  SEQ Figure \* ARABIC 5.  Use Case Example – Exercise ViewerFigure  SEQ Figure \* ARABIC 6.  State Machine Diagram Example - HLA ServicesFigure  SEQ Figure \* ARABIC 7.  Activity Diagram Example - Exercise Viewer InitializationFigure  SEQ Figure \* ARABIC 8.  Timing Diagram Example - Dead ReckoningFigure  SEQ Figure \* ARABIC 9.  Class Diagram Example - WMD Service<?xml version="1.0" encoding="UTF-8"?><wsdl:definitions targetNamespace="...">	...	<wsdl:message name="getWeatherRequest">    		<wsdl:part name="in0" type="xsd:string"/>  	</wsdl:message>	...	<wsdl:portType name="IWMDT">		...		<wsdl:operation name="getWeather" parameterOrder="in0">      			<wsdl:input message="impl:getWeatherRequest" name="getWeatherRequest"/>      			<wsdl:output message="impl:getWeatherResponse" name="getWeatherResponse"/>      			<wsdl:fault message="impl:HPACException" name="HPACException"/>    		</wsdl:operation>		...	</wsdl:portType>	...</wsdl:definitions>Figure  SEQ Figure \* ARABIC 10.  WSDL for Class Diagram ExampleFigure  SEQ Figure \* ARABIC 11.  Deployment Diagram Example - C2 Viewer with Role Based Access ControlXMIThe challenge with inserting the UML diagrams directly into the XML-based profiles is that any visual representation format has the potential to be voluminous, and it might not be interoperable.  The solution to this is to record the UML diagrams in XML Metadata Interchange (XMI) format, the XML representation of UML.  Although our preliminary experiments with the interoperability of XMI between different UML vendor tools was less than perfect, progress is being made on this issue and we expect this to be a valuable component of the profile standard.The Way ForwardAs stated in section  REF _Ref519657789 \r \h 1.3, the SG concluded that actually drafting the standard was out of scope for an SG, and that more progress could be made by trying to document some exemplars with our preliminary content and structure rather than attempting to exhaustively define the content and structure requirements.  While some progress has been made on the documentation of some exemplars, not as much has been made as hoped.  At the 2005 Fall SIW, the SG will decide whether to pursue more work on the exemplars, or if there is sufficient interest and progress to develop a Product Nomination for a Product Development Group.Key ContributorsThe author wishes to thank all the members of the XMSF Profile SG, and especially to recognize the contributions of the following individuals to the SG and the contents of this paper:Curt BlaisRyan BruntonFrank CarrDavid DrakePaul GustavsonScott HolbenAlan HudsonBob LutzDavid PayneMark PullenSteve ReichenthalAndreas TolkShon VickReferencesDon Brutzman, Michael Zyda, J. Mark Pullen, and Katherine L. Morse, “Extensible Modeling and Simulation Framework (XMSF) Challenges for Web-Based Modeling & Simulation,” HYPERLINK "http://www.movesinstitute.org/xmsf"www.movesinstitute.org/xmsf, October 2002.Katherine L. Morse and Robert Lutz, “The XMSF Profile Overlay to the FEDEP,” Proceedings of the 2005 Spring SIW, San Diego, CA, April 2005. Institute of Electrical and Electronics Engineers (IEEE), “IEEE Recommended Practice for HLA Federation Development and Execution Process (FEDEP)”, IEEE 1516.3, April 2003.Katherine L. Morse, Ryan Brunton, and David Drake, “Web Enabling an RTI – an XMSF Profile”, Proceedings of the 2003 European Simulation Interoperability Workshop, Stockholm, Sweden, June 2003.Ryan Brunton, “Documenting the Web Enabled RTI - An XMSF Profile Prototype,” Proceedings of the 2005 Fall Simulation Interoperability Workshop, Orlando, FL, September 2005.Martin Fowler, UML Distilled, Addison-Wesley, 2003.Katherine L. Morse, Mikel D. Petty, Paul Reynolds, William Waite, and Philomena Zimmerman "Findings and Recommendations from the 2003 Composable Mission Space Environments Workshop," Proceedings of the 2004 Spring Simulation Interoperability Workshop, Crystal City, VA, April 2004.Andreas Tolk, “Composable Mission Spaces and M&S Repositories - Applicability of Open Standards,” Proceedings of the 2004 Spring Simulation Interoperability Workshop, Crystal City, VA, April 2004.Session Initiation Protocol, IETF RFC 3261, http://www.ietf.org/rfc/rfc3261.txt?number=3261Author’s BiographyDr. Katherine L. Morse is a Chief Scientist with SAIC. She is a member of the DMSO SETA team, leading the HLA and LVC programs as well as the deputy manager of the Global Information Grid (GIG) M&S Community of Interest (COI).  Dr. Morse was a founding XMSF partner and is the chair of the SISO XMSF Profile Study Group.  She received her B.S. in mathematics (1982), B.A. in Russian (1983), M.S. in computer science (1986) from the University of Arizona, and M.S. (1995) and Ph.D. (2000) in Information & Computer Science from the University of California, Irvine. Dr. Morse has worked in the computer industry for over 20 years, specializing in the areas of simulation, computer security, compilers, operating systems, neural networks, speech recognition, image processing, and engineering process development. Her Ph.D. dissertation is on dynamic multicast grouping for Data Distribution Management, a field in which she is widely recognized as a foremost expert.2.  FEDEP PRODUCTIZATIONProductizationAlthough the technical improvements incorporated in the IEEE 1516 standard are expected to result in lower development costs and more robust M&S environments, it is generally recognized that adherence to the core HLA specifications cannot (by itself) ensure interoperability and consistency within a federation.  That is, there are many issues that need to be considered when building a federation that are not directly addressed by the core specifications, such as requirements development, database construction, coordinate systems agreement, and testing procedures.  In order for HLA application developers to have visibility into such issues, experience has shown that a supporting process model can be an extremely useful federation resource.   However, since the FEDEP was not included in the original IEEE 1516 standard, it appeared (particularly for new users) that no such process model existed.  Thus, although users were provided with an improved set of technical specifications, they were not provided with any real guidance on how to use the specifications to build federations. The desire to improve the linkage of the process model with the technical specifications provided the original stimulus for initiating the productization of the FEDEP within the IEEE in December 2000.  There were several additional reasons why the HLA community supported FEDEP productization.  First of all, it was recognized that while the FEDEP was developed entirely within the U.S. DoD, the range of potential users was actually much wider.  Thus, taking the document into an open standards process would provide a means for developers in other countries and other domain areas to actively participate in the development of the document.  This would have the effect of getting “buy-in” from a much broader community of users, and also result in a cleaner, more complete process description.  Another reason for productization related to the uncertainty associated with long-term DoD support for document maintenance.  The HLA community felt that such concerns could be best addressed by transferring responsibility for long-term maintenance to a reputable commercial standards organization.  Still other reasons pertained to the desire to make the FEDEP more usable for IEEE 1516 developers (particularly with regard to terminology), and to increase the visibility of the FEDEP within the HLA community via formal IEEE recognition.In addition to the fundamental need for FEDEP productization, there was also broad consensus within the HLA community that the FEDEP should become an IEEE Recommended Practice rather than a Standard.   That is, rather than require all HLA users to build federations in a specific way, efforts should focus on providing an overarching framework of suggested activities and resulting products.  This basic approach would allow users to tailor the development process to their individual needs rather than trying to force-fit a one-size-fits-all solution. 3.  Standards Development and Balloting ProcessAt the time that FEDEP productization was initiated, SISO was engaged in conversations with the IEEE to attempt to remerge the Simulation Interoperability Standards Committee (SISC) with SISO, making SISO an IEEE Standards Development Organization (SDO).  The goal was to unify IEEE SISC and SISO standards development processes, simplifying both standardization and its administration.  The FEDEP was targeted as the first SISO/IEEE standard to be developed under a proposed MOU memorandum of understanding (MOU) between SISO and IEEE.With SISO SAC Standards Activity Committee and EXCOM Executive Committee approval, a Product Development Group (PDG) was formed under SISO product development processes beginning in February 2001. The FEDEP PDG met for the first time on March 28, 2001 in conjunction with the 2001 Spring SIW, at which time officers were elected and a drafting group (DG) was selected.  The FEDEP had passed the first of the six steps in the SISO product development process:Activity ApprovalProduct DevelopmentBallot ProductProduct ApprovalDistribution and Configuration ManagementPeriodic ReviewFEDEP Version 1.5 [4] was submitted as the first draft of the product.  The Product Development step resulted in three rounds of formal review. Comment resolution meetings were held in May/June 2001, September 2001, and January 2002, corresponding to the three review rounds.  For each round, members of the PDG submitted comments against the latest draft via the SISO comment tracking web site.  The DG collated all the comments, recommended resolutions to the comments, and prepared new drafts of the FEDEP based on the resolutions. A subset of the PDG, the assigned reviewers (AR), reviewed the revised draft, comparing it with the votes taken at the comment resolution meetings (or recorded in electronic votes where items were resolved following the meetings)and provided feedback to the DG. The DG then implemented the any changes necessary to ensure that the next draft was consistent with the votes. taken at the comment resolution meetings (or recorded in electronic votes where items were resolved following the meetings).By March 2002, the SISO IEEE MOU had fallen behind the schedule required to get the FEDEP to timely productization.  The FEDEP PDG chair requested, and was granted permission to decide in May 2002, if it was in the best interest of FEDEP productization to go directly to IEEE via the SISC for standardization.  The SISC ratified this decision the same week.  At the same time, a FEDEP Working Group (WG) was formed under SISC in accordance with IEEE standards development procedures.  The FEDEP WG chair was also authorized to move forward with IEEE standardization at his discretion. Given the uncertainty of the MOU outcome and the timeline for achieving the outcome, the FEDEP PDG chair exercised the option to proceed with IEEE standardization in May 2002.A Product Authorization Request (PAR) was submitted to IEEE in April 2002 and the FEDEP was assigned standard number IEEE P1516.3.  This is the first step in the IEEE process.  The version of the FEDEP submitted was draft 4 from the PDG.  The FEDEP was now ready for balloting.IEEE balloting has several steps [5]:Ballot pool formation – the standards committee submits a list of potential balloters to IEEE.Ballot group formation – IEEE invites all members of the ballot pool to join the ballot group.Ballot group balancing – IEEE requires that the ballot group be fairly balanced between users, developers, and the general community.Balloting – for a standard to pass the ballot, at least 75% percent of the ballots must be returned, and of those, at least 75% percent must be affirmative.Ballot resolution – a ballot resolution committee (BRC) must work to resolve technical comments to the satisfaction of negative voters.Reballoting [optional] – a version of the standard (updated based on negative votes) must be recirculated to the ballot group for them to vote on the changes.The FEDEP ballot group was formed and balanced in August and September 2002.  In September 2002 the SISO DG was suspended and FEDEP productization responsibilities were assumed by the FEDEP WG.  One of the WG’s responsibilities is to appoint a BRC, which also happened in September 2002.  The FEDEP went to ballot in October 2002.  A timeline of these events is illustrated in Figure 3-1 REF _Ref440099332 \h  \* MERGEFORMAT . Figure  SEQ Figure \* ARABIC 1 - FEDEP Standardization Timeline4.  IEEE Balloting ResultsOn October 10, 2002 the electronic ballot opened for the FEDEP as IEEE P1516.3.  The P1516.3 ballot group had the following composition:Table 4-1. Ballot Group CompositionInterest CategoryEligible VotersPercent of GroupUser1023Producer49General Interest2149Government819Total Eligible Voters43100According to IEEE rules, any one interest category cannot make up more than 50% percent of a ballot group, and as the table shows, the P1516.3 ballot group met this balance rule.The FEDEP ballot closed on November 8, 2002 with the following results:Table 4-2. Initial Ballot ResultsVoteCountAffirmative31Negative3Abstention1No vote8Total Eligible43This was an 81% percent ballot return rate with a 91% percent affirmative vote proportion (31 affirmative vs. 3 negativeof the 34 non-abstention votes, the abstention votes does not count in the determination of the affirmation percentage).  By IEEE rules, for a standard to pass the ballot, at least 75% percent of the ballots must be returned, and of those returned at least 75% percent must be affirmative.  Thus, the FEDEP handily passed its ballot.5.   1516.3 EnhancementsWhen the PDG first met in March 1999, two major guiding principles were agreed upon which largely determined the form of FEDEP modifications. The first agreement was that the scope of the starting draft (Version 1.5) of the FEDEP was appropriate and that it should not change radically. The PDG also decided that the FEDEP should not address activities outside the scope of the initial FEDEP. For example, the FEDEP should be concerned with federation, but not federate development activities. Further the PDG agreed that the FEDEP should not contain application domain-specific information nor should it emphasize and specialize on the roles of any specific federation development participant. The second agreement was that the level of detail of the FEDEP was appropriate in the initial draft. There was a PDG consensus that a higher-level document would not be useful to the community, and while a significantly more detailed document would be much harder to understand, be less likely to be used, as well as being overly prescriptive. The intent was to develop a recommended practice that would provide a general, tailorable federation engineering process, not rather than a prescriptive, one-size-fits-all process standard that would imply strict adherence.One example of additional detail is the FEDEP Checklists [6]. These PDG addressed the Checklists in their initial meeting and agreed that this additional level of detail was not appropriate, could be viewed as overly prescriptive. Further the PDG agreed that the Checklists were relatively immature (compared with the HLA technical specifications and the broader experience history reflected in the body of the FEDEP). Based on these factors, the PDG decided not to include the Checklists (although eventually, a much broader list of recommended tasks was included as will be discussed later).The DG kept these agreements in mind when formulating their proposed recommended responses to PDG reviewer comments, and these tenets were upheld by the PDG during comment resolution meeting votes. The end result of the three rounds of PDG review and one round of IEEE balloting is a document that increased from 29 to 34 body pages (albeit with tighter spacing and a smaller font). The resulting FEDEP document is more consistent, complete, and easily understood. Overall, there were more than 600 comments submitted during the three review rounds and one balloting round. Over 90 percent percent of these were during the PDG review rounds. The following paragraphs summarize the major modifications to the FEDEP that resulted from this standardization effort and cover the majority of the technical comments that were submitted.5.1 Inclusion of Activity Inputs, Recommended Tasks, and Activity OutcomesInclusion of activity inputs, recommended tasks, and activity outcomes – Multiple PDG members requested that the FEDEP include lists of specific inputs, outcomestasks, and tasksoutcomes for each activity in the FEDEP. Much of the support for this change came from PDG members who also had familiarity with the EUCLID Synthetic Environment Development and Exploitation Process (SEDEP) [73]. The SEDEP provides detailed input, outcome, and tasks lists with detailed descriptions of each. The PDG voted in the first round to adopt such a structure, and asked that reviewers submit specific lists in the second review round. During the second round suchinput, outcomes, and tasks lists were provided by multiple reviewers, and the PDG voted to include them in total. The PDG did not agree that the lists were what they desired as the final outcome at that time, but they agreed that by including the initially proposed lists they had a baseline against which to submit comments in the next round. In that third round, the majority of technical comments did involve the input, outcome, and recommended tasks lists. After wrestling with reconciling the initial lists with multiple new sets of proposed revisions during a PDG meeting, the PDG approved the formation of a small “tiger team” to resolve the multiple comments against each list and to make recommendations back to the PDG. The PDG voted on these lists during the continuation of the third round comment resolution meeting. They approved the tiger team’s recommendations with some minor changes. The inclusion of these lists constitutes the single largest change to the structure of the FEDEP.5.2 Description of Conceptual ModelingDescription of conceptual modeling – During each round of review, multiple comments were received on the portion of the FEDEP that addresses conceptual analysis and modeling. The major thrusts of these comments addressed whether the conceptual analysis was a requirements definition or federation design activity and whether a process-focused or object-oriented approach was most appropriate. During the third comment resolution meeting, a group of subject matter experts in this area formed a recommendation that addressed all of the concerns. This recommendation included the finding that there is conceptual modeling during requirements definition which is refined later in the federation design stages. The recommendation was approved by the PDG.5.3 New Activity DescriptionsNew activity descriptions – PDG members made several recommendations to address federation development activities that were not in the original FEDEP draft. Many of these were driven by the desire of reviewers to achieve a consistency of scope and detail between the FEDEP and SEDEP. The PDG did vote to include some new activities and to expand the description of others activities within existing activity descriptions. For instance, a new activity was approved to describe the implementation of the federation infrastructure. The PDG also voted to implement a change from a single step for executing the federation and preparing results, to specifying two separate steps for 1) executing the federation to produce data and 2) analyzing that data, evaluating the results, and taking action based on the results. 5.4 Graphical Model of the FEDEPGraphical Model of the FEDEP – The PDG voted to make minor changes to the appearance of the detailed FEDEP graphical model representation and a major change to the overview graphical model. On the graphics which depict the activities within each step of the FEDEP, the PDG voted to label which activities provided the inputs and which activities utilized the outcomes, when those activities are not depicted in the same figure (that is, when they are produced or used by an activity in a different FEDEP step). Figure 2 5-1 provides an example where both activity inputs and activity outcomes flow from and to activities not shown on the diagram. The PDG also voted to replace the figure depicting all of the original 17 activities with a high level graphic which that only showed the 7 seven main FEDEP steps (with the inter-step information flows). Figures 5-23 and 5-34 illustrate the original and the new graphic. In addition the PDG voted to make the graphics consistent with the inputs and outcomes lists. These lists are structured so that they show major potential inputs and outcomes as bulleted item lists, with sub bullets for constituents of the major items. The PDG voted to show only the major inputs and outcomes (but not the sub-components) on the graphical depiction of the FEDEP. 5.5 Removing the U.S. DoD EmphasisFigure 2 – Example of Revised FEDEP Graphics (Step 3)Figure 3 – FEDEP Detailed View (DoD Version 1.5)Figure 4 – FEDEP Detailed View (IEEE 1516.3)Removing the US DoD emphasis – Because the FEDEP was initially developed within the US DoD, the initial draft contained many military-specific terms. Because the FEDEP was initially developed within the U.S. DoD, the initial draft contained many military-specific terms. The goal of the PDG was to make the document non-US U.S. specific and non-military application-specific. Thus, terminology that is generally understood only within the military domain was replaced. Further, the PDG removed references to products that were developed primarily by or on behalf of the US U.S. DoD. For example, references to the Object Model Data Dictionary and Modeling and Simulation Resource Repository were replaced by more general descriptions of the capability instead of the specific solution. 5.6 Support for Multiple Versions of HLASupport for multiple versions of HLA – Although the target of this standardization effort is a document in the IEEE 1516 series, the PDG voted not to make the FEDEP applicable to only the IEEE 1516 version of HLA. A substantial number of HLA users are still using the 1.3 version of HLA specifications and products, and it is anticipated that they will continue to do so in the near-future. Thus, the PDG voted to use neutral terminology or where necessary refer to both 1.3 and IEEE 1516 terms (for example, referring to both the 1.3 Federation Execution Data and the IEEE 1516 FOM Document Data).5.7 Definitions of Terms and AcronymsTo maintain consistency, and improve readability, the PDG decided to include the definitions of key terms. Where possible, the definitions from the core HLA specifications (Rules, Object Model Template, and Interface Specification) were used. In addition, all acronyms were listed in a separate section.6.  Next StepsAfter IEEE balloting was completed, the BRC immediately initiated efforts to resolve the technical comments of the three negative voters.  This involved a chain of emails and telephone conversations between the negative voters and the BRC.  The BRC also meet several times via telephone.  When the dialogue between the negative voters and the BRC was finished, one of the negative voters decided to change their vote to “Affirmative”, another chose to change their vote to “Abstain”, and the third kept their vote “Negative.”, with the following final vote tally: A 10-day recirculation ballot was then conducted to allow all ballot group members to review the objections of the one remaining negative balloter (along with the associated BRC/balloter correspondence), and to change their votes if desired.  The recirculation resulted in a balloter that voted “Affirmative” in the original ballot changing their vote to “Abstain”, and a balloter that did not vote in the original ballot submitting a vote of “Affirmative”.  Table 6-1 provides the final vote tally: Table 6-1. Final Ballot ResultsVoteCountAffirmative32Negative1Abstention3No vote7Total Eligible43The final results were an 83 percent ballot return rate and a 97 percent affirmative vote proportion (32 affirmative versus 1 negative, where again the abstention votes do not count in the determination of the affirmation percentage).The final results were an 81% ballot return rate and a 97% affirmative vote proportion (32 affirmative vs. 1 negative, where again the abstention votes do not count in the determination of the affirmation percentage).  The final phase of the BRC’s work is to prepare a package for the IEEE Standards Revisions Committee (RevCom).  This committee is responsible for reviewing submittals for the approval of new standards to ensure that the submittals represent a consensus of the parties having a significant interest in the subjects covered. The committee examines submittals to ensure that all applicable requirements of the IEEE Standards Association rules have been met, and makes recommendations to the IEEE-SA Standards Board regarding the approval of these submittals. The RevCom package contains the following:Form for submittal of proposed standardBallot summary Unresolved negative comments and BRC rebuttalsPAR (Project Authorization Request) and PAR approval letter Coordination responses from required committees and staff Electronic source file and PDF of the last balloted draft The RevCom examines whether or not the working group followed the principles of consensus, due process, openness, and balance throughout the project development. RevCom will carefully examine the receipt of coordination and the resolution of negative votes to ensure that this has been done.RevCom only makes recommendations to the IEEE Standards Board for approval or disapproval of a standard via a consent agenda.  Standards can, and often have been, pulled off this consent agenda for further discussion or a recommended change of action.  Final approval of all documents ultimately rests with the IEEE Standards Board. As with all IEEE standards, the FEDEP will have a five year validity. At the end of those five years, the sponsoring organization, the SISC in the case of the FEDEP, 1) can reaffirm the FEDEP using the same balloting process as was followed for the initial ballot, 2) can open the FEDEP to revisions, or 3) can withdraw the FEDEP. The SISC can vote to call for revisions prior to the five year deadline. Given that the FEDEP represents a recommended set of practices for a fairly new and evolving technology, we anticipate that the FEDEP will likely be opened for revision, possibly sooner than the five year validity period. During the revisions, the community will have the opportunity to incorporate lessons learned and best practices determined in the process of federation development and execution.7.  SummaryThis paper was intended to describe the technical evolution of the HLA FEDEP.  Since its first release in 1996, it has continued to improve and mature based on feedback from actual users.  The enhancements incorporated throughout the development of IEEE 1516.3 were the direct result of an open, structured standards process, providing an opportunity for all interested members of the HLA community to actively participate and to directly influence the technical content of the FEDEP document.  The result is a much more robust and complete process model that will serve the community well in the years to come.Once final editing is complete, the FEDEP document can be obtainedwill be available via the IEEE Wwebsite (http://www.ieee.org).8.  AcknowledgementsThe authors of this paper would like to thank the members of the FEDEP Working Group for their invaluable assistance throughout the development of the FEDEP document.  We would also like to express special thanks to the other members of the FEDEP Drafting Group and Ballot Resolution Committee (BRC) for their hard work and dedication.   The names of these members are Jake Borah, Chris Bouwens, Tommy Nordqvist, Eileen O’Donnell, and Chris Rouget.9.  REFERENCESNote: all references are available for download via the home page of the Defense Modeling and Simulation Office (site address http://www.dmso.mil) or in the SISO archives (site address http://www.sisostds.org).[1]	Under Secretary of Defense for Acquisition and Technology, “Department of Defense Modeling and Simulation Master Plan, DoD 5000.59-P,” October 1995.[2]	Lutz, R., Morse K, Little R, Scrudder R, “IEEE 1516: The HLA Federation Development and Execution Process (FEDEP) V1.1”, Simulation Interoperability Workshop, 0398S-SIW-081236, March 20031998.[3]	Scrudder, R., Waite W., Richardson, M., and Lutz, R., “Graphical Presentation of the Federation Development and Execution Process,” 98F-SIW-103, September 1998.Institute of Electrical and Electronics Engineers (IEEE), “IEEE Recommended Practice for HLA Federation Development and Execution Process (FEDEP)”, IEEE 1516.3, April 2003.Murphy S, Coolahan J, Lutz R, Saunders R, Feldman A, Mukkamala R, “Integrating Cardiac and Cardiovascular Simulations Using the HLA”, Simulation Interoperability Workshop, 02S-SIW-012, March 2002.Pratt S, Totten J, Jackson L, Melton A, “Analysis Process Overlay for the FEDEP”, Simulation Interoperability Workshop, 99S-SIW-142, March 1999.Roza M, van Gool P, Jense H, “A Fidelity Management Process Overlay onto the FEDEP Model”, Simulation Interoperability Workshop, 98F-SIW-083, September 1998.Horst M, Roberts D, Old J, “Testing Overlay for the FEDEP”, Simulation Interoperability Workshop, 98F-SIW-104, September 1998.Perkinson P, “A Full FEDEP Lifecycle Data Management System (DMS)”, Simulation Interoperability Workshop, 98F-SIW-209, September 1998.Turrell C, Bouwens C, McCormick J, “HLA Federation Development and Execution: Automated End-to-End Support of the FEDEP With the HLA Tools Suite”, Simulation Interoperability Workshop, 99S-SIW-130, March 1999.Dobey V, Lewis R, “Verification, Validation and Accreditation (VV&A) Process Overlay for the FEDEP”, Simulation Interoperability Workshop, 03S-SIW-085, March 2003.Igarza JL, Dugone T, “The WARRIOR/ELYSA Experience: A FEDEP Use Example”, Simulation Interoperability Workshop, 00S-SIW-142, March 2000.Morse K, Walter D, “The FEDEP in Systems Engineering and Conceptual Modeling for the WMDOA Federation”, Simulation Interoperability Workshop, 00F-SIW-053, September 2000.[4]	Defense Modeling and Simulation Office, “Federation Development and Execution Process (FEDEP) Model, Version 1.5”, December, 1999.[5]	IEEE, “IEEE Standard Companion,” 1995, http://standards.ieee.org/guides/companion/.[6]	Defense Modeling and Simulation Office, “Federation Development and Execution Process (FEDEP) Checklists, Version 1.5”, December, 1999.[73]	Euclid RTP11.13-TT&S SA-WE1.5-Volume 2, “SEDEP Version 1.0,” July 2001.Authors’ BiographiesyROBERT LUTZ is a Principal Staff Scientist at JHU/APL. He has over 22 years of experience in the design, implementation, and evaluation of computer modeling and simulation (M&S) systems for military customers.  Since joining JHU/APL in 1992, Mr. Lutz has assumed leadership roles on several M&S programs, including the Naval Simulation System (NSS), Joint Warfare System (JWARS), and the Simulation Based Acquisition (SBA) initiative.  Mr. Lutz also served as the technical editor for IEEE 1516.2 (HLA Object Model Template) and as working group chair for IEEE 1516.3 (HLA FEDEP).  Currently, he is the deputy M&S lead for the Multi-mission Maritime Aircraft (MMA) Program, and actively supports the U.S. Defense Modeling and Simulation Office (DMSO) on several technology projects. He also serves as a guest lecturer in The Johns Hopkins University Whiting School of Engineering.ROY SCRUDDER is a program Program mManager at the Applied Research Laboratories, Information Sciences Division, The University of Texas at Austin. Mr. Scrudder has over 20 years experience in systems analysis and design with the last nine years working in support of various data engineering and data management projects in the defense community. Mr. Scrudder is currently working with a variety of modeling and simulation programs and initiatives including the Joint Strike Fighter M&S efforts and synchronization of initialization data among the US U.S. Army’s C4I and simulation systems. He was a member of the Drafting Group and Ballot Resolution Committees for the IEEE 1516.2 HLA Object Model Template. Mr. Scrudder has served as the chair of the Drafting Group and Ballot Resolution Committee for the FEDEP standardization. Mr. Scrudder received his B.S. degree in Mathematics from the University of Tennessee (1979).REED LITTLE is a Senior Member of the Technical Staff at the Software Engineering Institute, Carnegie Mellon University.  He is currently the Vice-Chair of the IEEE FEDEP Working Group.  Previously he was the Technical Area Director for the FEDEP standardization effort when it was a SISO Product Development Group. In addition he investigates software architecture representation issues, especially the relationship to and support of software product lines.42DR. KATHERINE L. MORSE is a Chief Scientist with SAIC.  She received her B.S. in mathematics (1982), B.A. in Russian (1983), M.S. in computer science (1986) from the University of Arizona, and M.S. (1995) and Ph.D. (2000) in Information & Computer Science from the University of California, Irvine.  Dr. Morse has worked in the computer industry for over 20 years, specializing in the areas of simulation, computer security, compilers, operating systems, neural networks, speech recognition, image processing, and engineering process development.  Her Ph.D. dissertation is on dynamic multicast grouping for Data Distribution Management, a field in which she is widely recognized as a foremost expert.  With Don Brutzman (NPSNaval Postgraduate School) and Mark Pullen (GMUGeorge Mason University), Dr. Morse is one of the founding XMSF partners.  She is also a key contributor in the area of HLA-ADL Advanced Distributed Learning integration. I use the broadest definition of “software agent” in this context, i.e. any piece of software that aids in discovery and composition.Figure 3-1. FEDEP Standardization TimelineFigure 5-1. Example of Revised FEDEP Graphic (Step 3)Figure 5-2. FEDEP Detailed View (DoD Version 1.5)Figure 5-3. FEDEP Detailed View (IEEE 1516.3)Figure 2. FEDEP Detailed View (DoD Version