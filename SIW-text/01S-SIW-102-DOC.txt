Behavior Oriented CCTT Interoperability Definition and AssessmentPiotr S. WindygaAllison GriffinBrian R. GoldiezInstitute for Simulation and Training (IST)University of Central Florida3280 Progress DriveOrlando, FL 32826-0544pwindyga@ist.ucf.edu, agriffin@ist.ucf.edu, bgoldiez@ist.ucf.eduCharles T. SmithGeorge W. DahmDaniel A. MageeMadison Research Corporation12249 Science Drive, Suite 250Orlando, FL 32826csmith@MadisonResearch.com, gdahm@MadisonResearch.com, DMagee@MadisonResearch.comKeywords:Behavior, Interoperability, CCTT.ABSTRACT: The planned integration of the Bradley Advanced Training System (BATS) into the Close Combat Tactical Trainer (CCTT) set of simulators created a unique industrial experience, where the “interoperability” between simulators was a key issue. Interoperability is an ambiguous concept still waiting for a comprehensive definition. Even more, it can be defined at different levels of abstraction. The adoption of the Distributed Interactive Simulation (DIS) standard by CCTT’s designers allows for a coherent interchange of messages. Nevertheless, this standard does not deal with the way the simulators act and react in the CCTT virtual world to create a meaningful simulation-based training exercise. Moreover, being compliant with this standard does not guarantee that a “fair fight” can take place. This paper reports on a new approach in defining and assessing interoperability with CCTT. It is based on the observation of the “behaviors” that simulators have to manifest during a training exercise and assumes that the communication issue has already been overcome. Interoperability behaviors were defined and classified to assemble a general taxonomy. While some of these behaviors can be studied using analytical models, others can only be perceived as sensorial stimuli by trainees. A mechanism for achieving an aggregate rate of interoperability is described. A test plan concept is presented and its implementation for the particular case of BATS interoperability with CCTT simulators is analyzed. The behavioral approach proved to be generic and flexible enough to be used in interoperability prediction and assessment. It can be used independently of the underlying communication protocol, and can be automated to a great extent.1. IntroductionThe Close Combat Tactical Trainer (CCTT) is the first of the Combined Arms Tactical Trainer (CATT) family of virtual trainers. CCTT is also the first fully Distributed Interactive Simulation (DIS) compliant training system, and is being used as the standard by which interoperability with CATT is measured [1]. Lockheed Martin developed it from a centralized effort, with the interoperability among CCTT components embedded in the development process.For the first time, the U.S. Army Simulation, Training and Instrumentation Command (STRICOM) has joined with an outside Program Manager (PM Bradley) to develop an independent new member of the CCTT system. The Bradley Advanced Training System (BATS) is the first of this genre of experiences, and has defined a unique industrial scenario where the “interoperability” issue was of paramount importance.Before the BATS experience, interoperability with CCTT was defined by using a rigid hierarchical structure that encompasses concepts such as network connectivity, DIS compliance, models and databases compatibility, fidelity and correlation. Nevertheless, it is the harmony and/or reciprocity of “behaviors”, manifested among simulators in the virtual world during a training exercise, that is the ultimate criteria that can actually prove that the goal of “fair fight” has been achieved. Although this harmony has solid physical foundations, in many cases it can only be evaluated subjectively. Similarly, the assessment of interoperability in terms of an aggregated rate poses a big challenge.This paper defines interoperability based on behaviors and their relative influence on fair fight in a simulation-based exercise. The concepts derive from an in-depth IST study of CCTT interoperability [2]. We start our discussion with a brief review of the CCTT system and some interoperability concepts. Then we present our behavioral interoperability definition. Following, a taxonomy for the behaviors is presented and applied to the particular case of CCTT-BATS interoperability. The concept of an interoperability test is also studied. Finally, we propose mechanisms for the automatization of the interoperability prediction and assessment process.2. Background2.1 CCTTCATT consists of a group of fully interactive networked simulators and command, control, and communications work stations, replicating the vehicles and weapons systems of a company/team and its supporting combat, combat support, and combat service support elements. All these components operate in a highly complex synthetic battlefield on which soldiers can conduct training in a real-time combined arms environment.The initial (and current) baseline for CATT is CCTT. CCTT provides training of collective tasks for Armor, Cavalry, and Mechanized Infantry platoons through Battalion/Task Force in a variety of virtual environments to include: day, night, and varying fog densities. CCTT networked vehicle simulator manned-modules, Semi-Automated Forces (SAF) workstations with Computer Generated Forces (CGF), Combat Support workstations, and After-Action Review (AAR) systems are monitored and controlled by the Master Control Consoles (MCC)/Maintenance Consoles (MC). CATT will ultimately include air defense and aviation as well.CCTT manned-modules include the M1A1, M1A2, M2A2/M3A2, FIST-V, M113, and the HMMWV. These modules are high fidelity simulators, which require individuals and crews to correctly perform their respective tasks in order to successfully accomplish their collective missions. The Semi-Automated Forces have the capacity to create a wide variety of OPFOR (enemy) and BLUFOR (friendly) vehicles with which the units can train. The SAF entities exhibit highly realistic behaviors and can be tailored to varying levels of competence. Through the use of computer workstations, CCTT provides logistics, engineering, artillery, mortar, and close air support for the synthetic battlefield.2.2 DISCCTT is the first fully DIS compliant training system. DIS is a set of standards for connecting simulators that implements an entity-based approach to handle physical models, where subsets of entities are assigned to processors, and where defined interactions between models are supported. The precursor of DIS was the SIMNET (SIMulator NETworking) project, which is a network of homogeneous mockup combat training simulators. Many of the fundamental principles in SIMMET remain in DIS today [3,4].In a DIS network each simulator sends messages, called Protocol Data Units (PDUs), whenever its state changes in a way that might affect another simulator. One of the DIS standards [5] specifies the format and content of PDUs exchanged between simulators as well as when PDUs should be sent. Communication protocols and requirements are specified in a separate standard [6]. The current DIS protocol is such that packets sent from one computer are broadcast to all other entity computers. Each entity computer reads the information in each packet and may act upon it if relevant for the models implemented in the simulator.DIS is based on several underlying principles [7]:Autonomy of simulation nodesTransmission of “ground truth” informationTransmission of state change onlyUse of “dead-reckoning” algorithms (to predict the movements of other entities between the reception of state updates)A “heart beat” or default update rate for transmitting packetsCommunication latency of less than 100 ms2.3 Defining interoperabilityIn the context of distributed simulations, interoperability is commonly understood as the ability of one simulator to function with another simulator to achieve a predefined objective. A close look at concrete interoperability initiatives reveals a challenging problem characterized by a large set of interrelated factors, not all equally important. Even more, interoperability is a concept that can be defined at different levels of abstraction [8]. Interoperability between simulators is highly dependent upon the intended use of the resulting system. Efforts to date appear to address general matters of interoperability, but do not delve into the detailed treatment of what features need to align or how one is to conduct an interoperability assessment.When defining interoperability, it is fundamental to establish the difference between the overall goal and the collaborative means to achieve it. One of these means is the adoption of a common simulation protocol. CCTT adopted the DIS, which assures that a meaningful exchange of messages among simulations can be achieved. Nevertheless, being DIS compliant does not guarantee that the simulations can be connected together to create a training environment where the goal (e.g., fair fight) can be achieved. Moreover, basing interoperability on a particular standard makes it vulnerable to standard’s obsolescence. On the other hand, when simulations involve men-in-the-loop components, the fact that human perception drives the ultimate evaluation of interoperability cannot be neglected. A definition of simulation interoperability and a consequent interoperability rating system is required for the acceptance of new components of a simulation system.Since a robust definition of simulation interoperability, together with unambiguous guidelines to achieve and assess interoperability in all possible scenarios is still a promise, building simulation components to be interoperable with complex simulation systems represents a singularly difficult task. In the particular case of CCTT, control methods, communication mechanisms and the synthetic environment are the characteristics normally used in order to provide an interoperability rating to a candidate system. Five interoperability ratings are defined for simulations intended to interact with CCTT: non-invasive, compliant, compatible, interoperable and fully correlated. This rating, based on the performance of the system, is obtained from testing the candidate system against pre-established capabilities.The CATT Interoperability Control Document (ICD) has been developed by Lockheed Martin Information Systems to aid outside Program Managers (PM) in their quest to build applications that can interact within CATT. The ICD defines six capability areas [9]: DIS compliance, infrastructure, simulation management, synthetic environment, communications and image generator, and provides sets of tests with respect to the parameters in each of these characteristics of interoperability. An interoperability rating matrix is provided to interpret the results of the tests. Despite being a useful tool, the ICD does not offer a mechanism to assess overall interoperability, and does not contain enough details about interoperability requirements.3. Behavioral interoperability definitionIn order to achieve a generic CCTT interoperability definition, and avoid the constraints imposed by the adoption of industrial standards, we opted for basing our definition of interoperability on the goal of fair fight, which is essential for effective military training. Consequently, we assume that all underlying aspects related to communication and simulation management have been conveniently treated.We define behavior as any interaction among simulated entities that is meaningful for training exercise, and can be perceived somehow by trainees. In our behavioral approach, the discussion about behaviors and their manipulation are placed at three different levels of abstraction, depicted in figure 1 (see next page) and described below.3.1 The behavior definition layerAt this layer, the basic behaviors that represent the most relevant interactions among simulation entities are defined. These behaviors are directly related to what the simulator is supposed to do during a training exercise from the point of view of the users (trainees). In other words, all basic physical phenomena from which a training exercise is made of are defined in this layer.Behaviors have to be unambiguously defined and measurable either objectively or subjectively. Also, behaviors have to be self-contained. See, move, shoot and communicate are examples of high-level behaviors.3.2 The cases layerIn most simulation situations a behavior can involve different types of entities and/or accept fundamental variations. For this reason, the set of episodes or scenarios where a particular behavior is supposed to be manifested have to be listed in this layer.The behavior that allows the highest number of cases is the capacity of see. For instance, “see” can mean see a tree during daytime with fog using the commander’s binocular, as well as see a moving target at night using the gunner’s infrared site.3.3 The evaluation layerIn this layer, all the methods leading to the assessment or verification of a behavior are established. Each case/behavior is associated with a set of physical parameters. The evaluation could involve the use of analytical models of physical properties as well as subjective evaluation based on the human sensorial system. For instance, shoot direct fire involves such parameters like round type, location of hit, range from target, direction from which the target came, incidence angle and type of vulnerability kill.Figure 1: Layers of Behaviors4. Behavior TaxonomyWhile some behaviors involve interaction between entities that manifest behaviors (active entities) and entities provided by the virtual environment (passive entities), other behaviors involve iteration between two active entities. For this reason, at the top level of the taxonomy we have defined two main behavior categories, unary and binary. Some behaviors (e.g., see) are found in both categories but, depending on the category, the nature of the entities used to verify a behavior may differ.Figure 2: First level of the unary behavior taxonomy4.1 Unary BehaviorsUnder this label we gather all behaviors that a simulator is supposed to show, when not involved in any activity that requires other active entities to interact with. These behaviors are the foundation of interoperability in the virtual environment. Of them, see terrain and follow terrain are examples most characteristic of unary behaviors. Figure 2 shows the first levels under the unary group.4.2 Binary BehaviorsBinary behaviors allow for battlefield exercises that include engagement to take place. They usually involve reciprocity of behaviors between the simulated entities. The combinations of behaviors, see and be seen, and shoot and be shot, represent this category of behaviors.Figure 3 shows the first levels under the binary group, while figure 4 shows all behaviors under the logistic group (see next page).5. Interoperability AssessmentSince interoperability is a concept than encompasses a broad diversity of aspects, from our point of view behaviors and cases, a single aggregate interoperability rate, either qualitative or quantitative, is highly desired.Figure 3: First level of the unary behavior taxonomyObtaining such a rate is a very challenging problem due to the involvement of an explicit hierarchical structure that provides an aggregation/disaggregation mechanism for types of behaviors and their cases. The use of a weighted mean (arithmetic, harmonic or geometric) is inconvenient because the need of adaptive normalization and exhaustive definition of weighting factors. This would translate into a huge set of conditional functions that lead to the definition of weighting coefficients, which would themselves be functions of other behaviors. Instead, we propose the use of likelihood or degree of belief, a concept widely used in expert systems technology [10], which provides a means for a quantitative interoperability assessment. The likelihood is associated with the evidence used for testing hypothesis. In our interoperability approach, likelihood is replaced by the appreciation of the relative importance of manifesting a particular behavior/case, a value provided by a CCTT human expert. This is equivalent to a subjective probability.Providing an interoperability rate in turn becomes a problem of combination of evidence, in other words, a problem of reasoning under uncertainty that involves an inference chain. Probability theory provides a convenient answer for this problem.Figure 4: Logistic behaviors full taxonomy6. Interoperability test planFigure 5 depicts our high level view of the process of assembling a CCTT interoperability test plan (CCTT-IOT), towards an interoperability assessment. A CCTT-IOT intends to measure to what extent the ultimate goal of fair fight can be achieved, when the simulator under test participates in a CCTT simulation exercise. This assumes that fair fight is possible between the current set of CCTT simulators. Also, to reduce the effect of the trainees’ experience in the interoperability assessment, we require that participants in the exercise are experts in term of operating the simulators. A CCTT-IOT encompasses some assets available prior to proceeding with the testing, as well as assets that are either only useful or produced after completion of a simulation exercise. These two kinds of assets are described below.6.1 Pre-test assetsPre-test assets represent the “theory” behind the interoperability assessment process, as well as criteria that must be applied in order to come up with a scientifically correct statement. These assets provide general directions about how an exercise has to be observed. Pre-test assets are of three types as indicated below.Behavior taxonomy: The collection of behaviors defines the features that need to be studied in order to provide an interoperability assessment. Sampling the taxonomy allows for focusing the interoperability assessment on particular simulator properties. Cases where the behavior is manifested accompany each behavior.CCTT scenarios: Interoperability only has a meaning during the execution of a training exercise. CCTT exercises are based on a set of well-defined training situations called scenarios. Although a virtually infinite number of scenarios can be defined, most of CCTT training sessions are based on a compact set of 86 canned scenarios that gather basic training tasks. They are called structured CCTT scenarios (STRUCCTT). Since they provide a stable set of training conditions, STRUCCTT scenarios are well suited for a CCTT-IOT. For instance, in the primary maneuver fundamental 3 (PMF3-D) scenario, the platoon executes a defensive mission, which includes occupation defense procedures, defense of a battle position and displacement. The enemy consists of a company-size mechanized element and an artillery battery.Experiment design theory: It is not sufficient that a behavior is manifested just once during a simulation exercise in order to rule favorably. In consequence, verifying a behavior requires an appropriate sampling procedure. Sampling theory is a mature field of mathematics that provides precise directions regarding the number of samples and the sampling process in order to sustain a hypothesis with scientific credibility. The validation of a behavior then can be seen as a refusal of the null hypothesis, the null hypothesis, conversely, being the “no” verification of the behavior.6.2 Post-test assetsThese assets allow for an eventual assessment of the interoperability level achieved by the simulator under test during the completed exercise. They are of two kinds as detailed below.Exercise logs: These logs consist of data recorded by the CCTT’s After Action Review (AAR) and the Master Control Console (MCC). They are in the form of videotapes that contain the exercise’s “action” as was seen from the “outside” of the simulator under test. Also, the action as was seen from the simulator itself is included here for comparison purposes. These exercise logs are supposed to capture most of the trainees’ perception during the exercise.Inter-operability criteria: These criteria code the weighting of each behavior/case, as well as the pertinent values for the behaviors’ parameters that formalize the behavior. These values have to be confronted with those collected from the simulation exercise. This includes the ranges of acceptance for each one of those parameters.Figure 5: Interoperability test outlook7. The BATS Experience7.1 BATSBuilt by United Defense LP, BATS was conceived as a training device for the Bradley Fighting Vehicle System M2A3/M3A3. BATS would provide functional training on maneuver, re-supply and fire support. BATS would also support the Advanced Field Artillery Tactical Data System (AFATDS) interface, task loading between crew personnel and nuclear/biological/chemical procedures [11]. The BATS program envisioned two types of devices, BATS-M (maneuver) and BATS-G (gunnery). To accomplish the aforementioned tasks, BATS-M was to be located within the CCTT facilities and be completely interoperable with CCTT. BATS concept was the result of an army/industry cooperation incorporating software re-use [12].7.2 BATS Interoperability AssessmentBased on BATS’s nominal simulation capabilities, we assembled a BATS’s CCTT-IOT consisting of the following list of behaviors:Unary BehaviorsAccidents (due to driver error)Follow terrainReact to obstaclesAccelerationDecelerationSpeedCourseSee terrain base levelSee wadisSee valleysSee hillsSee BuildingsSee RoadsSee rail-roadsSee road bridgesSee rail-road bridgesSee power linesSee rocksSee vegetationSee lakesSee riversSee ditch engineer workSee minefield engineer workSee mobileSee log crib relocatableSee fighting position relocatableSee cloudsSee fogSee hazeSee rainSee unrestrictedSee dawnSee duskSee nightSee dayBinary BehaviorsHear SINCGARSbe-Heard in SINCGARSMount infantryDismount infantryShoot main gunShoot missilesShoot direct fire on stationary targetShoot direct fire on moving targetbe-Shot by direct fire from stationary firerbe-Shot by direct fire from moving stationary firerbe-Rearmed from groundbe-Rearmed from vehiclebe-Refueled from groundbe-Refueled from vehiclebe-RecoveredSee dismounted infantrySee manned modulesSee OPFORSee BLUFORbe-Seen out-of-the-window by AARbe-Seen by manned modulesbe-Seen by OPFORbe-Seen by BLUFORbe-Seen by dismounted infantrybe-Seen by PVDSINCGARS = Single-Channel Ground-to-Air Radio SystemBLUFOR = Blue forces (friendly)OPFOR = Opposing forces (enemy)PVD = Planned Video DisplayAAR = After Action ReviewBATS-M program was cancelled by PM Bradley shortly before the IOT was to take place. This fact prevented the full testing of our approach for the particular case of BATS. BATS-G will replace the M2 COFT (Conduct of Fire Trainer) for M2A3 units. Like COFT, there is no driver station while the Instructor Operator (IO) station is still present.8. Automated Interoperability AssessmentAs in many other testing and assessment situations, where the number of cases to consider is very high and the amount of information is huge, the automatization of the process becomes a necessity. We envision the development of a software tool that could be used before, during and after a development involving simulation interoperability with CCTT. Using the tool before the development starts would allow for a better estimate of the level of interoperability testing effort required, while its use at the end of the development would allow for the assessment of the level of interoperability achieved. The tool could also be used during simulator development to reduce technical risk and delivery time, by making use of embedded interoperability templates and libraries.The core of this tool will be an assisted decision system that will guide the simulator designer through the decision processes leading to establishing the requirements of the new simulator in order to achieve and anticipate the required level of interoperability. This tool will have coded most of the formal technical knowledge about CCTT simulation exercises and also expertise obtained from technical personnel who were involved in CCTT interoperability projects.9. ConclusionsWe have developed a conceptual framework for an interoperability definition and assessment based of the functional features, or behaviors, exhibited by simulators during a CCTT simulation exercise. These behaviors must be in some way perceived by trainees, as sensorial stimuli, since this is how trainees interact with the virtual environment. Our approach allows for a quantitative interoperability assessment independent of underlying interoperability protocol in use (e.g., DIS, HLA). The behavior taxonomy we developed, partially presented in this paper, leads to a multiplicity of tests and associated data, which calls for a computer assisted approach. We proposed the use of likelihood, an idea taken from the expert systems field, to deal with the aggregation of partial evaluations. Our view of a test plan encompasses a priori knowledge and is ruled by statistical fundamentals.Based on our behavioral interoperability definition we drafted an ad hoc test to assess the interoperability of BATS with CCTT that showed the generality of our approach. Our research will continue, focusing on the cases associated with each behavior, as well as the parameters and methods that allow for their verification.ACKNOWLEDGEMENTThe research described in this paper was sponsored by STRICOM under contract N61339-99-K-0005. Opinions expressed in the paper are those of the authors and do not necessarily represent the views of the sponsor.10. References[1]	STRICOM (2000). CCTT Interoperability Description Document. <http://www.stricom.army.       mil/STRICOM/PM-CATT/APM-CCTT/CCTT/       IOP/>. (2000, Dec. 27).[2]	IST (2000). Interoperability of BATS and CCTT: Test Plan. FL: IST.[3]	Fishwick, P.A. (1995). Simulation Model Design and Execution. Englewood Cliffs, NJ: Prentice Hall.[4]	Fujimoto R.M. (1998). Parallel and Distributed Simulation. In Banks, J. (Ed.). Handbook of Simulation (pp. 429-464). Danvers, MA: John Wiley and Sons.[5]	IEEE (1995). Standard for Distributed Interactive Simulation, IEEE Std 1278.1, Piscataway, NJ: IEEE Press.[6]	Institute for Simulation and Training (1994). Standard for Distributed Interactive Simulation: communication architecture requirements, Orlando, FL: IST.[7]	DIS Steering Committee (1994) The DIS vision, a map to the future of distributed simulation, Technical Report IST-SP-94-01, Institute for Simulation and Training, Orlando, FL.[8]	Goldiez, B. (1998). Integrating and Executing Simulations. In Cloud D.J. & Rainer L.B. (Eds.). Applied Modeling and Simulation: An Integrated Approach to Development and Operation (pp. 411-471). New York: McGraw-Hill.[9]	Lockheed Martin Information Systems (2000). Combined Arms Tactical Trainer Interoperability Control Document (Contract Report) Orlando, FL.[10]	Giorratano J. & Riley G. (1998). Expert Systems: principles and programming, Boston, MS: PWS.[11]	United Defense LP (1999). Crusader crew station trainer (CST), Minneapolis, MN.[12]	United Defense LP (1999). Bradley Advanced Training System (BATS): Bradley Crew Trainer, Minneapolis, MN.Authors BiographiesPIOTR WINDYGA is a Senior Computer Research Scientist at the Institute for Simulation & Training at the University of Central Florida. He is one of the members of the ITS’s Interoperability team. Dr. Windyga has conducted several projects related to the automatic interpretation of medical images, and developed software for high-level image understanding and 3D reconstruction. He has recently lead HLA-based interoperability projects.ALLISON GRIFFIN is an Associate in Simulation at the Institute for Simulation and Training, University of Central Florida. She has been working in the field of simulation for 4 years and is currently the project lead on the Support to the Simulation Interoperability Standards Organization. In the past, she has also participated in the HLABDS-D project. She also has over ten years experience in the field of nuclear power generation and the manufacture of nuclear fuel rods.BRIAN GOLDIEZ is the Deputy Director and Research Manager at the Institute for Simulation and Training, University of Central Florida. He has been active in interoperability research for 10 years and presently leads a research program whose goal is to move forward in addressing interoperability issues in simulators. He has published and lectured extensively in areas of testing, systems integration, interoperability, and computer graphics.CHARLES SMITH is a military analyst with Madison Research Corp supporting STRICOM and PM CATT. He has spent over twenty years in the Army from Infantry Platoon leader to the Pentagon. His experience includes combined arms operations, R&D, Operational testing and military acquisition. He has worked on the CCTT program since 1992.DANIEL MAGEE is a Senior Military Analyst at Madison Research Corporation, who works primarily on the CCTT Program for STRICOM. He is a retired US Army Lieutenant Colonel who has been working in the field of simulations for the last five years, primarily with the CCTT and AGTS systems. He is a US Army War College graduate and has commanded Army units through Battalion level.GEORGE DAHM is a Senior Computer Analyst with Madison Research Corporation supporting STRICOM and PM CATT. He has over thirty years of experience in the designing and building of computer systems that support database application. He is currently Project Coordinator for the CCTT Scenario library repository system (TREDS Library) used in CCTT. He developed and modified the STRUCCTT training scenarios intended to be used in the testing of BATS. EMBED Visio.Drawing.6  Definition EMBED Visio.Drawing.6  Inter-Operability ScoreInter-Operability CriteriaCCTT AAR/MCC LogsTest PlanExperiment Design TheoryCCTTTraining ScenariosCCTT Exercise BehaviorsFair Fight EMBED Visio.Drawing.6  CasesEvaluation