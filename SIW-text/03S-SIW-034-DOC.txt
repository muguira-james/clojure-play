New Validation Techniques for the Development of Future Combat Systems (FCS) Ms. Michelle T. BevanMaj. (R) Sean N. PriceModeling and Simulation Information Analysis CenterCranfield University Royal College of Military Science  (UK)mbevan@msiac.dmso.mil HYPERLINK mailto:MLong.dgrt@gtnet.gov.uk S.N.Price@cranfield.rmcs.ac.ukABstractThe Twenty-first century has been labeled “The Systems Century”.   Society increasingly relies on highly integrated, complex systems solutions to meet our requirements. This is particularly true in the defense world.  Modern defense systems tend to be highly integrated, complex amalgams of equipment, processes, people and organizations.  The advent of the information age, the growth in integration across and between systems and the increasing constraints on time, cost and personnel has had a very significant combined impact on the approach needed to conceptualize, develop and manage complex systems.  There is talk about “defense capability”, but there is widespread confusion about what it is and how it is measured. Lastly, systems are developed to defeat yet unknown enemies on future battlefields. How are traditional notions of model validation employed when the “real world” does not yet exist?  This paper will consider the meaning of validation for future combat systems, and will suggest an approach that may allow the development of models and simulations that are fit for purpose for decision making in the defense environment."The key philosophical question regarding the nature of models concerns their connection to concrete physical systems and the degree to which they enable us to draw conclusions about these systems."  1. Introduction.The Twenty-first century has been labelled “The Systems Century”.  Society increasingly relies on highly integrated, complex systems solutions to meet its requirements. This is particularly true in the defence world.  Modern defence systems tend to be highly integrated, complex amalgams of equipment, processes, people and organisations.  The advent of the information age, the growth in integration across and between systems and the increasing constraints on time, cost and personnel has had a very significant combined impact on the approach needed to conceptualise, develop and manage complex systems.  Further, we tend to talk about “defence capability”, but there is widespread confusion about what it is and how it is measured. Lastly, we often try to develop systems to defeat enemies whose capabilities are not yet known, across increasingly diverse battlespaces (e.x. the war against terrorism, other operations other than war, new types of engagements, support to the civil authorities). The defence community needs to extend traditional definitions of model validation to include the world that we do not yet know, by using models and simulations that are fit for purpose to address these problems.  In other words, how can we consider the relationship between a model and some “concrete physical system” when neither the system under consideration, the related and interacting systems nor the environment itself exists or is known with any degree of confidence?This paper will address the meaning of validation for future combat systems, and will suggest an approach that may allow the development of models and simulations that are fit for purpose for decision making in the defence environment.  It will be necessary to consider the various types of problems that the community faces in developing, maintaining and employing defence capability. In this paper the problem types will be examined utilising a proposed taxonomy.. [the authors] This paper presents an argument that different notions of model validity apply in different areas of this taxonomy. Further, we this paper will argue that traditional notions of model validity are inappropriate when addressing certain problem types, and that we need to introduce new ideas relating to model validity when addressing models of systems that do not yet exist.The U.S. Department of Defense (DoD) definitions of Validation, Verification and Accreditation are as follows: 1.1 Verification.  The “process of determining that a model or simulation implementation accurately represents the developer’s conceptual description and specification.”  Verification also evaluates the extent to which the model or simulation has been developed using sound and established software engineering techniques.  1.2 Validation.  The “process of determining the degree to which a model or simulation is an accurate representation of the real-world from the perspective of the intended uses of the model or simulation.”1.3 Accreditation. The “official certification that a model or simulation is acceptable for use for a specific purpose.”  It is worthy of note that Verification and Validation are processes, whereas Accreditation represents a decision.  Further, it should be noted that, in these definitions, verification is conducted against a conceptual model or specification, whereas validation is conducted against the real world. Central to the thesis presented in this paper is the fact that this real world often does not exist and is itself a subjective concept. Hence, there is the need to broaden traditional notions to include this. For clarity another pair of definitions are introduced at this stage, due to Law and Kelton:"Verification is determining that a simulation computer program performs as intended.....Thus, verification checks the translation of the conceptual simulation model..... into a correctly working program.  Validation is concerned with determining whether the conceptual simulation model.....is an accurate representation of the system under study.  If a model is "valid," then the decisions made with the model should be similar to those that would be made by physically experimenting with the system (if this were possible).This is useful because it seems to less imply the observable existence of the system under study.  Much of modelling theory has been developed on the premise that the referent (what is being modelled) exists in some absolute sense. In the case of future combat systems (specifically the U.S. Army's Objective Force and Future Combat System0, the referent and the context in which it exists is itself a concept, therefore, new notions of validation are required..  These new notions of validation will be presented in this paper.In this paper we will:Discuss the various types of problems in the defence sphere, introducing a taxonomy of classification.Discuss the meaning of validation in each area of the taxonomy.Consider the philosophical basis for model validation.Consider the specific problems associated with validating models developed to inform those developing the Future Combat System (FCS) and the Objective Force.Outline a proposed methodology for establishing fitness for purpose of models in this area.2.  The Nature of Defence Problems.In the past Systems Engineering in Defence has often dealt with well-bounded systems such as weapons platforms.  Therefore, the need to build up an explicit understanding of different stakeholder views, wider systems and related systems has not been apparent.   In fact, many of the problems that have been experienced when dealing with such apparently well-bounded problems have arisen because too many issues were taken for granted and not fully understood.  This whole situation is changing with the nature of modern systems challenges. Modern systems are highly integrated, complex amalgams of people, processes, hardware and software, where decision-making is often embedded and failure modes are far from simple and clear. They have multiple stakeholders and complex interrelations with other systems. These systems present us with much more open, unbounded, unprecedented problems (and opportunities) and demand a much more explicit systemic understanding of the systems problems, issues and solutions to be developed and communicated.  Further, objectives and expectations are now expressed not in terms of achieving a working technological system, but in terms of delivering a “capability” when the developed solution is introduced into the real world.  This makes the systems engineering challenge a very open-ended problem and demands a systems engineering approach that is much more focused on understanding the real world situation, proposing and exploring candidate system concepts, boundaries and behaviours based on coherent views of problem and system architecture. The move from platform to capability thinking has hence driven great changes in the systems engineering approach adopted.  For the purposes of this paper,  a model will be considered as:"a purposeful simplification of a named and bounded entity which is the “referent” of the model ... (which)... preserves key characteristics of the referent, suppressing others... (and) ... suits a particular problem in hand and a constituency of users."Models are key to the development of understanding how to relate to the types of systems described above, its communication, and ultimately its realization into a field able physical system. However, for any model to be useful it is necessary to feel confident that it is fit for purpose in order to support the decisions for which it is designed. This brings new challenges to traditional notions of simulation model verification and validation.The use of modelling and simulation in defence acquisition helps resolve problems. In the main, these problems relate to some notion of actual or perceived capability gap.  As the problem and its understanding is central to the development of a model set to support decision making, it needs to be very clear on what is meant by a problem. Sage describes a problem as: "An undesirable situation or unresolved matter that is significant to some individual or group and that the individual or group is desirous of resolving.  Problems have four basic characteristics.1.	There is a detectable gap between a present state and a desired state, and this creates a concern.2.	It may be difficult to bring about concordance between these two states.3.	The situation is important to some individual or group.4.	The situation is regarded as resolvable by an individual or group, either directly or indirectly.  Solving a problem would constitute a direct resolution.  Ameliorating or dissolving a problem, by making it go away, is an indirect resolution of the problem."3. PROBLEM TYPES.Problems can be classified according to their characteristics. The problems logically divide into the following classifications:Deterministic/QuantifiableQualifiable/CategoricalPartially DefinedResearch/UndefinedA matrix illustrating these problem types is shown in Figure  #1.EMBED PowerPoint.Slide.8Figure 1The characteristics of each problem type are discussed below.3.1 Area One:  Deterministic/Quantifiable.	Deterministic means that two or more given variables put together in the same sequence, with the same parameters, will always result in the same outcome.  Deterministic events are always the same, something on which one can count, and plan.  Quantifiable added to this definition means that the event is predictable enough to be able to quantify in exact numbers.3.1.1 Area One Example.	A chemical reaction of two elements, in the same environmental circumstances, will always be the same.  Add vinegar to the baking soda in your home-made volcano and you will always get a large, overflowing amount of foam.  	In simulation, semi-automated forces (SAF) are constructed by this principle.  If given A (a vehicle approaches a marshy area, then B (the vehicle behaviour will be to turn away) – each and every time. 3.2 Area Two:  Qualifiable/Categorical.	This sector depicts those events that cannot have a specific numerical value assigned to them each time. One is able, however, to categorize events by putting them in separate bins.  Those qualifiable bins might be small, medium and large.  They may be a range of actual numbers that are associated with those categories.  However, they are not as easily definable as a deterministic event.  These could have statistical weight added to them, with a category containing the mean, around which the bell curve was formed.3.2.1  Area Two Example.	Involving the human user into a simulation event to test the validity of a system design might mean placing different people into a mock cockpit or driver's compartment.  Questions about comfort, ease of use, and 'feel' of the system are not data that can be quantified (as you would with degree of look angle, measurement of reach, etc).  Those answers would be put into survey categories, with ranges assigned.  Therefore, the output of this type of simulation or event would result in data such as "good" or "bad." 3.3 Area Three:  Partially Defined.	Partially defined means that you have an idea of the type of problem that you want to solve, and perhaps an idea of what it might take to solve it.  But there are no definites.  Research and development ideas that have received approval to move forward would be in this area.  The ideas are well formed, but the way in which to solve those problems is unclear.  3.3.1  Area Three Example.	Perhaps the problem in this area is the issue of weight and resilience of the warfighters' clothing.  A researcher has developed a new material that is lightweight, yet very strong.  The testing of this material will be the way in which the categories of 'goodness' will be created.  For instance, it may be that the material is lightweight, very strong, rust-resistant, and yet causes a magnetic field that interferes with other parts of the soldier system.  Only continued testing and refining can show if the problem can be solved and with what technology.  The simplest form of simulation is testing a hypothesis.3.4  Area Four: Research/Undefined.	It is this particular sector that is the least well-defined.  This is the area of the unknown.  It is not known what technology will be developed in the future, or what warfare will look like.  Likewise, it is not known know what commerce and daily living will be like in the future.  To prepare for that future, we can only postulate. This area is one of pure research and speculation.  Even our language has changed due to technological development.  (The word 'rotary phone' was not needed until pulse dialling was invented). That  applies to the technology growth as well.  As one simulationist once said, “even the best buggy whip maker has to consider moving into the area of automobiles ONE day.”   The answer is to develop a variety of ideas that can be tested through time, those that allow for incorporation of technology, doctrine, and other factors as they develop.3.4.1 Area Four Example.Future combat systems are a perfect example of an Area Four problem type.  What will the future look like?  There are numerous organizations looking into that exact question.  There is a group within the National Aeronautics and Space Administration (NASA) whose job it is to consider ANY technology no matter how farcical it might appear.  Jules Vern and Michelangelo's ideas might fall into this category.  Yesterday's flying saucers and laser guns are now unmanned aerial vehicles (UAVs) and laser-guided weaponry.  4.  TAXONOMY OF OBSERVANCE.Another characteristic of problems can be illustrated by the use of a matrix relating system observability and system repeatability.  This is illustrated in Figure #2.Figure 2Each of the four areas shown in Figure 2 is discussed in greater detail in the following sections.4.1  Observability.Much of modelling and simulation theory has been developed around the idea of an existing and observable referent. Thus M&S is well-placed to support the organisation of logistics systems, the design of manufacturing systems and a multitude of other scenarios where the model can actually be compared to some existing reality.  However, in many of the cases that M&S is utilised to inform in the defence sphere, neither the systems nor the scenarios in which they operate exist. Thus it can be said that the referent is itself conceptual (and hence subjective); there is no generally accepted reality even in theory. 4.2 Repeatability  The development of statistics as a quantitative science relies on the existence of a set of events which are repeatable (i.e. the tossing of a coin, repeated shots at a similar target with similar munitions under similar conditions, etc.). Based on this notion of repeatability across a population of possible events, population parameters can be estimated based on sample statistics taken from a random sample. This in turn allows the development of (the related) notions of statistical confidence and significance. From this standpoint statistics can be utilised to predict outcomes based on notions of confidence, allowing the introduction of the concept of risk. However, there is another set of events which represent one-off, single-shot events. In these events (i.e. horse races, football games) the conditions surrounding the event mean that repeatability is impossible, even theoretically. This is because of the multitude of surrounding and influencing factors that drive the outcome of the event. This phenomenon of non-repeatable events can only be emulated as one of many possibilities in a simulation.  This type of simulation (referred to as Monte Carlo simulations) – whereby all the possible variations of circumstance are represented is itself limited.  The authors propose that there is no way in which to know that all possible circumstances, events, and variables can be modelled.  First, it is against the concept of modelling, which is a representation of one user's view of reality.  Secondly, it is impossible to know all combinations of possible circumstances and variables that might come into play in a real world scenario.  In the case of future combat systems in particular, whereby the environment, systems, friendly and opposing forces’ systems capabilities are only postulated.4.3  Area One:  Repeatable/ Observable.	This sector is the one in which experiments can be run, observed, measured and tested.  For each iteration, there is a methodology and way in which to document the results.  4.3.1 Area One Validation.	This type of validation is the most historical, and the easiest to conduct.  Because events are observable, quantifications can be made.  Because they are repeatable, one can validate theories that may arise for an explanation or answer to a problem.  Copious amounts of data are available. 4.3.2  Area One Example.	Field testing is the best example in this case.  Testing machinery is largely located in Area One.  A road test can be conducted on a vehicle time and again to determine wear on the tires.  The wear can be measured against exact conditions on the road test.  The tests can be performed again and again, and then the parameters can be changed, then the tests performed again.  Each time, the control lies with the tester/observer.4.4  Area Two:  Repeatable/Non-Observable.	Repeatability is a key here, again, to provide sufficient quantity of data for test results.  Not being able to observe a phenomenon, however, leaves one to postulate the cause for the behaviour that is repeated. This area poses a problem in the ability to decide which factor or parameter of a repeatable event was responsible for the outcome.  4.4.1 Nature of Validation for Area Two.	Validation in this sector is consequently more difficult to conduct because it is more difficult to pinpoint cause and event trails.  The type of validation in this sector is often left to something called "face" validation.  Face validation is when a sufficient number of experts have run a model a reliable number of times (note the subjectivity in both of those parameters) for the experts to have confidence that the model or simulation is valid.  In other types of validation, observable components are validated separately and the non-observable components are validated because of their association to the observable components.4.4.2  Area Three Example.	Chemical reactions at the sub-molecular level are an example of a repeatable process that is not observable.  Although techniques have been developed to slow time down and even provide motion capture at a molecular level, there are areas in which observation is still not possible.  It is not necessarily possible to see a chemical reaction between elements, but it is possible to see the results.  It is also possible to isolate some of the chemical components to test separately.  	One note is that some [what?] previously categorized here in Area Two have made the transition into Area One through the use of simulation techniques.  The Tank-automotive Armaments Command (TACOM) created a virtual simulation of a trailer hitch that, in field testing, continually broke.  There was no way in which to place a person or a camera to observe the way in which the hitch was moving when it broke in field test.  The replication in simulation allowed the virtual observer to see exactly what was happening.  Therefore, the component then could be fixed.. 4.5  Area Three:  Observable/Non-Repeatable. 	Warfare, riots, and most anything to do with human interactions given a specific set of circumstances are not repeatable. Anyone can watch a mob at work each time one forms, but you will never see the same thing twice. 4.5.1 Area Three Validation.Validation is very difficult in this sector according to traditional definition. Because the behaviour cannot be replicated, statistically significant data cannot be gathered to model it. The only way in which to model non-repeatable events is to 1) capture generic characteristics of the observed system and 2) understand that the data is the result of some inner determinant rather than the variable itself.4.5.2 Area Three Example.	Human factors modelling has been a challenge for as long as it has been attempted.  Great strides have been made in semi-automated forces (SAF) to model doctrinal behaviour to specific situations.  However, incorporating specific motivating factors behind a behaviour into those models  (thereby putting variability into the model that is more like a human mind) has been difficult at best.  One technology that is moving in the direction of a solution is in agent-based modelling using fuzzy logic.  That topic, however, would be the subject of at least another entire paper.4.6 Area Four: Non-Observable/ Non-Repeatable.	This area, without a doubt, is the most difficult to validate.  Area Four describes those events that only happen once and that humans cannot directly observe.  The inner workings of a leader's mind at a crucial decision point, for instance, is a process that cannot be directly observed nor repeated in a laboratory.  4.6.1 Area Four Validation.	Because statistical data cannot be recorded for these non-observable/non-repeatable types of events, traditional validation is not possible.  However, because we know that in wars these events not only take place, but also have great significance in our lives, we strive to find a way in which to represent them, and thereby perhaps, understand them better.    Area Four specifically focuses upon a new way to view validation4.6.2 Area Four Example.	The inner thought processes of Hitler are one example of non-observable/non-repeatable processes that jumps to mind.  How could one predict the creative cruelty of gas chambers?  How could one put sociological factors, the power of personality and the timeframe in which he reigned into a model to be able to predict his behaviour.  In this instance, engineers and simulationists have tried to 'reverse engineer' the way in which he might have thought, to find the factors that influenced him. In this way, they hope to be able to predict situations in which similar atrocities could happen in the future.5.  IMPLICATIONS FOR VALIDATION.Traditional validation theory has been developed to cope with models of observed, repeatable systems such as physics based models and well defined Operations Research (OR) problems such as supply chain models, logistics models, etc..  It is the authors’ contention that the move to establish confidence in un-observed, unrepeatable systems and quest type problems requires a move to a new concept of validation.  Indeed, use of the word validation in this area may itself be clouding the issue.  In painting-by-numbers type problems and repeatable observable systems we can validate our models against an existing observable real world. Then conclusions can be drawn and stated using statistical notions of confidence.  In quest type problems relating to unobservable, unrepeatable systems all an validation agent can do is achieve a degree of confidence that everything has been thought of in relation to the concept.  In essence we believe that we have developed a model that would allow us to address the problem with more confidence than if we did not have it.  It may well be that the modelling exercise itself produces any tangible benefit – the model itself is a transitional object that allows us to move from one level of understanding to another, heightened level.We believe that this confidence can be achieved through a systematic and systemic consideration of the perceived problem area. However, this will be necessarily subjective and will carry no notion of scientific confidence, much less any notions of correctness. In order to illustrate this it is necessary to revisit some of the philosophical tenets which underlie traditional notions of model validity.6.  Philosophical Basis for Validation.Modelling has been seen as "valid simplification". The process of modelling involves abstraction and the establishment of context in the light of some clearly stated problem. Without this clear problem statement it is impossible to know what can be abstracted out of the context of consideration.  Hence, a problem statement is central to validation requirements.  It follows that:(1) General validity is impossible, because this implies validity in consideration of all problems and;(2) Validation is as subjective as the modelling process itself, i.e. different models developed by different modellers in consideration of the same purpose may be equally valid to each of them. From this it can be observed that it is difficult to establish absolute standards in validation. Further, in quest type problems, where the problem itself is extremely unclear, how  a model is developed that is fit for purpose is an extremely difficult judgement. In this section  some of the ideas behind the establishment of validity are discussed.6.1 Turing Test Model of Validity.A new "working definition" of validity can be introduced, drawing on the idea of a Turing Test.  As has been recently stated, “(a)pplication of the Turing concept to a systems model is stated as follows:  A systems model passes a Turing Type test if a systems domain expert cannot determine if the data presented for inspection came from the model or from the physical system”.Thus it can be stated that a model is valid if the insights gained by the user in conducting his study are similar to what he would have come to if he were interacting with the real world reflected in the model. One of the consequences of this analysis is that validity is a necessarily subjective notion.  In the military domain, it is not unusual for experts to disagree in the light of the same environmental information.  Secondly, from the working definition of ???? (SE) given above it is foreseeable that different people will in essence lead to the emergence of different SEs.  This tends to make the notion of SE validity even more subjective.  As Boyd goes on to state, “(d)omain experts have formal training and/or experience in the systems domain.  However, domain experts are not infallible and have been known to reverse or even contradict themselves!  Frequently, participation in calibrating and validating a systems model will be a learning experience for them.  Even though validated by knowledgeable experts, the model continues to be regarded as a test hypothesis.”In the case of the existence of a system, or indeed when it could exist (for example, the outcome of an engagement involving certain weapon systems in some scenario) a Turing-Type test may be admissible. But in the case of Future Combat Systems (FCS) the domain knowledge does not exist because it is itself a subjective concept. Thus, it does not seem that a Turing-type test can be employed unless it is first recognised that the validity is judged by the individual validation agent based on his own subjective judgment and conceptual model set of the environment in which FCS will work and exist. Even where this is clearly stated as a set of assumptions, it still represents a conceptual model rather than an observable reality.6.2  Validation as Falsification.Sir Karl Popper introduced the idea that what distinguished scientific theories from theories that claimed to be scientific but were not (such as astrology) was the idea of falsification.  Earlier philosophers had developed the idea that scientific method involved stating a hypothesis and gathering evidence to support it.  Popper turned this idea on its head.  In essence, he stated that the primary responsibility of scientists was to attempt to refute their theories.  Central to the idea of falsification is the claim that “while we can never show beyond all doubt that a scientific theory is true we can often show that it is false.  For if a theory has true observational consequences, that does not show that it has to be true.  But if it has false observational consequences then it has to be false.  So with a single observation we can refute a theory.”    Hence, it is only possible to falsify theories through evidence, but never possible to support them through evidence.  Thus, the burden of proof lies in showing that the theory is wrong, not right.  Whilst this doctrine was developed to analyze the validation of physical law, it does not seem unreasonable to carry this across to the domain of modeling.  Therefore, the logical conclusion is that the validity of models and simulations can only be disproved, never proved.  To summarize, "Popper ... limited the role of experience in scientific endeavor to one of indirect and unilateral testing, inasmuch as it can beget only falsification and never verification.  Hence:"The possibility of refuting theories by observations is the basis of all empirical tests.  For the test of a theory is, like every rigorous examination, always an attempt to show that the candidate is mistaken - that is, that the theory entails a false assertion.  From a logical point of view, all empirical tests are therefore attempted refutations.”The establishment of validity thus reduces to an inability to disprove validity if this doctrine is accepted. To a large extent this is well understood by the modeling community.  The following quote from a recent book by John Sterman, the Systems Dynamicist, summarizes this well:  "Unfortunately, testing is often designed to "prove" that the model is "right", an approach that makes learning difficult and ultimately erodes the utility of the model and the credibility of the modeler ... Model testing should instead be designed to uncover errors so you and your clients can understand the models limitations, improve it and ultimately use the best available model to assist in important decisions."  In the case of FCS and the objective force operating in future scenarios, these empirical observations are in principal impossible.This also relates to the amount of effort that should be expended in the validation effort. If falsification is the goal, may only need initially an order of magnitude confidence in the model.  Greater effort will not have a greater chance of proving the correctness of a model, rather it will only serve to give us confidence that the model is useful for our purposes.  This equates to a decision about resource allocation. What is needed is an acceptable level of validation for each purpose.   Therefore, Acceptance Level One Validation is ALV 1, and so forth.  An early stage, low-resolution model may not require a high fidelity validation.  However, as the model is enriched and developed a greater V&V effort is required.  It has often been said that an Nth order model should be utilised for an Nth order purpose.  Perhaps we should borrow from this phrase to introduce a validation maxim, An Nth order problem requires an Nth order model, and an Nth order model requires Nth order validation.Figure #3 illustrates this balance in a graphical way.  Total validity is unachievable, but confidence can be gained from being unable to show that the model is not fit for purpose in some area.  If greater confidence is required, greater effort (and hence resources) are needed to establish this confidence.  Finally, the validating authority is the person who specifies what constitutes fitness for purpose.  In essence, then, establishing fitness for purpose involves trade-offs between resources (time, cost, effort) and confidence.  The figure attempts to illustrate this graphically, but is not meant to be taken too literally.Validation efforts are currently linked to mathematical, quantifiable results in the minds of many.  This is an idea that grew out of the reasoning that validation of a model was always possible because it was done in conjunction with testing, long timelines, and funding to allow for extensive study.  Originally in system acquisition, M&S was used as a supplemental tool, and this methodology could be pursued. In recent years, however, M&S has been used to not only supplement test data, but, in the case of future systems, supplant or replace it. This philosophy flies in the face of the original definitions and concepts of verification and validation (V&V), which was to augment. Figure 3However, the environment has rapidly changed to one of projecting the requirements, capabilities, and changing face of the battlefield/area of operation rather than existing scenarios.  This is a reason for creating a new term to address the issues needed to accredit a simulation/model for the Objective Force. Another interesting consequence of Popper’s ideas is what not being fit for purpose means.  A model is not fit for purpose if it is not useful.  In the case of a painting-by- numbers type problem system this may be an easy judgement to make, but in the case of a quest type problem relating to non-existent worlds, it is arguable that most models could be useful in helping to raise awareness of the issues involved.6.3 Simulation as the Observance of Theory.Simulation is an experimental science.  An oft seen definition of simulation starts with the phrase “simulation is an experimental technique…”.  This is true, but it obscures an important fact.  The defence community has been led to believe that a simulation experiment has much in common with a laboratory experiment.  However, in a critical sense, simulation modeling is an observance of the consequences of theory.  Simulation modeling allows us to investigate the consequences of theory in an often very graphic and realistic way.  For this reason there is the tendency to attribute a greater validity to simulation models than perhaps they warrant.  As has been stated, “computer experimentation is in a crucial respect on a par with all kinds of theoretical speculation:  the difference between them lies in the richness and variety of the information that the computer provides about the theoretical consequences of those speculations.”   The output of a simulation study is therefore, importantly, theoretical.  Thus the model demonstrates the consequences of our conceptual model (if it has been verified).  The primary difficulty is that, in general, human brains are conditioned to believe what they see above perhaps other sensory stimuli. Hence, the adage,” Seeing is believing.”  Because of this, it is discovered that people often tend to associate a greater credibility with simulations (particularly the high-fidelity, visually realistic virtual environments) than the underlying models and algorithms may warrant.  But there may be more than meets the eye.6.4 Validation as Fitness for Purpose.In previous sections it has been established that validation is necessarily a process of attempting to prove the unsuitability of a model, simulation or SE.  In other words, validation agents attempt to show that it is not fit for its intended purposes.  As Robinson has stated, “(i)n V&V the aim is to ensure that the model is sufficiently accurate.”  It becomes apparent, as stated above, that validation as a concept does not make sense without an understanding of the purpose for which the model is being used.  As there may be several purposes for which model may be used in its lifetime, each separate purpose (and therefore use) requires a new validation process.  These ideas may be in line with one of the earlier definitions of validity introduced here, which is due to the System Dynamicist Jay Forrestor; "(m)odel validity is a relative matter.  The usefulness of a mathematical simulation model should be judged in comparison with the mental image or other abstract model which would be used instead.”  Further, this destroys the notion of general validity.  General validity implies a suitability for all purposes, which is clearly not possible.It is determined therefore, that even in verification and validation methodologies that are employed today, the final requirement for usability is linked to the accreditation of the model or simulation for the system.  That means that each instance within which the model is used must be accredited.  Within an acquisition program, that might mean three or four times before various milestone events.  Unfortunately, even with an understanding of this requirement, timelines and funding often drive the depth with which the accreditation (and background V&V) is executed.  Accreditors are often forced to accept a poorly validated model because of those constraints.  The concepts behind the V&V should therefore be merged with the accreditation process.  Previously these were referred to as:(1)	Meeting the fitness of purpose requirements and(2)	Consideration of the use of a model in validation itself.6.5 Implications.A series of conclusions can be drawn about the nature of validity. They are:The establishment of general validity is not possible; validity can only be established in the specific context of a purpose.Domain validity (the validity of a model for a certain purpose) is established by determining fitness for purpose.A model is fit for purpose if its suitability cannot be falsified when used for its intended purpose.  In other words, if a model can be shown that it is not useful or fit for a specific purposes it would be normal to draw the conclusion that it can safely be used to assist the drawing of conclusions in the domain that it has been tested in.The Turing Test notion that a valid model will lead to similar insights to those gained from the real world that the model represents.Simulation modeling is the observation of the consequences of theory or assumptions.  It has no greater inherent reality than the axioms of that theory, or, alternatively, the assumptions in the underlying conceptual model. 7.  Requirements on Validation for FCS.The Objective Force (OF), the Future Combat System (FCS) and any other concept of operations that will be utilized for the future, will have different requirements for validation.  The reasons have been discussed previously, and can be summarised as follows:  Future systems will require futuristic capabilities, which cannot be pre-tested in the same way that existing systems can.  The acquisition lifecycle is, by necessity, getting shorter.  Reuse is of the utmost importance to have a chance of fielding a new system.  That reuse applies in the areas of models and simulations, technology, information storage and distribution.  This directly relates to the change in validation required for future systems – we must reuse information and test data in the areas of high confidence.  That is, we must use our knowledge of physics and the natural world to be able to have confidence in the way in which a system will work – even without being able to test it prior to manufacture.  The space shuttle program is a good example of pre-testing capabilities in a simulated environment before executing the mission.  There is no trial run for space operations.  There will be little if any opportunity for trial runs for future capabilities.   However, it is still essential to validate – or apply acceptance levels for those projected capabilities.8.  WHY TRADITIONAL VALIDATION THEORY IS INAPPROPRIATE.Traditional validation theory presumes the existence of a system and the availability of test data.  Only in recent years has the defence community started to trust modelling and simulation to provide additional data for evaluation of a system.  As discussed above, the future does not allow for long procurement timelines, large funding pots from which to pull, nor assurance that a technology will function years prior to employment in a system.  Therefore, it is essential that the community change the way in which validation is conducted.9. "MODERN" VALIDATION AS ACCEPTANCE LEVELS OF VALIDATION (ALV).9.1 Enhancing Confidence.	Throughout this discussion, validation has been referred to as the way in which to imbue a user with confidence about the way in which the model works.  Confidence has been linked to validation through observable, repeatable events for testing.  The thinking for the future must change as we boldly step forward into a new era of technology, for which battlespace and doctrine does not yet exist.9.2 Ensuring Completeness of Consideration.A crucial issue in moving from test-based results validation to future systems is ensuring accountability for  all angles. This means that all those involved throughout the acquisition lifecycle must play a part in 'validating' a system. It is no longer acceptable to have one group of testers or analysts validate a simulation or model for use.  Those models and simulations are now expected to work across acquisition lifecycle phases, and prove viability or non-viability.  This has to be done within the context of the operational concepts, doctrine and world events. 	Whether for a military endeavour, an international peace-keeping mission, or humanitarian aid involving every ilk of person across the spectrum of the world's population, completeness means trust from those using the system. 	Therefore, it is essential to develop a methodology that addresses the concerns of all individuals within a given scenario.  That translates to involvement of a representative of each of those areas be involved with development of not only a future system, but the models and simulations that accompany it.  9.3 Validation Effort.	Validation is now a consideration for the entire system, its sub-components, the users, doctrine/law and decision-makers.  Therefore, an authoritative representation of their involvement is needed for a proper, validated simulation for the future.9.4 A Subjective Process.	Naturally, when it comes to people, there will be as many opinions as there are people themselves.  Just as with statistical sampling or modelling and simulation, only a small subset of those involved with a problem/technology/area of interest will be represented.  The subset that represents those groups must be convincing to members of each of the groups themselves.  This means a change in culture, which is one of the cornerstones of the simulation based acquisition process.  Again – that could be the subject of yet another entire paper.  	Having laid the groundwork and justification for a new type of validation, next a framework for labelling and executing validation for future systems is proposed.10. Approved Levels of Validation.	How many levels of validation are enough?  Ask the participants. Who are those participants?  The participants are those who are  interested in validating a system. The answer to this question will evolve over time as the system is tested.  Our first proposed number of levels is three.  10.1 ALV One. 	ALV One is basic validation, related to face validation of previous years.  Face validation was often applied for Analysis of Alternatives (AoA) when there was no time or funding to do a formal verification or validation process.  However, the model may have been in use for several years in circumstances that were similar to one another.  Face validation also occurred for systems that did not have a change in their basic configuration, so none of the laws of physics were tested with a completely new system.  The older and better known the system, the more trusted the model or simulation that had been used to predict such factors as mobility and range.  	ALV One will extend that to models and simulations for which there has been a proven track record for current systems.  For instance, if a model represents a tracked vehicle operating on earth in well-defined areas (the soil characteristics, the weather patterns, etc. are known), a model would be assigned ALV One.  ALV would be used only for models that were not concerned with high priority level Measures of Effectiveness (MOEs) and Measures of Performance (MOPs).  For instance, ALV One would be insufficient to assign to a MOE or MOP that was concerned with survivability of the crew.  It would, however, be able to be assigned to the reliability of the material that the tracks were made of, within the parameters of past data.  For instance, this model would be used to validate the track and its functionality against understood threats (such as razor wire, land mines and various soil conditions).10.2 ALV Two.	ALV Two would consist of a greater risk to the system and require more effort in reviewing the model.  These models would deal with either 1) A higher risk MOE or MOP that was being addressed or 2) A technology that is less than 5 years old. 	ALV Two would be awarded when a model of a new technology was integrated into an existing system.  For example, a new radar technology might be added to an existing aircraft.  The technology is new, but the way in which it is used is known.  Laboratory testing of the model would be required, in conjunction with proven models of the existing system.  The reason ALV Two would be awarded is the relation between the proposed technology and the documentation and modelling results.	To receive ALV Two, the model must have appropriate documentation to explain the technology, and how it relates to the system itself.  The ALV itself is a step beyond using only test data  - because the simulation itself is proving the initial tests.  This is taken one step further in ALV Three.10.3 ALV Three.	ALV Three is used for the most risky, and newest technology.  It is involved with technology that has high impact on system and crew survivability, lethality and vulnerability.  Because it is the riskiest, it is the least well understood or trusted outside of those developing the technology.  There are new systems about which very little is known.  It is then imperative to rely on the documentation and theories behind the technology to be able to have any confidence in the models that represent it.	Documentation and research from accredited organizations (laboratories, universities and the like) is essential.  That documentation must be reviewed very carefully as well as, the model that represents the proposed technology.  Modifications to software and current models will be needed as the technology matures and can be tested in a simulation environment.	ALV Three is a certification that the model has undergone a rigorous examination of the conceptual technology. It has been reviewed by outside sources and 'tested' within the virtual environment. The simulations for the technology must have repeatability to have the user gain confidence in the technology. Those tests must be integrated into the simulation wherever possible to highlight where a technology change would affect a proposed system. 	In summary, ALV Three means that not only has the model or simulation been tested for accuracy, reliability and applicability, the technology itself has been re-verified by those who will be using the model.  11.  ConclusionThe very words 'validation' and 'verification' (V&V) have been defined so well that they are no longer flexible for determining new methods of performing them for future systems.  They are associated with long years of test data, existing systems, and understood technologies.  Because of these factors, and exponentially rising system costs, traditional V&V techniques have become cost prohibitive to embark upon in system acquisition.  Further, the way in which V&V is conducted precludes the ability to validate a system that has not yet been created and has no test data.  Our changing world and rapid technology development will not support the lag in the way in which we provide for confidence in our systems.Throughout this paper, the definitions, techniques and problems concerned with validation have been presented.  Also presented was a new way in which to not only perform validation, but to label it differently (Approved Levels of Validation (ALV)) so that those who will perform validation on future concepts will not be held back by traditional definitions.The world is a rapidly changing place. Technology has more than exceeded Moore's Law already, and yet our processes by which to build new systems to incorporate that technology lag.  With a better understand of how to imbue a user with confidence in the models used to demonstration and validate a system, we can take a step forward in getting those new systems and technologies to the user.12.  Biographies.Sean Price is a lecturer in the Engineering Systems Department, Cranfield University at the Royal Military College of Science where he is a member of both the Applied Mathematics and Operational Research Group (AMORG) and Systems Engineering Group (SEG).  He is the Academic Leader of the Systems Engineering for Defence MSc.  Prior to joining the academic staff of RMCS, Mr. Price was an officer in the Army for 13 years, leaving as a Major in 1998. His research interests centre on the use of M&S to enable the effective acquisition of defence capability, with particular emphasis on the closer integration of synthetic environments and systems engineeringMs. Bevan has been a part of the Modelling and Simulation community for 12 years, working primarily with military organizations.  She has been with the Modelling and Simulation Information Analysis Center (MSIAC) for three years.  Her experience in Verification, Validation and Accreditation (VV&A) started with the Army Test and Evaluation Command (ATEC) and the Comanche and Crusader programs.  She has created and taught courses in VV&A, Simulation Based Acquisition (SBA) and many other areas within M&S. Morrison. (1999). Models as Autonomous Agents. In Models as Mediators: Perspectives on Natural and Social Science (38-65). Cambridge: Cambridge University Press, 38 U.S. Department of Defense. (12 April 01) JP1-02, DoD Dictionary of Military Terms and Associated Terms (As Amended Through 9 January 2003), 559 Ibid. U.S. Department of Defense. (23 March 94) JP1-02, DoD Dictionary of Military Terms and Associated Terms  A. Law, & W. Kelton. (1991). Simulation Modelling and Analysis (2nd Ed). Singapore: McGraw-Hill, 299 Myers et al. (2001). Models for Effective Analysis of Systems An Industrial Case Study, Systems Engineering, 4(1), 76-85. A. Sage. (1992). Systems Engineering. Chichester: John Wiley & Sons, 232 D. Boyd. (2001). Systems Analysis and Modelling. Academic Press. Morton, Philosophy in Practice. Corvi, An Introduction to the Thought of Karl Popper, (Inner quotes taken from Conjectures and Refutations:  The Growth of Scientific Knowledge, Routledge and Kegan Paul, London 1963, p.192 J. Sterman. (2000). Business Dynamics: Systems Thinking and Modelling for a Complex World. London: McGraw-Hill. R. Hughes. (1999). The Ising model, computer simulation, and universal physics. In Models as Mediators: Perspectives on Natural and Social Science  as Mediators: Perspectives on Natural and Social Science (97-145). Cambridge: Cambridge University Press S. Robinson. (1999). Simulation Verification, Validation and Confidence: A Tutorial, Transactions of the Society for Computer Simulation International, 16(2), 63-69. PAGE 11 of  NUMPAGES 15EMBED PowerPoint.Slide.8