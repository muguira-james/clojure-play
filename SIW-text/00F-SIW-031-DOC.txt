RTI-NG Performance in Large-Scale, Platform-Level FederationsWayne CivinskasBrett DufaultDeborah WilbertLockheed Martin Information SystemsAdvanced Simulation Center37 North AvenueBurlington, MA   01803781-505-9500wcivinsk@lads.is.lmco.com, bdufault@ lads.is.lmco.com, dwilbert@lads.is.lmco.comKeywords:HLA, RTI, scalability, Joint ExperimentationABSTRACT: The capability to simulate some elements of a large-scale conflict at the platform level is an essential requirement for both the staff-level training and Joint Experimentation simulation domains. For example, the capability to locate and destroy tactical ballistic missiles (TBMs), a platform-level asset, remains a difficult challenge for our forces. As such, the ability to provide simulations of these threats and the appropriate counter-measures for analysis and training is required. The RTI must be able to support such simulations in a distributed fashion. One such federation is the JSAF Federation, which is being utilized by U.S. Joint Forces Command (USJFCOM) to support large-scale simulations using a non-standard networking infrastructure. Using the JSAF Federation and replacing the non-standard networking software with RTI-NG, experiments were conducted to determine the scalability of RTI-NG for these types of federations. This paper discusses these experiments, their results and the insight they provide into this important axis of RTI performance.1. Simulation Scaling Requirements for Joint ExperimentationJoint Experimentation applies distributed platform-level simulation technology to the problem of collecting, developing and exploring various concepts that may achieve significant advances in future joint operational capabilities. Given the large-scale nature of joint operations (i.e., theater-level conflict), Joint Experimentation inherently involves the simulation of many thousands of objects. For example, experiments that include target identification and nomination require simulating a large amount of background traffic to make that task challenging. Also, in addition to simulating “ground truth” platform-level objects, Joint Experimentation requires simulation of intangible components such as tactical knowledge and sensor information (i.e., “perceived truth” objects)[1].Consequently, large numbers of federates are required for Joint Experimentation. These federates are needed to provide both the large number of objects simulated in the exercise and the user interface workstations for the military operations experts who are participating in the experiment (“players”). In a large exercise, support functions such as exercise control and logging are especially critical and require several additional federates.Joint Experiments tend to be run for long time periods: several hours a day for several days. This implies a requirement for being able to save exercise state without interruption and the ability of late (re-)joiners to come online without any effect to the ongoing exercise.Also, implicit with the requirement for a large number of federates and objects is the ability to start or restart an exercise containing all these federates and objects within a reasonable time. The total startup time for a Joint Exercise must be about thirty minutes or less to be considered reasonable.These requirements indicate that the Joint Experimentation simulation system must be scalable. The scalability of the system as a whole is the complex result of system and application design, including interactions between components and the way resources are used. The RTI is a critical component that must perform in a scalable fashion in order to achieve total system scalability. The RTI must not only avoid hard internal limits, but must also algorithmically constrain its use of resources to remain scalable.In addition to these requirements in common for Joint Experimentation, there can be federation-specific requirements, which fall out of the design and use of those federations. These may (or may not) include, for example, high attribute update rates, removal of object rates, or heavy use of reliable transfers.The following sections investigate two Joint Experiments and their specific requirements. The first is J9901, which was completed in 1999. The other is Attack Operations 2000, which is currently ongoing.1.1 J9901 RequirementsJ9901 was a "discovery experiment" focused upon “the use of potential future surveillance systems to defeat mobile theater ballistic missile launchers." In the scenario, "the U.S. is an ally of Blueland. When Redland threatens Blueland, U.S. forces are deployed to the area. Redland responds with mobile TBM attacks. The U.S. counters with a special attack operations cell with dedicated sensor and attack assets"[2].A total of seven J9901 trials were conducted, each lasting about six hours a day, for four to five days.A typical event included around 10,000 "clutter" or background vehicles. While clutter vehicles are capable of movement, it was acceptable for most to simply be present and remain static. Other vehicles in the simulation included 1,200 semi-automated OPFOR vehicles, 150 semi-automated blue attack vehicles, 100 blue sensors and around 5,000 radar tracks, all of which were represented by objects. So, the total requirement in J9901 was for somewhat under 20,000 simulated objects. For the most part, these objects were provided by the JSAF v4 Computer Generated Forces combat simulation, or by a JSAF v4 variant, the ClutterSim[3].Blue staff (cell) workstations, based on JSAF Plan View Display (PVD) federates, displayed ground truth data about blue forces and blue sensor footprints, and perceived truth data about red forces. Red cell PVDs displayed red ground truth data.White PVD federates were used to support "battlemaster" functions as well as exercise management functions such as initialization, checkpointing, and recovery. White PVDs could be configured to perceive any point of view by the operator in the white cell. The white PVDs were often switched between blue or red perceived truth and blue or red ground truth, or some combination, in order to understand what the players were attempting to do, and why.The white MARCI (Multiple-host Automation Remote Control and Instrumentation) federate was instrumental in limiting the required manpower for exercise control and management. A single operator using MARCI was able to start the entire federation, consisting of about 75 federates disbursed across four sites, with fewer than 50 clicks from a single, centralized federate. Initialization took about 10 minutes to start all federates and another 10 minutes to create the initial object state, for an acceptable total initialization time of about 20 minutes.1.2 Attack Operations 2000 RequirementsAttack Operations 2000 (AO2000) builds upon J9901. The purpose is to determine if a Critical Mobile Target Attack Operations Cell (CMTC), similar to one used in J9901, can successfully find, track, and destroy critical mobile targets using weapons system capabilities consistent with the year 2007. The goal of the experiment is to find the most efficient design of the CMTC itself.As in J9901, blue cell staff play a key role using PVDs displaying perceived truth as filtered through the sensor models in the simulation. They are required to build up a cognitive picture of where the OPFOR are, and what they are doing. The OPFOR are hiding in forests, cities, buildings, hide sites, have camouflage capability, and can hide and/or mix in with the clutter vehicles. The blue players will use the kinds of tools that are expected to exist in 2007, such as a C4I display (emulated by the PVD) which incorporates an attack target/asset pairing algorithm, similar to those that exist today.The AO2000 experiment will require about 50,000 clutter vehicles, many more of which need to be in motion than for J9901. Other simulated "ground truth" vehicles will include approximately 500 red OPFOR, 100 attack blue, 300 sensors, and 20,000 mines. Perceived truth simulated objects will include approximately 30,000 "detection reports" (a.k.a. "blips": raw or minimally processed sensor feeds), and upwards of 2,000 tracks (which represent possible targets of interest). Therefore, the anticipated object count for AO2000 comes in at around 100,000, which is much higher than the requirement for J9901. Also, with more clutter vehicles in motion, attribute update rates will be higher.Interactions between objects will also be more common in AO2000, but the required rates need to be analyzed further.Further, detection report objects (blips) are typically short-lived, and only exist in the federation for fairly short periods of time (from about 5 minutes to about 2 hours). Therefore, these blip objects will be dynamically created and removed from the federation in an ongoing fashion during the exercise.There will be about 50 PVD-based federates, 10 for simulating clutter vehicles, 10 for white cell functions, and another 20 for semi-automated vehicles and sensor simulations, with the total number of federates coming in at around 120. Each federate is generally hosted on a separate machine. The machines will be disbursed around four sites (though one site will actually be divided into two, bringing the total sites to five). These federates will all need to be started within a reasonable timeframe.2. Test DesignThe Joint Experimentation work discussed above was performed using a non-standard RTI (known as RTI-s). A series of design changes and enhancements were made to RTI-s specifically to improve its scalability in support of Joint Experimentation. The purpose of the series of tests discussed in this paper was to determine if a general purpose RTI such as RTI-NG could scale appropriately to support Joint Experimentation.2.1. Test ApproachSeveral possible RTI scalability performance test approaches were evaluated prior to conducting the performance tests. The test approach selection criterion used was the minimization of the manpower required to conduct the tests while maintaining a sufficient comfort level with the test results. The test approaches that were considered are discussed in the subsections below.2.1.1 Exhaustive TestingComplete federation-independent performance testing of an RTI would require testing of the full range of RTI services. Without knowledge of a specific federation, the performance of all these services would need to be tested in all their possible modes of use. This is clearly an intractable task, especially when considering the possible combinatoric effects between functional areas.Even testing a single RTI service exhaustively in a federation-independent fashion is intractable. Each service supports many functions, and most of these functions are very flexible, making it impossible to test the possible combinations of ways in which these functions could stress RTI performance. One cannot test the failure points of functions independently and assume their combined usage scales linearly.Therefore, exhaustive testing was not practical for our goal of performance testing the RTI-NG.2.1.2 Case TestingThe surest method of determining whether an RTI performs adequately for a given federation is to run the required tests with the actual federates using the RTI under test. This is not possible under most circumstances, including those of the JSAF Federation for J9901 or AO2000.First, as mentioned earlier, the JSAF Federation used for J9901 was not HLA compliant. Testing with RTI-NG would require software changes to over a dozen federates. However, although these changes are not trivial, they are not show-stoppers. The compelling reason that running a JSAF Federation Joint Exercise as a performance test is not feasible is the cost in terms of systems resources and manpower. An actual Joint Exercise requires dozens of workstations networked across multiple sites and dozens of people qualified to control (application experts) and conduct (subject matter experts) the exercise over the course of several days.This cost could not be supported just to determine whether the performance of a given version of the RTI would be adequate.2.1.3 Critical Area TestingTherefore, the scope of the performance testing needs to be limited. However, the performance tests must still address critical areas for Joint Experimentation, or else the testing would not provide the confidence level needed for migrating the JSAF Federation to RTI-NG.To try to insure that the performance test covers critical areas, one needs to analyze the critical potential exceptional stresses induced by a Joint Experiment. In particular, one can focus on the requirements of J9901, a Joint Experiment that has already been successfully conducted. One should also keep in mind the likely requirements of AO2000, though its feasibility has not yet been completely proven.Supporting large numbers of federates and objects has historically been a limitation in previous RTI implementations, so verifying these required federate and object counts addresses both an unusual need of Joint Experimentation and a known RTI implementation issue. In addition to having difficulty attaining large federation and object counts, RTI implementations have had difficulty with the rate at which those federates and objects are created. This is because the act of creation poses an extra burden on the infrastructure, as registration and initialization is processed and coordinated across the network.These were the main scalability requirements of the J9901 Joint Experiment. Therefore, the first test for determining adequate RTI performance for Joint Experimentation is one which tests the number of federates which can be created quickly, along with maximum number of objects which those federates can create.2.1.4 Simulating the SimulationIn order to cover critical areas of performance, the performance test must allow for the creation of an adequate number of federates, and an adequate number of objects, in a sufficiently short time period. But the performance tests must also be conducted with extremely limited manpower, computation, and networking resources.The manpower for conducting the performance testing was limited to at most a few engineers (application experts) with no SMEs. The computation and network resources that were readily available are described in a following section, and fall far short of what is required for a full-scale Joint Experimentation exercise.Therefore, the ClutterSim was selected to create RTI objects for the scalability performance test. The ClutterSim provided the bulk of objects used during the J9901 exercise. It also had the advantage of being able to provide the 20,000 or more objects with minimal computing and manpower resources.In the DIS environment, all object information was broadcast (periodically), whether listeners were interested or not. However, in the HLA environment, information is only published if subscribers are interested in it. Therefore, one needs to determine the federates' requirement for the object information and include that requirement in the performance test environment.Unfortunately, from the resource utilization point of view, the JSAF Federation relies heavily on the use of PVDs for all sides: red, blue, and white. These displays subscribe to all relevant objects and tactical information. Depending upon the current view on the screen, DDM can be used to limit the required information. However, in the worst case, the PVD display will need information from the entire battlespace.PVDs, however, are relatively expensive from a computational perspective, at least when viewing many vehicles. The inclusion of actual PVDs in the scalability test suite would reduce the available hardware. This would be very undesirable, since the available hardware is a limiting factor in the performance testing.To avoid devoting critical hardware resources for PVD federates, the PVD requirement for information could be "simulated" in the performance test by modifying the ClutterSim, as described in a subsequent section.Therefore, the performance test environment is really a "simulation of the simulation" of J9901. The mix of federates and objects was replaced with a modified ClutterSim producing background traffic. The information consumption needs of J9901, which are lost when other federates are not included, are simulated with ClutterSim modifications.As noted previously, the ClutterSim used for J9901 was not HLA compliant. Therefore, a modified version of the ClutterSim was used to conduct the scalability testing. The ClutterSim under test was implemented with the Agile FOM Interface (AFI), a middleware that provides an interface to HLA Interface Specification v1.3 compliant RTIs[4,5]. This version of ClutterSim was available in the JSAF v5 repository.2.2 Test SoftwareThe RTI-NG software version under test was RTI1.3NGv3. As described in the previous section, the main software component for conducting the performance tests was the ClutterSim federate.2.2.1 ClutterSim DescriptionJ9901 required a large amount of background, or clutter, traffic to be simulated in order to provide the proper environment for identifying critical mobile targets. A scalable federate was needed to meet the requirement for 10,000 vehicles.As described by Ceranowicz et al., a scalable entity-level simulation was developed by stripping down the STOW Joint Semi-Automated Forces (JSAF) code to create a simulation with only those functions required for background traffic. Primarily, the capabilities required were road movement, damage calculation, response to sensor footprints, and publishing entity state.[1]The ClutterSim federate needed to be scalable in three resource dimensions: manpower, computation, and network. With such high vehicle counts, any of these resources would prove inadequate for conducting an exercise in a non-scalable fashion.2.2.1.1 Manpower ScalabilityOne aspect of scalability that needed to be addressed by this federate was the scalability of manpower. The ClutterSim federate needs to operate with minimal user input required for initialization and none required during the actual exercise.The ClutterSim was designed so that the user could choose the amount of traffic to simulate, the areas to concentrate vehicle population, and the mix of different vehicle types. This is all the information required for initialization, though runtime behavior can be controlled in great detail through the use of data configuration files. Prior to the start of the exercise, the ClutterSim will select individual vehicle start and target locations near roads and generate road routes between them.Further, once the exercise begins, the vehicles will drive along their routes automatically, speeding up or slowing down and sometimes stopping periodically. This allows the vehicles to behave as if driven by human direction without any operator intervention. Further, if the vehicles reach the ends of their targeted routes, they reverse the route and return to the beginning. Thus, a reasonable level of automated behavior can be simulated indefinitely without any operator intervention.With this approach, the manpower requirement for generating background traffic vehicles scales quite readily.2.2.1.2 Computational ScalabilityA second aspect of scalability that needed to be addressed by the ClutterSim was computational scalability. Computational resources are limited not just by their processing power, but also by their memory constraints. Achieving computational scalability can require achieving a balance between these resources, since they can often be traded off.Although processors and memory continue to get cheaper and faster, that trend cannot compensate for dramatically increased vehicle counts if the load of additional vehicles is nonlinear. Whenever all vehicles need to interact with all other vehicles (for example, to plan routes that avoid collisions with each other), the processing is inherently Order (n2). Thus, interactions between all vehicles need to be avoided.It was determined that, in J9901, there was no need for background traffic to behave intelligently enough to plan collision avoidance. This is because the training staff could not distinguish that behavior when viewing the perceived truth on their PVDs. So, collision avoidance processing was simply omitted from the ClutterSim, as were any effects from collisions that would occur.Once tracking other vehicles is not required for processing road movement, the total computation cost drops back to linear with the vehicle count (each vehicle needs only store and process its own state).It was also possible to reduce the amount of processing each vehicle needed to perform during the actual exercise. The processing for the road movement controller was front-ended and turned into an event-driven simulation. This was possible since no dynamic aspect of the simulation had an impact on route selection or vehicle speed.Damage calculations were also event-driven to maximize the clutter vehicle count. This left only updating entity state, some hull calculations, and reacting to sensor footprints as dynamic processing which needed to occur during the exercise. Reacting to sensor footprints is Order (n*m), where n is the number of vehicles and m is the number of sensor footprints. The number of sensor footprints can vary considerably (since the players can alter the sensor collection plan) however, in J9901, m << n. So, sensor footprint processing behaves "almost linearly" with the number of clutter vehicles.In fact, decentralizing sensor processing on to vehicle simulation processors (instead of sensor simulation processors) is part of the overall scalability strategy of J9901. If processing sensor footprints were part of the task load of each sensor simulator, those processors would be required to handle that sensor's load for however many clutter vehicles were created. This would non-scalably limit the feasible number of clutter vehicles in the exercise[6].2.2.1.3 Network Scalability Since the ClutterSim vehicles do not use the state of other vehicles in their own processing, the ClutterSim can refrain from subscribing to vehicle state information. The ClutterSim does need to subscribe to information about sensor footprints, but the number of sensors is much less than the number of vehicles.This means that workstations used to host ClutterSim federates (only) need to receive (and process) relatively few packets. If a site is used to generate background traffic, without any PVDs, the entire site can forego receiving vehicle state information from remote sites, though of course state information will still need to be provided to remote sites which host PVDs or sensors.The upshot is that there is no network scaling difficulty on behalf of the ClutterSim. With regard to number of vehicles, there is no networking requirement. With regard to the number of sensors, the ClutterSim scales Order (n) with the number of sensors, where n is modest.Other federates do require state information from the ClutterSim vehicles, and it is incumbent upon them to use selective subscription and DDM where possible to limit their networking requirements.This is critical because implementers of Joint Experimentation exercises are finding that the network is a limiting factor in system scalability, moreso than the RTI or computation resources. The required networking technology is not maturing quickly enough, and in particular the use of multicast for DDM relies on immature networking capabilities. Investigating this issue is beyond the scope of this paper, however it is worth keeping in mind that some aspects of scalability are completely outside the control of federation implementers.2.2.2 ClutterSim Test Federation ChangeAs described earlier, the test federation needs both publishers of and subscribers to the clutter objects.In the normal mode of the JSAF Federation, Data Distribution Management (DDM) techniques are used to restrict the subscriptions of the ClutterSim federate. Given a federation made up of only ClutterSim federates, there would be no subscribers to the ClutterSim objects, and thus there would be no packet processing or network loading as part of the performance test.In the actual JSAF Federation, the PVD federates potentially need all vehicle information at any given point in time. In order to simulate the presence of PVDs, the ClutterSim test federation was set up to run without DDM, and thus to subscribe to all object information.2.3 Test HardwareTwo hardware suites were used to conduct the testing. Group 1 hardware was comprised of 12 PCs in the 200-233 MHz range. All Group 1 machines contained 256MB of memory and 300 MB of swap, and ran under the Linux OS. The full Group 1 configuration is shown in Table 2.3-1. All Group 1 tests ran on a private 10 Mb/s Ethernet sub-LAN.Group 2 hardware was comprised of 5 PCs in the 450-700 MHz range. All Group 2 machines contained 384 MB of memory and at least 400 MB of swap, and ran under the Linux OS. The full Group 2 configuration is shown in Table 2.3-2. The Group 2 tests ran on a shared 10 Mb/s Ethernet LAN.2.4 Test SetupEach PC was set up as a single ClutterSim federate. Each ClutterSim was configured to subscribe to all information (to simulate PVD usage) and to create a specified number of objects. Several trials were run, attempting to create a larger and larger number of objects per federate. The amount of time required to create all objects was recorded.Two separate series of runs for each hardware group was conducted; one where the clutter vehicles were stationary, one where the clutter vehicles were mobile.Table 2.3-1: Hardware configuration for Group 1Machine NameModel NameCPU MHzTotal Memory (MB)Swap Memory (MB)OSpc1Pentium Pro200256303Linux 2.2.13 i686pc2Pentium Pro200256303Linux 2.2.13 i686pc3Pentium II (Klamath)233256303Linux 2.2.13 i686pc4Pentium Pro200256303Linux 2.2.13 i686pc5Pentium Pro200256303Linux 2.2.13 i686pc6Pentium Pro200256303Linux 2.2.13 i686pc7Pentium Pro200256303Linux 2.2.13 i686pc8Pentium II (Klamath)233256303Linux 2.2.13 i686pc9Pentium II (Klamath)233256303Linux 2.2.13 i686pc10Pentium II (Klamath)233256303Linux 2.2.13 i686pc11Pentium Pro200256303Linux 2.2.13 i686pc12Pentium II (Klamath)233256303Linux 2.2.14 i686Table 2.3-2: Hardware configuration for Group 2Machine NameModel NameCPU MHzTotal Memory (MB)Swap Memory (MB)OSpc13Pentium III600384514Linux 2.2.12-20 i686pc14Pentium III600384514Linux 2.2.12-20 i686pc15Pentium III700384514Linux 2.2.12-20 i686pc16Pentium III700384514Linux 2.2.14-5.0 i686pc17Pentium III450384407Linux 2.2.14-5.0 i6863. Test ResultsThe results from the scalability performance testing are shown in Tables 3-1 through 3-4. Plots of the results are shown in Figures 3-1 and 3-2.The results clearly indicate that RTI1.3NGv3 was able to support the creation of over 20,000 stationary objects in less than seven minutes. Also, the results further indicate that RTI1.3NGv3 supported the creation of about 15,000 moving objects in less than ten minutes. This indicates that the main requirements for performance of J9901 could be met by the RTI1.3NGv3.Table 3-1: Group 1 test results for stationary objectsMachine NameTest 1 No. objectsTest 2 No. objectsTest 3 No. objectsTest 4 No. objectsTest 5  No. objectsTest 6 No. objectsTest 7 No. objectsTest 8 No. objectsTest 9 No. objectsTest 10 No. objectspc1-pc12200400600800100012001400160018002000Total Objects2400480072009600120001440016800192002160024000Start-up Completion Time01:2601:5702:4503:4004:0204:5305:2006:1006:5708:18Table 3-2: Group 1 test results for moving objectsMachine NameTest 1 No. objectsTest 2 No. objectsTest 3 No. objectsTest 4 No. objectsTest 5  No. objectsTest 6 No. objectsTest 7 No. objectsTest 8 No. objectspc1-pc122004006008001000120014001600Total Objects240048007200960012000144001680019200Start-up Completion Time03:4605:5306:1206:2806:4408:2815:1232:28Table 3-3: Group 2 test results for stationary objectsMachine NameTest 1 No. objectsTest 2  No. objectsTest 3 No. objectsTest 4 No. objectsTest 5 No. objectsTest 6 No. objectsTest 7 No. objectsTest 8 No. objectspc13-pc1712002400320036004400480060007200Total Objects600012000160001800022000240003000036000Start-up Completion Time02:5003:2204:3306:1607:1108:4210:4812:50Table 3-4: Group 2 test results for moving objectsMachine NameTest 1 No. objectsTest 2  No. objectsTest 3 No. objectsTest 4 No. objectsTest 5 No. objectsTest 6 No. objectsTest 7 No. objectspc13-pc171200240032003600440055006000Total Objects6000120001600018000220002750030000Start-up Completion Time05:2307:5508:4710:1316:2827:0938:11Figure 3-1: Stationary ClutterSim objects vs. start-up timeFigure 3-2: Moving ClutterSim objects vs. start-up timeNote that the tests that were conducted do not necessarily imply that this figure is the highest number of vehicles that can be supported by the RTI. This is because the machines on which the tests were conducted are not the fastest available. At this point, we also do not know whether configuring the machines with more memory might reduce total startup time, although given the results of the moving object tests, this seems a likely outcome for object counts above 20,000.Additionally, the ClutterSim federates were configured to subscribe to all information. This does not reflect the optimizations that could be achieved in actual operation.Additional investigation is required to see what percentage of the processing requirements are devoted to the RTI, and under what conditions the startup time can be reduced.4. Lessons Learned4.1 RID File ModificationsThe RTI can be "fine-tuned" by altering the contents of its RID file, and the importance of understanding these RID options cannot be overstated.In the case of RTI1.3NGv3, the "Advisories" section turned out to play a crucial role in the scalability tests. Testing began using the sample RID supplied in the RTI distribution, which leaves all RID options on their default settings. After a few test runs, it became very apparent that this wasn't a viable option - even a couple of federates with 500 vehicles apiece were taking so long to start up that we assumed something had crashed or deadlocked.Having noted that the Advisories section of the RID file contained warnings about "significant performance cost[s]" in calculating the advisories, the advisories were disabled in the RID and testing resumed. As the results in the previous sections indicate, we were able to achieve a large number of objects in reasonable federation start-up time.4.2 Federate Architecture ModificationsAnother lesson learned a little further into the scalability testing process was that it is sometimes useful to disable elements of a simulation architecture that support a different distributed simulation paradigm. In the case of the ClutterSim, code was present to "heartbeat" entities at five-second intervals, and to time out entities if no data was received within twelve seconds. While this didn't matter for low entity loads, it resulted in a form of deadlock condition at even moderate loads (approximately 4,000 stationary vehicles). As the load level increased, the ClutterSims would sometimes require more than twelve seconds to update all their vehicles. And as soon as that started to happen, all the other ClutterSims would time out these vehicles and locally delete them. Of course, since the vehicles were still out there, they were rediscovered almost immediately, and the ClutterSims would start requesting attribute updates for the recently deleted vehicles. This served to decrease the time available to update the local vehicles for each ClutterSim, causing even more ClutterSims to delete (and immediately rediscover) vehicles. One can see the resulting death spiral - soon all the ClutterSims were spending all their time in a needless cycle of deletion and rediscovery.5. ConclusionUsing a simulation of the simulation to show that an RTI can provide a level of service in the right ballpark for critical areas is valuable, even if it is not definitively proven that a specific exercise can be supported. Our results indicate that RTI1.3NGv3 should be able to provide support for a Joint Experimentation exercise on the scale of J9901 (that is, on the order of 20,000 simulated objects).Further investigation is required to determine whether future Joint Experiments (such as AO2000) would also be supported adequately.6. References[1]	R. Dehncke, C. Morgan: “Virtual Simulation and Joint Experimentation, STOW and Joint Attack Operations”, Simulation Interoperability Workshop, 99F-SIW-079, September 1999.[2]	A. Ceranowicz, M. Torpey, B. Helfinstine, D. Bakeman, J. McCarthy, L. Messerschmidt, S. McGarry, S. Moore: “J9901: Federation Development for Joint Experimentation”, Simulation Interoperability Workshop, 99F-SIW-120, September 1999.[3]	A. Ceranowicz, P. Nielsen, F. Koss: “Behavioral Representation in JSAF”, 9th Conference on Computer Generated Forces & Behavioral Representation, 9TH-CGF-058, May 2000.[4]	D. Macannuco, B. Dufault, L. Ingraham: “An Agile FOM Framework”, Simulation Interoperability Workshop, 98F-SIW-025, September 1998. [5]	D. Macannuco, D. Coffin, B. Dufault, W. Civinskas: “Experiences with a FOM Agile Federate”, Simulation Interoperability Workshop, 99S-SIW-052, March 1999.[6]	S. McGarry, M. Torpey: “Back to Basics: Balancing Computation and Bandwidth”, Simulation Interoperability Workshop, 99F-SIW-188, March 1999.Author BiographiesWAYNE CIVINSKAS is the Manager of Lockheed Martin Information Systems Advanced Simulation Center (LMIS-ASC). His responsibilities include advanced concept development of simulation system architectures, technologies and techniques that support distributed simulation. Wayne's current focus is on transition of distributed simulation technologies from the prototype stage to full-scale engineering development and production programs.BRETT DUFAULT is a Staff Software Engineer at Lockheed Martin Information Systems Advanced Simulation Center (LMIS-ASC). Brett is currently working on JSAF v5 development in support of the Tasmanian Devil project. Previously, Brett was a lead software designer and developer of the Agile FOM Interface. Prior to his work with HLA, Brett was involved in JSAF development for the Synthetic Theater of War (STOW) Advanced Concept Technology Demonstration Program.DEBORAH WILBERT is a Senior Staff Software Engineer at Lockheed Martin Information Systems Advanced Simulation Center (LMIS-ASC). Deborah is currently implementing tools that support FOM Agility in HLA compliant federates. Her experience in distributed simulation includes other HLA-related design and development efforts, environmental simulation, CGF development, scalability research, protocol development, and C4I simulation.  EMBED Excel.Sheet.8   EMBED Excel.Sheet.8  