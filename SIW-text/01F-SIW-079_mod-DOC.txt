On the Road Again: Paint the Night Lessons Learned from SMART 2001 and FCC2 Integration TestingMr. Maximo LorenzoCECOM Night Vision and Electronic Sensors Directorate10221 Burbeck Road, Building 309Fort Belvoir, VA 22060703-704-3185lorenzo@nvl.army.milBill Riggs, John LangworthyScience Applications International Corporation4001 N. Fairfax Drive, Arlington VA 22203briggs@nvl.army.mil,  HYPERLINK mailto:mcaruso@nvl.army.mil,jlango@nvl.army.mil,dsulla@nvl.army.mil mcaruso@nvl.army.mil,jlango@nvl.army.mil,dsulla@nvl.army.milKeywords: Paint the Night, HLA, FOM Development, Terrain ModelingAbstract:Paint the Night (PTN) is a key component of the AMC RDEC Federation, which achieved a significant milestone at the SMART 2001 conference held in April 2001. Concurrently with SMART 2001, NVESD conducted integration testing for the FCC2 experiment at a US Army simulation center. This paper will discuss new and recurring issues involved in Federation Development and Execution, including exercise design. FOM development, terrain database development and interoperability, target modeling, distributed testing over the DREN, on-site integration, network analysis, and system stability. 1. IntroductionIn April and May 2001, NVESD supported back-to-back large scale simulation exercises that focused on the virtual prototyping of Future Combat Systems. The first of these exercises was a demonstration of the Army Material Command (AMC) Research Development and Engineering Center (RDEC) Federation simulation infrastructure. The AMC RDEC Federation seeks to link the simulation capabilities of AMC laboratories specializing in munitions and ballistic weapons, aircraft and missiles, communications systems, sensors, automotive systems, soldier systems, training systems, and advanced technologies. As such, the RDEC federation represents the bulk of the US Army’s applied research and development capacity to support virtual prototyping and simulation based acquisition. NVESD’s participation in the Future Combat Command and Control (FCC2) experiment reflects its ongoing partnership with the user community, represented by the US Army TRADOC battle laboratories. The focus of NVESD’s participation in FCC2 was the simulation of reconnaissance, surveillance, and target acquisition (RSTA) functions, given the availability of robotic scouts/unmanned ground vehicles (UGV), unmanned aerial vehicles (UAV), and unattended ground sensors (UGS) in the brigade combat team. 2. Overview of SMART 2001 and FCC2 Exercisesa. SMART 2001 The AMC RDEC Federation conducted a large scale distributed simulation demonstration at the Army SMART 2001 Conference held at Orlando, Florida from 16-19 April 2001. Participants in this demo included the Communications Electronics Command (CECOM, including the Command/Control, Night Vision and Electronic Sensors and Intelligence/Electronic Warfare directorates, Aviation and Missile Command (AMCOM), Tank Automotive Command (TACOM, including Tank Automotive Research Development and Engineering Center (TARDEC) and the Armaments Research Development and Engineering Center (TACOM ARDEC) the Simulation Training and Instrumentation Command (STRICOM) and Army Research Laboratory (ARL).  The Federation brought together over thirty (30) key simulations and models from the participating members. The exercise scenarios corresponded to the first, second and third “dreams” described in the “The Defense of Fombler’s Ford” by Gen.  (Ret.) Paul Gorman. Fombler’s Ford depicts a set of dreams in which a futuristic platoon of the Combined Arms Battle Team protects the ford in a defensive position.  The use of  “dreams” to describe tactical scenarios was taken from the classic tactical lessonbook, “The Defense of Duffer’s Drift”, used to train US Army officers at Fort Leavenworth and elsewhere.SegmentSimulated Mission/TaskScenario Description1st  DreamAnti-Armor EngagementPlatoon attacks lead element tanks (6), while the brigade attacks main body (~30 armored vehicles) in depth with attack helicopters, UAV reconnaissance, and artillery. This was the largest battle with numerous C4I threads, demonstrating battlefield coordination of close battle and deep operations.2nd  DreamReconnaissanceA battle team reconnaissance patrol encounters ATGMs. Two FCS Scout Recon Vehicles with robotic scouts engaged three threat ATGM teams. This scenario demonstrated inter-RDEC cooperation on robotic modeling.3rd  DreamNight DefenseThreat infantry attempted to penetrate a Battle Team night defensive perimeter and were subsequently detected and engaged. This scenario depicted close combat and interaction with dismounted infantry, including the use of active protective systems (APS), unattended ground sensors (UGS), anti-personnel land mine alternatives (APLA), other advanced weapons, decision aids, C4ISR, and fire support.Figure 1: Fombler’s Ford Dreams in SMART 2001 RDEC Federation DemoFigure 2 below depicts the simulation architecture used during the SMART 2001 exercise. As this deployment diagram shows, the network consisted of three  components:An ethernet-based HLA network using RPR_FOM 1.0 to pass HLA objects and interactions among native HLA applicationsAn ethernet-based DIS network passing interactions as entity states and other PDU traffic. A DIS-HLA gateway bridging the two networks. For this exercise, the MaK DIS/HLA gateway was used in this role. Figure 2: SMART 2001 Simulation NetworkFigure 3 shows a top-level description of the SMART 2001 development, testing and integration schedule. As this chart shows, planning and preparations for the demonstration took about six months. A significant element of the predemonstration testing and integration efforts took place at home station, with the RDEC federates linked through the Defense Research and Engineering Network. This preparatory phase began in January 2001 and continued through the end of March. The RDEC Federation simulation components were transported to Orlando, arriving at STRICOM on April 8, with further testing and integration efforts taking place from 8-12 April at STRICOM. On 9 April, the RDEC Federation network was transported to the conference facility, the Hyatt Regency hotel in Orlando, becoming operational on the following day. Several important lessons were learned through this process. The DREN offered an excellent means to conduct connectivity testing, to work out scenario design issues, and to test individual software components, particularly simulation modules that were being integrated with HLA, or the RPR FOM for the first time. In the Paint the Night simulation system, this meant the development and testing of an interfederation gateway to translate RPR FOM objects and interactions into PST Federation objects, etc. However, complete integration of platform simulation components could not be accomplished remotely, and therefore a considerable amount of control level integration was delayed until the week prior to the demonstration. Also, the physical network at STRICOM and the Hyatt, based on gigabit Ethernet, differed in bandwidth and design from the native DREN configurations hosted by each of the RDEC laboratories. This latter change invalidated the load testing conducted over the DREN, and caused the physical network to be divided into two subnets – one for DIS traffic, the other for HLA. The use of two subnets complicated the deployment of federates such as the NVESD generic entity controller which subscribe to both DIS and HLA traffic. As with all distributed simulation exercises, enumerations and enumeration-model mapping consumed overhead in demonstration planning and preparations, especially during the final week. However, last minute changes were executed without noticeable problems, in large part due to excellent management by the CECOM and STRICOM personnel involved in these tasks. Terrain and target modeling issues are discussed later in this paper.Figure 3: Planning Schedule for SMART 2001b. FCC2  The FCC2 experiment took place from 14-24 May 2001. The exercise scenario differed greatly from SMART 2001 “Fombler’s Ford” vignettes, with an entire brigade combat team in play, with a full TOC representing maneuver, fire/ effects, and intelligence, surveillance, and reconnaissance functions. However preparations between the two exercises coincided, and, since a number of the same RDEC players, particularly the CECOM RDEC NVESD and I2WD, were involved in both, a degree of leveraging was possible. This was particularly the case with respect to the simulation of FCS vehicle concepts developed by TARDEC, including troop transport, direct fire, command/control, mobility, reconnaissance, and indirect fire variants  EMBED Word.Picture.8  Figure 4: FCC2 Deployment DiagramFigure 4 depicts the FCC2 floor plan, depicting the brigade’s close combat assets. NVESD sensor simulation assets were integrated to run with the reconfigurable scout simulator platforms (ACRT), representing the imaging sensor assets available to future commanders in FCS. Although the preponderance of simulation assets in FCC2 were constructive, or at least semi-constructive, based on OneSAF Testbed projecting individual and aggregated entities, the FCC2 experience shows an understood need for high quality sensor views to correctly capture situational awareness problems.Like SMART 2001, the FCC2 schedule was driven by fixed exercise dates and related resource commitments. In terms of NVESD activities to support FCC2, the initial plan went as follows:ActionStartFinishDevelop Experimental Plan1/17/012/1/01Develop Terrain Database1/17/014/1/01Establish Network1/17/013/13/01Integration Test3/26/014/15/01User Training4/15/014/2301Simulation Debugging4/24/015/3/01Reconfigurable Simulator Integration1/17/013/20/01PTN Federate Development1/01/013/20/01Figure 5: FCC2 Timelines Several modifications of this plan proved necessary during the preparations for FCC2. Most significant of these were the following:Integration of Paint the Night into the ACRT proved to be more difficult than originally understood. Although the ACRT used the same terrain database format (Performer Fast Binary) as Paint the Night, additional metafiles were required by the ACRT to correctly load a correlated thermal database. As with SMART 2001, it was found that remote integration of visuals and controls was infeasible, and an ACRT desktop simulator was shipped to Fort Belvoir to accelerate the progress of testing and integration at NVESD.Cross-application support for 3D visuals and CGF platforms proved to be a real challenge. MBBL initially pursued a terrain database conversion strategy based on a CTDB database of the exercise area to be produced by NVESD, using CTDB as the input format to support FLT database production. This approach itself proved problematic, as the Tuzla terrain database required significant thinning of forested areas (e.g. 100 meter tree spacing) and elevation post spacing (64 meters), and even then, the size and density of the output files overmatched the ability of the deployed ITB hosts to run CTDB databases in excess of 256 MB.3. Implementation and Correlation of FEDEP with the Paint the Night Development Cycle In conjunction with an upgrade to the RTI 1.3VNG, the Paint the Night team conducted a thorough redesign and rewrite of the PTN libraries during the first and second quarters of FY01. As originally conceived, this process was to proceed in three phases: Phase 0 - Fundamental Prerequisites. This phase laid out the prerequisites for software baseline development; this included getting the Concurrent Version System (CVS) operational, and evaluation of XML parsers used in loading configuration management information. In this phase, an OMD – code converter was developed. This “OMD2Code” program parses an OMD file and generates C++ object and interaction classes to be integrated in the Paint the Night simulation. Documentation describing federate behavior in the context of a working PST Federation was created. Phase I - Develop Core PST Federation Functionality. This phase focused on basic PST federate behaviors, prior to integration with external applications (e.g. through a gateway). It included the implementation ofSupport for matrix, quaternion, and 3D vector operationsCoordinate conversion from external coordinate systems to PST Federation local coordinates.Input federate, including a GUI version of the Virtual Flybox controllerView Federate, which controls independent and attached scene traversal.Sensor Image Generator federate, which creates an image from the current viewpoint, using the current state of the HLA objects.  This federate renders entities and executes attachment to the entity mount points based on ViewFed input. Initial plans called for the development of synchronization functions to support capture of individual images, either in an interactive scenario, or scripted through a Snap federate, which would capture images based on position, FOV, lighting, atmospheric conditions, time of day and other variables.  	Phase II – Extension of Core Capabilities. This phase expanded Phase I development, including integration with external applications (e.g. OneSaf testbed) through the PST gateway. Two initial gateways were to be developed, using the OMD2Code generator previously discussed. One gateway, to be used in SMART 2001, was the RPR to PST Federation gateway; the other was a DIS to PST gateway, planned for use in FCC2. Federate functions would be expanded to support the objects and interactions published through these gateways. This phase also involved the development of a GUI-based automation program through the fed daemon and the fed client. The sensor effects federate, was planned for this phase. This federate post-processes (SIG federate) generated images in real time, applying noise, blurring, and convolution to the images to simulate the performance characteristics of specific imaging sensors. The Sensor Effects (SensorFX) federate also supports AAL5 ATM video transfer for delivery of PTN images to a Video Display federate across high speed (OC3 or better) wide area networks.  Finally, plans for this phase also included the development of a simple environment federate to manually control time of day and atmospheric conditions (transmissivity and path radiance).Figure 6 encapsulates the outcome of this development plan in terms of essential PST Federation components. Phase 0 was completed in December 2000, leaving about 10-12 weeks for Phases I and II to be completed. As Phase I development proceeded, it was determined that some Phase I development tasks, mainly those tasks relating to synchronization to capture individual images from the SIG Federate, were not required for either SMART 2001 or FCC2. Consequently, these tasks were deferred to concentrate on identifiable requirements applicable to either or both exercises. With the exception of the different gateway versions to accommodate integration with RPR FOM 1.0 versus DIS, most Phase I developmental tasks supported basic functionality needed for both exercises. However, additional development was required to integrate with specific simulator configurations unique to each exercise. Developmental bottlenecks and conflicting priorities began to emerge from late February through March, as Phase II development coincided with the integration testing timelines for both FCC2 and SMART 2001. The ACRT integration for FCC2 proceeded in a relatively smooth manner due to the availability of the simulator controls and displays at NVESD; however, such facilities were not available for VTT integration in support of SMART 2001. Distributed development and integration was complicated by inconsistencies in byte ordering in the DIS/HLA gateway with the 1014 XDR standard used to govern byte ordering. PRIVATEFederate/ComponentFunctionsProjectedCompletedProblems EncounteredInputTranslates device input into HLA objects and interactionsIntegrated to Virtual Flybox, Unwinder joystick, ACRT controls (LRAS only)January 31Initial Development Complete February 15Integration Complete March 31ViewCalculates view position, orientation, and velocity based on input federate dataJanuary 31Development Complete February 15Integration Complete March 31SIGComputes scene frames based on view data and terrainFebruary 15April 6 (First Release)May 15 (Second Release)- Database pager- DI heap memoryGatewayDISRPR FOMOtherTranslates simulation objects from foreign protocol to PST FOMApril 2April 2- Slowness in discovering new entities- RPR FOM implementation constructs corrupt DI objectsSnap Takes individual frames and writes them to a file based on timing parameterMarch 15Ongoing- No FCC2 or SMART requirementSensor EffectsApplies noise, blurring, and convolutionApril 15April 6- Memory leakVideo TransferTransmitted processed images over ATM line to displayApril 15May 1LRAS FTL indicator not updatingHLA WrapperProvides baseline calls to RTI servicesJanuary 31February 15Figure 6: PST Federation Development Timelines and Results3. Terrain and Target ModelingFigure 7 depicts the SMART 2001 and FCC2 scenario areas. The FCC2 scenario/area was a 180 x 130 kilometer area representing an Objective Force brigade area of operations with adjoining areas of interest. The “Fombler’s Ford” area was adapted to the Doboj locale of this larger area, within a 32 x 32 kilometer box.  Although preexisting terrain databases, including the PTN “Tuzla” and an S1000-derived “NE Bosnia” terrain datasets were available off-the-shelf, both the FCC2 and SMART scenarios called for the optimization of terrain databases. This optimization was defined in terms of terrain and feature resolution, runtime database size and tiling schemes, placement of scenario-specific features (including MES buildings in the Doboj area) and supported formats. In addition to the PFB format used in Paint the Night, both SMART 2001 and FCC2 had requirements for CTDB and OpenFLT terrain; in at least one instance, one of these formats was to be used as a “feeder” format for a visual or CGF terrain database. For example, the ITEMS/IDEEAS model as used in FCC2; MetaVR was used in FCC2. The SMART 2001 configuration was considerably denser than that of FCC2. The 32 x 32 kilometer “Doboj” subset used an oversampled 16 meter post spacing derived from DTED Level 2 (about 23 meters post-to-post spacing in this region), with individual trees placed at distances ranging from 5 – 100 meters apart. The Tuzla dataset, on the other hand, was produced at 64 meter post spacing derived from the same elevation source data. 15 MES buildings were added to both terrain databases, using existing MES models and templates. The recompile tool was used to add these structures, to add additional volume models and abstract features (powerlines and railroads), and to correct soil attribution in preexisting CTDB files.Figure 7: Bosnia Terrain Used in SMART and FCC2Target modeling was similarly constrained in terms of format, content, and resolution. The same tools were used to convert and thin PFB format target models, including the TARDEC notional FCS vehicles to desired runtime optimization.4. FEDEP Processes. These experiences offer useful insight into the application of FEDEP, from both operational and developmental perspectives. Like the FCC2 exercise plan, FEDEP is a waterfall model, and assumes that requirements are clearly defined in advance, with low developmental risk. The SMART 2001 model was somewhat less articulated in terms of FEDEP steps or functions – but it should be noted that the SMART 2001 “conceptual model of the mission space” was very strongly articulated. In SMART 2001, the scenario was tailored to fit the capability of preexisting simulation tools; in FCC2, individual simulation components were plugged in or pulled out based on a predefined schedule, and the availability of those components as demanded by the exercise management and systems integrator. Both experiences highlight the reality that in the real world, distributed simulation exercises are time-driven, rather that event-driven. Problems can arise when requirements and risks are poorly understood. All too often, this causes exercise planners to reduce project-specific development to the minimum essential level, or to reduce risk by shifting the burden of risk mitigation entirely on the development end. Development of scenarios in a vacuum, with no consideration of the developmental costs and timelines associated with implementation of the Conceptual Model of the Mission Space (CMMS) vision, and unwillingness to negotiate scenarios with developers prior to requirements lock-in, are symptomatic of this phenomena. In practice, simulation exercise planning and execution begins to resemble a spiral model shown in Figure 8. If the exercise schedule permits it, a limited prototype may be developed, mainly using off-the-shelf simulation components, in an initial “pilot” cycle. The project specific development plan can be used to modify ongoing “program level” or “product level” development plans for one or more simulation components. For example, the PST Federation and its component federates would be an example of a “product level” component-based simulation). The articulation of a second prototype validates the requirements defined initially in concept. Later cycles permit elaborated design, documentation, integration, and acceptance by end users. Figure 8: A Spiral Development ModelAlthough FEDEP is generally understood as a waterfall model, in fact its semantics reflect functionality rather than sequencing. For this reason, no formal modification of FEDEP is needed to implement it as a spiral model – one simply has to perform the FEDEP process in the iterative manner suggested in Figure 8. However, it is important to ensure that program managers, systems integrators, scenario developers, and simulation developers understand how such a model relates to FEDEP, and can plan, organize, coordinate, and execute their tasks so as to maximize scarce development time, minimize and measure risk, and develop flexible backups when problems occur, as they often, if not always, do. 6. Conclusions and RecommendationsThe experience of FCC2 and SMART 2001 demonstrates the importance of adherence to FEDEP as a sound basis for simulation development and implementation. At the same time, the problem of managing a software development cycle in relation to project/exercise specific requirements reflects a generalizable problem that must be managed creatively within the rubrics of FEDEP. Further discussion of this issue in SISO should focus on “best practices” that facilitate successful “just-in-time” simulation system development, with given resources or timelines.References:[1] “Product Nomination Proposal: HLA Federation Development and ExecutionProcess (FEDEP)” Version 1.0[2] Lorenzo, Maximo; Riggs,  B., Caruso, M. and Schell, D. “Integration of Engineering Level Sensor Federation into a Brigade Level C4ISR Experiment Using RTI V1.7” SIW Paper Number 00f-SIW-050, September 2000MAX LORENZO is the Chief of the CECOM Night Vision and Electronic Sensors Directorate Virtual Prototyping Systems Branch. He has a B.S. in Geology from The College of William and Mary.BILL RIGGS is the SAIC task manager for the Paint the Night Effort. Mr. Riggs has over 12 years experience in distributed simulation development and exercise support, with NVESD, USATEC, and the Mounted Maneuver Battle Lab at Fort Knox. He has an M.S.F.S in international relations from Georgetown University. JOHN LANGWORTHY is part of the Night Vision Paint the Night sensor simulation development team.  John is the PTN team lead developer for the view control and video transfer federates.  He has also done research in machine learning and semi-automated forces.  He has an MS in electrical and computer engineering from CMU (Carnegie - Mellon University).