Dynamic Distributed NetworksRyan McKeonRichard RicartRodney RivenScott WolframAccenture9432 Baymeadows Road Suite 155Jacksonville, FL 32256904-899-0290ryan.mckeon@accenture.com; richard.ricart@accenture.com; rodney.riven@accenture.com, scott.d.wolfram@accenture.comKeywords: Networking, Dynamic Distributed Networks, TENA, TADIL, JMETC, T&E, VPN, IPSec, SOA, OpenESB, XMPP, BPELABSTRACT: The cost of testing, training, and analysis events must be reduced and potential expanded to effectively and efficiently support development of critical capabilities for the Warfighter. Traditional event setup requires manual configuration of routers and the opening of portals within firewalls to allow data traffic to pass through. In the past, it has taken weeks to identify the appropriate IP addresses; coordinate and communicate with all participants; and debug any errors created due to this manual configuration process. This excessive cost and time overhead has had the effect of both limiting the number of events that can be supported over a given period in addition to limiting the scope of those distributed test events. When persistent networks are indeed used, there is no partitioning of data to allow for multiple simultaneous events.  Simultaneous events are either not a possibility, or require manual manipulation of network hardware to create Virtual Local Area Networks (VLANs).Dynamic Distributed Networks (DDN) is an advanced research project for the Joint test and evaluation community, focused on demonstrating the ability to create overlay networks to connect live, virtual, and constructive systems across a wide area network (WAN). The DDN project is harnessing the commercial investment in web-automation technologies to the T&E infrastructure by developing a solution for dynamically generating overlay networks between resources, as well as building tools to provide management and monitoring of those networks. The Extensible Messaging and Presence Protocol (XMPP)—an open standard for instant messaging—is harnessed to provide presence and signaling across sites. This signaling is used to initiate a Virtual Private Network (VPN) between the resources that are to be included in the event so that the media traffic can flow. Resource availability is indicated via a console which can discover and reserve resources through a thin-client user interface. The event is composed and saved through a standards-based set of web service tools, allowing for quick integration into other applications and easy extensibility for new tools to be added. The goal of the DDN project is to show that a dynamic environment enables administrators to quickly set up and monitor dynamic testing events and system networks. The work includes researching alternative approaches, developing an architecture, building a prototype, and testing the proof of concept between defense testing sites. The result of this work is an initial body of knowledge and prototype for distributing data across wide area networks. This paper describes the project’s operational goals, technical architecture, results, and future areas of research.IntroductionDistributed EventsThe cost of testing, training, and analysis events must be reduced and potential expanded to effectively and efficiently support development of critical capabilities for the Warfighter. Traditional event setup requires manual configuration of routers and the opening of portals within firewalls to allow data traffic to pass through. In the past, it has taken weeks to identify the appropriate IP addresses; coordinate and communicate with all participants; and debug any errors created due to this manual configuration process. This excessive cost and time overhead has had the effect of both limiting the number of events that can be supported over a given period in addition to limiting the scope of those distributed test events. When persistent networks are indeed used, there is no partitioning of data to allow for multiple simultaneous events.  Simultaneous events are either not a possibility, or require manual manipulation of network hardware to create Virtual Local Area Networks (VLANs).Dynamic Distributed NetworksDynamic Distributed Networks (DDN) is an advanced research project for the Joint testing community, focused on demonstrating the ability to create overlay networks for test and evaluation. The DDN project is harnessing the commercial investment in web-automation technologies to the T&E infrastructure by developing a solution for dynamically generating overlay networks between resources, as well as building tools to provide management and monitoring of those networks. The Extensible Messaging and Presence Protocol (XMPP)—a proven industry favorite and open standard for providing cross-enclave voice over Internet protocol (VoIP) communication—is harnessed to provide presence and signaling across sites. This signaling is used to initiate a Virtual Private Network (VPN) between the resources that are to be included in the event so that the media traffic can flow. Resource availability is indicated via a console, which can discover and reserve resources through a thin-client user interface. The event is composed and saved through a standards-based set of web service tools, allowing for quick integration into other applications and easy extensibility for new tools to be added.The purpose of this research is to investigate alternatives to rapidly configure overlay networks for isolating event traffic from the underlying persistent network.  We considered a few options.  These included earlier approaches we undertook using Session Initiation Protocol (SIP) appliances to develop secure tunnels between enclaves [1] [2], automatically configuring Virtual Local Area Networks (VLANs), and automatically configuring Virtual Private Networks (VPNs).We discounted using SIP because of the challenge of having to tunnel all communications within the Real-Time Transport Protocol (RTP) [3].  Although we have tunneled UDP traffic such as Distributed Interactive Simulation (DIS - defined by IEEE standard 1278), it would be more difficult to tunnel TCP traffic through RTP.We decided that the VLAN approach was not feasible at this time.  This would have required us to access every network device across all enclaves we are targeting, the core routers in the WAN, and get buy in from the numerous organizations involved.Therefore, we decided that the best approach is to use VPNs.  DDN creates event aware overlay networks by automatically configuring dial-up IPSec (IETF RFCs 4301–4309) VPNs.  These overlay networks isolate participant communications from the rest of the underlying network. This innovative use of VPNs provides new capabilities and benefits to the T&E community.  These include:The ability to configure and run events within minutesThe reduction of firewall rules necessary to allow participants to communicateThe ability to run simultaneous events without the worry of cross-talk between the inter-event participantsThe ability to run simultaneous events at different security levelsThe brain of DDN is a specialized control component that manages the set up and teardown of the event VPNs. At startup, the DDN control software generates VPN policies on the fly and pushes them to a Juniper SSG 350 VPN server to set up a dial-up VPN for a pre-defined set of participants.  After the DDN configures the VPN, it sends startup commands via XMPP [4] to special purpose XMPP clients (named Overlay Agents) that reside on all participant hosts. The Overlay Agents, in turn, start up co-located VPN clients and instruct them to connect to the VPN server, thereby establishing IPSec tunnels between the VPN clients and server.  After the VPN tunnels are established, the participants can securely communicate with each other during the event.  When the DDN receives an event stop command, it relays it to the Overlay Agents, which disconnects the VPN clients from the server and shuts them down.  The DDN then removes the event policy from the server.Other DDN components include the Event Planning & Coordination Console (EPACC), which allows the event planner to register participant resources, to discover the registered participants in order to compose an event, and to start the event.  The EPACC also has a visualization client that shows a logical representation of the event overlay network, all the participants in the event, and the communications between them.  The visualization client allows the event manager to visually monitor the health of the event.The visualization client communicates with other visualization components that gather and process participant information in a format suitable for the client to process and display.This paper describes in detail the DDN architecture and all the major components that compose it.DDN ArchitectureDDN is a service-oriented architecture (SOA) [5].  As such, DDN is comprised of numerous stand-alone Web Services, which are loosely coupled.  As depicted in Figure 2, DDN is comprised of several major components: an Event Management Componenta DDN Control Componenta Control Communications Componenta VPN Appliancea set of Participant Host Agentsa Visualization ComponentThe Event Management Component consists of the EPACC, which manages the composition of events.  The DDN Control Component manages, creates, and destroys the event overlay networks.  The Control Communications Component is comprised of the open source Openfire XMPP server.  We use the Openfire Server to distribute VPN client startup and shutdown commands to all participant hosts via XMPP.  The Juniper SSG 350 VPN appliance establishes the IPSec VPN tunnels for the events.  The Participant Host Agents include an Overlay Agent that receives XMPP commands from the DDN control component via the Openfire Server, the VPN dial-up client that establishes VPN tunnels with the VPN server, and the Visualization Listener that captures the participant’s traffic, processes it, and forwards it to a Visualization Processor that resides in the local enclave.  All Visualization Processors, in turn, send processed participant traffic data to the main Visualization Server.  The Visualization Server finally collates data it receives from all the Visualization Processors and forwards it to the Visualization Client embedded in the EPACC for display.  The Visualization Client, Visualization Listener, Visualization Processor, and Visualization Server comprise the Visualization Component.The following sections describe each of the major components in detail.Event ManagementThe Event Management Component defines and manages events.  The Event Management Component is comprised of several loosely coupled Web Services.  We developed the Web Services using the WS-I Basic Profile 1.1, JAX-WS , EJB 3.0, and JPA standards.  These Web Services include:Registration Service – a general-purpose registry whose entry fields are configurable by the user.  We configure two types of registries, one to register participant resources and one to register associated Overlay Agents.Discovery Service – a service that distributes registry queries to all registries across enclaves in a federated environment.  The Discovery Service collects the query results and provides them to the service caller.Event Composition Service – a service that defines an event.  An event definition includes a event name, time and duration of the event, notes associated with the event and event runs.  An event can consist of many test runs.  The run definition includes a run name, time and duration of the run, notes, and the list of all participants resources and associated Overlay AgentsEvent Repository Service – a service that stores event information.  The event information is stored in XML and saved on disk for later retrieval. Event Execution Service – a service that requests stored events, communicates with the DDN control module to start and stop event runs, and keeps track of currently running event runs.EPACC graphical user interface (GUI) application – a thin client application developed using Servlets, JSP, Javascript, and EJB3.0.  The EPACC is an interface to all the Event Management Services to facilitate the planning, management, and control of starting and stopping event overlay networks.  The EPACC also has an event run control window, which has the embedded Visualization Client.The Event Management Component via the EPACC provides the necessary tools for an event manager to configure and establish event overlays. DDN ControlThe DDN Control Component is the brain of the system that establishes event VPNs.  The DDN Control Component receives a list of participant resources and their associated Overlay Agents and automatically generates VPN policies based on that information, pushes the policies to the VPN server, and signals the Overlay Agents to start and stop the VPN clients on the participant hosts.  The DDN Control Component also keeps track of all event runs.  Additionally, it receives status information from the Overlay Agents via XMPP and publishes that status to a Really Simple Syndication (RSS) [6] feed and copies the status in a file on disk.We chose Sun Microsystem’s open source OpenESB platform to implement the DDN Component SOA.  OpenESB provides a number of communications components, a Web Service orchestration engine called Business Process Execution Language (BPEL) [7] to orchestrate DDN Component Web Services, and other OpenESB features that allow easy and fast integration of Web Services to create enterprise class composite applications.OpenESBOpenESB is an open source and standards based alternative to proprietary SOA development environments.  OpenESB conforms to the Java Business Integration specification (JBI) JSR 208 [8].  OpenESB is comprised of a set of pluggable components and an in-memory message bus that integrates enterprise services.  The bus is called the Normalized Message Router (NMR) or JBI bus.JBI components come in two flavors:Service Engines (SEs)Binding Components (BCs)Service Engines are specialized processors that provide specific services in the JBI runtime environment.   Available SEs includeBPEL SE Encoding SE Enterprise Data Mashup SE ETL SE Intelligent Event Processor SE Java EE SE SQL SE XSLT SE The DDN Control component employs the Java EE SE and the BPEL SE.The Java EE SE provides an interface between the Glassfish application server and the JBI runtime environment for Web Service consumers and providers.  This allows direct access to Web Services via the NMR, which reduces request-processing time.BPEL is an XML based business processing language that is used to orchestrate services in the JBI environment.  These services can be external services or internal services such as SEs, Web Services exposed via the Java EE SE, or other BPEL processes. Sun’s NetBeans IDE provides a graphical BPEL editor with BPEL control and logic modules that one can drag and drop onto the graphical design canvas.  To orchestrate Web Services and/or other BPEL processes, one simply drops their WSDL [9] interfaces onto the canvas.   BPEL “programming” consists of literally connecting the dots between control, logic, and the WSDL interfaces.Binding components allow external connectivity to the JBI environment.  OpenESB currently provides 27 BCs:ADABAS Natural CICS CICS BC CORBA BC DCOM BCEJB BCEmailBC (IMAP) File BC FTP BC HL7 BC HTTP BC IMS BC JDBC BC JMS BC LDAP BC MQ Series BC MSMQ BC RSS BC SAP BC SIP BC SMTP BC SNMP SWIFT BC TCPIP BC UDDI BC XMPP BC EXEC BC There are many more BCs in the works.  The BCs provide a protocol agnostic interface to external producers and consumers of JBI services.  We use the HTTP BC, XMPP BC, RSS BC, and the File BC in the DDN Control module.For detailed information about each JBI component, visit http://wiki.open-esb.java.net/Wiki.jsp?page=Jbicomps. Figure 3 illustrates the JBI runtime environment.  In this example, an external service consumer accesses a JBI service via a BC.  The BC receives a message, translates it from the external protocol to a normalized XML based message, and sends the message to the NMR.  The NMR then routes the message to an SE for further processing.  After processing the message, the SE sends the response to the NMR, which routes it to the appropriate BC.  The BC in turn receives the response, translates it from the internal normalized message format to the external protocol, and returns it to the service consumer.DDN Control FunctionBefore one can use DDN to manage and run events, a system administrator needs to install and configure all the participant host agents on the participant hosts.  Each Overlay Agent has a unique identifier.  The administrator then registers all the Overlay Agents in the Openfire server.  Once the participant hosts and Openfire server are configured, an event run can proceed.Figure 4 shows the control flow of the DDN Component.  The illustration does not show the interaction of the Visualization components.  Upon event run initiation, the Event Management Component sends a list of participant resources and Overlay Agents to the start operation interface of the DDN Control composite application.  The DDN Control application flow upon receiving the start command follows:The control application instructs the Openfire XMPP server to create a chat group for the current event run.The control application sends an Invite command to the chat group with a list of all the participants of the run.The chat group signals the Overlay Agents to join the group.The control application develops the VPN policy for the run, establishes an SSH session with the VPN server, and pushes the policy via the VPN server’s command line interface (CLI).The control application sends a start message to the chat group.The chat group distributes the start message to the Overlay Agents.The Overlay Agents start the VPN clients and instructs them to connect to the VPN server.The VPN clients dial-up the VPN server and establish the IPSec tunnels.The VPN assigns IP addresses to the VPN client’s Virtual Adapter.  The participant operators may have to reassign IP addresses in the application.The participant operators start the simulators or systems.Upon a stop command, the DDN Control application causes the VPN clients to disconnect and shutdownthe Overlay Agents to disconnect from the chat groupthe Openfire server to remove the chat groupto unset all VPN policies associated with the event runto clear all internal representations of the event runto signal the EPACC that the event has shut down.DDN VPNsThe Juniper SSG350 is one of a series of Juniper IPSec VPN servers.  Juniper supports two VPN tunnel types: site-to-site tunnels and dial-up tunnels.  As the name implies, site-to-site tunnels connect multiple sites together via their respective VPN servers.  Figure 5 illustrates how two sites connect via a site-to-site VPN tunnel.  Unless specifically prohibited by firewall rules, resources in LAN1 and LAN2 are able to communicate with each other in this scenario.In a traditional dial-up VPN scenario, a computing device (e.g., a laptop) with a dial-up client that resides in an “untrusted” zone (Untrust Zone) connects to resources in a “trusted” zone (Trust Zone) via a dial-up VPN tunnel as depicted in Figure 6.  In this scenario, the dial-up tunnel extends from the dial-up client to the VPN server in the Untrust Zone of the VPN server.  The trusted resources in a LAN reside in the Trust Zone of the VPN server.  Once the tunnel is established, the laptop can access the resources specifically configured for the Trust Zone.  DDN employs dial-up VPNs for event overlay networks.  The scenario for DDN is a variation from the traditional one shown in Figure 6.  In DDN, resources or event participants in the Untrust Zone do not access resources in a Trust Zone but other participants in the Untrust Zone.   Figure 7 illustrates a typical DDN scenario.  All the event participants across the different sites reside in the Untrust Zone.  The example depicted shows how participants in Pt. Mugu Naval Base, CA; Patuxent River Naval Base (PAX), MD; and Eglin Air Force Base, FL communicate with each other after they have established dial-up VPN tunnels with the VPN Server.  Participant Host AgentsIn order to extend the reach of the DDN Control plane into the participant host machines host agents are installed. The agents provide the following capabilities:Point of ControlPoint of PresenceVPN ConnectivityVisualization of trafficPoint of Control is necessary to support the Call Out model that is currently being used. Support for a Call In model is planned for the future. Point of Presence is necessary to enable monitoring and management of the participants in an overlay network. XMPP’s built in presence capabilities are a solid match for this. Overlay AgentThe Overlay Agent is a Java based enhanced Visualization Processor and XMPP capable User Agent Client (UAC) that provides point of control, presence, and visualization capabilities. It includes pre determined behaviors for various messages that enable it to provide local control for event overlay networks. XMPP signaling provides the ability to control the participation of the agent in events via the multi user chat capabilities provided by the XMPP extension specification XEP-0045. Upon receiving an invite the agent determines if it is allowed to join in the event. It will then either accept or reject the invitation based upon the current policies that it is enforcing. If the agent transitions to the state in which it is part of an event it will send a presence update to the XMPP server and the multi user chat indicating that it has joined an event. While participating in a given event multiple messages can be used to control the agent. A start message to the agent will trigger the subsequent invocation of the VPN client to begin the processes that will ultimately create the VPN connection enabling participation in the event overlay network. A stop message can be used to trigger the process that ultimately tears down the VPN connection ending participation in the event overlay network. To complete the signaling capabilities there are various ways in which the agent can be signaled to leave the event it is currently participating in. First, the user agent can be kicked from participating in the multi user chat. It will interpret this as both a stop message and a leave event message. The second method it will respond to involves the destruction of the multi user chat on the XMPP server. The agent listens for the specific presence message indicating the destruction of the multi user chat and interprets is as both a stop message and a leave event message.Throughout the signaling processes, the agent both consumes and produces presence updates. Each state transition with in the event overlay network control process produces presence updates to the agent’s XMPP presence providing both indicators of the agents current state as well as allowing monitoring of the overlay creation / destruction process by the DDN Control Functions. This allows the DDN Control Services to take corrective actions as necessary to maintain the health of the event overlay network. It also enables Event Administrators to take action as necessary should a catastrophic failure occur. The overlay agent also provides critical visualization capabilities. When VPN sessions are created and destroyed the agent notifies the visualization server of the event. This allows the visualization clients to display the VPN sessions to administrators providing information on the health of the overlay network from the perspective of the overlay participant.VPN ClientThe VPN client will provide the virtual network connection to the VPN device for each participating host. The VPN client requirements for DDN have several characteristics that have proven difficult to find in one client. Obviously the client needs to be compatible with the VPN hardware configuration chosen. For DDN this means that the client at a minimum needs to support IPSec with IKE key exchange protocol using pre-shared keys. The other more specialized requirements are as follows.The DDN overlay agents need some way to communicate with the VPN client and issue commands to start up, connect, disconnect, and shut down. The most intuitive way is through calls to a command line program provided by the VPN client.The NAC listener needs a network interface that properly implements the NDIS [10] specification to listen to the simulation traffic flowing on the virtual network.  The VPN client therefore needs to provide a virtual network adapter to appear to be a physical network adapter with the ability to see unencrypted traffic flowing inside the virtual network.It was found that some simulators and client/server programs need a network interface in order to understand the assignment of a virtual IP address. This further concreted the need for the VPN client to implement a virtual network adapter. The virtual network adapter would then be used as a common place holder for these programs to learn the virtual IP address.The overlay agents need the ability to dynamically configure the VPN client. There are three typical methods of providing this feature.Most enterprise level VPN clients provide a separately packaged server that allows the clients to contact this for their configuration.Direct access to the client configuration files.Importation of a text file directing the VPN client Preferable the client would have a built in basic firewall program to allow the enforcement of firewall rules on particular programs and not just the global computer level. The firewall was found to be useful to prevent the simulation traffic from accidentally flowing onto the physical network directly. The benefit of having the firewall built in the VPN client is that it is not active when the client is not active, although this could obviously be worked around having it built it reduce some potentially irritating complexities.Of the several potential clients reviewed it was found that NCP’s Secure Entry Client [11] was most suited for the needs of DDN. The Secure Entry Client provided all of the required characteristic as well as a firewall feature that can be enforced on specific applications.Visualization ListenerThe visualization listener is a generic network packet sniffer used to detect specific traffic on a network interface and report it to visualization processors for eventual display in the network visualization client.The visualization listener’s network listening and filter capability is built on the open source packages WinPcap [12], jNetPcap [13], and jNetStream [14]. It is a Java-based User Agent (UA) that enables visualization of traffic both originating from and destined for the participant machine that it is monitoring.  The listener uses JNI (Java Native Interface) via the jNetPcap libraries to interface with WinPcap to promiscuously listen to all packets, subject to CPU availability, on a particular interface. The visualization listener has configurable filters to define which protocols, based on ports, are of visualization interests. The packets are parsed using the jNetStream libraries and the configured protocol filters are consulted to determine which packets should be reported as which protocol to the visualization processors for display in the visualization client.The listener uses three techniques in order to collect and process information. These include sniffing, flattening, and sampling.  Sniffing allows the listener to record information about the packets flowing through the network adapter. Like WireShark the listener uses filter criteria to determine if a given packet is valid. The criteria include:Source portDestination portSource AddressDestination AddressThe listener uses pre configured information in applying this filter to determine what protocol the packet is using. If the packet is found to be valid then the information in the packet is recorded for transmission to a visualization processor. The information recorded includes the following:Source addressDestination addressSource portDestination portProtocol typePacket sizeTime of interceptionThe rest of the techniques are used to improve performance and minimize the impact upon both the host system and the remote system processing the recorded data. Flattening enables the listener to append subsequent packet data to an existing recorded packet image. When this is active, if a packet is intercepted that matches and existing collected packet, the packet size is appended to the collected data for the transmissions between the two network agents. This enables large amounts of data to be observed without incurring a 100% increase in traffic on the local network due to duplication when notifying a visualization processor of a captured packet. Sampling enables the listener to selectively select packets to process. This lowers the amount of CPU required by the listener when processing large amounts of data. While sampling enables the listener to increase the amount of network packets that it can effectively processes, there chance of missing a packet is increased. In the scenario where an event participant makes a rare or one time invocation to another participant it is possible that the listener will miss that should the packet fall within the period of time that the listener is not processing packets.VisualizationMonitoring of the dynamic overlay network enables and enhances the management capabilities provided by the DDN Control Functions. Providing near real time visualization of the overlay network creation / teardown process and the data traffic allows administrators to monitor the overall health of the overlay network and the various participant systems involved in it. While the Control Functions are capable of taking corrective action when errors occur, there are situations where human intervention is required. Visualization reduces the time it takes for the intervention to occur through easy to understand animated clients that display all recorded traffic, events, and status of both participants and the underlying supporting infrastructure. In order to enable these capabilities the visualization system needs to be able to scale both horizontally and vertically. As such it has been divided into a number of layers that include:A Visualization Server to aggregate data and generate administrative views.A Visualization Processor to processing data recorded by participant listeners.A Visualization Listener agent installed on a host machine to monitor local activityVisualization ProcessorThe Visualization Processor is a Java based daemon process that helps enable scaling of the visualization solution. It serves as a content aggregator and buffer for the visualization server. When in an environment with multiple visualization listeners, visualization processors are deployed to aggregate their collected data into a format that can be processed by the visualization server. If necessary, multiple visualization processors can be deployed to provide both horizontal and vertical scalability with each processor handling a subset of the overall visualization listener load. This will increase the throughput of the visualization server so long as the aggregate load does not exceed its processing capabilities.Visualization ServerThe Visualization server is a Java based Web Application that is supported by an Oracle database for data processing. It provides the following capabilities:Aggregation of dataView generationThe visualization server allows for XML based input of observed entities and events that are then transformed and processed via XSLT and database rules. The transformation and data processing serve to aggregate the data from the various data sources correlating entity identities, updating their status and base information and creating a graph of inter entity communication. The inter entity communication is based on bidirectional information allowing for both visualization of outbound and inbound communication. This enables the detection of overlay and network failures where participant A confirms an outbound communication with participant B, however participant B never confirms and inbound communication from participant A. The visualization server allows clients to receive views of the aggregated information. This can be performed either with XML or AMF3.  This in turn allows client applications to request information from the visualization server and display them to administrators to increase management, and monitoring capabilities. DemonstrationThe Phase I DDN project demonstration included testing participants in Pt Mugu, CA and Eglin AFB, FL across the JMETC (a persistent network that connects multiple enclaves across the SDREN) network.  The Pt Mugu site was chosen as the center to host the Event Management, the DDN Control Components, and the VPN server.  The participants in Pt Mugu included a Range Data Gateway (RDGW), a JIMM/InterTEC Asset, a TENA Naming Service host, and an Environmental Logger (EL).  The RDGW receives radar signatures from live radar sources or from simulated sources through a special interface.  It communicates the radar signatures to other participants in the network via the TENA protocol.  The JIMM is a simulated battle environment with numerous models that depict aircraft, land mobile platforms such as tanks, and naval resources.  The JIMM communicates via TENA through the InterTEC Asset interface.  The JIMM can both receive and send radar tracks.  In the demonstration, the JIMM and the RDGW in Pt. Mugu communicated with each other.  The EL logs data from participants that communicate via TADIL.The participant in Eglin was the C2 IT Weapon System.  This C2 system generates C2 data and communicates via TADIL.  The C2 system and the EL in Pt. Mugu shared data in the demonstration. DDN successfully established the VPN and instructed the VPN clients to set up dial-up IPSec tunnels with the server; thereby creating an event overlay network.  The participants also successfully communicated with each other during the demonstration.  Their traffic was isolated from the rest of the network. ConclusionsThe DDN architecture, prototype, and demonstration succeeded in meeting the project’s objectives for Phase I.  It provided the means for signaling with XMPP, then transporting TENA and TADIL traffic across the JMETC WAN on a segregated overlay network.  The planning console enabled the event administrator to discover the available participants, include them in the event, and monitor the network status through a visualization tool. The research and prototype from the DDN project provides a robust platform for future growth. The web services and standards-based architecture allow for easy flexibility and adaptation to discovered requirements.  Upcoming phases are planned to investigate and expand the capabilities of the original system.  In addition to the current unicast traffic, the system will be expanded to support multicast and broadcast traffic.  This is expected to save much time and effort currently associated with configuring and managing multicast traffic in events.  Additional research will be performed on federation of the system, using distributed web services and site-to-site VPNs so that all traffic need not be routed through a single hub.  Security requirements and capabilities will also be investigated.  DoD security policies may require the opening of VPN packets, inspection, and repackaging of the traffic before it leaves an enclave’s boundaries.  This need and possible alternatives for ensuring security will be investigated and implemented.As the need to connect distributed systems continues to grow exponentially, the importance of rapidly configurable networks will grow with equal importance.  The DDN research has shown that dynamically configurable networks are indeed possible, and that changes to both the network infrastructure and current operations will be needed to scale distributed events to their full capabilities.ReferencesS. Holben, R. McKeon, “Providing Asserted Identity Services for Distributed M&S.” SISO 06F-SIW-110, 2006.L. G. LiaBraaten, R. McKeon, “Creating Dynamic Logical Overlay Networks for Distributed Simulations.” SISO 06F-SIW-087, 2006.H. Schulzrinne, S. Casner, R. Frederick, V. Jacobson, “RTP: A Transport Protocol for Real-Time Applications.”  http://tools.ietf.org/html/rfc3550.P. Saint-Andre, Ed. “Extensible Messaging Protocol (XMPP): Core.” http://www.ietf.org/rfc/rfc3920.txt.E. Thomas, SOA Principles of Service Design, Prentice-Hall, 2007.RSS, http://en.wikipedia.org/wiki/RSS_(file_format)A. Alver, A. Arkin, and others (Eds.), “Web Services Business Process Execution Language 2.0,” April 11, 2007, http://docs.oasis-open.org/wsbpel/2.0/OSwsbpel-v2.0-OS.docR. Ten-Hove and P.Walker, “Specification: JSR 208, Java Business Integration (JBI) 1.0, Final Release” Sun Microsystems, August 2005.R. Chinnici, J-J. Moreau, A. Ryman, and S. Weerawaran, “Web Service Description Language (WSDL) Version 2.0 Part 1: Core Language,” W3C Recommendation 26 June 2007, http://www.w3.org/TR/wsdl20/3COM Corporation / Microsoft Corporation, “Network Driver Interface Specification Version 2.0.1”NCP Corporation, “NCP Secure Entry Client”, http://www.ncp.de/fileadmin/pdf/datenblaetter/NCP_DS_Entry_Client_Win.pdfWinPcap Team, “WinPcap Documenation 4.0.2” http://www.winpcap.org/docs/docs_40_2/html/main.html“JNetPcap User Guide”, http://jnetpcap.sourceforge.net/?q=userguide“JNetStream User Guide” http://jnetstream.sourceforge.net/docs/userguide.html Author BiographiesRYAN MCKEON is a Product Owner for Accenture.  He has extensive experience in distributed modeling and simulation in the training and testing communities.  He has co-authored three SISO papers, and serves on the SISO Distributed Simulations Processes and Tools Planning and Review Panel.  He holds a B.S. in Computer Science and is currently pursuing an MBA, both from the University of Florida.RICHARD RICART is a Technical Architect for Accenture and is the current technical lead in the DDN project.  He has over 20 years experience as a principal investigator conducting research for DoD and integrating telephony, Web applications, and networking technology for enterprise level systems.  Mr Ricart has an M.S.E.E from the Air Force Institute of Technology.RODNEY RIVEN is a Senior Consultant for Accenture with 10 years of advanced distributed systems experience. He has implemented medium to large scale systems for various US government and quasi-government entities, with user bases ranging from hundreds to millions of distinct users.SCOTT WOLFRAM is a Senior Consultant for Accenture. The majority of his career has been in the design, implementation, and integration of large scale J2EE applications.  He holds a B.S. in Computer Science and is currently pursuing an M.S. in Software Engineering, both from the University of North Florida.( 2008 Accenture. All Rights Reserved.Figure  SEQ Figure \* ARABIC 1: Dynamic Distributed Networks OV-1Figure 2: DDN ArchitectureFigure 3: JBI Runtime EnvironmentFigure 4: DDN Control FlowFigure 2: DDN ArchitectureFigure 5: Site-to-site VPN TunnelFigure 6: Dial-up VPN TunnelFigure 7: DDN Dial-up VPN Tunnel