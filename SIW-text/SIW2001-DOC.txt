Overview on a Cluster-gateway based HLA DVSEChen Dan, Bu-Sung Lee, Wen-Tong Cai and Stephen TURNERNanyang Technological UniversitySchool of Computer EngineeringBlk N4, #02A-32, Nanyang AvenueSingapore 639798{ p146414471,ebslee, aswtcai,assjturner}@ntu.edu.sgKeywords:HLA, Cluster-Gateway, CDVSE, DVS, FDKABSTRACT: Under High Level Architecture (HLA) specification, federates are limited to interact with each other within the context of a single federation execution through a single Runtime infrastructure (RTI). Although RTI supports federation execution over WAN, the execution of distributed interactive simulation on WAN is restricted due to the limited bandwidth.In order to gain more scalability in HLA compliant distributed simulation, the concept of Cluster-based DVSE (CDVSE) is proposed to support large-scale simulations. The CDVSE group federates into clusters interconnected by high-speed communication medium. Clusters are supported by cluster-gateways and connected to each other to form a hierarchical federation that is compliant to HLA specification. Thus, HLA Cluster-based distributed simulation over WAN is enabled, in which federates share a single Federate Object Model (FOM).A prototype CDVSE system was developed using Federated Development Kit (FDK 2.0) from Georgia Institute of Technology. This paper will discuss the issues of interaction among federations in HLA Cluster-based distributed simulation. It will introduce the functionality of Cluster-gateway to support different RTI services, and discuss the design and other issues involved in the cluster-gateway. This paper will highlight the message exchange mechanism used in the Cluster-based distributed simulation, which is a subset of Object Management services in RTI. To achieve more efficiency in inter-cluster communication, data-filtering technology, the solution to reduce bandwidth requirement in inter-cluster communication is investigated and implemented in our work. Declaration management services are successfully supported by cluster-gateway for data filtering. Performance comparison results will be presented in the paper.Introduction Under High Level Architecture (HLA) [1], federates are limited to operating within the context of a single federation execution and interacting through a single RTI [2]. Current RTI only supports federation operating on a WAN, distributed interactive simulation is under some restriction due to lack of bandwidth in WAN. In another word, more scalability is required in HLA DVSE. One method to overcome this limitation is use of clusters. Cluster-based DVSE [3] (CDVSE) was proposed to group federates into clusters that are supported by cluster-gateways and are connected to each other via LAN/WAN to form a hierarchical federation. Michael D. Myjak has proposed the concept of multiple-federations [2] to represent those discrete HLA federations which may interact to each other by employing special mechanism. In CDVSE, utilization of cluster-gateway enables the interoperation between homogeneous federations. Thus, much more scalability is achieved in CDVSE with absolute compliance to HLA specification.It should be noticed that cluster-gateways are introduced as the bridges between same type HLA federations other than that described in [4]. In HLA DVSE, the nature of interaction is message interchange between federates. Message interchange technique in CDVSE is the main concern in this paper. CDVSE operates as a message-driven system; it requires our cluster-gateways to guarantee reliable dissemination of messages. In addition, data-filtering method is applied to optimize inter-cluster communication.In our paper, another essential concern is the so-called synchronization mechanism in CDVSE. In a federation execution, RTI services are arranged in strict chronological order in HLA DIS. Synchronization between different stages is mandatory to avoid disarray during simulation. For instance, we must introduce a synchronization layer between Declaration Management (DM) and Object Management (OM). It guarantees subscription of all federates being accomplished before any federate sends “update” & “interaction” messages. Otherwise, some federates may miss interaction data that they have subscribed to.2. Cluster-gateway Overview2.1 FDK-DRTI services supported by  cluster-gatewayTable 1: RTI services APIs in FDK supported by GatewayRTI services in FDKCluster-Gateway support methodsFederation ManagementJoinFederationExecutionNot NecessaryDeclaration ManagementPublishObjectClassNot NecessaryPublishInteractionClassNot NecessarySubscribeObjectClassAttributesReflectAttributeSubscriptionSubscribeInteractionClassReflectInteractionSubscriptionObject ManagementCfedAmbCRTIAmbRegisterObjectInstanceDiscoverClusterObjectInstanceRegisterClusterObject InstanceUpdateAttributeValuesReflectClusterObjectInstanceUpdateClusterAttributeValuesSendInteractionReceiveClusterInteractionSendClusterInteractionTime ManagementNot SupportCurrent CDVSE is developed from the Debbie’s RTI (DRTI) in the Federation Development Kit (FDK) 2.0 distributed by Georgia Tech Research Corporation [5]. FDK is an open-source RTI development platform. RDE Forum at the 2000 Spring SIW identified the point that “when programmers on the Internet can read, redistribute, and modify the source for a piece of software, it evolves”[6]. Minimal modification has been done to FDK to meet some special demands for interacting with cluster-gateway. Such modification does not affect communication mechanism of FDK or offend the HLA specification.FDK-DRTI provides modest yet essential APIs to organize HLA federations. Together with modified DRTI APIs, our cluster-gateway support all the services provide by FDK-DRTI except Time Management that is left for future development. Table 1 lists these FDK APIs and corresponding support methods built in cluster-gateway. Here we use cluster-based distributed Virtual simulation (CDVS) to represent distributed simulation that is built based on CDVES. The architecture of CDVSE can be illustrated in figure 1.  EMBED Word.Picture.8  Figure 1: Architecture of Cluster-based DVSEIn HLA DVS/CDVS, RTI services work in sequence for different purposes. The employment order is Federation Management service, Declaration Management service and Object Management service. In this sense, a HLA DVS/CDVS execution may be divided into three relatively independent stages, say FM stage, DM stage and OM stage:In FM stage, the joinFederationExecution method is responsible for creating, joining and resigning federations in FDK-DRTI. Cluster-gateway works like a normal federate in joining federation in FM stage and does not interact with remote clusters. No interaction is necessary between different clusters, so no corresponding method is available in cluster-gateway. Cluster-gateway will collect intra-cluster information and prepare for inter-cluster interaction.In DM stage, RTIGATE gathers subscription information of each federate for both Class Objects and Interactions in local cluster by applying modified DM subscription services. GATECOMM will broadcast gathered intra-cluster subscription information to remote cluster-gateways. At the same time, RTIGATE collects such subscription information from remote clusters. A Remote Object Subscription and a Remote Interaction Subscription database are established by RTIGATE to store subscription information of  remote clusters when DM stage of CDVS accomplishs. Cluster-gateways act as pure subscribers that means no pubishing method is needed.After DM, federates overall the entire cluster-based federation may enter OM stage to interact with each other under HLA specification. OM services consist of three relative subsets: register object instance, update Attribute Value and send interaction. As long as a federate register an instance of a object class, cluster-gateway should notify this event to each subscribers of that object class across the entire federation. The situation is the same in cases of updating attributes and sending interactions. In this stage, cluster-gateway takes care of disseminating these events to remote clusters in which exist certain subscriber(s) and it is responsible for collecting updating messages from remote clusters. As for common federates, the cluster-gateway should be transparent in the whole OM service stage. The implementation of such inter-cluster interaction is our principal concern, which will be highlighted in following section.2.2 Architecture of cluster-gatewayCluster-gateway at each cluster provides proper and efficient interoperability between the inter-cluster federates as well as facilitates coordination of multiple RTIs in CDVSE. As shown in Figure 2, cluster-gateway contains two mudules, GATECOMM and RTIGATE. EMBED Word.Picture.8  Figure 2: Architeture of cluster-gatewayGATECOMM and RTIGATE are two independent processes that work together through IPC to form the cluster-gateway. IPC is set up to facilitate message transmission between these two modules. Particular synchronization mechanism is fertilized to ensure proper data propagation between the two modules, which will be discussed in later section.The inter-gateway communication is set up to enable interaction between cluster-gateways, which was developed on MCAST-kit [3]. GATECOMM is responsible for reading messages from the inter-process and the inter-gateway communications; it directly interacts with remote clusters to implement “gateway-communication”. It can be regarded as the inter-cluster process of cluster-gateway. Non-blocking mode is used for reception in both communications, that is, control will be passed back to calling procedure immediately if incoming messages unavailable. RTIGATE is a special federate in local cluster. It acts as the bridge between RTI and inter-cluster communication. It has a federate ambassador (CfedAmb) and a modified RTI ambassador (CRTIAmb). RTIGATE collects messages from GATECOMM through IPC and disseminates them to local subscribers through its CRTIAmb. CRTIAmb is responsible for publish messages to intra-cluster. Comparing to GATECOMM, RTIGATE can be regarded as the intra-cluster process.Through RTI, RTIGATE responses for each event generated by local publishers and passes relevant message(s) to GATECOMM when necessary. CfedAmb collects and distributes these intra-cluster messages to remote clusters in real time.3. Cluster-based Distributed Simulation3.1 Inter-cluster Interaction in CDVSAs we have discussed above, when an instance is registered or attributes of an instance are updated or an interaction is sent, those particular subscribers in a CDVS should be invoked by these events. This does nothing with that they belong to the same cluster with the source federate (publisher) or not.CfedAmb methods (see table1) in RTIGATE, the callback module defined in HLA specification, capture each message generated by intra-cluster publishers. RTIGATE creates certain message(s) for each interaction, which packs data acquired from publishers.As a sequence to packing messages, RTIGATE  search the Remote Object Subscription or Remote Interaction Subscription database for desired class or interaction,  which is established in DM stage. Search result is employed to determine the destination clusters of messages generated by RTIGATE. Once subscription to certain Object Class or Interaction of any federate in a cluster been confirmed, this cluster is considered as a destination. Such process is defined as data filtering, which is important in reducing network bandwidth cost in inter-cluster communication and gaining maxium efficiency of CDVS.As for destination cluster, GATECOMM passes each incoming interaction message from remote clusters to RTIGATE in real time. RTIGATE employs CRTIamb innovations (see table1 ) to deal with them. In this sense one can also say CRTIamb is invoked by remote interaction messages. RTIGATE calls the corresponding routines to inform intra-cluster federates the new instance registered or object attributes updated or interactions created in remote clusters. RTIGATE will response to any message generated by intra-cluster federates. RTIGATE itself should react to its CRTIamb innovations inevitably. Once CfedAmb module in RTIGATE is invoked by the event generated by CRTIAmb methods, then current message will be disseminated to remote clusters and the whole CDVS should fall into confusion for an additional unrecognizable message. This phenomenon is called “self-reflect”. Methods are successfully built to prohibit RTIGATE  to reflect events created by itself. Cluster-gateway in interaction source cluster acts as a pure subscriber comparing to other federates. As for interaction destination cluster, cluster-gateway employs RTI-like services to “register” or “update” instance. In this case, it does not mean that cluster-gateway is a publisher. In fact, cluster-gateway does not generate any instance, and instead it only acquires instance handle together with relative data from remote cluster. What cluster-gateway actually does is distributing received message(s) to local subscriber(s). Following example may be helpful to understand such an inter-cluster interaction process. In further section, we will discuss the synchronization mechanism for reliable and stable CDVS.3.2 CDVS Message FlowFigure 3 illustrates the architecture of a CDVS example.  EMBED Word.Picture.8  Figure 3: Architecture of a CDVS exampleThere are three clusters in this example. In cluster 2, Fed-n has subscribed to object class A. In cluster 3, fed-l has subscribed to object class B and interaction N. Publisher Fed-m in cluster 1 has published class A and interaction N.  These federates work together to form a cluster-based federation. Update messages will be generated for instance of object class A and interaction N respectively by federate m. Following figure illustrates the flow of this simple CDVS example. To avoid extra concerning with Time Management, this paper will only present the procedure in which one message is passed across the whole cluster-based federation. We may use five steps to describe the procedure of simulation.  EMBED Word.Picture.8  Figure 4: Message interchanging flow of a CDVS exampleAfter the first synchronization been done, fed-n and fed-l concurrently send messages of subscription to their cluster-gateways.Cluster-gateway 2 and cluster-gateway 3 broadcast local subscription information to remote clusters. After synchronization of all clusters is accomplished, fed-m registers instance I of class A. This new instance invokes the CfedAmb module in cluster-gateway 1. The interaction message destination, say cluster 2 other than cluster 3, is determined by certain method of cluster-gateway 1. When message reaches cluster 2, cluster-gateway 2 strips out data from the incoming message. Sequentially its CRTIAmb module notifies fed-l the new remote instance I.Fed-m updates instance I. This message invokes CfedAmb module in cluster-gateway 1. Similar to the former step, a message which stores update information reaches cluster-gateway 2. Then cluster-gateway 2 passes the remote update message to fed-n.Fed-m generates update data of interaction class N’s parameters through multicast. Similar to step 4, fed-l in cluster 3 receives this remote interaction message finally, which has subscribed to interaction N. Step iv and v will loop until all federates get termination signals.3.3 Synchronization System There is an even simply but effective function built in FDK-DRTI named “barrier”. FDK user employs barrier to provide synchronization among federates. It guarantees all federates have accomplished certain operation after its execution. For federates supported by FDK, barrier is necessary between DM and OM to guarantee subscription of Class Objects and Interactions being accomplished before any federate may start to disseminate update or interaction messages. In CDVSE, not only is intra-cluster synchronization mandatory but also in cases of inter clusters. Innovations in modified RTI are applied to create two synchronization layers for CDVS. The mechanism of synchronization can be presented as figure 5. EMBED Word.Picture.8  Figure 5: Synchronization System ModelDue to the limitation of message buffer of inter-process communication (IPC), deadlock will break if there are too many incoming messages to be dealt with before receiver(s) can extract them from IPC message queue. The first synchronization layer is designed to prevent such deadlock in IPC between RTIGATE module and GATECOMM module of cluster-gateway.  Methods are proposed, which ensure RTIGATE modules being ready to react to messages passed by local GATECOMM modules through IPC before cluster-gateway may collect subscription information from remote cluster. There are N*(N-1) (N represents total number of clusters in a CDVS) messages in this synchronization process, which is swell when comparing to the overall communication amount in the whole CDVS.Cluster-gateway employs its DM support methods to disseminate subscription information that created by the normal federates to update the subscription databases of remote cluster-gateways. In OM stage, data filtering is achieved based on the databases that store remote-cluster-subscription information of object classes and interactions accordingly. For example when an instance has been successfully registered in a cluster-based federation, this event must be transferred to all federates which have subscribed to certain object class across the entire federation and may not reach other federates who never show interest in this class. Local  RTIGATE should browse its Remote Object Class Subscription database to locate the destination cluster which GATECOMM should send message(s) to. Synchronization layer between DM and OM ensures update of the two databases described above (see section 3.1) have been done when any federate (especially for message sender) begins its OM service.Let us turn to the CDVS example illustrated in figure 3. Figure 6 describes the whole procedure how Synchronization System between DM and OM works. Similarly following procedure can be divided into several steps for discussion. These steps are in strict chronological order. EMBED Word.Picture.8  Figure 6: Messages exchanging flow in Synchronization System between DM and OMFed-n and fed-l concurrently send messages of subscription to their cluster-gateways.Cluster-gateway 2 and Cluster-gateway 3 broadcast local subscription data to remote cluster-gateways. Fed-m sends a message to its cluster-gateway. This message covers DM termination information. It is the same for fed-n and fed-l. As far as cluster 1 is concerned, cluster-gateway 1 gets the message created by fed-m in step iii. It will check whether all intra-cluster federates have accomplished step 3 or not. Once confirmed, cluster-gateway 1 broadcasts a message to other remote clusters to indicate all members in local cluster have subscribed ready. At the same time, it will check itself has received the same message from all remote clusters or not. Finally cluster-gateway 1 breaks message-exchanging loop; cluster 1 goes into OM stage. It is the same for cluster–gateway 2 and cluster gateway 3. When DM done, operation described above should be carried on to make sure each cluster-gateway had its remote subscription database updated before invokes barrier. Here barrier guarantees intra-cluster federates will not try to update any instance or send interaction before cluster-gateway is ready.  Experiment and  ResultsHardware:2 x D-Link Systems DFE-904, 4 ports, 10/100 Mbps Dual-speed Hubby4 x Intel-based PCs with configuration:Intel 450 Mhz Pentium III (2 machines)Intel 450 Mhz Pentium II (2 machines)128 Mbytes of RAM3COM 3C905B-TX 10/100 Mbps Network Interface CardsPlatform: Sun Solaris 7.0/x86Following experiments measure the one-way latency between 2 federates. We use approach of the latency benchmark used in DMSO HLA. The latency is defined as the delay when any federate sends out a message to the point at which destination federate receives the same message.  EMBED Excel.Chart.8 \s Figure 7: Latency benchmark on DVSE VS intra-cluster communication in CDVSE (100Mbps Ethernet)Above figure is the benchmark results for latency taken between normal federates in the same cluster for original FDK and for CDVSE with message size from 100 to 1000 bytes. EMBED Excel.Chart.8 \s Figure 8: Latency benchmark on CDVSE for inter-cluster communication (100Mbps Ethernet)Figure 8 shows latency taken between 2 federates in different clusters which supported by CDVSE.ConclusionFDK-DRTI architecture was successfully modified to support CDVSE. Cluster-gateway actualizes communication and interaction (supported by OM service) among different clusters. It is implemented based on a message-driven mechanism. High reliability of message transmission is achieved in current design. Efficiency and real-time transmission are achieved in CDVS with full compliance on HLA specification. Compatibility of original HLA federates can be expected in current CDVSE. Data filtering supported by CDVSE reduces communication traffic in inter-cluster interaction. Synchronization over cluster-based federation is achieved. The synchronization layer between FM and DM guarantees IPC communication inside cluster-gateway efficiently. With the synchronization-mechanism discussed above, higher reliability and stability of Declaration Management Services and Object Management Services in CDVSE can be expected. Current design minimizes the cost on additional communication induced by synchronization.Experiment results show a working CDVSE system. A major problem is the additional latency incurred in CDVSE. Much more time is consumed in message processing in cluster-gateway than network communication. Two processes in cluster-gateway compete for CPU resource. The interdependence between them lower down the efficiency in communication. Even effort had been done to multithread cluster-gateway [7]; an optimized architecture of gateway is still expected to enhance the performance of current CDVSE. ReferenceDefence Modelling & Simulation Office  HYPERLINK Http://www.dmso.mil Http://www.dmso.milMichael D.Myjak, Sean T. Sharp, “Implementations of Hierarchical Federations”, Proceedings of Simulation Interoperability Workshop, Sept. 1999Liang Aik Hwa, Lawrence, “bandwidth Reduction Techniques for Distributed Interactive Simulation”, Master’s Thesis, Nanyang Technological University, 2000.Douglas D. Wood, Mikel D. Petty, “HLA gateway 1999”, Proceedings of Simulation Interoperability Workshop, Mar. 1999Federated Simulations Development Kit  HYPERLINK Http://www.cc.gatech.edu/computing/pads/fdk.html Http://www.cc.gatech.edu/computing/pads/fdk.htmlBret R. Givens, “Position for and against an Open-Source RTI”, Proceedings of Simulation Interoperability Workshop, Mar. 2000Robert L. Youmans, “Improving Performance of HLA Applications By Multithreading RTI Services Using the Proxy Design Model”, Proceedings of Simulation Interoperability Workshop, Mar. 19997. Author BiographiesCHEN Dan received his B.A.Sc. from Wuhan University (P.R. China) in 1994 and MEng. from Huazhong University of Science and Technology in 1999 respectively. He currently pursues  higher degree in the School of Computer Engineering of Nanyang Technological University (Singapore). His interests include Internet Technologies, Broadband Networks and HLA applications. A/Prof. Lee Bu Sung received his B.Sc.(Hon) and Ph.D. from the Electrical and Electronics Dept., Loughborough University of Technology, U.K. in 1982 and 1987 respectively. He is presently a lecturer in Division of Computing Systems, School of Applied Science, Nanyang Technological University. He is a member of the Asia Pacific Advance Network committee and is the Application Manager of Singapore Advance Research and Education Network project. His interest are in Broadband networks and its applications.Wentong Cai is currently an Associate Professor in the School of Applied Science, Nanyang Technological University (Singapore). He received his BSc in Computer Science from Nankai University (P.R. China) in 1985, and his PhD also in Computer Science from the University of Exeter (UK) in 1991. He was a Post-Doctoral Research Fellow at Queen's University (Canada) from 1991 to 1993.Dr Cai has served as program committee member in many international conferences, and was a coordinator of the Parallel and Distributed Simulation Mini-track in HICSS'32 (1999). He is a member of IEEE, and has published over 50 refereed papers in journals, books and conferences. His current research interests include parallel and distributed simulation, parallel programming environments and tools, parallel algorithms and architectures and system performance analysis.Stephen Turner received his MA in Mathematics and Computer Science from Cambridge University (UK), and his MSc and PhD in Computer Science from Manchester University (UK). He is currently a visiting Senior Fellow in the School of Applied Science at Nanyang Technological University (Singapore), on leave from Exeter University (UK), where he is Director of the Distributed Systems Group.His current research interests include: parallel and distributed simulation, visual programming environments, parallel algorithms and architectures, distributed computing and agent technology. He is Co-General Chair of the PADS 2000 (Parallel and Distributed Simulation) conference and a member of the advisory committee of DS-RT (Distributed Simulation and Real Time Applications).PAGE  1PAGE  1PAGE  1PAGE  4PAGE  1PAGE  8