RTI Benchmark StudiesBrad Fitzgibbons, Thom McLean, Richard Fujimoto College of ComputingGeorgia Institute of TechnologyAtlanta, GA, 30332 {bradf, thom, fujimoto}@cc.gatech.eduKeywords:HLA, RTI, Performance, BenchmarkABSTRACT: HLA federations are dependent upon the underlying Run-Time Infrastructure (RTI) to provide various services connecting individual federates, and the performance of these services affects the overall performance of the federation.  We compare three RTIs: the DMSO RTI-NG 1.3v4 and two versions of the Georgia Institute of Technology Detailed RTI (DRTI).  The first version uses a Tick() call to give control to the RTI and the second uses an additional thread to process services in an interrupt-driven manner.  We explore three benchmarks provided with RTI-NG and propose alternative methods of RTI benchmarking.  A performance-critical HLA federation requires a RTI with performance characteristics best suited to the simulation in question.  We compare differences between the RTIs with respect to simulation design and analyze the testing strategies used.  IntroductionThe High Level Architecture (HLA) has become the standard technical architecture for modeling and simulation in the U.S. Department of Defense.  One component of the HLA, the Interface Specification (IFSpec)  REF _Ref395702650 \r \h [1], defines the set of services that are used by individual simulations to interact with each other.  HLA simulations use runtime infrastructure (RTI) software to provide services to support interconnecting simulations as well as to manage the distributed simulation execution.  Although the IFSpec is unambiguous with respect to the meaning of simulation services, many underlying implementations are possible.  DMSO has fielded several RTI implementations.  Other parties have developed additional complete and partial RTI implementations.  In developing an RTI implementation, programmers make certain assumptions about the underlying architecture of the simulation system, and the manner in which the RTI will be employed.  These assumptions will affect the performance of the RTI under various operating conditions.  Typically, an RTI implementation will have to strike a balance between efficiency and generality.  While it is possible to construct very efficient implementations for certain execution environments, custom coding of such an implementation can be tedious, and is not always portable.  Conversely, a generalized implementation can provide portability and stability across many systems, but will sacrifice certain optimizations possible on some systems.Because of these trade-offs in RTI design, it is important for federation developers to understand the performance implications of different RTI implementation strategies.  Some of the performance characteristics of an RTI can be readily understood with simple, well-known benchmark programs.  However, many important RTI performance characteristics are not well understood.  Certainly, the community would benefit from a better understanding of RTI performance characteristics and the applicability of those characteristics to federation execution requirements.MotivationThe Georgia Tech Federation Development Kit (FDK) is a research code base used to construct RTI implementations and study various implementation alternatives for distributed simulation.  The FDK has been modified and enhanced over several years to provide insights into efficient implementation of RTI code.  In a recent study, the communications libraries were supplanted with a different communications paradigm.  (The specific changes are explained in Section  REF _Ref409548560 \r \h  \* MERGEFORMAT 3.  )  In particular, we have changed the manner in which incoming messages are delivered to the federate.  To understand the effectiveness of this new implementation, we employ various tests and measurements to understand the performance trade-offs.  Our testing revealed, as a by-product of the research, that there is not enough detail in our understanding of RTI performance measurement.  The effects of RTI implementation alternatives cannot easily be accounted for in testing methods.  We do not have sufficient understanding of the typical ways in which RTIs are used in a federation, and how this may highlight (or mask) certain inefficiencies in an implementation.  We are particularly interested in high-performance federations (e.g.: hard real-time execution, HPC environments, etc.), so we concentrate on issues related to high-performance communications implementations. HLA Testing ExtantTesting has been an important part of the development of HLA.  From the outset, DMSO commissioned the development of various HLA testing components.  Other parties have done various federation specific tests, but none are widely recognized within the HLA community.  Generally two types of tests have been developed: 1) compliance or verification tests, 2) performance benchmarking.HLA compliance tests exist for both federate and RTI compliance.  Federate compliance testing is an off-line (not in the context of an executing federation) set of tests to ensure that a federate conforms to the IFSpec and correctly implements its stated capabilities.  RTI certification is accomplished through a lengthy and exhaustive set of tests to ensure that an RTI correctly and completely implements the IFSpec.  An additional verification testing capability for verification is provided by the Federation Verification Tool (FVT).  Each of these tests is available through DMSO at  HYPERLINK "http://www.dmso.mil" http://www.dmso.mil.  HLA performance tests are also available from the DMSO web site through the Software Distribution Center (SDC).  There is a set of tests provided in the Run-Time Infrastructure Performance Benchmarks.  We inspect three of these benchmarks designed to address the following areas: 1) latency, 2) through-put, and 3) time-management.  Other than these three measures of general performance, no other tests are widely accepted.  HLA does not include any specific guidelines for testing, nor do testing procedures exist in companion standards (e.g. FEDEP).RTI BenchmarkingIn measuring the performance of different implementations, we are concerned with RTI overhead and how it might be affected by details of the implementation.  For example, we would expect a benchmark measuring message latency to reflect the differences between disparate communication implementations.  In addition we might wish to measure RTI performance with respect to federate design characteristics such as how often in gives control of execution to the RTI or how long a handler executes.We present our thoughts on general benchmarking of RTIs and offer alternative methods that might better demonstrate differences between various implementations.  Of particular concern is measuring the efficacy of our approaches toward a real-time RTI.  It then becomes necessary to measure distinct services within the RTI, especially those involving communication.OrganizationThe remainder of the paper is organized as follows.  Related work is presented in Section 2.  Section 3 discusses the Georgia Tech FDK and DRTI, a collection of libraries for RTI development and associated RTI, respectively.  Section 4 gives an overview of current synchronization models used in RTIs.  In section 5 we describe test setup, and sections 6, 7, and 8 hold comments on each benchmark used.  Section 9 presents possible alternative methods of benchmarking, followed by possible RTI extensions to support asynchronous execution in section 10.  Finally, section 11 contains our conclusions.Related WorkPerformance tests have been a frequent topic of SIW papers and presentation.  Most recently, paper 01F-SIW-033, presented at the Fall 2001 SIW, detailed the development of extensions to the DMSO performance benchmarks  REF _Ref409548661 \r \h [9].  The results of that effort were somewhat convoluted in the paper and presentation, which showed different outcomes.  The paper also did not describe the federation execution paradigm represented in the approach to testing.  Subsequent work on the benchmarks presented, and additional test results have been submitted for this workshop.  The work by these authors represents the only benchmarking effort that is independent of a major simulation program.  Such autonomy is beneficial to the community as a whole, in that it is not biased toward funding issues.In addition to general performance tests, several past SIW papers have presented capacity or scale results from specific programs  REF _Ref409548698 \r \h [2].  While these program execution results are somewhat interesting, they do not support a broader understanding of the importance of specific RTI performance characteristics in particular execution environments.  Conversely, several papers in other workshops and symposia highlight “raw” performance research  REF _Ref395702876 \r \h [4] REF _Ref535703189 \r \h [5] REF _Ref409548757 \r \h [7] REF _Ref409548775 \r \h [8].  Neither the program reports, nor the basic research reports are appropriate for setting expectations in particular executions.  In related work on real-time performance, McLean explores real-time repeatability in  REF _Ref409548794 \r \h [10] and characteristics of a real-time RTI in  REF _Ref535702497 \r \h [11].  Models for real-time execution were also presented.  A good background for understanding the performance of time management was presented by Fujimoto in  REF _Ref409548828 \r \h [6].Federated-simulation Development Kit (FDK)The Georgia Tech FDK is a collection of software consisting of RTI-Kit, a set of libraries for building RTIs, sample RTIs, and example federates.  Currently, the RTI-Kit provides several implementations of the underlying communications libraries to take advantage of specific architectures (e.g., shared memory, gigabit networks, and TCP) and needs (e.g., real-time vs. non-real-time).  A specific implementation is chosen at compile time for inclusion in a RTI using RTI-Kit.Design PhilosophyThe FDK is intended to supply researchers with a means of developing and testing various RTI designs.  Each RTI-Kit library provides a public API and might have multiple implementations.  The RTI-Kit collection of libraries can be used in whole or part to develop a RTI.Figure  SEQ Figure \* ARABIC 1 – RTI-Kit ArchitectureA RTI provides a set of services to facilitate data exchange and manage time in a federation, and many of these services require communication between federates.  For example, updating attributes of a shared object (UpdateAttributeValues) will send data from the calling federate to other federates which have expressed interest in the updated attributes. Also, time management requires a distributed computation to take place in order to guarantee the correct advancement of time at all federates.  These services are accessed via a standard API that may have many possible implementations.  It follows that we can target specific architectures or needs by varying the underlying implementation.  Some current implementations include shared memory for MMPs, gigabit networks using Myrinet, and TCP for commodity TCP/IP networks.A real-time implementation should provide services with predictable execution times. Therefore, all communication-based services will require bounded network latencies in order to reliably predict the time needed to complete any service.  In addition, as QoS networks become available we would like to extend RTI functionality to understand specific communications requirements of a federate or federation.Current efforts have concentrated on a multithreaded design, allowing for asynchronous (or interrupt-driven) message delivery.  Asynchronous communication is required by an RTI that expects to meet deadlines predicated on bounded message latency.   In a synchronous implementation, a federate must call Tick() in order to give control to the RTI.  Once given control, the RTI can then process messages and pass them to the federate.  The synchronous model is inherently unpredictable since no guarantees are made on how often a federate calls Tick().In light of the various implementations available, we are now developing a unified communications API in order to provide one abstract interface to all underlying implementations.   This library, Comm-Kit will eventually provide a powerful interface to specify communication characteristics at run-time.Architecture REF _Ref536543768 \h Figure 1 contains a simple diagram denoting the layered relationship between RTI-Kit, RTI, and federate.  In addition it shows a subset of the libraries within the RTI-Kit.  We will concentrate on the libraries involved in communication and time management.Communication in RTI-Kit has traditionally been provided by separate unicast (FM) and multicast (MCAST) interfaces.    Recently, we’ve begun to concern ourselves with developing an implementation to facilitate real-time communication, and more specifically, predictable communication latencies.  We have developed new FM and MCAST implementations around ECho, a collection of libraries that abstract architecture and transport from the communications process.  In addition, it supports a multi-threaded design used to facilitate asynchronous communication.  ECho is a continuing effort by Greg Eisenhauer  REF _Ref395698961 \r \h [3], a research scientist at the Georgia Institute of Technology.  The new implementation uses a thread to receive messages in an interrupt-driven manner, allowing the RTI to execute independently of the federate.  This development represents initial research toward providing real-time RTI services.The time management library (TM) is responsible for ensuring that simulation time within a time-managed federation remains consistent.  One federate should not be able to advance its time beyond the simulation time of the federation.  It also accounts for all timestamped messages and ensures correct delivery order.Detailed RTI ImplementationThe Detailed RTI (DRTI) is an FDK-based RTI that provides a subset of the services specified by the IFSpec.  When compiling DRTI, specific implementations of the communication libraries can be specified for inclusion.  Development of the ECho implementation includes some design changes to DRTI, but any operational effects are minimal.RTI Synchronization ModelsA RTI synchronization model refers to the method used by the RTI to communicate with federates.  A synchronous model requires the federate to give control to the RTI in order for the RTI to complete certain services on behalf of the federate.  In contrast, an asynchronous model maintains an independent thread of execution, allowing the RTI to execute without explicit federate interaction.Real-time execution implies predictable deadlines for RTI services.  It follows that a real-time RTI would benefit from the asynchronous model.  There are no guarantees on when or how often a federate must give control to the RTI.  Therefore, an RTI-owned thread would allow the RTI to operate concurrently with the federate, thereby allowing the RTI to ensure internal deadlines can be met.We will refer to three RTI implementations: RTI-NG, DRTI, and DRTI-ECho.  RTI-NG is a RTI provided by DMSO and is compliant with version 1.3 of the IFSpec.  The most current version as of this writing is RTI-NG 1.3v4.  DRTI will be used to refer to the RTI released with FDK 3.0, and DRTI-ECho contains the modifications mentioned with respect to ECho and represents our initial efforts toward a real-time RTI.Synchronous RTIsThe traditional model of synchronization in the RTI requires the federate to call Tick() in order to receive any waiting messages and allow the RTI to perform any necessary execution.  Both RTI-NG and DRTI use the synchronous model.  However, they vary in implementation.RTI-NG uses a thread to receive messages asynchronously, but nothing is delivered to the federate until Tick() is called.  Services not requiring federate interaction might also use the thread.  DRTI is single-threaded and requires a Tick() call to both receive and deliver messages and perform any other necessary execution.  However, each implementation conforms to the synchronous model.Asynchronous RTIsAs mentioned, a real-time RTI necessitates asynchronous operation of the RTI.  This allows us to bound execution of various RTI services without depending on federate design.  DRTI-ECho is our first step toward a real-time RTI.  It uses a thread to receive and deliver messages in an interrupt-driven manner.  Time management currently uses the synchronous model, but we plan to redesign it to take advantage of the asynchronous model.Test Configuration and SetupIn this section we discuss configuration issues on using the DMSO benchmarks and describe the system upon which we tested.  It is the intent of the HLA to provide a standard interface for all RTIs.  It follows that porting a federate between RTIs should need few, if any, modifications.  Our experience in porting the benchmarks to DRTI and DRTI-ECho reflects this intended ease of portability.The benchmarks were designed to work with RTI-NG. However, we discuss configuration issues with respect to our testing.  RTI-NG can be configured at run-time by specifying options in a supplied configuration file.  Porting From RTI-NG to DRTI and DRTI-ECho Certain details of the federation model with respect to data exchange are contained in a configuration file called the FED.  Some trivial changes were made to the FED for both DRTI and DRTI-ECho.  DRTI does not support comments so comments were removed.  DRTI-ECho uses a more robust parser that does support comments (future versions of DRTI will include this parser).  Also, both FDK RTIs expect objectRoot and interactionRoot to use lower-case letters at the beginning of each.  The FED provided by the benchmarks used upper-case letters at the beginning of each string and were modified to work with DRTI and DRTI-ECho.Neither FDK RTI implements synchronization points, a service meant to ensure all federates have reached a certain point in their execution.  Instead they provide a barrier function to provide the same functionality.  Code changes were made in one place to replace the synchronization point interface with the barrier interface.Both RTI-NG and the benchmarks were developed using egcs++ 2.91.66.  Therefore, DRTI and DRTI-ECho were also compiled using the same compiler, and the resulting benchmark federates linked without problem to each RTI.RTI-NG ConfigurationFigure  SEQ Figure \* ARABIC 2 – Latency ResultsNeither FDK RTI supports MOM, a feature of the HLA used to report information about a running federation.  Using MOM incurs additional overhead and was disabled by setting MomServiceAvailable to No in the provided RTI.rid configuration file.  However, the benchmarks use MOM to wait until all expected federates have joined the federation.  We replaced this section of code with a trivial call to sleep(), providing us with enough time to start all the federates.RTI-NG also provides an option to enable/disable message bundling.  That is, when enabled all messages collected within a finite window are bundled and sent together.  When disabled each message is sent immediately.  We tested RTI-NG under both conditions.An additional difference between the FDK RTIs and RTI-NG involves federation management.  The FDK RTIs operate in a peer-to-peer fashion, distributing state information across the federation.  RTI-NG, on the other hand, requires an additional process to mediate state information on behalf of the federation.  This program (rtiexec) can share a computer with a federate or run on a computer independent of the federation computers.  All tests were run with rtiexec running on the same computer as a federate.Test SetupAll tests were conducted on 2-16 dual-Pentium II 300Mhz computers running RedHat Linux 7.1 and communicating via a commodity 100Mb Ethernet network.  Each RTI uses the standard TCP protocol.  We discuss each benchmark in the following three sections.  Benchmarking Update LatencyThe DMSO BmLatency federate is designed to measure the average one-way latency of an update between two federates.  The timer is started immediately before the sending federate calls UpdateAttributeValues().  The receiving federate reflects the update, and sends an update back to the sending federate.  The timer is then stopped immediately after the sending federate reflects the second update.  The round-trip time (RTT) is divided by 2 to calculate average-one way latency. Each test consisted of measuring 1000 average one-way latencies.  A series of tests was run for each RTI with increasing attribute (message) size.  In each trial the mean is calculated from the 1000 average one-way latencies.Experiences REF _Ref536565897 \h Figure 2 shows the results of our tests split between bundling and non-bundling implementations.  It can be observed that bundling forces messages to be delayed, resulting in higher latencies.  The latencies stabilize as messages become too large to bundle.  Unbundled operation results in a similar curve between the RTIs.  These curves are consistent with our expectation that latency should increase with message size.CommentsThe BmLatency program attempts to measure the average one-way latency between two federates.  The resulting average includes latencies imposed by the network, RTI, and reflecting federate.  However, we might ignore federate-imposed latency to better understand how RTI overhead affects update latency.   For example, we might expect to see lower values for RTIs using an asynchronous model.  Figure  SEQ Figure \* ARABIC 3 – Sender Throughput ResultsIn addition, we might simulate federate load to better understand its effects on different RTI implementations.  In testing a synchronous RTI, we might insert load between Tick() calls to reflect the effects of different execution models on RTI performance.  An asynchronous RTI might be tested with load in the federate thread to test any possible effects on the RTI thread.  However, we would expect minimal if any effect since RTI operation is not affected by federate execution.  This was demonstrated in  REF _Ref535702497 \r \h [11].This suggests separating measurement of RTI- and federate-imposed overheads.  Separate measurements would better describe the relationship between federate behavior and RTI performance.Benchmarking Update ThroughputFigure  SEQ Figure \* ARABIC 4 – Receiver Throughput ResultsThe DMSO BmThruput federate is designed to measure update throughput between two or more federates.  Federates are designated as being either senders or receivers.  The senders record the time needed to send a fixed number of updates, and the receivers record the time it takes to reflect those updates.  This series can be repeated over a specified number of cycles, and the resulting two metrics are updates/sec and reflects/sec for senders and receivers, respectively.  In addition the size of the update and several other characteristics we don’t explore are available for testing.Each test consisted of 30 cycles where each cycle involved measuring the throughput of 1000 updates.  We ran a series of tests involving a single sender where the number of receivers and message size were independently varied.Experiences REF _Ref536571485 \h Figure 3 contains results for sender throughput divided among four graphs, one for each implementation.  We can see that bundling is advantageous with respect to RTI-NG.  However, both DRTI and DRTI-ECho perform comparably without bundling and excel in the case of two federates.  Otherwise, the results reflect our expectations of decreasing throughput as either message size or number of receivers increases. REF _Ref536572551 \h Figure 4 contains results for receiver throughput and has the same layout as  REF _Ref536571485 \h Figure 3.  Here we observe that bundling has a dramatic effect when the message size is small.  However, somewhere between 128 and 256 bytes, the advantages of bundling become negligible.  Again, throughput decreases as either message size or number of receivers increases.CommentsThis benchmark is designed to measure the raw data transfer capacity of the RTI.  In testing, a communication implementation can be tuned to provide results comparable to bulk transfer rates as does ftp.  These conditions are not generally applicable to realistic federation executions.  A better model of throughput might account for the federate delay in handling the incoming message.  Also, a more realistic test would determine throughput capacity when all of the federates were both senders and receivers.  Figure  SEQ Figure \* ARABIC 5 – BmTimeAdv ResultsIn both synchronization models, the time spent inside a reflect callback will affect throughput at a receiving federate.  Also, we might expect federate load (as mentioned in Section 6.2) to affect the performance of each model differently.  For example, we would expect federate load to affect an asynchronous model less than a synchronous model since the former can deliver all messages in light of federate load.We might then choose to measure the simultaneous effects of both handler execution time and federate load in order to better understand the effects of various federate behaviors on update throughput.  As with latency, this suggests separating the measurements of various components to suggest their effects on each other.Benchmarking Time AdvancementThe DMSO BmTimeAdv federate is designed to measure the time needed to advance time a specified number of units.  Multiple cycles are then averaged to produce a resulting grants/sec.  Each test consisted of 30 cycles, where a cycle involved measuring the time to advance time 1000 units.  A series of tests was run for an increasing number of federates.  The benchmark also provides the ability to specify a federate lookahead, but we did not specifically use this feature.  The default lookahead is one unit of simulation time.ExperiencesRTI-NG performed similarly regardless of message bundling and for all federation sizes RTI-NG averaged 18-20 grants/sec.  DRTI and DRTI-ECho perform quite differently in spite of using the same time management algorithms.  This disparity can be explained by the fact that DRTI-ECho is currently processing time advancement in a synchronous manner.  This requires additional overhead and decreases performance.  We intend to develop asynchronous time management at some point in the future.  Otherwise, as the federation grows performance decreases as expected.CommentsThis benchmark is handicapped by the presumption that raw time management efficiency will translate to federate performance gains.  Practically, this is not necessarily true.  For example, lookahead, and the symmetry of lookahead in the federation affect both the speed and efficiency of time management computations.  Also, a federation is unlikely to use time management services and not exchange messages.  Measuring time advancement with various levels of timestamped message load should demonstrate the effects of various federation behaviors on RTI performance.As mentioned in Sections 6.2 and 7.2, we might also impose various amounts of federate load and/or vary the time spent in a grant callback to better understand RTI overhead as affected by different federate designs.  Therefore, we find more evidence that measuring each component involved might lead to a better understanding of the system as a whole.Alternative MethodsMeasuring RTI performance is of interest to both RTI and federation designers.  In both cases, we are often concerned with testing the implementation of one or more services, either separately or concurrently.  In this section we present example designs for benchmarking two services, UpdateAttributeValues and TimeAdvanceRequest.  They can be run separately or together, and individual federates can be configured to model various federation designs.The benchmark should differentiate between performance characteristics of RTI and federate implementations.  That is, we should be able to measure both peak performance of a RTI service in lieu of federate overhead as well as performance with respect to various federate behaviors.  For example, we should be able to measure the peak performance of a service with an artificial federate, designed to impose no extra overhead.  On the other hand, we might impose some amount of load at one or more places in the federate to model various common behaviors.  In this way we can measure how federate design might affect RTI performance.UpdateAttributeValuesUpdateAttributeValues is the primary method used to exchange data among federates.  It follows that measuring performance characteristics of its execution could provide meaningful help to RTI and federation designers.  The DMSO benchmarks measure latency and throughput separately.  However, we propose a single benchmark for the service that can potentially measure each of its characteristics.Figure  SEQ Figure \* ARABIC 6 - Diagram of UpdateAttributeValues Benchmark REF _Ref536544533 \h Figure 6 shows an exchange of updates between two federates where t1 and t3 are times recorded just prior to sending an update, and t2 and t4 are times recorded at the beginning of the reflect callback.  We can use combinations of these recorded times to calculate latency and/or throughput.  The figure also shows how we might add load to either the loop containing Tick() or to the reflect handler.We can define update latency as the time elapsed between an update and invoking its respective reflect handler at any one federate.  That is, latency represents the time needed to make data available at a remote federate and is equal to (t1 – t0) or (t3 – t2).  However, it is not possible to accurately measure latency with a single message (update) between remote nodes because there is no way to perfectly synchronize two remote clocks.  Therefore, we must measure RTT as described in Section 6 and either use this value or divide by 2 for an average one-way latency.  Each provides a similar approximation of latency.  In follows that RTT is the sum of the two update latencies and can be calculated as (t3 – t0) – (t2 – t1).  This method ignores any federate-imposed latency that might take place between t1 and t2 and conforms to our definition of latency.As does BmThruput, we separate sending and receiving throughputs as being independently meaningful, and we define them in the same way.  To measure sending throughput, we can record the first t0 and the last t0 of a series of updates.  Dividing the size of the series by the time elapsed will give updates/sec (assuming the times are in seconds).  Similarly we can measure the first t1 and last t1 over a series of reflections to determine receiver throughput, and reflections/sec is calculated in the same way.To measure latency we must record all four times for each update in a series to calculate RTT.  However, throughput only requires 2 measurements per federate, once at the beginning of a series and again at the end.  We can then measure latency and throughput either separately or together.  It follows that when only testing throughput we need only record the appropriate 2 times for any one series of updates.  Also, measuring one-way throughput involves only half the cycle needed to measure latency.A federate can be configured to be either a sender or a receiver as shown in  REF _Ref536544533 \h Figure 6.  We define a stream to be a series of k > 0 updates in a sender-receiver relationship where one- and two-way streams use half the cycle (t0..t1) and the complete cycle (t0..t3), respectively.  In addition, we could assign properties to the updates associated with a stream that might include size, ordering (i.e., timestamped or not), and transport (i.e., reliable or best effort).  Within a federation, we can define multiple streams and which federates are end-points for each.  In this way, we can characterize all one- and two-way communication with respect to a specific federation design.  It should be noted that one-way streams will only provide throughput measurements.We define an iteration of a stream as the time needed to send its complete series of k updates.  Additionally, a phase is the time needed for all defined streams to complete one iteration.  A run of the benchmark is then defined by n > 0 phases and is equivalent to n iterations of each stream.TimeAdvanceRequestTimeAdvanceRequest is called by a federate to inform the RTI it is ready to advance time.  The RTI then delivers all remaining TSO messages and advances time when appropriate with respect to the federation.  When time advances, the RTI invokes a federate grant handler.  Time management in a distributed federation requires communication between the RTIs involved to ensure that simulation time is consistent across the federation.  An interesting RTI performance metric is how often it can advance time under various federation conditions.The BmTimeAdv benchmark tests the time it takes to complete some number of advances.  This involves recording the time at the beginning and end of a series of time advances.  Given the elapsed time and the size of the series, we can easily calculate advances/sec (assuming time is in seconds).  However, we may desire a more fine-grained approach.  We define grant latency to be the time elapsed between submitting an advance request to the RTI and when control is returned to the federate via its grant handler.  Then for each request, we can record the time immediately prior to calling TimeAdvanceRequest and again at the beginning of the corresponding grant callback.  Benchmarking this service would allow for measuring advances/sec and grant latency separately or together.Here we define phase in a similar manner as above.  A phase is the time needed to complete t > 0 advances, and a run of the benchmark consists of n > 0 phases.  To model federate behaviors we can insert load in between Tick() calls or inside the grant handler.  In addition, we might overlay a stream configuration and define some number of iterations per advance request.  This allows us to model any communication that might take place in between each advance.  We can then define more realistic models of federate execution in testing this service.BenefitsThis type of benchmark is useful to both RTI and federation designers.  It would measure specific characteristics of RTI performance using user-defined federation models.  We could test peak performance on a wide variety of federation configurations by imposing no federate load.  We can then insert federate load to model how federate behavior affects performance.  This will help federation developers in understanding the limits and execution characteristics of RTIs, and it will facilitate valuable testing for RTI developers.We can test each service using either a coarse- or fine-grained approach.  That is, we can measure individual update and grant latencies, or we can measure a complete series of updates or advances.  The fine-grained approach would be especially useful in testing a real-time RTI, where each individual invocation of a service should conform to a deadline.  In contrast, we can get a snapshot of performance using a coarse-grained approach.  We may also choose to measure all possible metrics to get an overall characterization of the system.RTI Extensions to Support the Asynchronous ModelThe current IFSpec does not differentiate between the synchronization models discussed here.  Current practice employs the synchronous approach, invoking handlers only when the federate gives control to the RTI by calling a function such as Tick().  Since a handler is executed while the RTI has control, the federate need not worry about concurrent access to data.  However, the asynchronous model allows for a handler to be invoked whenever the RTI deems it appropriate.  This implies a multi-threaded model, and the federate is then responsible for protecting any data that may be shared between a handler and executing federate.  It follows that there are fundamental differences in both federate design and operation with respect to each synchronization model.We propose an extension to the IFSpec to allow a federate to request a specific synchronization model.  This might be in the form of a function like SetAsynchronousOperation that accepts a boolean parameter, where true/false is specified to enable/disable the asynchronous model.  This extension does not affect the design or operation of current federates, maintaining the synchronous model as the default.  However, it would allow future federates to take advantage of the benefits of the asynchronous model.Conclusion and Future WorkCurrent RTI benchmarks do not sufficiently test the performance characteristics of RTIs. and we should consider more sophisticated methods.  There are direct relationships between the RTI, the federate/federation, and the underlying communication infrastructure, and the performance of any one RTI implementation will vary over the set of all relationships.  While measuring raw performance reflects the limits of a RTI, it does not demonstrate how the RTI is affected by federate behavior.  Therefore, when measuring RTI performance we should be explicit about the conditions under which the tests take place.We expect that RTI performance issues will continue to be critical research and development area for distributed simulation standards.  The lack of well-defined, relevant benchmarks precludes any well-informed decisions regarding the sufficiency or appropriateness of a particular RTI implementation.   Without a clear understanding of how to characterize the performance of an RTI in a particular federation execution, we cannot develop benchmark tests to allow us to estimate performance.We will further explore measurement of RTI services as we progress toward a real-time RTI.  It will become necessary to guarantee both communication and execution bounds, and federate behavior should have minimal if any affect.  It will become important to differentiate between latencies imposed by the various components involved in order to adequately characterize the service.Also, further implementations of the underlying communication facilities are planned after our transition to Comm-Kit.  We will wish to test the efficacy of these implementations under various conditions in order to better understand how and when they should be used.References Defense Modeling and Simulation Office, High Level Architecture Interface Specification, Version 1.3. 1998: Washington D.C.Bachinsky, S., G. Tarbox, E. T. Powell, "Data Collection in an HLA Environment," Proceedings of the 1997 Spring Simulation Interoperability Workshop, Orlando FL,  March 1997.Eisenhauer, G., The ECho Event Delivery System, http://www.cc.gatech.edu/systems/projects/ECho, 2000ReferencesFujimoto, R. et al, Design of High-performance RTI software, in Proceedings of Distributed Simulations and Real-time Applications, August 2000 (DIS-RT-2000)Fujimoto, R. M.  "Parallel Discrete Event Simulation," Communications of the ACM, vol. 33, pp. October 1990, 1990.Fujimoto, R. M. Zero Lookahead and Repeatability in the High Level Architecture. Proceedings of the Spring 1997 Simulation Interoperability Workshop, March 3-7, Orlando. Paper No. 97S-SIW-046.Fujimoto, R., and P. Hoare: "HLA RTI Performance in High Speed LAN Environments" Proceedings of the Fall Simulation Interoperability Workshop, September 1998Fujimoto, R., and S. Ferenci. RTI Performance on Shared Memory and Message Passing Architectures, 1999 Spring Simulation Interoperability Workshop, March 1999Knight, P., et al. Independent Throughput and Latency Benchmarking for the Evaluation of RTI Implementations, in Proceedings of the Fall Simulation Interoperability Workshop, 2001. Paper 01F-SIW-033.McLean, T. and R. Fujimoto, Repeatability in Real-Time Distributed Simulation Executions, in Proceedings of the 14th Workshop on Parallel and Distributed Simulation, 2000.McLean, T., R. Fujimoto and B Fitzgibbons., Middleware for Real-Time Distributed Simulations, Submitted to the Journal of Concurrency and Computation. Author BiographiesBRAD FITZGIBBONS is a Ph.D. student in the College of Computing at the Georgia Institute of Technology.  He is currently researching real-time distributed simulation with respect to the HLA.. Dr. RICHARD FUJIMOTO is a Professor in the College of Computing and the Director of the Georgia Tech Modeling & Simulation Research and Education Center (MSREC).  He… Dr. ANGUS L. M. THOM McLEAN is a Senior Research Scientist at the Georgia Tech Research Institute.  He has several years experience in Naval Aviation, Simulation and Training, and Distributed Simulation Systems.  He is currently pursuing research interests in large-scale real-time distributed simulation, splitting his time between the Parallel and Distributed Simulation (PADS) research group in the College of Computing, and the Distributed Simulation Systems (DSS) group in GTRI.  He has authored several papers for SIW and other Simulation fora.   UpdateAttributeValues (t0)ReflectAttributeValues (t3)ReflectAttributeValues (t1)Tick Loop:while (reflects_pending)    tick_load()    Tick()Reflect Handler:if (measuring_latency)    get_time()handler_load()Federate A (Sender)Communication LibrariesMCAST-LibFM-LibRTI-Kit LibrariesReflectAttributeValues (t1)Federate B (Receiver)UpdateAttributeValues (t2)Time ManagementLibrariesTM-KitOther LibrariesDDMRTICoreUtilitiesDRTI or other RTIFederate(s)