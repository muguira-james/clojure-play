Improvements to the HLA Federate Compliance Testing ProcessMargaret M. HorstDavid Rosenbaum Kyle A. CrawfordGeorgia Tech Research InstituteGeorgia Institute of TechnologyAtlanta, GA 30332-0832 404-894-3578, 404-894-3464, 404-894-1027margaret.horst@gtri.gatech.edu, david.rosenbaum@gtri.gatech.edu, kyle.crawford@gtri.gatech.edu Michael B. WoldtIITRI/AB Technologies Group1901 N. Beauregard St, Suite 400Alexandria, VA  22311703-933-3337mwoldt@msiac.dmso.milKeywords:HLA, compliance, testABSTRACT: U.S. Department of Defense simulations are moving toward compliance with the High Level Architecture, with well over 100 federates already certified as HLA compliant.  Based on the experience gained from these federates’ compliance tests, improvements are being made to the compliance testing process and to the software that supports it.  This paper describes improvements in three areas:  1) In the runtime component of the compliance testing process, the federate must demonstrate a subset of the capabilities documented in its Simulation Object Model (SOM), and it must demonstrate the successful use of the services listed in its Conformance Statement.  Currently, the particular subset of SOM capabilities to be demonstrated is decided upon before the test and documented in the test sequence.  The new process will be simplified by the elimination of the predetermined test sequence.  Instead of having to demonstrate a particular subset of SOM capabilities at runtime, federates will be free to demonstrate any sufficiently comprehensive subset.  2) The collection of tools that support the activities of the Certification Agent is being replaced by a single Federate Compliance Testing Tool based on the Federation Verification Tool. 3) The web site where federate developers apply for compliance testing and provide information and materials necessary to testing is being upgraded to support the new testing process, to improve the Certification Agent’s ability to administer the testing process, and to facilitate its potential future deployment at multiple Certification Agent sites.1. IntroductionCompliance with the HLA was mandated for U.S. Department of Defense (DoD) simulations in 1996 [1] and reaffirmed in 1998 [2].  In response to the HLA mandate, the Defense Modeling and Simulation Office (DMSO) set up a federate compliance test process to evaluate simulations and certify them as HLA compliant. [3]  To date, over 100 federates have been certified as compliant with HLA version 1.1 and 1.3, and more federates are currently in the pipeline for certification under v1.3.To be certified as HLA compliant, a federate must demonstrate its adherence to the three specification documents defining the HLA:  the HLA Rules [4], the Interface Specification [5], and the Object Model Template Specification [6].  The HLA Compliance Checklist [7] was developed as a straightforward, procedure-oriented summary of requirements for HLA compliance across the three specifications and serves as the basis for the official federate compliance test process.Figure 1.1  The Original HLA Federate Compliance Test Process2. HLA Compliance Test ProcessThe original HLA federate compliance test process consists of four steps, as shown in Figure 1.1 above.  The first step is merely an exchange of information between the Federate Under Test (FUT) and the Certification Agent (CA) to start the certification process.  In Step 2, the FUT provides required documentation, including the Simulation Object Model (SOM) and the Conformance Statement (CS) listing the interface services supported by the FUT.  The CA checks the documentation for conformance to the specifications, and, if the SOM and CS prove to be syntactically correct, internally consistent, and consistent with each other, the CA uses them to construct a test sequence for the Interface Test (IF Test).  The FUT has the option to provide suggestions for the test sequence in the optional scenario file.Step 3 is the exchange of information between the FUT and the CA in preparation for the IF Test in Step 4.  The IF Test requires the FUT to demonstrate every service and SOM capability in the predetermined test sequence, which is designed to represent a subset of the complete capability of the FUT.  The final part of Step 4 is the After Action Review (AAR) and paperwork to document the federate’s certification of compliance with the HLA.2.1 Guiding Principles for Compliance Test ProcessThe development of the federate compliance test process was guided by a few specific principles.  The first was that HLA compliance would require demonstration of technical interoperability only, not substantive interoperability as discussed in [8].  That is, certification of HLA compliance in and of itself does not automatically mean that a particular federate is suitable for a particular federation.Another guiding principle for federate compliance testing was that the tests should require as little additional work for the federate developer as possible.  Some documentation, such as the SOM, is required by the HLA specifications, but additional documentation not specifically required by HLA is deliberately minimized and simplified wherever possible.  The CS, for example, can be filled out in any text editor by editing a sample CS.The notion of a test sequence was also derived from the desire to minimize the amount of additional work required by the federate developer.  Exhaustive testing, where the federate would be required to demonstrate every capability (possibly hundreds or more) indicated by its SOM, was rejected as an unnecessary burden for the FUT.  Instead, the FUT is asked to demonstrate a representative subset of the capabilities indicated by its SOM.  For example, if the FUT’s SOM indicates that it can update a large number of different attributes, the FUT is asked to demonstrate updating at least three specific different attributes.After the initial federate compliance testing with a few “friendly victims,” a suggestion was made and adopted to let the FUT suggest the subset of SOM capabilities to be demonstrated in the test sequence by submitting scenario data in the form of a SOM subset file.  The rationale for this suggestion was that SOM capabilities picked at random by the CA might very well result in a test sequence that was difficult for the FUT to set up and execute, and it should not really matter which SOM capabilities are demonstrated, so long as the representative subset is comprehensive enough.2.2 Lessons Learned from Compliance Testing: Suggestions for Test Process ImprovementsIn the process of testing well over 100 federates for HLA compliance, experiences during IF Testing indicated areas where changes to the federate compliance test process and/or the testing tools could better support the guiding principles of HLA federate compliance testing and make the testing more “friendly” without compromising results.  Several lessons learned during testing have directly led to changes in the test process.Despite education efforts and papers to explain the concept of the test sequence [9], its purpose and use continued to be a problem for federate developers.  In the most common case, the FUT would not submit optional scenario data to suggest SOM capabilities for the test sequence in Step 2.  Then, when the automated tools generated a test sequence, the federate developers would complain that the randomly selected capabilities were hard to demonstrate.  The FUT would then request that the CA create a specific scenario file to select objects, interactions, and attributes that were easier to use.  In many cases, this delayed the test schedule for that federate.In some instances, errors were encountered in the generation of the test sequence due to the fact that the SOM in question was very large and contained a complicated class hierarchy.  In these cases, the CA was forced to go into the tools and create a representative SOM subset by hand, again causing time delays in the testing process.2.3 New HLA Compliance Test Process Figure 1.2 illustrates the new, improved HLA federate compliance test process.  It is not markedly different from the original process in Figure 1.1, and the changes serve to further support the guiding principles of compliance testing based on experience with real federates.The test application process in Step 1 is essentially unchanged, although some minor changes have been made to some of the on-line forms to make them easier to use and some additional data is requested to help the CA plan ahead for the IF test.  For example, the FUT must indicate whether it can support Internet testing.  Figure 1.2  New HLA Federate Compliance Test ProcessLikewise, the FUT’s submission of required documentation in Step 2 is very little changed.  The SOM and CS must still be submitted, although the optional scenario data is no longer applicable.  The FUT’s FED (Federation Execution Data) file and RID (RTI Initialization Data) file are now uploaded in Step 2 rather than with the environment data in Step 3 as before, because the file checks now include data from those files as well as the SOM and CS.The conformance tests on the SOM and CS and the cross-check between the SOM and CS have been reorganized, but the items tested are unchanged and now the CA does not generate a test sequence.  Instead, the CA monitors the IF test (now moved up to Step 3) using the new Federate Compliance Testing Tool (described below) until the tool indicates that a sufficiently comprehensive set of SOM capabilities has been demonstrated.  After this point is reached, the IF Test is concluded.  Step 4 concludes the process with the After Action Review and documentation of certification of HLA compliance.3. HLA Compliance Test Tools3.1 Lessons Learned from Compliance Testing:  Suggestions for Test Tools ImprovementIn addition to suggesting changes in the test process, the lessons learned from the experiences of federate compliance testing also led to suggestions for improvements in the supporting test tools used by the CA.For example, in many instances all of the federates in a given federation would apply for HLA Federate Compliance Testing simultaneously.  With the first generation of the test tools, this testing had to be done on each federate individually, which meant one federation run for every federate in the federation.  The ability to test all of the federates in the federation at once was sought in order to save time and effort for both the FUT and the CA.In some instances, federates were unable to demonstrate all of the services listed in the CS in a single federation execution.  There are any number of valid reasons for this happening, particularly in complex simulations with many alternate logical execution paths.  This situation could be accommodated with the first generation of the test tools, but the CA had to manually combine multiple test log files together in a coherent manner to allow the federate to pass compliance testing.  This task was sometimes quite time consuming.  Being able to either merge multiple test log files in an automated way or just being able to keep logging between federation test runs was another upgrade desired.3.2 “Many Tiny Tools”The first generation of federate compliance testing tools was developed in conjunction with the initial development of the federate compliance testing process.  To facilitate rapid development and experimentation with the tools as the process matured, a “many tiny tools” approach was taken, which resulted in a collection of highly specialized tools that communicate via text file intermediaries, after the fashion of popular Unix command-line utilities.  These tools were originally intended to serve as prototypes only, but they proved to be adequate to support a Certification Agent after extensive training in their use, and they were used at a single CA site for the lifetime of the original federate compliance testing process.3.3 Service Sequence VerificationOne of the main goals of the first-generation test tools was to verify at runtime that, not only were the expected HLA services being called, but that all HLA services were being called in the correct sequences.  This goal was referred to as service sequence verification.  Although the HLA Interface Specification requires the RTI to throw exceptions whenever services are invoked in incorrect sequences, at the time the first-generation test tools were being developed the available RTI implementations were themselves prototypical in nature and were not expected to be able to verify in all cases that HLA services were being called in the correct sequences.  The foundation of  the first-generation test tools’ service sequence verification capability was the HLA Master Sequence, expressed in Message Sequence Chart (MSC) notation [9], which described all allowable HLA service invocation sequences.  The Master Sequence also served as the foundation of the first-generation tools’ implementation of  CS consistency checking.Although the first-generation test tools were adequate to their purpose, they were difficult to install, difficult to use, and difficult to maintain.  These difficulties resulted in large part from their “many tiny tools” architecture, which complicated virtually all aspects of their operation and maintenance, and from their reliance on the Master Sequence, which was essentially a simplified state model of the RTI and thus was very complex.  When the test tools were upgraded from supporting the HLA 1.1 specification to support the HLA 1.3 specification, these problems came to a head.  Creating a new Master Sequence for HLA 1.3 proved to be extremely difficult and time-consuming, and the result included errors and omissions whose rectification consumed even more time.  Experience with HLA federate compliance testing under HLA 1.3 uncovered even more shortcomings of the Master Sequence approach, as federates began to implement services in new and unexpected ways, requiring additions and modifications to the Master Sequence.  As the IEEE 1516 HLA specification began to emerge, it became clear that upgrading the first-generation tools to support this specification would be a daunting task, and investigation was begun into finding a more efficient and less expensive alternative.Two factors proved to be critical to realizing a better alternative to continuing to upgrade the first-generation test tools.  The first was DMSO’s RTI Verifier project [10].  Because of this project, modern verified RTI implementations can be counted upon to verify that HLA services are being called in the correct sequences, and thus there is no reason for federate compliance testing tools to continue to perform service sequence verification.  It is now adequate to simply verify that the expected services are being called.  The second factor was the availability of the Federation Verification Tool (FVT).  This tool was developed with the benefit of the experience gained from the development of the first-generation HLA federate compliance test tools, and its abilities to verify at runtime that expected HLA services are being called and that expected attribute updates, attribute reflections, interaction sends, and interaction receives are being performed were a close match for the needs of the federate compliance testing process.3.4  Federate Compliance Testing ToolThe solution that emerged was to develop a single unified Federate Compliance Testing Tool (FCTT) based on the FVT code base.  FCTT’s fundamental testing capabilities are largely the same as those of the first-generation test tools, with three important differences.  The first is that FCTT does not perform service sequence verification; instead, it simply verifies that the expected services are being called.  The second is that FCTT does not require the FUT to adhere to a predetermined test sequence; instead, FCTT is capable of ascertaining when the FUT has demonstrated any sufficiently comprehensive subset of SOM capabilities.  This difference allowed the test process to be simplified as described in Section 2.  Finally, FCTT is capable of testing more than one federate at a time.FCTT’s operation occurs in two phases: file checking and runtime testing.  After a FUT’s representative submits the federate’s SOM, CS, and FED files in Step 2 of the test process, the CA uses FCTT to perform two checks of these files.  The SOM/FED check verifies that the FED file describes the same class hierarchy that is described in the SOM.  The CS/SOM check verifies that the CS is internally consistent and that the SOM and the CS are mutually consistent.  This test is based on a set of predicate logic rules which describe what it means for a CS to be internally consistent and what it means for a SOM and a CS to be mutually consistent.  An example of a CS internal consistency rule is:registerObjectInstance => publishObjectClass;This rule can be read as “if a federate implements the Register Object Instance service, then the federate must implement the Publish Object Class service.”  An example of a SOM/CS mutual consistency rule is:ObjectPublished = publishObjectClass;This rule can be read as “a federate’s SOM should indicate that it publishes one or more object classes if and only if the federate implements the Publish Object Class service.”  FCTT’s CS/SOM check replaces separate CS consistency check and SOM/CS cross-check tests that were performed by the first-generation test tools.  The first-generation CS consistency check relied on the Master Sequence, while FCTT’s CS/SOM check uses the much simpler predicate rules described above.  Because of this difference and because FCTT does not perform service sequence verification, FCTT does not rely on a Master Sequence in any way.The second phase of FCTT’s operation is runtime testing.  At runtime, the FCTT federate joins the test federation and verifies that the FUT calls the HLA services indicated in its CS and that it demonstrates a sufficiently comprehensive subset of SOM capabilities.  FCTT’s Services View shown in Figure 3.1, which is identical to FVT’s Services View, shows for each HLA service whether the FUT’s CS indicates that the FUT is expected to call it, and whether the FUT has in fact called it.Figure 3.1  FCTT Services ViewFigure 3.2  FCTT Thresholds ViewFCTT’s Thresholds View shown in Figure 3.2 indicates the progress of the FUT in demonstrating a sufficiently comprehensive subset of SOM capabilities.For an example of the interpretation of this display, see the cell at the intersection of “Land Simulation 2” and “Attribute Reflects.”  The “4” in the cell’s upper right means that Land Simulation 2’s SOM asserts that Land Simulation 2 reflects four distinct attributes.  The “3” in the cell’s lower right means that it will be sufficient at runtime to demonstrate the reflection of three distinct attributes.  The large blue “3” in the cell’s left means that Land Simulation 2 has already demonstrated the reflection of three distinct attributes and thus that it has passed this part of the test.The following list outlines FCTT’s advantages over the first-generation test tools:No need for a predetermined test sequenceEasier to installEasier to useEasier to maintain, in part because of the elimination of the Master SequenceAble to test multiple federates at a timeFigure 4.1 Web Page for Step 1 of HLA Federate Compliance Test System4. Federate Test Management SystemThe Federate Test Management System (FTMS) is a Web-based system for administering federate testing.  This process begins with a candidate federate’s application for testing and continues with the uploading of required test documents (e.g., SOM and CS) and the specification of key test information (e.g., test environment, security restriction, and contact information for the certificate).  FTMS, which was fielded over three years ago, was originally implemented in a Unix environment using basic HTML and Perl CGI scripts.  This system has been significantly revised to take advantage of new developments in Web technologies and computer hardware.The new system, FTMS v2.0, is implemented via Active Server Pages residing on a Windows NT 4.0 server running Internet Information Server 4.0.  FTMS v2.0 features a simplified user interface leading to improved usability and shorter page download times, an improved administrator interface for use by the Certification Agent, and an internal architecture designed for more efficient long-term maintenance.  The new system will significantly reduce operating costs while improving the overall test process for both its users and its administrators.  Porting the FTMS from a Unix environment to Windows NT 4.0 and Internet Information Server 4.0 will facilitate later deployment to multiple CA sites.FTMS v2.0 resides at  http://hlatest.msiac.dmso.mil.5. Summary and ConclusionsThe HLA federate compliance test process has been streamlined and simplified by the removal of the predetermined test sequence for a federate’s Interface Test.  Federates must still demonstrate all of the interface services that they assert that they support, as well as a reasonably comprehensive subset of their SOM capabilities, to obtain HLA compliance certification, but the federate developer now has complete freedom to choose a subset of capabilities and design the test run.  Federate compliance testing no longer tests IF service sequence order, since verified RTIs are assumed to catch any errors in service sequence order.The Certification Agent is supported by a new tool, the Federate Compliance Testing Tool, and an improved Web site and Federate Test Management System.  The HLA Federate Compliance Test System is designed to be easy and straightforward to use so that certification of HLA compliance is not a major issue for simulations.6. References [1]	Paul Kaminski, “DoD High Level Architecture (HLA) for Simulations,” USD(A&T) Memoran-dum, 10 September 1996[2]	Jacques Gansler, “DoD Transition to the High Level Architecture (HLA) for Simulations,” USD(A&T) Memorandum, 1 April 1998[3]	Margaret L. Loper, et al., “The HLA Federate Compliance Testing Process, Revised,” Paper 97F-SIW-062, Fall 1997 Simulation Interoperability Workshop, Orlando, Florida,  September 1997[4]	US Department of Defense, “High Level Architecture Rules Version 1.3,” 20 April 1998[5]	US Department of Defense, “High Level Architecture Interface Specification Version 1.3,” 20 April 1998[6]	US Department of Defense, “High Level Architecture Object Model Template Specification Version 1.3,” 20 April 1998[7]	US Department of Defense, “High Level Architecture Compliance Checklist Version 1.3,” May 1998[8]	Judith Dahmann et al., “HLA and Beyond: Interoperability Challenges,” Paper 99F-SIW-073, Fall 1999 Simulation Interoperability Workshop, Orlando, Florida, September 1999[9]	Laura L. Burkhart et al., “The Federate Test Sequence Explained,” Paper 98F-SIW-152, Fall 1998 Simulation Interoperability Workshop, Orlando, Florida, September 1998[10]	Jeff Nielson and Susan Symington, “HLA RTI Verifier Update,” Briefing to HLA Architecture Management Group, AMG-35, 9 February 2000, http://hla.dmso.mil/amg/briefs/amg35/AMG35-07verifier.pdfAuthor BiographiesMARGARET M. HORST is a Principal Research Engineer at GTRI.  She is part of the GTRI team that developed the Federate Conformance Test system for DMSO to certify federates as HLA compliant.  Ms. Horst is currently serving on the Planning and Review Panel for the Federation Development Process Forum (PROC) and for the RD&E User Forum.DAVID ROSENBAUM is a Research Scientist in the Distributed Simulation Systems (DSS) group at the Georgia Tech Research Institute (GTRI).  He is the current director of the project responsible for the development of the HLA Federate Compliance Testing Tool (FCTT).KYLE CRAWFORD is a Research Engineer in the Distributed Simulation Systems (DSS) group at the Georgia Tech Research Institute (GTRI).  He is the primary author of the Web based test management system for HLA Federate Compliance Testing.MICHAEL B. WOLDT is a Certification Agent at the HLA Federate Compliance Test Lab, Alexandria, VA.  DMSO appointed him as a Certification Agent for HLA Federate Compliance Testing. Certification AgentFederate under TestSuccessGenerate test sequence; set IF test dateConduct SOM/CS testsCompleteCheck compliance databaseReview applicationSuccessPrepare letter and certificate of compliance; conduct AARLog test data, process and analyze logged dataGenerate final test sequence and set up connectivity testReturn certification letter and certification of complianceSubmit certificate request and schedule AARReturn IF test successReturn IF test results with deficienciesConfirm IF test date/Conduct connectivity testReturn SOM/CS success, test sequence, IF test dateReturn SOM/CS results with deficienciesApprove application and send user ID/passwordReturn if incompleteExecute test sequence during IF testGather certificate informationReview and prepare FUT to execute test sequenceGather environment data, FED file, RID filePrepare Conformance Notebook (SOM, CS, scenario data)Complete test applicationSubmit environment data, FED file, RID  file/Confirm IF test dateSubmit Conformance NotebookSubmit application requestStep 1Step 4Step 3Step 2SuccessSet IF test dateConduct SOM/CS testsCompleteCheck compliance databaseReview applicationCertification AgentFederate under TestSuccessPrepare letter and certificate of compliance; conduct AARConduct IF testReturn certification letter and certification of complianceSubmit certificate request and schedule AARReturn IF test successReturn IF test results with deficienciesReturn SOM/CS success,  IF test dateReturn SOM/CS results with deficienciesApprove application and send user ID/passwordReturn if incompleteGather certificate informationGather environment dataPrepare Conformance Notebook (SOM, CS, FED file, RID file)Complete test applicationSubmit environment data, Confirm IF test dateSubmit Conformance NotebookSubmit application requestStep 1Step 4Step 3Step 2