The Need for, and Design of, an IO-ISR Federation of SimulationsDr. Patrick D. AllenGeneral Dynamics Electronic Systems100 Ferguson Dr.Mountain View, CA  94043650-966-2758pat.allen@gd-es.com Dr. Chris C. DemchakAssociate ProfessorUniversity of ArizonaCyberspace Policy Research GroupSchool of PA and PolicyTucson, Arizonademchak@u.arizona.edu520-621-7965Keywords:Information Operations, ISR, HLA, Federation, Multi-level security, Training, Testing, Planning, OperationsABSTRACT: Information Operations (IO) are supported by both unclassified and protected programs.  This dichotomy leads to two unacceptable situations:  First, our forces are not be able to ‚Äútrain as you fight‚Äù in the realm of information superiority.  Second, real-world military operations are not fully supported by, or coordinated with, our national IO capabilities. [1] To overcome this problem, we present a conceptual model and approach to the incremental development of an IO-ISR federation of simulations (IO-Fed) to support achieving testing and training objectives and real-world operational requirements.  This paper will address the components of an IO-Fed that already exist, the components that need to be added, interfaces that need to be developed, and in particular how to handle issues of multilevel security in training and in multinational operations.  The final section presents a suggested priority of which components of the IO-Fed should be developed first, including suggested demonstration events and milestones to help guide the IO-Fed development over time.1.  BackgroundOne of the primary enabling thrusts of Joint Vision 2010 (JV2010) is information dominance or information superiority.  Dominating the information battlespace leads to significant advantages to the side with information superiority, such as the need to withhold fewer reserves, identifying and exploiting enemy weaknesses, and better opportunities to avoid combat under unfavorable circumstances.However, turning this vision into a reality is plagued by numerous problems, including lack of common framework, high levels of classification, and lack of an adequate representation of IO in training, testing, analysis, and operational planning.  Most legacy training and analytic models are very limited in their representation of C4I and organizational processes.  The Fall ‚Äô98 Military Operations Research Symposium (MORS) workshop discussed the lack of process in most areas of representing C4ISR. [2] For example, one of the most basic elements of combat models is that they need to account for factors that show C4ISR makes a difference on the battlefield.  Yet most ground combat models do not even account for the difference between a frontal assault and a flank attack.  [3]One particularly sensitive topic in IO is the level of classification.  Information Operations (IO) are supported by both unclassified and protected programs.  This dichotomy leads to two unacceptable situations:  First, our forces are not be able to ‚Äútrain as you fight‚Äù in the realm of information superiority.  Second, real-world military operations are not fully supported by, or coordinated with, our national IO capabilities. For example, the US component supporting NATO during the Kosovo operation stood up an IO cell to plan and execute IO missions in support of the operation.  Unfortunately, due to the IO cell members not having the proper clearances to even know about actual US IO capabilities, they were not able to exploit these capabilities.  Nor were they able to prepare an IO campaign plan that supported the rest of the military operation using these untouchable capabilities.  As a result, the results of the IO cell in support of the Kosovo operation were rather disappointing compared to what could have been accomplished. [1] and  [4]As a result of these classification concerns, US IO capabilities have not been allowed to be adequately represented in training exercises, especially multinational training exercises, in order to preserve these uncompromised capabilities for use during a conflict.  However, this leads to a problem for personnel called upon to perform IO planning and execution functions during a conflict for which they have not been trained.  Until we figure out a way to allow our commanders and staffs to ‚Äútrain as they fight‚Äù in the realm of IO, they will continue to be plagued by the lack of synergy between IO and the rest of the military operation.  Moreover, the US will be unable to train realistically in multinational exercises unless we can find an efficient yet secure way to account for highly classified IO effects in less classified exercises.2.  Conceptual ModelThe first step is to define an overarching conceptual model of IO and its key components.  This material is substantially condensed from a report on the End Run IO model design developed for DARPA under SBIR 991-012.  [5]  Figure 2.1 presents the basic model that will be explained in detail in the remainder of this paper.  Features of interest include:  dividing the problem into an IO Attacker and IO Defender; dividing the IO Defender into Thinkers, Doers, and Information Networks; distinguishing between the direct and indirect effects of IO; and highlighting the direct effects of the IO defender on the performance of his own information network.  The need for, and significance of, these components will be presented, followed by the three categories of models and simulations necessary to implement the IO-Fed design. The paper continues with a suggested approach to provide the multilevel security features required for an IO exercise or experiment, and concludes with a recommended roadmap for implementing the IO-Fed incrementally over time.2.1  Conceptual model componentsThe following paragraphs sequentially build the conceptual model summarized above.  Figure 2.2 represents one side (the IO Defender) defending against IO attacks from an opposing side.  Although each side will be defending against and attacking the opponent simultaneously, dividing the problem into two distinct parts makes it easier to visualize the component interactions.  In this model, we divide the IO defender into Thinkers, Doers, and information networks. This breakout is consistent with volumes of literature on human interactions in socio-technical systems. [6] The Thinkers box represents the personnel and staff of an organization that perform cognitive information processes (e.g., perceive, plan, decide, implement and monitor).  Perception generators are those that gather the raw data and generate a composite picture or perception of the battlespace.  The planners take these perceptions and the commander‚Äôs guidance and prepare plans.  The decision-maker decides which course of action will be implemented.  The managers monitor the progress of the plan and modify it as necessary within the boundaries of the plan to achieve its objectives.The ‚ÄúDoers‚Äù box represents the implementors of actions. Below a certain echelon, everyone is considered a ‚ÄúDoer.‚Äù  Although sensors are implementors, their information collection function is part of the information network.  The information networks connecting the two (and supporting each in performing their respective tasks) include the IO defender‚Äôs information content, telecommunications systems, and the information storage, retrieval, and processing systems.  Note that the Information networks diamond is part of the Thinkers box and the Doers box.  Thinkers talk to other Thinkers and Doers talk to other Doers through information networks as well.  Although the focus of this picture is on the communications between the Thinkers and the Doers and their vulnerability to IO, IO attacks can be performed against the information network used between Thinkers and among Doers.Figure 2.1:  IO Conceptual Model Overview.Figure 2.2:  Representation of information systems connecting Thinkers and Doers.2.2  IO attack direct effectsFigure 2.3 shows the direct effects of IO attacks on the IO Defender‚Äôs information network.  Direct effects include the delay or disruption of defender communications; destruction of communications systems, sensors, or information content; deception of enemy sensors and communications; modification of information content; the reading of the defender‚Äôs information  content; and control of the defender‚Äôs information network.  Note that the IO attacker can strike against the information network while information is flowing from Doers to Thinkers, from Thinkers to Doers, and among Thinkers and Doers.  Undestroyed information flowing from the Doers to the Thinker is gathered within the Thinker‚Äôs Perception Generation Center (PGC).  The IO Defender may or may not be aware of whether the information received is true, false, partially true, intentionally distorted, or if it has been read by the enemy.  The perception generation center provides the raw information to the perception generators who generate a perception of the situation for the planning and decision-making processes.  The planning and decision making process may be performed by humans (training audience or role player) or automated (through rules or advanced algorithms), which allows this design to be readily applied to training applications.  2.3  IO attack indirect effectsIn Figure 2.4, the large arrows around the picture show the IO attacker‚Äôs indirect effects on the Defender.  The focus of the IO attacks is to influence the mind of the enemy commander to take a specific action or inaction.  Since these outcomes require some cooperation from the enemy, the ultimate effects of an information operation are more indirect than direct.  The enemy commander may still make the right decision and win the battle in spite of the information that he has available.  This approach is consistent with a large literature on game theoretic two-person and n-person probabilistic decision exchanges. [6] and [7]  Note that the only ‚Äúknobs‚Äù the attacker can affect are direct effects against the information content or the information network processes.  The IO attacker has no direct effect knobs to use against the mind of the enemy commander or his decisions.  (That may be the next revolution in military affairs!)2.4  IO defense direct effectsFigure 2.4 also shows the IO defender‚Äôs direct effects on the information network.  As the IO defender takes action to negate or mitigate the effects of IO attacks, the defender usually creates a secondary direct effect on the defender‚Äôs information network.  For example, increased information system security usually entails a decrease in information system performance either across the network or against portions of the network.  In general, an information network with higher security features activated will have a lower level of system performance than the same info network with less security features activated.3.  IO Federation of SimulationsTo turn this conceptual model into a reality, we need to build four required component model groups:  joint operational models, information network models and IO attack and defense direct effects models, Organizational Behavior models and IO indirect effects models, and the federation support modules.  Such an IO-Fed would ensure that the necessary interactions between each of the required IO model components will be accurately and efficiently represented.  Based on the High Level Architecture (HLA) and the Federation Development and Execution Process (FEDEP), Figure 3.1 shows the highest level of an IO-Fed and some key required interactions.  [8]The first model category (Joint Military Operations Models) includes the traditional synthetic environment of joint combat models‚Äîthe tanks, ships, planes, and other assets that move and fight on the land and sea and in the air and sea.  The ALSP Confederation of Models fulfilled this role for many years, while JSIMS is being designed as the next generation Joint training model. Intelligence models, such as WIM or NATSIM, will provide the sensor models.  Computer Generated Forces and Advanced Joint Synthetic Forces (JSF) should be able to operate the Doers and implementors without extensive human intervention.   The second category of model includes models of the information networks as well as direct IO attack and defense activities. Although there are several telecommunications models currently being used, most of these models were designed for analysis rather than for planning, training, or mission rehearsal applications.  As a result, they tend to be much more cumbersome than what will be required to support IO planning or IO training exercises.  However, if IO training objectives are included in an exercise, then some sort of model of the telecommunications systems, operations of other information storage and retrieval systems, IO attack methods and IO defense methods will be needed to support the exercise. Figure 2.3: IO Attack Direct Effects on Information Networks.Figure 2.4: IO Attack Indirect Effects and IO Defense Direct EffectsFigure 3.1: Four Categories of Models Required to Support IO ModelingThe third category of model includes models of organizational behavior and IO attack indirect effects.  If the Thinkers are represented by humans, then organizational behavior models are not required in training exercises for cells manned by humans.  However, as the need for reducing manpower support to exercises continues, many of the formerly manned cells will need to become automated through models of organizational behavior.  For IO planning systems, some planning tasks will require an estimate of IO defender responses to specific IO attacks.  This means that IO planners will eventually require automated representations of IO defender organizational behaviors to perform certain planning tasks, such as an IO defender‚Äôs course of action analysis. The fourth category of models is exercise or simulation support tools, including the C4ISR interfaces to the training audience. Although such tools exist or are being developed for the Joint Synthetic Battlespace, they will need to be expanded to handle the telecommunications, IO attack and defense, and organizational behavior models necessary to run the IO-Fed.  Under the principle of ‚Äútrain as you fight,‚Äù the IO planner should use the tools (including hardware, software, TTPs) in training that he or she would use in planning the actual operation.  Therefore, the training audience will participate in the exercise using their own planning tools (on their own C4ISR equipment) that will be stimulated by events in the synthetic environment.  The training audience participates in the exercise using their own C4ISR systems, which in turn have been connected to the synthetic IO training environment.  4.  Multi-Level Security ApproachThis section proposes an approach to representing various aspects of IO capabilities to overcome the challenges of operating in a multilevel security environment.  The solution is not to declassify everything, nor is it to continue keeping everything so classified no staff planners can use it.  The solution lies in determining what aspects of our IO capabilities can be available to train with and to operate with.  We need to categorize the IO techniques by what makes them classified and what effects need to be represented in training and provided to real-world planners.  To address this problem, we have used the End Run Conceptual Model to identify locations in the model where the effects of direct and indirect IO attacks can be best represented.  We have identified four locations in the End Run design where security-required work-arounds can be applied, thereby keeping the level of classification appropriate for the exercise.  (See Figure 4.1)  However, there are tradeoffs with respect to training realism that must be considered when selecting each location for the work-arounds.4.1  Category A‚Äîunclassified IO direct processesSome types of IO attack and defense are well known and well advertised, such as the hacker codes and vendor patches globally available on the web.  Hackers can easily download hacking codes for free from the web that use an easy point-and-click user interface to map networks, hacks against specific versions of software, encryption-breaking software (codecrackers), and backdoors.These ‚Äúdo it yourself‚Äù hacker kits are available to anyone around the globe, and are considered viable threats to any accessible computer network.  At the same time, they are so well known that none of the hacks or patches are considered classified, and can therefore be represented explicitly in unclassified models.  The representation of such readily available and unclassified IO attack and defense capabilities can provide a wealth of IO functionality to any exercise, even multinational exercises.  Category A IO representation means that the whole process of how the IO attack works and how the IO defense works is publicly known and can be represented in the model in full detail without compromising any security.  Therefore, the detailed representation of IO attacks and defenses, and their direct effects, can be represented in the information network models without compromising any classified capabilities.  Figure 4.1: Handling Security Issues Through Conceptual ModelAn alternative way to provide such an unclassified IO representation in experimentation is to use hypothetical future capabilities, as was used during the Joint Experimentation Center‚Äôs J9901 experiment. [9]  Hypothetical capabilities projected 10 to 15 years into the future are unclassified because they do not actually exist.This approach of explicitly represented unclassified IO capabilities allows for good support of a detailed after action review (AAR), which is the most important part of the exercise.  By allowing for the tracing of the cause and effect of given IO actions, one can demonstrate the contribution of IO to the overall military effort.4.2  Category B‚Äîunclassified IO direct effectsThe second category (B) includes those IO capabilities where how the system performs its functions is classified, but that the effects of what it does are not classified.  For example, we may have an EW system that can intercept an enemy message on certain frequencies.  The existence of such a capability is not classified, but the mechanism of how it accomplishes the task will likely be classified.  For this category, then, the effects of delays, destruction, reading, and manipulation of information can be represented prior to this information reaching the perception generation center.  None of the details of how the process works need be represented, only a realistic representation of the time and general resources it takes to generate those effects, and the how well those effects can be generated given the IO defense posture and activities.Note that one could build an unclassified model of these effects given the types of IO attacks and defense available.  This could provide a sufficient level of realism for joint and multinational exercises without representing the intricacies of the details of the process. As an alternative, one could build a classified model of the detailed IO attack process against the IO defense, thereby increasing the level of realism in the representation.  This detailed and classified model would have to be run in a secure enclave, and only the results of the IO attack would be passed from the enclave to the less-classified portion of the exercise.  This is very similar to the TACSIM that has been used or years to support intelligence play in exercises.  The category A processes are represented and retained within the secure enclave, while the unclassified effects (category B) are released from the enclave to the less-classified exercise.  Either of thee approaches support a robust AAR for the training audience.  In the first (unclassified models) case, the AAR focuses on the effects of IO that cause changes to the perceptions of the IO defender, and thereby cause changes to the defender‚Äôs decisions and subsequent actions.  Detailing this cause-and-effect trace is essential in AARs, and provides the most significant learning for the training audience.  In a similar manner, the cause-and-effect trace for why certain IO attacks did not work against certain IO defenses are also worthwhile.In the second case, where classified models were used in a secure enclave, two AARs can be supported.  The first is the one described above, where the cause-and-effects trace for the unclassified IO effects are presented and discussed.  The second AAR is a classified AAR, where the details of the IO attack and defense processes are presented and discussed.  Such classified AARs support the improved development of better IO models, as well as the refinement of IO doctrine.4.3  Category C‚Äîunclassified IO indirect effectsThe third category (C) assumes that the very existence of a hypothetical capability to effect certain types of communications may be classified.  Therefore, not only is the IO process classified, the effects that can be generated against certain types of systems may also be classified.  With this distinction, we have exceeded the capabilities of traditional model and exercise design approaches that have previously been used to separate classified and unclassified capabilities.  If certain types of information are associated only with certain types of information systems, then we need to divorce our representation from this association.  Our recommended approach to solving this problem is to represent the indirect effects of IO on the perception generation process of the IO defender.  Rather than focusing on the information that is being provided to the perception generation center (as in category B), this approach focuses on the use of information within the perception generation process.  As shown by the C in Figure 4.1, these effects are completely divorced from the systems that are effected, and their effects are represented on the processes performed within the function of perception generation. For example, the perception generation process may require additional time to prepare the perception for the planners and decision-makers.  Note that the specific cause of this delay need not be specified, only that it has been delayed due to IO effects (if known by the IO defender).  The planning processes that use multiple data sources could be restricted in the number of factors considered due to IO attack effects.  As an alternative, the IO process may have another option, preferred by the IO attacker, entered into consideration to represent the IO attack indirect effects.  This approach of explicitly representing elements of the IO indirect effects allows for a great deal of real-world IO direct effect capabilities to be thoroughly protected.  Note that these indirect effects can be represented either in cells run by automated organizational models, or in manned cells.  For automated cells, the automatically generated list of options can have the desired IO attacker option(s) included for consideration.  In a similar manner, the weight of validity or confidence in certain situations being perceived as the true situation can be manipulated through explicitly represented IO indirect effects.For manned cells, the insertion of category C indirect IO effects into the IO defender‚Äôs perception generation process requires the cooperation of one or more cell member.  For the Threat cell, for example, one of the Threat personnel can be contacted by the White Cell to include certain perceptions into Red‚Äôs view of the battlespace, or include Blue‚Äôs desired option into the set of options to be considered by Red. Since it is less likely that known Red IO threats will be highly classified, the converse situation of requiring a trusted White Cell agent in the training audience is much less likely to be required.Unclassified models of the IO indirect effects can be built even if divorced from the IO direct effects that produced the indirect effects.  At the same time, the ability to calibrate and validate the IO indirect effects models will be sorely hampered without detailed models of the IO direct events.  By running the classified IO direct effects models before the exercise, one can calibrate and validate the IO indirect effects that will be employed in the less-classified exercise.One could also run these classified IO models of category A and category B direct effects in the secure enclave, and only release the category C indirect effects to the less-classified exercise or experiment.  This allows for a classified post-exercise AAR to be run to ensure the credibility and effectiveness of the IO direct effects to produce the resulting IO indirect effects, and subsequently how the IO indirect effects affected the course of the exercise or experiment.  Note that this approach provides three ways to support category C IO representations in an exercise or experiment.  The approach that provides the best AAR support is to run the category A and B IO direct effects simultaneously in a secure enclave, and sending the category C indirect effects to the exercise in real-time.  The second, less desirable, method is to run the IO direct effects in a secure enclave to calibrate the IO indirect effects to support a less-classified exercise at a later date.  The third and least desirable approach is to use uncalibrated IO indirect effects in category C alone.  It is hoped that this third option is only used until the classified IO direct effects models can be built and used to calibrate the less-classified IO indirect effect models.4.4  Category D‚Äîunclassified IO aggregate indirect effectsAlthough difficult to imagine, some day there may exist certain types of IO capabilities that could be traced back through their indirect effects on the IO defender‚Äôs perception generation process.  In this case, a fourth category (D) is required, as shown in Figure 4.1.  In this approach, the White Cell scripts the outcomes of the Defender‚Äôs decision process.  For example, even though the Red commander may have chosen to go left, the Control Cell changes the orders for the Red Doers to go right instead.  If the White Cell has adjudicated that the IO attacker‚Äôs efforts were successful, then the effect on the IO defender would be implemented as though the information operation were successful.  In other words, the White Cell or Control Cell overrides the IO defender‚Äôs decisions and implements the IO indirect effect desired by the IO attacker.Similar the previous case (category C), a secure enclave could be used to represent all IO processes and effects for category A, B, and C.  This will keep all sensitive IO effects secure and unavailable to the exercise or experiment.  The secure enclave will only provide D-category outputs to the White Cell to implement the necessary effects by fiat.  As with the previous case, the secure enclave could run real-time in support of the exercise, run to calibrate the ‚Äúmodel‚Äù of the success of IO attack indirect effects on the IO defender, or not run at all to calibrate the IO indirect effects model.With this approach, all effects appear as Acts of God and can never be traced back to an IO attack capability.  Although this option provides the surest protection of classification, this option does not provide the best level of training or operational planning.  During the After Action Review, it would be very difficult to determine cause and effect based on ‚Äúbecause I said so.‚Äù  Even so, it may be the only way that some very sensitive capabilities could be included in exercises, especially in certain multinational exercises.4.5 Summary of multilevel security approachThe End Run approach provides four options for representing IO processes and effects at varying levels of classification, as summarized in Table 1.Prior to the End Run study, most exercises either handled all sensitive factors under the category A approach, or under the category B approach (as in the case of TACSIM-supported exercises).  By applying the End Run Conceptual Model to the problem of multilevel security, we have identified two new mechanisms (category C and D) which allow for the representation of highly sensitive IO capabilities in a less-classified exercise through the focus on the IO indirect effects.Overall, existing and emerging IO capabilities must be examined for their applicability to support training and to be coordinated with real-world planning and operations.  If they cannot support the latter, then the IO campaign plan will not be coordinated with the operational campaign plan.  And if they cannot support the former, we will never be able to ‚Äútrain as you fight‚Äù in the IO arena.5.  Time-Phased Development RoadmapThe IO-ISR FOM is definitely a large undertaking.  To attempt to build it all at once would be fool-hearty.  We suggest following the adage based on the riddle ‚ÄúHow do you eat an elephant?  One bite at a time.‚Äù  This section presents a suggested priority of which components and interfaces of the IO-Fed should be developed first, including suggested demonstration events and milestones to help guide the IO-Fed development over time.The elements of the IO-Fed that already exist (or are emerging) are the Joint Operational Models.  Although the development and fielding of JSIMS has been delayed, other federations exist that can be used until JSIMS and its intelligence models are completed.  For example, the STOW and the Pegasus Federation of models exist and can be used to support selected training and experimentation events.  [9] and [10] For sensors, the SLAMEM model has already been connected to STOW, and is under consideration for Pegasus.  Even though there are substantial limitation in what features these joint operational (and sensor) models can represent, they provide at least the foundation for supporting training and experimentation.  Regarding telecommunications models and IO attack and defense direct effects models, only the telecommunications models currently exist.  Models such as OPNET and COMNET have been traditionally used to support analysis, but could be adapted to supporting training, experimentation, and operational planning. Other than the telecommunications models, there do not yet appear to be models of the information storage, retrieval, and processing systems available for use in training.  Moreover, there are not yet any accepted models of IO attack and IO Defense direct effects that can yet be used to support exercises or mission rehearsal.  Some of the features of these needed models can be provided in exercises through work-arounds, but eventually the training community will require all component models of the IO-Fed.None of the third category of models (organizational behavior and IO attack indirect effects) currently exist. Even though the DoD 1995 Modeling and Simulation Master Plan stated that organizational models were sorely needed, most of the effort to date has been in developing tactical-level Doer-type cognitive models.  For example, the Semi-Automated Forces (SAF), and Computer-Generated Forces (CGF) developed in the last few years are focused on allowing fewer response cell operators to maneuver groups of units at the Doer level.  While these models of implementors are necessary to reduce the amount of manpower that traditional exercises required, they do not capture the depth or breadth necessary to model organizational behavior within an IO environment.  Therefore, all of these models, and models of IO indirect effects, need to be designed and built. Work-arounds and selected tools can be useful in the support of selected aspects of IO, but to train or rehearse the full range of IO will require a more complete IO-Fed.Table 1:  Summary of End Run Multilevel Security OptionsCate-goryIO Direct ProcessesIO Direct EffectsIO Indirect EffectsUse of EnclaveAAR SupportAUnclassifiedUnclassifiedUnclassifiedNot NeededExcellentBClassifiedUnclassifiedUnclassifiedRequired for AGoodCClassifiedClassifiedUnclassifiedRequired for A and B*AcceptableDClassifiedClassifiedTraceableRequired for A, B, C**Poor*  Enclave support for C can be real-time, calibrating IO indirect effects, or non-existent.** Enclave support for D can be real-time, calibrated, or non-existent.A core of the exercise and simulation support tools already exist for each of the joint operations federations, and can provide the basis for the new modules necessary to handle the IO-specific support modules.  In addition, although progress has been slow, advances are being made in the capabilities of C4ISR interfaces with simulations.The recommended milestones for incrementally developing the IO-Fed are near-term exercises and events that can be used to build the necessary components of the IO-Fed.  For example, the Joint Experimentation Center will be performing J0116, which involves hypothetical Blue attack capabilities, organizations, and doctrine against Red IADS and TBM launchers.  Representing the role of Blue IO attacks to enhance Blue targeting of these Red systems will demonstrate IO‚Äôs contribution to the effort, demonstrate the value of the conceptual model, and help build some of the key components of the IO-Fed.  The preliminary design for IO support for this event is in the End Run final report.  [5]A similar event for the training arena would also be useful.  Annual events such as Unified Endeavor or Ulchi Focus Lens would be useful platforms to showcase the contribution of IO and help build additional components of the IO-Fed.  Of particular interest is the opportunity to encourage the participation of at least one protected IO program willing to participate in one of these exercises or experiments.  Demonstrating the ability of the End Run approach to effectively protect the features of the program while providing the effects to the training event or experiment will set a precedent for the future participation of real-world IO capabilities in less classified exercises and experiments.Later milestones will focus on the development first of rudimentary organizational behavior models that can be used to support exercises and experiments.  One could also ‚Äúrole play‚Äù the various types of organizations and their behaviors using manned cells in order to help develop the key parameters of these organizational behavior models.6.  ConclusionsCurrent classification of real-world IO capabilities are precluding the inclusion of US IO capabilities in training, and therefore precluding their effective use in real-world operations.  To satisfy the principle of train as you fight,‚Äù the US needs to employ its real-wold IO arsenal in exercises.  To help develop the necessary doctrine and familiarity with the strengths, limitations, and lead times of these IO assets, the real-world IO capabilities need to participate in joint experimentation.    To address these issues, the End Run conceptual model provides a useful framework for defining the various elements of Information Operations and their interactions.  This IO conceptual model defines how the effects of protected IO capabilities could be represented in training exercises and operational planning without compomise.Moreover, this IO conceptual model helps define the models and interfaces necessary to create an IO Federation of Simulations necessary to support training, experimentation, mission rehearsal, and operational planning.  Components of this IO-Fed already exist, while major categories of models have yet to be built.  This paper presented an approach to building this significant capability over time by providing selected IO features to upcoming exercises and experiments so that the IO-Fed can be built incrementally yet be useful while being developed.7.  References[1] 	Ellis, James O., Admiral, 1999. ‚ÄúA View from the Top.‚Äù  (See Brewin, 1999)Federal Computer Week, Vol. 13, No. 34, September 27.[2]	MORS Workshop ‚ÄúAnalyzing C4ISR for 2010‚Äù October 1998, http://www.mors.org.[3] 	Allen, Patrick D., ‚ÄúThe Need to Represent a Wide Variety of Type Battles in Air-Ground Combat Models,‚Äù Military Operations Research Journal, Vol I No. 3, Fall, 1995.[4] 	Brewin, Bob, 1999. ‚ÄúKosovo Ushered in Cyberwar.‚Äù  Federal Computer Week, Vol. 13, No. 34, September 27.[5] 	Demchak, Chirs C., and Patrick D. Allen, End Run: A Simulation Architecture For Information Warfare Report, DARPA SBIR 991-012, Final Report, December 1999. [6] 	Pew, Richard W. and Anne S. Mavor, eds. 1998. Modeling Human and Organizational Behavior: Application to Military Simulations, National Research Council Research. Washington D.C, National Academy Press.[7] 	Pearl, J. 1988. Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference. San Francisco: Morgan Kaufmann.[8]	Defense Modeling and Simulation Office, www pages on HLA and FEDEP, http://www.dmso.mil.[9]  Dehncke, Rae W., and C. Todd Morgan, ‚ÄúVirtual Simulation and Joint Experimentation:  STOW and Joint Attack Operations,‚Äù Fall 1999 SIW Workshop, paper #079.[10]	Zabek, Anita A., ‚ÄúJoint Warfighting Program Information Superiority Experiment Trailblazer,‚Äù Fall 1998 SIW Workshop, also available from http://hla.dmso.mil/implement/jwp.html.Author BiographiesPATRICK ALLEN is a Senior Technical Manager at General Dynamics Electronic Systems in Mountain View, CA.  He is the technical lead for M&S development at GD-ES responsible for the design and implementation of IO-ISR testing, training, and planning applications.CHRIS DEMCHAK is an Associate Professor in the University of Arizona's College of Business and Public Administration, School of PA and Policy, and a cofounder of the transnational Cyberspace Policy Research Group.  She studies the integration of complex technical systems into large-scale organizations across nations, focusing especially on the implications for military effectiveness and structural or operational options.