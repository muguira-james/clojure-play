Performance Oriented Wide Area Network Advanced Distributed Simulation via the Defense Research Engineering NetworkThomas A. MoultonCeleste S. KennamerE-OIR Measurements, Inc.P.O. Box 1240Spotsylvania, VA  22553703-704-1093, 703-704-2847 HYPERLINK "mailto:Thomas.Moulton@nvl.army.mil" Thomas.Moulton@nvl.army.mil,  HYPERLINK "mailto:Celeste.Kennamer@nvl.army.mil" Celeste.Kennamer@nvl.army.milDouglas H. PaulComputer Sciences Corporation703-704-2070 HYPERLINK "mailto:Douglas.Paul@nvl.army.mil" Douglas.Paul@nvl.army.milPamela M. JacobsMaximo LorenzoMid SelfU.S. Army CECOM Night Vision and Electronics Sensors Directorate (NVESD)AMSEL-RD-NV-MS10221 Burbeck RoadFort Belvoir, VA  22060-5806703-704-1091, 703-704-3185, 703-704-1285 HYPERLINK "mailto:Pamela.Jacobs@nvl.army.mil" Pamela.Jacobs@nvl.army.mil,  HYPERLINK "mailto:Max.Lorenzo@nvl.army.mil" Max.Lorenzo@nvl.army.mil,  HYPERLINK "mailto:Mid.Self@nvl.army.mil" Mid.Self@nvl.army.milKeywords:ATM, DIS, DREN, HLA, HPCMO, IP, MBone, Multicast, Network, QoS, SSW, Simulation, WANABSTRACT:  This paper discusses the ADS (Advanced Distributed Simulation) architecture employed by the OSD’s (Office of the Secretary of Defense) SSW (Smart Sensor Web) project.  This paper profiles SSW’s emphasis on the importance of providing real-time, on-demand sensor information to the warfighter.  Secondly, this paper discusses how SSW interjects virtual sensors into a live environment.  Lastly, this paper chronicles the SSW ADS architecture’s use of ATM (Asynchronous Transfer Mode) and IP (Internet Protocol) Multicast to offer performance oriented WAN (Wide Area Network) ADS via the HPCMO’s (High Performance Computing and Modernization Office) DREN (Defense Research Engineering Network).IntroductionNetwork technology supports the rapid exploitation and dissemination of sensor information across the battle space.  A sensor or series of sensors can provide detail to the commander on his Area Of Interest (AOI), but the ability to provide this information in a timely manner for a commander, whose battles can be decided in minutes or hours, is critical. The use of current sensor and weapon systems to gather this combat relevant information for commanders at brigade and below is the premise of the Smart Sensor Web (SSW).  Battlefield sensor systems can provide timely visual or derived intelligence to a maneuver unit commander, which should improve his targeting capability and situational awareness.  However, this information will only be beneficial if the delivery of sensor products can be synchronized with the battle rhythm of the commander.  The Office of the Secretary of Defense (OSD) sponsored Smart Sensor Web (SSW) initiative addresses this issue.Smart Sensor WebThe SSW is comprised of five baseline sub-web efforts (see Figure 1) and is structured to incorporate additional web technologies and experiments in the future.  Each of the sub-web efforts leverages existing programs and technologies to provide a degree of stand-alone capabilities.  However, the long-term vision for the SSW is to provide interoperability among the sub-webs to realize the full advantage of collaborative, distributed sensing.  The SSW establishes live and virtual environments for evaluating how best to provide distributed web page content to the future commander at brigade level and below based on the information content received from a variety of mission critical sensor sources.  These sensor sources include imaging and non-imaging products, or products derived from battlefield systems.  This information is transmitted using C4I (Command Control Communication Computers and Intelligence) gateways, which provide interfaces and the communications infrastructure between these live and virtual environments. The demonstration of these SSW technologies is conducted at Fort Benning’s McKenna Military Operations in Urban Terrain (MOUT) facility.  This facility and terrain allows warfighter-in-the-loop evaluation and refinement of the SSW system of systems design.  It also permits the use of the SSW virtual simulations as a supplement to the live activities for a more representational force for evaluation.A series of experiments began with the demonstration of an initial operating capability in August 2000 and will support technology insertion and evolution of improved capability over the course of several years. This series of experiments, to be conducted every four months over the next two years, will offer insights into whether web-based access to sensor systems can produce informative products in a timely manner and provide utility to the unit commander. EMBED Visio.Drawing.5  Figure 1:  Illustration of SSW Participants.Simulation Web (SimWeb)The U.S. Army Communications and Electronics Command Night Vision and Electronics Sensors Directorate (CECOM NVESD, Fort Belvoir, VA) heads the SimWeb effort (one of the five sub-webs).  They developed a Simulation Web Testbed (SWT) that addresses the Advanced Distributed Simulation needs of SSW.  This SWT focuses on the following simulation issues:Management of the ADS Wide Area Network (WAN) connectivity between all participating sub-webs.Incorporation of synthetic sensors and environments into SSW.How to orchestrate the ADS and enhance the SSW exercises by interjecting both friendly and enemy simulated forces to play with live forces.How to facilitate the information transfer between live and virtual simulation.Development of a high-resolution virtual terrain database of the McKenna MOUT site for both PTN (Paint the Night) and ModSAF (Modular Semi Automated Forces).The first two issues speak to SSW’s approach to delivering performance oriented Wide Area Network Advanced Distributed Simulation and are the focus of the remainder of this paper.Advanced Distributed Simulation Wide Area Network.One of the biggest hurdles to conducting Advanced Distributed Simulation across a WAN is the lack of a predictable and consistent level of quality.  “A network is advertised to be of a certain Quality of Service (QoS) if it can consistently meet the same level of quality for a given set of measurable parameters.” [1, p.1]  Without QoS the integrity of an ADS is unknown.  Critical data may arrive late or worse yet, never arrive at all!  Presently the only WAN solution that provides QoS is ATM (Asynchronous Transfer Mode).  Fortunately ATM is the network that comprises many WANs including the Defense Research Engineering Network (DREN).  The SWT makes use of the DREN as its WAN solution.  The DREN is a DoD (Department of Defense) and HPCMO (High Performance Computing and Modernization Office) sponsored initiative to facilitate interagency collaboration with requirements for a high-speed dedicated WAN.  The SWT makes use of the DREN’s ATM network fabric to deliver real-time physics based synthetic sensor imagery produced by NVESD’s Paint The Night (PTN) program.  The SWT links the remaining sub-webs together using IPv4 (Internet Protocol version 4) Multicast to foster ADS across the WAN.QoSIn terms of computer networking, QoS refers to the ability to guarantee a specified throughput (e.g., 40Mbps) at all times.  “Unfortunately the Internet was designed as a best-effort network, and did not originally intend to make any QoS commitments.  This best-effort philosophy is quickly becoming unacceptable because the quality degrades rapidly as the network grows.  Simply deploying larger bandwidth links or extremely large buffers cannot provide QoS guarantees.” [1, p.1]  Presently the only widely available computer networking protocol with inherent QoS is ATM.Asynchronous Transfer Mode (ATM)Today the Internet is based upon IPv4; a routing based protocol where each packet contains the necessary information to proceed from point A to point B.  Based upon a packet’s header information each router (or hop) determines the next hop the packet will encounter until it reaches its final destination.  Thus, the path a packet takes to get from point A to point B is not predetermined.ATM on the other hand is a switching based protocol.  Before a cell (ATM uses the notion of a data cell while IP uses the notion of a data packet) of data is sent from point A to point B, the path upon which the cell will travel is negotiated first.  All cells are sent sequentially and their header contains just enough information for it to be switched across this predetermined path.Virtual Path (VP)“Virtual paths, which are carried within a physical transit medium (e.g., DS-3, OC-3, OC-12, etc.), are used to establish connections between two nodes in an ATM network.  Many virtual paths can be transmitted within a single physical link.  Two types of virtual paths exist (see Figure 2):  Virtual Path Connections (VPCs), also known as through paths, and originating/terminating paths, also known as Virtual Path Terminators (VPTs).  VPCs allow virtual paths to be cross-connected at a switch node while VPTs allow Virtual Channel Connections (VCCs) to be cross-connected or switched at a switch node.” [5, p.1-3] EMBED Visio.Drawing.5  Figure 2:  Illustration of VPTs and VPCs. [5, p. 1-4].Virtual Channel (VC)“Virtual channels ride inside of virtual paths (see Figure 3).  The combination of the two specifies a Virtual Channel Connection (VCC).  Unlike VPCs, which carry one or more VCCs, virtual channels describe a single virtual connection between two endpoints.” [5, p.1-11]  Thus, ATM cells pertaining to a specific data transaction are switched together via a unique VCC.  VCCs with the same start point and end point will get switched via a unique VPC. EMBED Visio.Drawing.5  Figure 3:  Illustration of VPs and VCs. [2, p.75]Permanent Virtual Path (PVP)ATM provides QoS through a concept called a PVP.  The name says it all; it is a permanent virtual path.  QoS is established at the VPTs via a Contract Bit Rate (CBR) agreement.  “The bandwidth allocated to the originating and terminating paths is used to control the amount of VCC bandwidth entering or leaving the virtual path.  The total guaranteed bandwidth used by virtual channels on an originating or terminating path cannot exceed the amount of bandwidth allocated at that path.  For example, as illustrated in Figure 4, if each of the three virtual channels shown is using 10 Mbps of bandwidth, then the originating and terminating paths must have at least 30 Mbps of bandwidth allocated.” [5, p.1-6] EMBED Visio.Drawing.5  Figure 4:  Illustration of QoS via a PVP. [5, p1-6]Internet Protocol over a PVPIn reference to the OSI (Open Systems Interconnection) Seven Layer Network Model, ATM is classified as a layer-two network protocol (Data Link Layer).  As with most layer-two networking protocols it has been designed so that layer-three network protocols such as IPv4 can run overtop of it.  Thus, IPv4 applications can enjoy the spoils of ATM completely transparent to the IP layer.  CLIP (Classical IP), LANE (LAN Emulation) and RFC 1483  (routed and bridged) are the most popular and non-proprietary implementations of IP across ATM.  Unfortunately these standards do not allow the IP layer to take advantage of a PVP’s QoS capability.  All CLIP, LANE and RFC 1483 VCCs are Unspecified Bit Rate (UBR) based.  UBR and CBR VCCs can co-exist within the same PVP.  “UBR traffic bandwidth, which is a best effort service class, is not limited by the VP’s allocated bandwidth since its bandwidth is not guaranteed; however, actual UBR VCC traffic transmitted within a PVP may exceed the VP’s allocated bandwidth.” [5, p.1-6]  Even though IP cannot take advantage of a PVP’s QoS, it can still benefit tremendously from a PVP’s ability to bypass IP routers.PVPs Bypass IP RoutersA PVP bridges the ATM fabric of two distinct networks making them one.  Essentially the originating site’s Local Area Network (LAN) is extended to the terminating site via a PVP due to the fact that the PVP bypasses all IP routers between the originating and terminating paths.  Figures 5 and 6 illustrate this point.  The obvious advantage to bypassing all IP routers is that a simulation does not suffer from the IP router’s inherent latency and unpredictable performance. EMBED Visio.Drawing.5  Figure 5:  Illustration of IP traffic across an ATM WAN. EMBED Visio.Drawing.5  Figure 6:  Illustration of IP traffic via a PVP over an ATM WAN. Oversubscribing a PVP CBR via Tagging“Tagging refers to the action of degrading a high-priority cell to a low priority cell.  Lowering the priority of the cell makes it ineligible for QoS guarantees, but it may still reach the destination if the network is not overloaded.” [1, p.34]  By enabling tagging on a PVP, a CBR VCC can use more bandwidth than contracted for (if available).  For example, if a PVP has a CBR of 40Mbps and a VCC exceeds this bandwidth, the ATM cells within that VCC that oversubscribe the PVP are tagged.  If the ATM fabric encounters congestion, the tagged cells either lose their high-priority status or get dropped.An application can voluntarily tag its own cells.  This is useful if an application is transmitting both critical and non-critical information.  The non-critical data cells get tagged immediately so they don’t compete with the critical data cells.Servicing Virtual Sensors via a PVPThe August 2000 SSW exercise focused around the McKenna MOUT site (Fort Benning, GA).  Each live soldier is issued a wireless LAN based wearable computer capable of requesting imagery from a multitude of live and virtual sensors (i.e., cameras, thermal imagers, etc.).  When a soldier requests imagery from a virtual sensor, Paint the Night (Fort Belvoir, VA) is triggered to generate a stream of synthetic imagery based upon the location and FOV (Field Of View) of that virtual sensor.  The resulting synthetic imagery is sent across the PVP.  The entire transaction takes a matter of seconds.  Amazingly enough the PTN portion to include the synthetic sensor imagery transfer across the DREN takes less than 200ms of the entire transaction (see Figure 7). EMBED Visio.Drawing.5  Figure 7:  Illustration of the Permanent Virtual Path over which PTN provides synthetic sensor imagery.It is important to note that PTN transfers its imagery at the ATM layer instead of at the IP layer to take advantage of the PVP’s QoS.  In addition, PTN will not make use of any lossy image compression algorithms for fear of corrupting the integrity of the physics based synthetic sensor imagery.  In the future PTN may employ loss-less compression if an implementation can be found that imposes acceptable latency.PTN uses the DMSO (the Defense Modeling and Simulation Office) HLA (High Level Architecture) RTI (Run Time Infrastructure) as its simulation backbone to link all of its subcomponents.  NVESD is working with DMSO to incorporate bulk data transfer (e.g., imagery) as an RTI native capability.  In turn DMSO has funded NVESD to look at the scalability of their RTI and has deemed the PVP connection between Fort Belvoir and Fort Knox as an HLA test-bed. IP MulticastIP Multicast is a subscription-based protocol that allows applications on different subnets to join multicast groups.  IP Multicast capable routers maintain this subscription information.  Whenever an application sends information to a multicast group the IP Multicast capable routers deliver this information to the subnets associated with each member.  IP Multicast has an added benefit that only one copy of the data is sent.  A minimum spanning tree algorithm ensures this data does not traverse the same network path more than once.  In other words, IP Multicast is scalable because no matter how many members join a group only one copy of the data will traverse the network.  The downside to IP Multicast is that it was not until the early to mid 1990’s that IP router vendors started to support IP Multicast.  While many organizations have IP Multicast capable routers, which provide an inherent IP Multicast capability within their organization, WAN providers have not been expedient in enabling IP Multicast across their network clouds.  The IP Multicast community has addressed this issue via the MBone (Multicast Backbone).  The MBone is a series of IP tunnels (virtual networks) across non-IP Multicast capable sections of the Internet that act as conduits bridging IP Multicast capable sites together (see Figure 8). EMBED Visio.Drawing.5  Figure 8:  Illustration of an IP Multicast Tunnel.ADS via IP MulticastSimWeb’s Advanced Distributed Simulation is largely based upon DIS (Distributed Interactive Simulation) with the use of High Level Architecture in PTN.  DIS based applications traditionally function in a broadcast mode where all simulation PDU’s are sent to and received from the local subnet’s broadcast address.  This is fine for local simulations but what if you want to interoperate with simulators on other subnets within your organization or outside of your organization.  A more efficient way to accomplish this goal is to use IP Multicast.The DREN already has a strong MBone infrastructure in which to tap into.  The key for SSW was tying the simulation players into the DREN MBone so they could share IP Multicast traffic.  Enabling the sites to interact via IP Multicast was not the only concern.  Many of the sites were using DIS compliant applications that did not support IP Multicast.  That is, these applications only knew how to send to and receive from their local subnet’s broadcast address.  This problem was overcome by writing a software agent that converts IP Broadcast to IP Multicast and vice versa.  In addition, PTN HLA federates interacted with SimWeb’s DIS environment also via IP Multicast through the use of NVESD’s HLA Gateway.  Using these tools SimWeb was able to successfully tie all of the simulation players together in time for the August 2000 exercise (see Figure 9).It is important to note that a PVP was only configured between NVESD (Fort Belvoir, VA) and the McKenna MOUT site (Fort Benning, GA) for the August exercise.  Thus the IP based simulation traffic from the other participating sub-webs did not benefit from using PVPs during the exercise. EMBED Visio.Drawing.5  Figure 9:  Illustration of SSW’s DREN IP Multicast connectivity.SummarySSW and NVESD are shaping the future of WAN ADS. Network protocols such as ATM and IP Multicast are the building blocks upon which performance oriented Wide Area Network Advanced Distributed Simulation across the DREN can be accomplished.  ATM is a powerful yet complex WAN protocol providing simulations a much-needed QoS capability, while IP Multicast’s scalability is well suited for connecting a multitude of simulation sites.  As SSW’s Simulation Web Testbed progresses, the focus will be on connecting all of the simulation sub-webs.  SSW will build a series of robust and mature network tools and procedures to monitor, profile and manage these connections. The intent is to construct a networking infrastructure model other DoD programs can draw from.ReferencesGiroux, N. and S. Ganti. 1999. Quality of Service in ATM Networks: State-of-the-Art Traffic Management. Prentice Hall PTR, Upper Saddle River, NJ.Goralski, Walter J. 1995. Introduction to ATM Networking. McGraw-Hill, Inc., New York, NY.Handel, R., M.N. Huber and S. Schroder. 1995. ATM Networks Concepts, Protocols, Applications. Addison-Wesley. Wokingham, England.Hay, R. 2000. “Comparing POS and ATM Interfaces.” Computer 33, no. 8 (Aug.): 102-106.Marconi Communications. 2000.  ATM Switch Network Configuration Manual.  MANU0148-09, Revision A.Onvural, R.O. and R. Cherukuri. 1997. Signaling in ATM Networks. Artech House, Inc. Norwood, MA.Author BiographiesTHOMAS A. MOULTON is a Senior Member of the Technical Staff for E-OIR Measurements, Inc (Fredericksburg, VA).  He presently supports the U.S. Army CECOM Night Vision and Electronics Sensors Directorate’s (NVESD) Modeling and Simulation Division in Fort Belvoir, VA in the area of systems integration.  Mr. Moulton has a B.S. in Computer Science from James Madison University and a Masters in Computer Science from George Mason University.  He is a staunch advocate of the Free Software Foundation and the Linux operating system.CELESTE S. KENNAMER is a Senior Member of the Technical Staff for E-OIR Measurements Inc (Fredericksburg, VA).  Ms. Kennamer is the Modeling and Simulation Tech Cell Leader (TCL) supporting the U.S. Army CECOM Night Vision and Electronic Sensors Directorate (CECOM NVESD), Fort Belvoir, VA.   Her team is responsible for integrating systems under development into current U.S. Army Systems.  Her team is also responsible for the development of system simulators and conducting distributed simulation exercises.  Ms. Kennamer spent 10 years with Nichols Research Corporation (Huntsville, AL), providing engineering support to a wide variety of US Army Missile Systems and Advanced Concept Technology Demonstration Programs.  Prior to the move to Nichols Ms. Kennamer was with AMTEC Corporation (Huntsville AL) supporting the development of applications that collected, analyzed, and developed vibration specifications for air and ground systems. Ms. Kennamer is a graduate of Jacksonville State University, and holds a B.S. Degree in Computer Science and Engineering.DOUGLAS H. PAUL is a Team Leader for the Computer Sciences Corporation (CSC) in Fort Belvoir, VA supporting the U.S. Army CECOM Night Vision & Electronics Sensors Directorate’s Modeling and Simulation Division.  Mr. Paul retired from the U.S. Army in 1999 after 20 years in the Infantry.  He served three tours in Kuwait, two tours in Germany, one tour in Panama, one tour in Korea, and has held numerous state side assignments.PAMELA M. JACOBS is a Principle Investigator for the Simulation Web of Smart Sensor Web.  She works for the U.S. Army CECOM Night Vision and Electronic Sensors Directorate to develop virtual and constructive modeling capabilities to support operational evaluations of developmental NVESD hardware.MAXIMO (MAX) LORENZO is the Chief of the CECOM Night Vision and Electronic Sensors Directorate Virtual Prototyping Systems Branch. Mr. Lorenzo is the government sponsor and project manager for Paint the Night, a high fidelity real-time EO/IR sensor and scene simulation used to support NVESD and TRADOC Battle Lab experiments.  These experiments require Paint the Night’s unique high fidelity visual system, HLA-based architecture, correlated terrain and model databases and experimental support of target acquisition, battle command and control, countermine and automated target recognition functions.  Mr. Lorenzo has a B.S. in Geology from The College of William and Mary.MID SELF is the Chief of the Virtual Experiments Team at the U.S. Army CECOM Night Vision and Electronics Sensors Directorate.  Mr. Self has been with NVESD since 1984.  While at NVESD he has held positions in land warfare technology, technology planning, and modeling and simulation.  He also spent 18 months as CECOM liaison to the ASA (ALT).  Mr. Self received his B.S. in Engineering and Physics from Washington & Lee University (Lexington, VA) in 1983.		"One Ring to rule them all,One Ring to find them,One Ring to bring them all,And in the darkness bind them.”JRR Tolkin, “Lord of the Rings”