Next Steps in Simulation Standards DevelopmentMartin R. Stytz, Ph.D.Sheila B. Banks, Ph.D.Institute for Defense AnalysesCalculated InsightWashington, DCOrlando, Fl  32828(407) 497-4407, (703) 338-2997(407) 353-0566 HYPERLINK "mailto:mstytz@ida.org" mstytz@ida.org ,  HYPERLINK "mailto:mstytz@att.net" mstytz@att.net ,  HYPERLINK "mailto:mstytz@gmail.com" mstytz@gmail.com HYPERLINK "mailto:sbanks@calculated-insight.com" sbanks@calculated-insight.comAbstractStandards for simulation environments establish the bounds for the possible within simulations.  While, of course, standards can be ignored or modified for a specific use; in the main they are exploited in order to reduce the cost of implementation and maintenance of the simulation and to pave the way for interoperability with other simulation systems.  However, the standards we currently employ do not address many of the newest and emerging components of the modern battlespace and civilian surround, and we contend that it is time to develop the standards needed to address the issues posed by these newest components of the battlespace and civilian environment.   These new battlespace components cover a broad range, from cyber operations to tribal cultural modeling to computational power to the non-combat aspects of security and stability operations.  Standards for these new components of the battlespace can not be modeled by the traditional standards format, the new standards will be more complex because they must address more complex battlespace components than have heretofore been addressed, be context sensitive, and address both the user and the objectives of the simulation.  In this paper we discuss the new components of the battlespace that require standardization, the issues and challenges that must be addressed, and suggest an approach for developing the required standards.1.	IntroductionThe broad outlines of future simulation environments are emerging.  The environments will be very complex, lifelike, and have high fidelity in physics and lighting properties.  The need for simulation of traditional combat, logistics, intelligence, and surveillance operations will continue, but there will also be new elements in the battlespace with pre-eminence given to the new cyberwarfare actors [1-15].  The computer-generated actors will possess improved reasoning capabilities and human behavior models[16-27].  Because of the demands for increased environmental fidelity and new uses for simulation coupled with the increases in computational power and low cost of gaming systems, there is an obvious motivation for an increased use of commercial gaming environments as the foundation for complex military simulation environments.  However, the exploitation of the computational power will be inhibited, if not prevented, if we do not develop standards and guidelines for the use of these more powerful computation abilities to simulate more realistic simulation environments.  Because of the demand for increased environmental complexity and increased computational power, a new breed of standards are needed for the simulation community.  The complexity of these new required standards indicates that the development of standards for simulation environments has reached a crossroads.  The physical and communications standards for simulation environments have been, to a large degree, developed.  While the standards that we have in hand, such as for terrain and data exchange, are useful and can be refined, extended or even replaced, they do not address the core needs for the future of simulation.  The standards that we have do not address complex simulation issues related to human representation, environment representation, cultural representation, and even weapons’ effects representation.  While it is true that many de facto standards have arisen to address portions of these issues, these “standards” or specifications are based upon the popularity of deployed systems and were not developed with larger simulation issues in mind.Our predicament is, perhaps, best illustrated by analogy.  In the physical sciences, equations, principles, and “laws” are used to describe the world and guide the development of systems that operate within the world.  For example, Bernoulli’s principle describes the flow of air across a wing and so play a significant role in the design of aircraft; a role that need not be addressed by standards or specified in contracts because science has provided us with means and methods for modeling the real world and for designing systems to operate within it.  A simulation, however, is a virtual world.  While some real world equations, principles, and laws may be used within a simulation, they do not actually govern the operation of the simulation because the simulation is, after all, a representation of reality.  A simulation is not the real world it is virtual; this aspect of simulation provides the simulation designer with great flexibility but also makes simulation environment specification, design, and implementation difficult, complicates testing, and leads to duplication of abilities.  Hence, in our view, the need for a new type of standards; standards that address issues at a more complex level than the standards we currently have.  The type of simulation standards that are now needed must fulfill the role played by laws, principles, and equations in the real world.  Obviously, these standards will be complex.  But the greater challenges lie in determining what to standardize, how to describe and prescribe what area of simulation that the standard addresses, and what the content and specification of the standard should be.   Determining the specification is, clearly, the main challenge because this decision will determine specific properties of the simulation environment for all simulations that employ the given standard.  Simply, the decisions made concerning these new standards will determine the properties of the virtual worlds instantiated using the standards.To advance the state of the art and of the practice for simulation environments we require a set of specifications that define different levels of quality, capability, and fidelity for each of the major components of a simulation environment.  The standards/specifications should permit the definition of meaningful, distinct categories of capabilities for the major components.  The set of capability specifications for each component should span the range of capabilities for each component, from the most primitive but useful to those capabilities that are beyond our current ability but are, nevertheless, desired and needed.  Obviously, the capability specifications for a component should be grouped, so that all of the specifications for the most primitive acceptable performance form one complete description of the capabilities required of the component to achieve a consistent level of performance at a given point in its capabilities spectrum.  The specifications for a given point in the spectrum should be comprehensive, disjoint (both from other simulation environment components and other points in the spectrum), and able to operate as defined with any other component.  Obviously, the specifications will be complex and will require a concerted effort by the simulation community to develop.In this paper, we discuss the need for the new type of standards, or specifications, that we propose, their benefits, and the challenges. The next section, Section Two, introduces the major new components of simulation technology that we believe are required.  Section Three contains a discussion of the challenges that we anticipate and the characteristics of the standards that must be developed.  Section Four contains our conclusions and suggestions for further work.2.	New Components of Simulation EnvironmentsThere are many types of new simulation environment components that are required in order to effectively simulate the real-world.  These components are complex, recently of importance in the real-world, and there are few simulations that currently represent more than one of these components.  There are many new components that are required, the most obvious of these are, of course, 1) cyberoperations simulation, 2) cultural and human behavior simulation, 3) stability operations simulation, 4) multi-national operations simulation, 5) gaming technology exploitation, and 6) terrorist activity. For each of these components, there are multiple dimensions of the event that must be represented.  Because of space limitations, we cannot explore each of these topics in detail.  Therefore, we will examine a few of these topics in order to illustrate the challenges that must be addressed in order to develop needed standards (and guidelines) all of these components.  Of this set of simulation environment components, cyberoperations simulation is perhaps the easiest to simulate because it is primarily an effects-based activity in the real world; hence, the actual cyberoperation need not be executed.  So, for this component of the simulation environment, we need to determine how to present the effects of different types of cyberoperations, using dimensions such as reducing available bandwidth, information compromise, information uncertainty, unavailability of information, and loss of communication.  A second important new component of simulation environments are culture and human behavior modeling. The modeling and simulation community has seen a surge of interest in the field of human behavior modeling in the past decade as the recognition that traditional probabilistic modeling lacks the richness and robustness required to accurately portray human activities. The representation of human behavior through modeling addresses the task of making the behavior and reactions of any computer-generated entity within a modeling and simulation (M&S) environment seem realistic by developing behavior models that yield a reasonable analogy of the output of the human decision-making process.  The most important aspects of developing the behavioral model are knowledge acquisition, which is acquiring the information needed to effectively model human behavior; knowledge representation, which is putting the knowledge base into a form that can be accessed readily and used for analysis and decision making during simulation operation; and assembling the decision making apparatus that performs decision making.  All three of these aspects of behavioral modeling fall into the realm of artificial intelligence.  Knowledge acquisition and knowledge representation jointly determine the information about the human mental models brought to bear in the decision process.  Cultural-specific knowledge about the information that humans use in the decision-making process is also needed in order to permit the portrayal of nuanced human behaviors.  Cultural and human behavior modeling are now known to play a major role in influencing actions in the real world, and therefore they need to be modeled with greater fidelity within simulation environments.   Their influence is not straightforward or cumulative, however, so the assembly of a cultural model or human behavior model is complex and must address a number of factors, including intent.  What a user intends to do in an environment is the result of events occurring in the environment, knowledge, culture, and the goals he/she is trying to obtain as a reaction to stimuli.  These goals can be explicit or implicit, physical or cognitive.   To achieve a goal, a user must perform certain actions.  Goals can be composed of multiple actions, with many pre- and post-conditions.  Pre-conditions include directly observable events in the environment as well as indirectly observable events that cause a user to pursue a goal.These two new components of simulation environments, like the others, are complex and add multiple new dimensions to simulation design, development, and operation.  Standards and guidelines will help address the complexities and challenges by these new dimensions of simulation, we will address these issues next.3.	Challenges and StandardsThe challenges posed to the US military by the change in its philosophy, approach, and technologies for combat and stability operations are increasing its reliance upon communication and information are inevitably increasing.  This new form of warfare that is being adopted by the US and many of its allies, in which a great premium is placed upon timely, accurate information, is called network centric warfare (NCW) [28-34].  For this future vision of warfare to be achieved and be effective there are a number of challenges that must be addressed, challenges such as level of detail available each level of command, speed of information distribution, and information security. Information protection will be a new form of combat; this new combat arena, the cyberbattlespace, has many unique characteristics that call for new training technologies to prepare warfighters to manage them.  Some of these characteristics are the extreme speed with which events occur, the capability for rapid change of attack vectors and tactics, the high degree of technical expertise needed at all levels of command in order to comprehend the situation, the lack of metrics with which to measure the effectiveness of defense techniques, the difficulty humans face when developing situation awareness and mental models of the cyberbattlespace, the difficulty encountered in achieving a level of prediction for cyberbattlespace activity, and the extreme susceptibility of the combatants and civilians to intended and unintended effects of the results of operations within the cyberspace battlespace.  As a result of these characteristics, training in the cyberbattlespace is more difficult to perform than for other forms of training.  Coupled with the addition of the new, complex components to the simulation environment the design, implementation, and operation is becoming increasingly complex and calls for standards and guidelines that are both comprehensive and fluid.In NCW, the key to achieving a cyberbattlespace training and testing capability is the development of high-fidelity cyberbattlespace opponents and computer-controlled (generated) actors, which is closely tied to the need to improve cultural and human behavior modeling within simulations.  Even within the relatively narrow perspective of the requirements of NCW, the development of the computer-controlled actors and the simulation of cyberoperations will require standards that describe the wide and continuously changing form, characteristics, and observables of cyberoperations.  These standards, in turn, require a wide breadth of knowledge, knowledge that includes taxonomies of attack exploits, taxonomies of defensive techniques and technologies, attack vectors and avenues, and improved understanding of how to structure defenses.  Additional knowledge that is needed includes vulnerability categories, attack categories, network intrusion detection taxonomies, vulnerabilities that arise from architecture and design choices as well as implementation choices and strategies, development of metrics and measures for measuring security capabilities, and development of techniques for vulnerability analysis.  The cyberoperations research community has some of this required information in hand in addition to possessing a large and ever increasing library of exploits that can provide insight into attack strategies and tactics as well as insight into hacker methodologies and approaches employed to hijack computer systems, networks, and software applications.  However, most of their information is not in a form that is readily exploited by the simulation community and, therefore, developing standards will be difficult.  Unfortunately, this same state of affairs obtains for the other new and important components of simulation environments, as is illustrated by the field of human behavior and cultural modeling simulation.The purpose of cultural and human modeling is to determine what must be performed in an environment in order to properly portray a human in the environment that has the same knowledge, culture, and mission.  In this context, intent is an important part of behavior modeling.  This approach is based on the belief that what a user intends to do in an environment is the result of events occurring in the environment and the goals.  We also have no methodology or standards with which to utilize knowledge acquisition (KA) products, which are critical to the human behavior modeling effort, nor any facility to find available products and access them.  Our current behavior models utilize specialized development environments, if any exist at all, which make the use of or modification of a specific model by a non-expert programmer (non-expert in the sense that the person is not intimately familiar with that specific model) almost impossible.  To develop standardized human behavior models that achieve the required capabilities requires investigation and integration of techniques and technologies not previously addressed within the military human behavior modeling arena.  In addition, to apply these diverse research developments within simulations for military training, analysis and acquisition, the standards for the human behavior models must be carefully developed and understood in addition to being comprehensive in their coverage of modeling of behaviors and their possible expressions within a simulation environment.  Therefore, standards in the following areas of research are called for when modeling human behavior:  Artificial Intelligence (AI), Human-Computer Interaction (HCI), Human and Organizational Psychology, and Modeling and Simulation (M&S).  Obviously, one component of the standard must address access to the models because the human behavior modeling representation must be separate from the techniques utilized for entity decision-making.  Another component of the standard must address the wide variety of number of human behavior models that have been developed in other fields and can be reused in the M&S environment. One type of user model, often used in the field of human-computer interaction, is a physical model.  Physical models are based on empirical knowledge of the human motor system, and focus on task execution (one example of this is Fitts’ law, a model for the prediction of user hand movement time, is an excellent example of a physical user model [9]). Another user model, the neurological model, maps user actions or thoughts onto specific regions of the brain.  This model has not been used extensively in the design of intelligent systems, although as our understanding of the human brain increases it could play an important role. The two user models of primary interest in the M&S community, behavioral and cognitive models, are used to determine a user’s future actions.  The primary difference between the two models lies in the level to which the user is modeled.  Both types of models observe the user’s execution of actions; however, cognitive models then attempt to determine the user’s goals, whereas the behavioral model directly forecasts user activity.  Because of their predictive nature, both models have been applied within M&S applications.  As can be readily determined, cultural and human behavior modeling is complex, broad, and composed of many rapidly changing sub-components.  As is the case for cyberoperations simulation, since cultural and human behavior simulation is complex and fluid, so the development of traditional standards will be a challenge.  Because of the need for standards and guidelines coupled with the fluidity and challenges posed by the new and crucial components, we propose using new technologies that are uniquely suited to presenting and managing information that is complex, rapidly changing, and expanding in content.  We discuss our proposal next.One severely limiting issue that affects and will retard the development of the necessary standards is the difficulty of collaborating between researchers from within and outside the United States.  This limitation is especially significant within the human behavior representation area where areas such as cultural effects research and joint command team behavior modeling require the participation of various cultural and national representatives.  But, the other new dimensions of simulation environments are just as challenging, require as much collaboration, and are as significant.  In all of these dimensions of simulation, significant advances can be made in just six months, but by and large years are required to update and revise standards and guidelines.  The overall process that we propose for standards documentation relies heavily upon the internet and the so-called Web 2.0 technologies [44-50].  Standards are captured and documented using wikis, videos, audio, podcasts, and blogs to document the fixed portions of the standard, report and document new results related to portions of specific standards, and to propose new portions to the standard.  Of course, commonly accepted definitions and an ontology for each dimension will be needed; so as is normal, the first step in the process is the identification of definitions and ontologies.  In order to organize the standards, we propose the use of Unified Modeling Language (UML) [35-38]-type use cases to identify the portion of a standard or guidelines affected by a proposal.  The use cases will help to minimize error in both the addition to the standard and its use, as the use will be specifically described in the use case.  The third step is the development of exemplar cases based upon the use case definitions; the exemplars serve two purposes, they provide more specificity about the exact range of applicability of the use case and they provide the “ideal” situation(s) when a specific use case (and its associated standards) should be called upon and employed. The fourth step is the development of the scenarios, tests, and experiments needed to evaluate the standards and performance of simulation systems, development of the templates for the needed components (using the eXtensible Markup Language (XML)[39-43] to define items such as knowledge bases, human behavior models, intent inferencing models, software, class diagrams, component diagrams, etc.), and a description of the minimum acceptable performance that the system must exhibit in the scenarios, tests, and experiments.  This information should be linked directly to the exemplars that they apply to and to the use cases that encompass the exemplars.  The fifth step is validation of standard(s) as well as new portion(s) of the standard as they emerge in order to revise portions of the standard as new data about a particular portion of the standard is obtained.  Validation is accomplished by the execution of the experiments that are defined to test the standards and then to refine them.  An advantage of the approach that we advocate is that the experiments, their results, evaluations of the experiments, and voting/comments on the standard can all be attached to the baseline standard and to any new portion as it is developed.  The sixth step is analysis of the experiments and refinement of the standards and their supporting documentation such as the ontologies, DTDs, use and employment cases, and other components of each standard as warranted by the data and the outcome of the experiments.  The standards will evolve quickly, but still be under the control of a standards body.  While anyone can (conceivably) propose an addition to the standard, only those additions whose experimental data and supporting documentation satisfy the requirements of the standards body need be adopted as part of the standard.  However, the proposed change is not lost but is available to others to consider and build upon.  Each standard, then, will have a vast array of supporting documentation, examples, definitions, and even video and audio descriptions available to the implementer and simulation designer.  Mere words cannot match the expressive power that can be achieved using the approach that we propose.  Words cannot adequately describe standards in the degree of complexity and richness of detail that is needed for the simulation environments that we must provide, but an approach that exploits newly emergent communication technologies can be the solution that we require.4.	Conclusions and Future WorkSimulation environments of the future will be very complex, lifelike, and have high fidelity in physics and lighting properties.  The computational power that is available will enable these high fidelity simulations, which is fortunate because of the new and complex dimensions that must be added to future simulation environments.  These dimensions include, but are not limited to, 1) cyberoperations simulation, 2) cultural and human behavior simulation, 3) stability operations simulation, 4) multi-national operations simulation, 5) gaming technology exploitation, and 6) terrorist activity.  These new dimensions are rapidly changing, broad, and complex and pose new challenges for simulation designers and developers.  Standards and guidelines are clearly needed to help us address this situation; but the standards must enable experimentation and the adoption/incorporation of new data.  Standards for simulation environments establish the bounds for the possible within simulations.  While, of course, standards can be ignored or modified for a specific use; in the main they are exploited in order to reduce the cost of implementation and maintenance of the simulation and to pave the way for interoperability with other simulation systems.  However, the standards we currently employ do not address many of the newest and emerging components of the modern battlespace and civilian surround, and we contend that it is time to develop the standards needed to address the issues posed by these newest components of the battlespace and civilian environment.  Standards for these new components of the battlespace can not be modeled by the traditional standards format, the new standards will be more complex because they must address more complex battlespace components than have heretofore been addressed, be context sensitive, and address both the user and the objectives of the simulation.  In this paper we presented our ideas for a new approach to standards documentation, one that is simultaneously comprehensive while also being fluid and adaptable.We encourage comments on this proposed approach format and hope that others will implement, test, and extend the format as well.  Another area to be investigated is the stylesheet(s) used to display the knowledge bases to humans.  While XML can provide a simple HTML-like display of a knowledge base’s contents, we believe that the process of understanding, verifying, and using a knowledge base can be improved by exploiting the customizable display capability that XML Stylesheets provide.  ReferencesCyberoperations ModelingAlexander, I. (2003) “Misuse Cases: Use Cases with Hostile Intent,” IEEE Software, vol. 20, no.  1, January, pp. 58-66.Amoroso, E.G. (1994) Fundamentals of Computer Security Technology. Prentice Hall: Englewood Cliffs, NJ.Banks, S.M. and Stytz, M.R. (2004) “Cyberwarfare Distributed Training Considerations and Requirements for Operators in Network Centric Warfare,” Fall Simulation Interoperability Workshop, Orlando, FL, 19-24 Sep, pp. 303-314.Brinn, M.; Berliner, J.; Helsinger, A.; Wright, T.; Dyson, M.; Rho, S.; and Wells, D. (2004) “Extending the Limits of DMAS Survivability: The Ultralog Project,” IEEE Intelligent Systems, vol. 19, no. 5, September, October, pp. 53-61.Collberg, C. S. and Thomborson, C. (2002) “Watermarking, Tamper-Proofing, and Obfuscation – Tools for Software Protection,” IEEE Transactions on Software Engineering, vol. 28, no. 6, June, pp. 1-13.Erickson, J. (2003) Hacking:  The Art of Exploitation.  No Starch Press: San FranciscoHoglund, G. and McGraw, G. (2004) Exploiting Software:  How to Break Code, Addison-Wesley: New York.Howard, M. and LeBlanc, D. (2002) Writing Secure Code.  Microsoft Press: Redmond, Washington.Khan, K. M. and Han, J. (2002) “Composing Security-Aware Software,” IEEE Software, vol. 19, no. 1, January-February, pp. 34-41.Lampson, B.W. (2004) “Computer Security in the Real World,” IEEE Computer, vol. 37, no. 6, June, pp. 37-47.Larochelle, D. and Evans, D. (2001) “Statically Detecting Likely Buffer Overflow Vulnerabilities,” Proceedings of the 10th Usenix Security Symposium,  pp. 177–189.Potter, B. and McGraw, G (2004) “Software Security Testing,” IEEE Security and Privacy, vol. 2, no. 5, September-October, pp. 81-85.Stytz, M.R. and Banks, S.B. (2003)  “Progress And Prospects For The Development Of Computer Generated Actors For Military Simulation Part 1 – Introduction And Background,” Presence: Teleoperators and Virtual Environments, MIT Press, vol. 12, no. 3, June, pp. 311-325.Thadakamalla, H.P.; Raghavan, U.N.; Kumara, S.; and Albert, R. (2004) “Survivability of Multiagent-Based Supply Networks: A Topological Perspective,” IEEE Intelligent Systems, vol. 19, no. 5, September, October, pp. 24-31.Whittaker, J. and Thompson, H. (2003) How to Break Software Security, Addison-Wesley: New York.Cultural and Human Behavior ModelingBarnard, P., “The Contributions of Applied Cognitive Psychology to the Study of Human-Computer Interaction”, Readings in Human-Computer Interaction: Toward the Year 2000,. Baecker, R. M. et. al.. (eds.), Morgan Kaufmann Publishers, San Francisco, pp. 640-658, 1991.Cannon-Bowers, J. & Salas, E. (eds), Making Decisions Under Stress:  Implications for Individual and Team Training and Simulation, Washington, DC:  American Psychological Society, 1998.Cox, M.T. and Zhang, C. (2007) “Mixed-Initiative Goal Manipulation,” AI Magazine, vol. 28, no. 2, Summer, pp. 62-73.Chandrasekaran, B., Josephson, J.R., and Benjamins, V.R.,  “What Are Ontologies, and Why Do We Need Them?,” IEEE Intelligent Systems, pp. 20-26, January/February, 1999.Ferguson, G. and Allen, J. (2007) “Mixed-Initiative Systems for Collaborative Problem Solving,” AI Magazine, vol. 28, no. 2, Summer, pp. 23-32.Hearst, M.A. and Hirsh, H.  “AI’s Greatest Trends and Controversies,” IEEE Intelligent Systems, pp. 8-17, January/February, 2000.Hendler, J.  “Making Sense out of Agents,” IEEE Intelligent Systems, pp. 32-37, March/April, 1999.Horvitz, E. (2007) “Reflections on Challenges and Promises of Mixed-Initiative Interaction, AI Magazine, vol. 28, no. 2, Summer, pp. 19-22.Pew, R. & Mavor, A. (eds) Modeling Human and Organizational Behavior: Application to Military Simulations, Washington, DC:  National Academy Press, 1998.Siksik, D.N.  “Intelligent Computer Generated Forces Through Expert Systems,” Proceedings of the 3rd Conference on Computer Generated Forces and Behavioral Representation, pp. 3-10, 1993.Stokes, A., Wickens, C., & Kite, K.  Display Technology: Human Factors Concepts.  Warrendale, PA: Society of Automotive Engineers, Inc., 1990.Tecui, G.; Boicu, M.; and Cox, M.T. (2007) “Seven Aspects of Mixed Initiative Reasoning:  An Introduction,” AI Magazine, vol. 28, no. 2, Summer, pp. 11-18.Network Centric WarfareAlberts, D.S.; Hayes, R.E.; Kirzl, J.E.; Leedom, D.K.; and Maxwell, D.T. (2002) NATO Code of Best Practices for Experimentation, DOD Command and Control Research Program:  Washington, DC.Alberts, D.S. and Papp, D.S. (2001) Information Age Anthology, Volumn 1: The Nature of the Information Age. CCRP Press, CCRP Publication Series: Washington D.C.Alberts, D.S.; Garstka, J.J.; and Stein, F.P. (1999) Network Centric Warfare: Developing and Leveraging Information Superiority. CCRP Press, CCRP Publication Series: Washington D.C.Alberts, D.S. and Hayes, R.E. (2003) Power to the Edge CCRP Press, CCRP Publication Series: Washington D.C.Michel, T. and Haanpaa, D. (2006) “A Simulation to Analyze Aircraft-Centric Network Wireless Link Performance,” Fall Simulation Interoperability Workshop, Orlando, FL, 10-15 Sept., pp. 4147-152.Pratt, J. and Tregenza, M. (2006) “Developing an NCW Experimentation Programme,” SimTecT 2006, Melbourne, Australia, 29 May – 1 June, pp. 61-68Smith, E.A. (2003) Effects Based Operations: Applying Network Centric Warfare in Peace, Crisis, and War. CCRP Press, CCRP Publication Series: Washington D.C.UMLAlbir, S.S. (1998) UML in a Nutshell, O'Reilly Press, Sebastopol, CA.Booch, G. (1998) The Unified Modeling Language User Guide.  Addison Wesley, Reading, MA.Booch, G.; Rumbaugh, J.; and Jacobson, I. (1999) The Unified Modeling Language User Guide, Addison Wesley, Reading, MA.Henderson-Sellers, B. and Unhelkar, B. (2000) Open Modeling with UML, Addison-Wesly Reading, Mass.XMLHarold, E.R. (1999) XML Bible.  IDG Books Worldwide: Foster City, CA.Lacy, L.W. & Tuttle, C. (1998) “Interchanging Simulation Data Using XML,” The 1998 Fall Simulation Interoperability Workshop, Orlando, FL., 13-18 Sep., pp.1110-1119.Megginson, D. (1998) Structuring XML Documents. Prentice Hall: New York, NY.Miller, G.J. & Filipelli, L.J. (1999) “An XML Representation of HLA Object Models,” The Spring Simulation Interoperability Workshop, Orlando, FL, 14-19 March, pp. 565-570.Eastlake, D.E. and Niles, K.  (2003) Secure XML.  Addison-Wesley: Boston.Web Services and Web 2.0Griffin, Donna and Pesch, Dirk. (2007) “A Survey on Web Services in Telecommunications,” IEEE Communications Magazine, vol. 45, no. 7, July, pp. 28-35.Karunamurthy, R.; Khendek, F.; and Glitho, R.H. (2007) “A Business Model for Dynamic Composition of Telecommunication Web Services,” IEEE Communications Magazine, vol. 45, no. 7, July, pp. 36-43.Newcomer, E. (2002) Understanding Web Services:  XML, WSDL, SOAP, and UDDI, Addison-Wesley Professional.Rao, J. and Su, X. (2004) “A Survey of Automated Web Service Composition Methods,” Proceedings of the 1st International Semantic Web Services and Web Processes Exposition, Springer-Verlag, pp. 43-54.Berndt, H.; Hamada, T.; and Graubmann, P. (2000) “TINA: Its Achievements and Its Future Directions,” IEEE Communications Surveys and Tutorials, vol. 3, no. 1, pp. 2-16.Dustdar, S. and Schreiner, W. (2005) “A Survey on Web Services Composition,” International Journal of Web and Grid Services, vol. 1, no. 1, pp. 1-30.Ferguson, D.F. and Stockton, M.L. (2005) “Service Oriented Architecture:  Programming Model and Product Architecture,” IBM Systems Journal, vol. 44, no. 4,  HYPERLINK "http://www.research.ibm.com/journal/sj/444/ferguson.html" http://www.research.ibm.com/journal/sj/444/ferguson.html.