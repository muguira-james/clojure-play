A Plan to find the optimal condition for streaming system over HLA-RTISung-Dae Hong, Han-Suh Koo and Chang-Sung JeongDepartment of Electronics Engineering, Korea University1-5ka, Anam-dong, Sungbuk-ku, Seoul 136-701, Korea+82-2-3290-3229 HYPERLINK "mailto:guslsum@hanmail.net" guslsum@hanmail.net, { HYPERLINK "mailto:esprit@snoopy, csjeong@charlie}.korea.ac.kr" esprit@snoopy, csjeong@charlie}.korea.ac.krKeywords:HLA, RTI, StreamingABSTRACT: In Distributed Virtual Environment (DVE), each systems exchange data, event and messages with other systems. To develop a more practically applicable DVE, a mechanism that can transmit video data as well as audio data is needed. The HLA-RTI is an efficient way to build a DVE for event transmission and multicasting, but it does not provide a complete solution for large data transmission, as video data, to the present. So we develop an audio and visual data streaming system running on RTI.1. IntroductionNetwork virtual environment is a dynamic environment that consists of individual and independent simulation machines connected by a network that can join or leave the environment whenever they want to. And they can interact with each other after joining the virtual environment group.War game simulation is a good example for this. War game simulation consists of some real players (people) and objects (tank or combat weapon) in the virtual environment. The objects connected with real objects. They interact in real time. Each real player controls real object by interconnection with virtual object. If real player gives orders, virtual object will send their results about orders and processes follow them.HLA-RTI helps this kind of mechanism. Fundamental application for Networked virtual environment exchange events about conditions of each objects such as position, time, fire, live, dead and so on. These days, multimedia data are also needed to present in the networked virtual environment. But HLA_RTI is not developed to this situation yet. Multimedia data transmission requires large bandwidth, timing control and data ordering. The widespread high-speed network helps large data transfer but it is not sufficient for multimedia data. So streamming technique is developed rapidly. Also streaming application make timing problems and ordering problems between delivering data blocks. We have made an effort to solve timing problems. Our system sends two kinds of data over RTI. One is the real data containing audio and video data sent by RTI API's sendInteraction() and receiveInteraction(). The other is the description of interaction process proposed by our system that is essential for efficient data streaming.  This part solves the timing issue. We implemented interaction process to control Sender  and Receiver. Sender performs data-dividing and sending to receiver. Receiver have buffering-process to reconstruct incoming data and moving-process to write the data to device buffer for playing. Of course, we must consider some problems such as receiver’s buffer-overflow and buffer-underflow, which problem will be occurred when relationship between data sending rate and playing rate isn’t considered. We develop the buffer-management to prevent buffer-overflow/underflow. Buffer have two kind of level. We will find optimal buffering level to play multimedia data continuous without noise.2. Streaming data traffic and RTI reviewMultimedia data transfer requires streaming architecture because the size of data is very large and the bandwidth of network is not sufficient to send the data at once.Some problems such as misordering or loss of sliced data can arise. HLA_RTI helps solve these problems. It provides timestamp ordering. What we should do is just controlling data loss and timing. In this paper, we will solve timing issue by introducing interaction processes.2.1 Stream data trafficThere are two kinds in streaming data traffic. One is general data, and the other is variable bit rate data usually compressed data[2].General data traffic delivers same size of data during streaming traffic. It is called constant bit rate transfer. Uncompressed data give rise to this traffic. Variable bit rate traffic appears in compressed video data transfer because video frames are compressed in different bit rate. We tested our system on condition of constant bit rate transfer.2.2 Streaming issuesThere are many problems to consider in developing of streaming application.Delay jitter: average value difference between maximum delay and minimum delayLost, corrupted or misordered data packetsDelivering rate should be faster than playing rateBuffering time: The time to take for saving sufficient data to play in the buffer.Ways to solve above problems are satisfied with following condition.Low jitter: using buffer at receiver partLow latency: it depends on RTI ability and network condition. To solve this problem, some control message is used. Adaptability against changing network condition provides efficient way for low latency.Good performance for large network and large number of connections is provided by RTIBuffering time is necessary for streaming because of delivering, encoding, and decoding time of compressed data.Modest buffer size must be decided within the network condition: To obtain modest buffer size, we must consider some conditions such as latency, delivering speed, and playing speed.Buffer management for streaming.Data loss: There are two kinds of streaming  applications. One can tolerate data loss, and the other can’t tolerate it. data loss can tolerate in uncompressed data streaming. Tolerating application for data loss uses best effort transfer. The other uses reliable transfer. The choice depends on the purpose of application.Buffer management and modest buffer size will be  decided by considering  delivering time ,playing rate and latency2.3 HLA_RTI reviewHLA requires federate interaction. RTI provide interface between federates.  Federates are created, federate execution consists of join and resign. Fig.2 shows federation execution.RTI software implements the interface specification and represents one of the most tangible products of the HLA. It provides services in a manner that is comparable to the way a distributed operating system provides services to applications[3]. RTI-object management uses sendInteraction() and receiveInteraction() pairs and updateAttribute() and reflectAttribute() pairs in this paper. sendInteraction() and receiveInteraction() pairs are used to send real multimedia data. updateAttribute() and reflectAtrribute() pairs are used to send control message. Fig.3(a) shows sendInteraction() and receiveInteraction() pairs. sendInteraction() service sends an interaction into the sender federation. The interaction parameters may be in FED file. receiveInteraction() service provides the receiver federate with a sendInteraction(). Fig.3(b) shows updateAttribute() and reflectAttribute() values. updateAttribute() values service provides current values to the federations for instance attributes owned by the federate. The federate provides instance attribute values in the FED file. reflectAttribute() values service provides the federate with new values for instance attributes.3. Our workIn this chpter, we will introduce our interaction management for streaming. Our system consists of sender and receiver parts. Sender is a data sending part, receiver is a data receiving part. Receiver manages connection using receiveInteracation() and reflectAttributeValue() of RTI. Multimedia data are divided into data and header, data are divided into constant blocks. They are delivered by sendInteraction()  at sender and received by receiveInteraction() at receiver. Our system uses some messages for stream control. They are delivered by updateAttributeValue() and received by reflectAttributeValue()[4].They are defined as follows. Simple interaction doesn’t consider buffer-overflow and buffer-underflow problems.( Messages for simple interaction1. READY: ready to send at sending part2. REQUEST: request of data at receiving part 3. START: Start data sending process at sending part4. OK: Data are received at receiving part5. END: All data are sent, at sending part6. REVEND: end message received at receiving partThere are synchronization problems and ordering problems. RTI provides Timestamp-ordering for ordered delivering.Synchronization requires buffers at the receiver to store the data temporarily until playing time. There is a buffer problem as follows.( Buffer-overflow and buffer-underflow.Variable sending data size can solve buffer-overflow/underflow problem. First receiver and sender agree on stream data size for interaction concern with network condition. According as delivering rate is decreasing, delivering data block size is smaller than earlry block size. the problem depends seriously on RTI system's ability and network condition. To decide data block size is difficult. So we developed optimal buffer size and buffer management Buffer-overflow/underflow problem must be solved before losing any data at the receiver. There are three messages to managing buffer.( Messages for buffer management1. BUFFUL: Having no remaining buffer space, receiver sends this message to sender2. BUFOK: Receiving BUFFUL message, sender suspends sending data.3. RESTART: Requesting data again, receiver sends this message to sender.3.1 Schedule for receiving and playingSynchronization needs buffer. Buffer has read-operation and write-operation. Receiving from network is connected with write operation. Read operation must be performed continuously before being empty in the device. These operations are executed simultaneously. Two Threads solve this simultaneous accessing to buffer.Synchronization makes sure a consistent state between the threads. Synchronization must be carefully implemented to avoid deadlocking in this application, deadlocking occurs when one object is waiting for another to release a lock, and that object is also waiting. If circular dependency occurs, then the waiting threads are never executed. To prevent this, it's important not to hold a lock while waiting for another resource that requires locking. Fig.4 shows the two thread operations( Thread 1 writes data from ReceiveInteraction() of RTI.( Thread 2 reads data from buffer and write device. 4.2.Circular buffer AlgorithmBuffer receives data depend on receive interaction. Device reads playing data from this buffer which is implemented as circular buffer because read/write operations happen simultaneously. Read operation occupies the buffer space and write operation leaves the buffer space. Circular buffer is a good solution for both case.Fig.5 shows circular buffer architecture.         m-read          m_writeFig.5 circular buffer(Circular buffer data- m_read: reading position- m_wirte: writing position reading position and wiriting position move to first blcok when they reach last block.- size: buffer size(Circular buffer operations- getsize() : getting size- read(data, data_size) : reading from buffer.- write(pdata, data_size) : writing to buffer.Write () operation can read from buffer if there is more space than reading data size. This operation execute simultaneously. Thread 1 accesses to this operation. Write() operation consists of three kind of actions. That is Lock(), Memorycopy(), and Unlock().(Lock(): assign upon entering the synchronized block (in the buffer ).(Memorycopy(): copy the data to the allocated memory area that is equal to data size.(UnLock(): release as necessary when the block is exit  Read() operation can write to device if buffer is not overlapping and device has sufficient space for writing.Thread 2 accesses to read() continuously. Read() operation is the same as write() operation.  Lock(), Memorycopy(), and Unlock() can synchronize read-operation and write-operation  simultaneously.3.3 Sender architectureSender must manage multimedia data and sending data size. If receiver wants data, sender reads the file and finds data information by extracting the header of the file. After analyzing the data information, the file is divided into data block (sending data). The size of data block is variable to network condition. First network condition level must be divided as network situation. The data size varies as network condition. Network condition is decided by receiver’s reports and results. Buffer management controls data size by network condition. Sender distributes READY message meaning “getting ready for sending to Receiver” after  data size is decided temporarily. SendInteration() in Update() method is used to send data block.Fig.6 shows sender architecture Fig.6 sender Architecture(Process as following 1. Read the audio file2. Extract header and format of audio and video data3. Ready to send header information to receiver4. Join the RTI5. Distribute the message READY6. Wait for receiver's request3.4 Receiver architectureReceiver requires buffer for synchronization. Buffer acts as temporal storage to reduce interval between data blocks arriving adjacently. Buffer access is discussed above. Fig 7. shows receiver architecture.Fig.7 Receiver ArchitectureBuffer management is mentioned in next chapter. Receiver sends the message REQUEST to sender until it receives the message START from sender. After that, receiver receives header information. Device is set for data presentation. Receiver uses circular buffer. The size of buffer is default value. The size is changes adaptively according to varying network condition and data type.ReceiveInteraction() in update() is used to receive data block( Process as following1. Join the RTI2. Request the required data as sending REQUEST message 3. Receive header information of  required data4. Make the buffer for synchronization5. Device setting for required data.3.5 Simple interaction between Sender and ReceiverAbove defined messages provide stream control for RTI interaction with simple solution without buffer management. Following process has 5 steps without considering buffer problems. Fig.8 shows simple interaction between sender and receiver as following processFig.8 Simple interaction( 6 steps for simple interaction1. When sender is ready, it sends READY message.2. When receiver receives READY message, it sends REQUEST message. Receiver waits for READY message until time is expired3. When sender receives the REQUEST message, it starts to send data block and DATA message which means sending state.    4. Receiver receive data block and push the data to buffer. After receiving DATA message, receiver sends OK message 5. When final data block is sent, sender sends END message.     6. When receiver receives END message, send REVEND message.Control messages notify sender when the sending operation is started. After that, Sender sends data continuously. After end of data is sent, control messages order the application to stop delivering. This process omits the interference of network error, buffer overflow and underflow. Buffer problem is discussed in the next chapter.3.6. Buffer managementBuffer is needed for synchronization. It solves jitter and buffering time problem. It was implemented as circular buffer.In case of buffer-overflow, received data will be lost because of no space to store in. To prevent this situation, delivering should be suspended for a while. In case of buffer-underflow, player remains in silence because it has no data to play. The determination of appropriate buffer size is essential. And problems are solved by  introducing Buffer level [7]. Fig.9 Buffer LevelFig.9 shows buffer level. Default level is needed for prevention in overlapping between write() and read() operation. Low level prevents buffer underflow. Receiver informs Sender of shortage of data when buffer enter lowlevel condition. High level prevents buffer overflow. Receiver informs Sender of overflow when buffer enter highlevel condition. Each level is decided by considering Network states.  Low level must consider playing rate and the delivering time of messages. Playing rate is a consuming rate in the device buffer. High level must consider incoming rate at buffer and delivering time. This application must also consume buffering time before playing with stream over RTI.(Buffering time : Total buffering time is spending time for  continuous playing(Delivering time(Dt) : the time until message reach sender(Default level : it can be decided by considering the relationship between writing rate and reading rate.(Normal size(Ns) : adaptable space between low level and high level(Low level(Ll) : Ll= (Playing Rate) x (Dt) + (Default level)(High level(Hl) : Hl= (Ll) +(Ns)(Total buffer size: Hl +(Incoming Rate) x (Dt) (Playing rate : Consuming rate in the device(Incoming rate : Data receiving velocity  from network  in Receiver buffer.If Incoming rate is larger than playing rate, then Overflow will happen. Otherwise  Underflow will  happen.Fig.10 Buffer managementFig.10 shows buffer management  in the following process .(Buffering Receiver receive and store in the buffer until buffer level is higher than buffering level. After buffering . Device is played.If Incoming rate is larger than playing rate. Overflow will occur. If Playing rate is larger than Incoming rate. Underflow will occur.(Overflow1. When Receiver buffer level is higher than high level, Receiver sends BUFFUL message.2. If sender receives BUFFUL, then it suspends reading from file and sending to receiver until receiving RESTART message(Underflow 1.When Receiver buffer level is lower than low level , Receiver  sends RESTART message.2.If sender receives RESTART message, then  it restart sending process.3.When Buffer level is lower than default level. Receiver stop playing. And buffer enter buffering state. Above process is simple buffer management, not efficient. This situation should be improved. Network situation must be reported to decide suitable sending data size and receiving buffer size. And the network situation is divided into some level. After that, we will decide more efficient sending data block size without stopping sending operation.   4. Test4.1 test environmentPC: Pentium 3-750 MHzRTI version: 1.3 NGOS: Windows 2000 ProfessionalLAN: 100BaseTAudio: 8 Bits/PCM/Mono , 11KHz10010 BPS is required for playing at second.4.2 Test result4.2.1 When playing rate is larger than Incoming rateIn this case  underflow will be happened. To prevent underflow. This application must have buffering level. We will calculate buffering level and Normal size .( Data transfer rate without controlling with messagesData transfer rate is the time during a data block reaches receiver from sender. It is regarded as Incoming rate in buffer. Data transfer rate =Incoming Rate=  Delivered data volume / Average of times9.29 Bytes/msec = 16000 Bytes/1722 msec  (Delivering time is the sum of end-to-end latency and time consuming message control . (Delivering Time(Dt)= Total time/ Number of Message= 50 msec( Playing rate is the device playing velocityPlaying Rate = Data Volume(byte)/ Playing time(msec) 10 (bytes /msec) = 980184 (byte)/ 98sec( Default Level =  1000 byte( Low Level =  1000 + (2 x 50 x 10 )= 2000 ( High Level = Low level + Ns (Total buffer size = Hl + (2 x 9.29 x 50)(Buffering level (10 byte/msec –9.29 byte/msec) x (98000msec)+default level = 70580 bytes  (Buffering time(buffering volume+ defaultlevel)/ (Incoming rate) =70580/9.29=7597msecFrom above result. we can decide buffer level and buffering time. finally we can also decide  Ns .(Normal sizeThe range of buffering level is between high level and default level.Ns > buffering level – (lowlevel +incoming rate x deliveringtime x 2)Ns> 70580-(2000 +929) =67651 bytesTherefore we find that Ns is larger than 67651 bytes, and buffering time is longer than 7597 msec .  Fig 11. go to show that relationship between buffering time and Receiver behavior.  When buffering time is 8000 msec . there aren’t underflow. BufferingTime(msec)Feedback Number of messageUnderflow (msec)10001854030009250500037070000.720800000Fig .11 Receiver behavior depend on buffering time.Undering has only occured because Playing rate is larger than Incoming rate. so buffer must have sufficient data in Buffering process4.2.2 When Incoming rate is similar to playing rateIncoming rate is similar to playing rate. Buffering level is default level. Receiver must have adaptable space in buffer. The size of adaptable space is normal size(Ns). Normal size can be small in this case. Fig. 12 go to show that the behavior of Receiver varies according to Ns. The actions of Receiver can be decreased according as Ns increase.  if Ns is larger than 100 Kbyte . there is no over /underflow. Ns(Kbyte)Feedback Number of messageUnderflow (sec)Overflow(sec)1230.0190.0101020.0060.00010000.0000.000100000.0000.000Fig .12  Receiver behavior  depend on NsConclusionWe have shown that relationship between buffering time and underflow ratio. We have also explained that Buffering time is needed to reduce jitter and the effect of latency. To find the optimal condition for streaming system, We must find optimal buffer level from relationship between Incoming rate and playing rate. If Incoming rate is larger than playing rate. Then Overflow will occur. In this case. Buffering level is equal to default level. If playing rate is larger than Incoming rate, then Underflow will occur. In this case. Buffering level can be calculated as follow.Buffering level  is larger than (Incoming rate – Playing rate) x (Playing time).Buffering time is larger than (buffering volume + default level) / (Incoming rate).Underflow/Overflow decrease according to Normal size increase.If incoming rate is similar to playing rate. Normal size has sufficient space. The From above result, we found best buffering time.  After that, we find buffering level based on the buffering time. Finally the time is needed for reducing jitter and latency due to change of network condition .8.References [1] DMSO homepage. http//www.dmso.mil/[2] Willam stallings “High speed network “, Prentice Hall.[3]  RTI 1.3 -NG programmer's guide.	[4]  HLA Level Architecture Interface Specification.[4]  Hui  Zhai and Bucikas D.Georganas. An Apporach for Stream Transmission over HLA-RTI in Distributed Virtual Environments[6]  Hui Zhao and Nicolas D. Geoganas. An Apporach for stream Retrieval over HLA_RTI in Distributed Virtual Environments.[7] Markus Mielke and Aidong Zhang . A Multi-level Buffering and Feedback Scheme for Distributed Multimedia Presentation Systems.[8]  MSDN  library.RTIUpdate()sendInteraction()Read()fileRTIreceiveInteraction()Federate (Receiver)Federate (Sender)sendInteraction()Read()outiceRTIUpdate()Receive-Ieraction()write()uFig.4 Architecture for playingFig.3 Object managementsbfferdevSenderReceiverbufferREADY   DATA ENDREQUESTOKREVENDSenderReceiverbufferDATARESTARTOKBUFOKBUFFULContinuous Simple interaction process Stopreading sendingtemporaryoutRTIbufferdeviceDarknessFederationExecutionExistsSupporting FederatesJoin Federation ExecutionResign Federation ExcutionCreate FederationJoin FederationResign FederationDestroy FederationTT(a) constant rate(b) variable rate rateFig.1 kinds of data transmissionFig.2 Basic states of the federation execution(a) sendInteration() and receiveInteraction() pairRTIReflectAttributeValue()Federate (Receiver)Federate (Sender)UpdateAttributeValue()(b) updateAttributeValue() and reflectAttributeValue()Thread 1thread 2Buffer sizeDefault level   Low level           High LevelNormal Size