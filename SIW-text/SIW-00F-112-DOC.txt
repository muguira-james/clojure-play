Distributed Process Control for HLA and the RPR FOMMonte L. Porter Jr.Michelle R. HermanHirome FujioEddie LandryComputer Sciences CorporationPO Box 400002 MS 4-2-6Huntsville, AL 35815-1502256-885-7056, 256-885-7523, 256-885-8395 HYPERLINK mailto:mporter@csc.com mporter@csc.com,  HYPERLINK mailto:mherman@csc.com mherman@csc.com, hfujio@csc.com,elandry@csc.comKeywords:  Process Control, HLA, RPR FOM, Modeling and Simulation. ABSTRACT: The military is putting more reliance on simulation technology for training, T&E, and RDA.  This is due to a convergence of increasing computer capability and decreasing budgets.  The increase in computing capability allows simulations to be more realistic, the smaller budgets for training, testing and other real-world requirements forces users to look to simulation for solutions. The credibility, reliability and realism of the simulations used must therefore be assured.  Hardware, software, networks and simulation participants must provide a quality solution validated through rigorous, non-intrusive monitoring and process control. CSC has developed a test-bed to prove out integration processes and control tools in an HLA environment. This paper will present a description of the HLA based operational integration test-bed developed by CSC to examine quality of service and process control issues related to distributed simulation.Introduction.  As the military and industry begin to put more emphasis on distributed interactive simulation to examine processes and to make decisions, the need for intelligent real-time monitoring and control of those simulations becomes imperative.  These testing and analysis tools must be applied to research and development, training, and materiel testing domains.  They must provide value added by measuring both automated and human in the loop process activity and providing metrics to ensure the entire simulation is “in control”. Under the military’s acquisition reform program, simulation is being used more often to make acquisition decisions (vice test).  The credibility of the simulations used must therefore be assured  through intelligent monitoring and process control.  Many of the issues discussed had their genesis in DIS but the tools discussed have been applied in an HLA federation using the RPR FOM v 1.0.  Other RPR FOM federations can benefit from the lessons learned and the tools that have been developed.   Having a monitoring system that assures the process is “in control” allows the decision maker to place more reliance on the simulation results and enable him/her to make hard decisions earlier. 2.  A Case for Process Control.Distributed simulation was used to support the Rapid Force Projection Initiative Advanced Concept and Technology Demonstration (ACTD).  In this effort, the Army wanted to provide light, early entry forces with advanced sensors, digital command and control, and improved accuracy for delivery systems. Hunter systems used advanced sensors extending the units range for acquiring targets.  Then, communicating via digital communications networks, those hunters provided the unit commander with improved situational awareness.  Using the digital data commanders were able to engage targets effectively well beyond line-of-sight.  Figure 1-1 shows the Hunter-Stand-off Killer concept that was a major theme of RFPI.Figure 1-1 RFPI ACTDDistributed simulation for this program was developed over 5 years in an iterative fashion to support a large scale field experiment in August of 1998. We had approximately 2,000 soldiers supporting the Field Experiment. Throughout the task the paradigm was to model the phenomenon, test it and then fold the test results back into the model.  VV&A was a major part of the development effort.  At the end of the exercise, the customer wanted the results of the experiment used to recreate the scenario in constructive simulation (CASTFOREM is the Army’s constructive simulation of choice) to support Army acquisition decisions.   To support this effort, CSC was commissioned in FY 99 to conduct a “forensic analysis” to support the reconstruction of the scenario [1]. The basic tenets of the analysis will be reconstructed here.  	Forensic AnalysisWebster’s Dictionary defines the term “Forensic” as being “characteristic of or suitable for a law court or public debate”.  When most of us hear the word forensic we think of the show “Quincy” where a forensic pathologist conducts a battery of tests on a corpse to solve a crime.  The evidence in the body of the victim provides the proof needed in a court of Law.  Forensic analysis of distributed simulation is much the same in that it is a battery of tests that examines evidence from the simulation to provide insights on what happened and to identify anomalous behavior. In either DIS or HLA, distributed simulation leaves its mark in the messages that are passed back and forth between participants.  While the simulations themselves can be verified through regression testing and other normal means, the insertion of man-in-the loop creates an environment where human decisions effect the outcome of the simulation.EvidenceUsing a data-log (which contains all the messages passed between simulations) we extracted or mined the data and then analyzed the evidence of activity in the log.  Then, using a battery of tests we identified some anomalous behaviors that were not detectable during the conduct of the exercise.  The “evidence” was primarily examined visually in a set of charts  Evidence in time history form.  Figure 2-1 shows an example time-history chart where a military organization was supposed to fire at the same time so that the effects of the action would be significant to the target.  The chart shows that the humans chose not to follow the prescribed procedure.Figure 2-1  Time HistoryEvidence in bar chart form.  Figure 2-2 shows a number of fire missions for each of three launchers in the first column and then the effectiveness of each mission from very effective to not effective in the next three columns.  Man in-the-loop decision processes had a major impact on the success of this system.Figure 2-2  Bar ChartEvidence in trace form.  Figure 2-3 shows the trace of each missile in flight - evidence of the targeting solution decided upon by a human operator.  The prescribed method of engagement for this missile was to use a dog-leg flight path that aligned the missile along the avenue of approach (fly up the roads).  The figure shows that the prescribed  method was frequently not used.Figure 2-3 Trace ChartDuring the exercise, a detailed data collection program was monitoring the exercise and three separate “battle-master” stations were employed.  These assets provided  a visual monitor and “command and control” of the exercise - however, the anomalies shown on the previous figures and others still happened - and the control centers were unable to discern the complexities of the interactions in real time. We didn’t know what we didn’t know.  The simulations involved were robust and valid - the human factor introduced problems that were hard to detect with visual inspection.This demonstrated a need for process control. An intelligent system is needed to monitor the flow of data as it happens to provide a “controlled process” for our customer. Process Control Development3.1 Trace-abilityThe forensic credibility of our approach was keyed by the development of an “audit-able”  footprint we used to trace entities through the simulation.  We created a unique identifier or ID tag for each entity in the simulation that was a type of “bumper-number” for the system.  An example is shown in Figure 3-1.Figure 3-1 Bumper NumberIn military units, each major piece of equipment is labeled on the “bumper” for easy identification of unit and organization. This tag was familiar to the soldier participants and provided discrimination down to the individual vehicle.  The bumper-number provided a kind of finger-print for each simulation message that was unique.  This allowed the team to rigorously sort the data and examine each vehicles activities in spite of simulation crashes, re-instantiations and other perturbations of the simulation process. As shown in figure 3-2, the bumper-number mnemonic attached to each system allowed the aggregation and de-aggregation of data for the analysis.  This allowed the team to drill down into the data to discover anomalies. Using Trace-ability in Analysis The atomic level element for the chart in Figure 3-2  was the squad (defined by battalion, than company, platoon and squad).  A11 in this example stands for A Company, 1st  Platoon, 1st Squad.  The horizontal lines are enumerated in multiples of “loads” (the maximum number of rounds available after a complete reload). We can clearly see the shots taken by each squad, each company and each battalion.  We can also compare companies and then compare battalions (2-502 and 3-502 were the names of the battalions).  Figure 3-2 Aggregation of EffectsOne of the artifacts of the exercise was the existence of invulnerable targets.  The virtual database was larger than the live database - therefore we put virtual targets in the force that would hand off to (or become) live targets at the edge of the live battle space.  The plan was for the virtual targets to stop and the live targets to prosecute the battle.  To ensure that live target were able to play, the virtual target was made invulnerable.  The anomaly occurred when the virtual target missed the hand-off and proceeded into the close battle in the invulnerable state.  The yellow here shows precisely which players were affected by the invulnerable targets.Using the audit trail, the team was able to process collected data by time, type, unit, with visibility into unit/battle dynamics.  Time history charts provided a feel for the flow of the battle.  The data plots highlighted what was interesting to include     -Units acting inappropriately as a whole   -Platforms acting inappropriately in an individual     instance    -Artifacts of the battleIn Figure 3-3  is a time history plot of missile shots at range versus time.  Using the time history we can see the initial contact, then a good while later we see the main battle.  The colored lines differentiate between platoons.  The invulnerable target engagements are shown in yellow.Figure 3-3  Time HistoryBased on the data and the battery of “forensic tests”, we conducted the analysis which provided authoritative, defendable results to the customer. The data extraction and analysis featured  a clear audit trail from actor to action to response.  This gave us the “evidence” we needed to draw credible conclusions. Implementation of  Process ControlIn order to examine HLA integration and process control issues, we formed an operational testbed (OTB) with two separate networks within CSC’s  Simulation Center of Excellence.  COTS products were used where possible and to keep costs down we focused on Windows NT platforms.   The primary connectivity between  the two nodes was ATM (edge technology provided by Sonoma). Specific sensors, weapons, and environments were identified and analyzed. Interface data were compiled and specifications were developed. Integration and testing were iteratively performed over a 3 month period of time.  Because of time constraints, products that did not support RTI 1.3v6 were not included.  Figure 4-1 shows the federation. 4.1 Federation DescriptionThe “Wolf” Federation was derived from the RPR FOM and was used to examine process control and latency issues related to distributed training for the U.S. Air Force.  A diagram of the federation is shown in Figure 4-1.4.1 Federates DescriptionThe aircraft were HLA “LiteFlite” simulators that had been fitted in cockpits modified to interface with a missile server.  The AWACS was a FLAMES based emulator that provided a radar screen for tactical direction and control with the fighters.  A FLAMES based CGF provided red forces and yet another FLAMES based application provided a missile server.  SMOC was used to allow us to interface with a legacy stealth system (DIS) and to create a database for our forensic analysis.  The control center was the focus of the project.  The question was, how to ensure in real time that the federation processes were “in control” – and to do it with as few people as possible (goal of 2).  A layout of the control station is shown in figure 4-2.  Figure 4-2 Operations CenterComputer Associates Net Center was used to monitor the SNMP traffic and measure the workload and the traffic over the ATM switches.  A 3D stealth was used to provide a means for selectively viewing activity in 3D within the federation. This assured us that the entity of interest was behaving in a realistic way.  A planview on the control center provided tactical awareness to the control team. HLAControls/HLAResults was used to monitor connectivity and  check for FOM compliance. The final tool was HLA Prospector, a real-time intelligent application that incorporates much of the forensic analysis methodology but moves it to real-time and makes it interactive.  Control IssuesNow that you know the players, it would be appropriate to describe the control issues we were trying to manage.	Bandwidth usage.  Bandwidth today is not yet ubiquitous and is certainly not free.  In highly complex distributed simulations the monitoring and control of bandwidth usage is vital.  We found that it is not enough to know the total bandwidth being used by the federation but we needed to know which federates were  using it.  A key measure of bandwidth usage we used for individual entities was update rate measured in hertz.  As a design consideration we wanted our systems to maintain an update rate of  2hz to reduce the total bandwidth requirement and at the same time reduce the load on the RTI.  Requirements for higher rates (e.g. between missiles and their targets were handled with a missile server (not HLA)).Latency.  We found that even with ATM technology the latency for cost to coast can be between 45 and 80 ms depending on the number of hops.  Latency must be managed, therefore it must be measured.  When we measured latency through the RTI we found a range of latency (given the above update rate) of between 20 and 23 ms.  When the update rate was raised to 30 hz the latency associated with the RTI increased to almost 1 second.  Through the ATM switch the added latency is in the nano seconds.  Over the ATM cloud the latency is directly related to the type of service, the number of switches involved and the distance traveled.  Lost Packets.  When we examined the ATM technologies available we found that packets are not delayed when your level of service is exceeded.  The switch manages your input to the cloud and packets that cannot be input into the stream are dropped.  Therefore if you monitor the lost packets at the switch and see there are no packets dropped, you can be relatively certain you did not exceed your planned/budgeted bandwidth.	Connectivity. We knew that connectivity between federates was key to successful operations.   We found that monitoring connectivity  as the federation was in progress was vital.  Process control in complex federations requires a use rule-based reasoning and proactive network probes to rapidly isolate faults within IP networks, determine the root cause of reachability problems, filter out sympathy event messages, predict related reachability problems, and advise operators accordingly. Level Playing field.  Successful interoperable federation implementation involves the close interaction of three tightly interrelated program components(standards, communications, and processes. Standards provide the commonalties to ensure that all participating federates are engaging on a level playing field. The networks provide the communications necessary to support federate interactivity. Processes provide the methodologies needed to design, develop, and maintain the interoperable federations that have: (1) The ability to provide and accept services to and from other federates and use those services to enable effective inter- and intrateam operations, and (2) the ability to interact in a “fair fight,” while achieving sufficient spatial, temporal, and behavioral correlation among synthetic environments and forces to allow each federate to meet its objectives.	Man in the loop.  To assure a process that is in control, man-in-the-loop activities must be monitored and controlled.  Since much of the man-in-the-loop processing happens off-line (i.e. in the players head) the process must be monitored for events that are clearly passed in a federation message (e.g. Weapon fire).  These must be collated and reasoned over to analyze for anomalies.  This requires a real-time intelligent system.5 ImplementationMany of the capabilities in the operations center are well known and/or documented well elsewhere.  This section will discuss the real-time intelligent system developed as part of the operations center capability.HLA Prospector is a G2 based real-time intelligent application that expresses objects, rules, methods and processes using a structured natural language so that models can be readily understood, tested and modified by process control team .  HLA Prospector allowed the control team to apply knowledge dynamically to their federation execution in order to reach conclusions, provide advice, and take action in real time.  The team could follow multiple lines of reasoning and analyze large amounts of data and many trends concurrently.  HLA Prospector’s Object-oriented design offered highly reusable code.  This allowed us to rapidly prototype and iteratively develop the system.  The objects in HLA Prospector combined both data and structure of the entities within the federation and for the RPR-FOM assumed the attributes of the entities involved.  Figure 5-1 shows an attribute table for an aircraft.Figure 5-1 Sample Attribute TableUsing inheritance, we were able to map object definitions inside the code.  Figure 5-2 InheritanceHLA Prospector was used to collect data and maintain up-to-date knowledge about the state of each entity.  Using rules, the application reasoned over the data to determine if an anomaly existed. . Using a real-time reference engine, the system was able to provide exception reports much like the forensic analysis but in real time.The entire data stream was passed into HLA Prospector and key rules were invoked to assess the information.  Data that was not relevant was discarded.  However, because the entire data stream was processed, the team was able to create a new rule or change an existing rule in real time (no compile required) to “drill down” into the data stream if a new anomaly was suspected.  Figure 5-3 shows an example rule and demonstrates the natural language syntax.Figure 5-3 Example RuleBy intelligently monitoring for anomalies, the control team was able to execute a complex federation that was “in control”.  Some anomalies targeted by the control team  included:Federate putting out irrelevant data.  Federate not filling out HLA message traffic     or using the RTI services IAW the ICD. Simulated entity committing a tactical   anomaly ( firing more munitions than basic    load, exceeding max speed, etc.). Federate not  reachableWe were able to plot data in real time to determine key measures like actual latency, dropped packets at the switch, or update rate in hz.  Figure 5-4 shows a plot of the update rate over time of an F-16 federate.Update Rate in Hz of an F-16 FederateUsing COTS tools, the data mining system of the forensic analysis process, and HLA Prospector , we were able to rapidly develop a monitoring capability within a RPR FOM based HLA implementation that measured the impact of humans on simulation experiments.  Prospector shifted a significant amount of the post-process forensic capability to a real-time analytical and control capability.6.Benefits of Real-time Process Control6.1 Improved CapabilityThe real time intelligent systems improves the ability of humans to handle information.  We were able to convert volumes of data (at the atomic level) into knowledge at the human operator level.  Because we were able to examine trends and see the whole process, we were able infer unmeasurable information.  We were also able to reconcile conflicting data using reasoning engines which allowed us to detect and diagnose problems before they affected operations.6.2 FlexibilityThe HLA Prospector proved to be very flexible.  The natural language syntax and graphic design allowed  rapid  prototyping allows the team to iterate with federate constituents early.  It allowed a rapid response to changes (rules  “on the fly”).6.3 Continuous ImprovementForensic analysis and process control provides value to the distributed simulation practitioner.  -   The practitioner gets better data - if the data is credible, the simulation can  become a suitable alternative to a more expensive live test.-   The practitioner gets a better distributed simulation product.  Leveraging knowledge acquisition capabilities of an intelligent system provides a path for continuous improvement. -   Overall risk is mitigated.  The practitioner has a means to assure the desired results will be achieved.7. Summary (So where do we go from here?)In defense applications, the customer is relying more and more on simulation to reduce cost, flesh out concepts early and reduce total cycle time. The increasing reliance on simulation demands that simulations be realistic, credible, and in control.Distributed simulation is moving from DIS Protocol Data Units (PDU’s) to High Level Architecture (HLA) and into commercial practice.  The architecture is open, standards are agreed upon by constituents, but plug and play is still far from reality.Forensic analysis of the simulation can provide a key role in giving evidence for the credibility of the simulation.  Real time monitoring and control will provide the critical measure of the man-in-the-loop dimension.BiographyMONTE PORTER is a Senior Computer Scientist and was the team lead for development of the real-time intelligent monitoring capability at CSC’s Simulation Center of Excellence.MICHELLE HERMAN Senior Engineer and was the lead systems developer for the OTB at CSC’s Simulation Center of Excellence.HIROME FUJIO is a Senior Operations Research Analyst and was the analytical lead for the forensic analysis and the operations center at CSC’s Simulation Center of Excellence.9.  References [1]	Porter, Herman, Fujio: “Forensic Analysis and Process Control in Distributed Simulation”  99F-SIW-026.  