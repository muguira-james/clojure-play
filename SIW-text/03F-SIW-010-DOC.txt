Further Studies On The Feasibility Of A Distributed ISS and HTV SimulationGrace D. LauderdaleDanielle V. SnyderUnited Space Alliance, LLC600 Gemini, M/C USH-483RHouston, TX 77058grace.d.lauderdale1@jsc.nasa.gov, danielle.v.snyder1@jsc.nasa.govEdwin Z. Crues, Ph.DDavid A. HasanTitan CorporationAstronautics Engineering Unit1020 Bay Area Boulevard, Suite #200Houston, Texas 77058, U.S.A.ezcrues@titan.com, david.hasan@titan.comKeywords:International Space Station, Visiting Vehicles, High Level Architecture, Run-Time InfrastructureABSTRACT: The United States National Aeronautics and Space Administration (NASA) and Japanese National Space Development Agency (NASDA) are currently investigating the feasibility of a distributed training simulation for Japanese H-II Transfer Vehicle (HTV) operations in the vicinity of the ISS.  This paper presents the findings of a study using the Defense Modeling and Simulation Office’s High Level Architecture (HLA) and NASA’s Trick Simulation Toolkit to implement such a simulation.  After introducing the motivation and background for the project, we discuss performance benchmarks and simple distributed simulations we ran using four different implementations of the HLA technology.  We further continued the study by turning the simple distributed simulation into a Federation development exercise between NASA and NASDA.  These technologies look very promising and will be incorporated in the subsequent phases of the ISS/HTV simulation development and most likely in other similar simulation projects.IntroductionISS and the Challenge of Visiting VehiclesThe International Space Station (ISS) is a complex multi-national orbiting laboratory.  The program will include operational support provided by visiting vehicles from several countries, for example, the Japanese National Space Development Agency (NASDA) H-II Transfer Vehicle (HTV).  The HTV will be launched from Japan, rendezvous with the ISS, be grappled by the Canadian Space Agency’s (CSA) robotic arm and berthed to the ISS.The operation of visiting vehicles like HTV in the proximity of the ISS is a complex and dangerous proposition.  Consequently, these vehicles and their missions are simulated in great detail to maximize the probability of mission success and minimize the risks to the ISS and its crew.While the ISS international partnerships bolster its use and value, they also provide additional political, cultural, organizational and technical challenges.  During integrated simulation of visiting vehicles to the ISS, these challenges include Ensuring compatible model fidelity,Protecting proprietary technology and data,Taking into account the cultural and organizational differences of the different operations teams,Sharing the burden of the simulation development costs among the participants.One approach to addressing these issues is to use distributed simulation.  Distributed simulation facilitates the development of high fidelity models by diverse groups, provides a mechanism for protecting proprietary technology/data, provides a mechanism for different teams to participate in the simulation simultaneously and allows development costs to be spread across a broader base while reducing duplication of effort.High Level ArchitectureThe Automated Vehicles and Orbit Analysis group at the National Aeronautical and Space Administration (NASA) Johnson Space Center (JSC) is investigating distributed simulation technologies applied to rendezvous and docking simulations of ISS visiting vehicles. We are currently focusing on a distributed simulation technology called the High Level Architecture (HLA).  HLA is a standardized architecture and set of processes for creating cooperative collections of distributed simulations [1, 2, 3, 4].  These include processes for planning, design and implementation.  It also provides a standardized API and collection of software libraries and tools for implementing HLA based distributed simulations.  A group of simulations that can participate cooperatively in a distributed simulation form a federation.  Each individual simulation participating in a federation is referred to as a federate.  Interaction between cooperating federates is supported by a collection of generalized services: Declaration Management, Object Management, Time Management, Ownership Management, and Data Distribution Management.  These services are provided through a rich, but somewhat complex, set of APIs.A Study of HLA-Based Distributed SimulationsIn cooperation with NASDA, we are investigating the feasibility of a distributed ISS/HTV simulation.  The HTV component is hosted in Japan and the ISS component in the United States.  The underlying infrastructure is based on HLA.  Our objectives are togain an understanding of HLA and its associated application program interfaces (APIs), evaluate HLA runtime infrastructure (RTI) performance,investigate HLA system interoperability, understand any related networking issues and assess the implications of distributed simulation on simulation design.We used DMSO benchmark applications to measure the performance of four different RTIs: DMSO, Mäk, Mitsubishi, and Pitch.  This paper presents the results of these benchmark tests. To explore network issues associated with HLA-based simulations, we looked at three network configurations for the tests: open Internet, Integrated Services Digital Network (ISDN), and a Virtual Private Network (VPN).  We used an open Internet configuration to test RTI performance over a large distance (Houston, Texas to Kamakura, Japan), an ISDN configuration to gather RTI performance over a dedicated but long-haul, low bandwidth connection (Houston to Kamakura) and a VPN configuration to investigate the effect of a VPN on system performance and to test connectivity and security of the RTIs communicating between two private networks separated by firewalls over an encrypted connection.  In addition to RTI performance, we studied issues of HLA-based simulation design and operation.  We paid particular attention to time synchronization, data transmission delays, repeatability and issues related to ownership transfer by simulating a simple dynamic system. As with the benchmark tests, these tests were run for each RTI vendor. This paper presents the results from these tests along with a summary of observations and conclusions on distributed simulation design issues associated with HLA.Why Distributed Simulations?The complexity of the operations involved with the HTV approach to the ISS (in particular, the distributed nature of the flight control teams) suggests that the usual, centralized approach to simulation might not be ideal. On the surface, it seems reasonable that the underlying simulation infrastructure for an inherently distributed operations environment should also be distributed.  In this section, we present specific reasons why that is so.There are four components of the HTV operation that require coordination.  The first being the crew onboard the ISS. The crew will have the responsibility of visually monitoring the HTV through cameras mounted on the ISS, and through windows on a cupola, when available.  However, their biggest responsibility is to grapple the HTV with the ISS robotic arm. They will also have the ability to perform some contingency operations.  The second element is the HTV.  The HTV will be automated to execute HTV flight plans and contingency operations based on predefined fault conditions.  The third element is the HTV-CC, which is the NASDA ground control facility in Tsukuba, Japan.  The HTV-CC is responsible for all HTV operations.  All commands from the ground to the HTV will be sent by the HTV-CC.  The fourth element of the operations involves the MCC-H, which is NASA’s ground control facility in Houston, Texas.  The MCC-H is responsible for the overall operation beginning at a pre-determined point in the operation.Two requirements have been identified to address the complexity of integrated ISS/HTV operations.  They are (1) procedures development and verification and (2) joint training for NASA and NASDA flight controllers, and ISS crew members.ProceduresAlong with normal procedures, contingency procedures must also be developed and verified.  For vehicles docking to the Station, flight software model accuracy is essential.TrainingJoint training for the two flight control teams and crew is crucial for mission success. The teams must consistently train together to develop a common operations language.  Another training issue is NASDA’s relative lack of rendezvous experience.  Much simulation time will be needed to resolve the details of team coordination during rendezvous.TrickThe Trick Simulation Development Toolkit (Trick) is a suite of simulation tools used at the NASA Johnson Space Center (JSC) for the development of a wide variety of space-based simulations. Trick originated in the early 1990's in the Automation, Robotics and Simulation Division of the Engineering Directorate at JSC.Although many Trick-based simulations developed at JSC are space system applications, Trick itself is domain independent. Its goal is to provide a development environment that provides simulation support throughout the engineering life cycle: analysis, system development, operations planning, training, system integration, system testing, flight and maintenance. Trick provides a general-purpose runtime executive and a suite of support utilities [5, 6].    As a result, it has found use in a wide variety of space-based simulation domains at JSC: robotics, guidance, navigation, control, operations analysis, operations planning, Human-In-The-Loop training, hardware integration and systems testing.ObjectivesRTI EvaluationOne component of the Feasibility Study is to evaluate RTI performance (or select an RTI based on performance).  NASA and NASDA have agreed on a set of criteria with which to assess the RTIs.  These criteria include scalability and performance (latency, time management and ownership transfer), and repeatability.  A suite of software developed by DMSO was selected to test the performance and scalability of the various RTIs.Simulation Design IssuesAnother part of the Feasibility Study is to identify potential simulation design issues.  During the study, a couple of areas of concern warranted further investigation: repeatability and ownership transfer.  A Trick-based simulation has been written to test these concerns.  In an additional test, NASDA had developed an independent federate using the same object model as with the previously mentioned Trick-based simulation.Performance Benchmarks DMSO Benchmark Tests To better understand the performance of the runtime infrastructure for the four HLA vendors, a suite of three performance benchmarks that were part of the DMSO distribution were run.  The benchmarks measurenetwork latency,ownership transfer performance, andtime advance performance.We gathered statistics for all four HLA systems running in three network configurations, (a) the Internet, (b) a dedicated ISDN line, and (c) a VPN. Detailed benchmark statistics were gathered from the Internet and ISDN configurations. The VPN configuration provided a test bed for security and firewall investigation and provided us a better understanding of problems and performance issues associated with designing a federation that will run between two private networks separated by a firewall.Test ConfigurationsThe following tables show the network configurations and the specifications of the workstation used in these tests. TestConnection TypeBandwidthVPNSSH/PPP VPN across JSC internal network10 Mbps symmetricInternetADSL 1.5 Mbps uplink; 6 or 8 Mbps downlinkISDNSingle Line ISDN64 Kbps asymmetricNetwork ConfigurationsWorkstationLocationCPURAMOSEwokHouston750 MHz256 MBRed Hat Linux 7.2WookieHouston750 MHz256 MBRed Hat Linux 7.2GraspingHouston2.2 GHz256 MBRed Hat Linux 7.2 hla1Houston2.2 GHz256 MBRed Hat Linux 7.2GalexandHouston900 MHz256 MBRed Hat Linux 7.2MelcoKamakura930 MHz256 MBRed Hat Linux 7.3Workstation ConfigurationsThe Internet results are based on a single execution of the benchmark applications run over one day. The latency and ownership transfer tests each consist of four executions with gradually increasing attribute size. The time advance tests consist of one trial with only one reflecting federate.  No attempts were made to account for Internet traffic variability. These tests had the HLA RTI and the initiating federate running in Houston, Texas and the reflecting federate running in Kamakura, Japan. The following figure shows the configuration and participants in the Internet testing.  EMBED Word.Picture.8   Figure  SEQ Figure \* ARABIC 1: Internet Test ConfigurationWe collected data for two similar ISDN configurations: (1) with the initiating federate running in Houston, Texas and the reflecting federate running in Kamakura, Japan, and (2) with the initiating federate running in Kamakura and the reflecting federate running in Houston.  In both configurations, the RTIs were executed on the Houston workstation at a statically specified port, and the workstations were completely isolated from any external networks except for the ISDN line. The results presented below correspond to the first configuration.  The results from the second configuration were similar. The following figure shows the configuration used for the ISDN tests.  EMBED Word.Picture.8  Figure  SEQ Figure \* ARABIC 2: ISDN Test ConfigurationEach ISDN based test was repeated three times during the day with each RTI tested on subsequent days.  The latency and ownership transfer test series each consist of four tests with the attribute data size increasing with each test. The time advance test series consists of between three and eight trials with the number of reflecting federates increasing with each test.This VPN testing took place across the JSC internal network, with an SSH/PPP VPN set up linking hla1 and wookie, and with grasping and ewok configured as firewalls. The evaluation RTIs ran on either hla1 or ewok on a statically specified port. The following figure shows the VPN configuration. EMBED Word.Picture.8   Figure  SEQ Figure \* ARABIC 3: VPN Test ConfigurationLatency BenchmarksLatency is a measure of how long it takes data to arrive at its destination. The Latency benchmark measures the time it takes to transmit HLA attribute updates.  The application allows the attribute size (in bytes) to be explicitly specified. For a real-time simulation, the latency must be less than 1,000 ms to maintain simulation fidelity. Ideally, latency below 500 ms will provide margin and flexibility in the simulation design.  These thresholds are indicated on the plots of the results shown below.  In these tests, latency measurements from 100 cycles were used to calculate an average.Latency Results (Internet) Figure  SEQ Figure \* ARABIC 4: Internet LatencyThe four RTIs meet the preferred latency of 500 ms for all data sizes except the largest.  The largest 10,000-byte data size meets the minimum acceptable 1,000 ms requirement for all RTIs except RTI B. Although RTI B performs well for the smaller data sizes, its performance decreases substantially for the largest size. One note of caution: bandwidth variations due to Internet traffic have not been factored out of these results.Latency Results (ISDN)Figure  SEQ Figure \* ARABIC 5: ISDN LatencyThe four RTIs meet the ideal latency of 500 ms for all but the largest data size.  For each data size, the RTI C has the best performance. Although the RTI B performs well for the smaller data sizes, the performance decreases substantially for the larger sizes. This indicates that RTI B does not handle breaking up the data to fit through the available bandwidth well or that it has a large overheadOwnership Transfer BenchmarksIn order to coordinate updates to remotely distributed data, HLA associates a single owner with each attribute.  Only the owner of an attribute may generate new values for it.  However, ownership of a particular attribute may be transferred between members of an HLA federation.  The Ownership Transfer benchmark measures ownership transfer rates. Specifically, the initiating federate registers an object and pushes ownership of one of its attributes to the reflecting federate. The initiating federate then pulls ownership of the attribute back. This is performed several times in order to calculate ownership transfer statistics.  The application allows the size (in bytes) of the attribute as well as the number of ownership push/pull operations to be explicitly specified.For each data size, the average transfer rate for 500 transfers determined the average rate. An ownership transfer must take no longer than 1000 ms to maintain simulation fidelity. Ideally, the ability to perform two ownership transfers in one second will provide margin and flexibility in the simulation design. These thresholds are indicated on the following plots.Ownership Transfer Results (Internet) Figure  SEQ Figure \* ARABIC 6: Internet Ownership Transfer ResultsAll the RTIs fail to meet the preferred rate of two transfers per second. Only RTI D fails to meet the one transfer per second threshold. For each size, RTI B is the best performer with transfers just under two per second. RTI A and RTI C fall within the marginal range where as RTI D is within the unacceptable range. The performance of each RTI fluctuates for each data size, which indicates the performance is influenced by network variability.Ownership Transfer Results (ISDN)Figure  SEQ Figure \* ARABIC 7: ISDN Ownership Transfer ResultsNone of the candidate RTIs meets the preferred transfer rate of two transfers per second. For all sizes, RTI C is the best performer. RTIs A and B fall within the marginal range, and RTI D does not. The performance of each RTI is consistent with data size. These results suggest that ownership transfer rates are indeed a function of the RTIs, and not the underlying network bandwidth. RTI B’s performance, as with the Latency results, tails off with the larger data size. Again, this may indicate that RTI B does not handle breaking up the data to fit through the available bandwidth well or has a large overhead.Compared to the Internet test results, the data is more consistent and the order of performance for the RTIs is different. However, the range of performance is similar, from about 0.5 to 2.0 transfers per second.Time Advance BenchmarksOne of the fundamental challenges in distributed programming is defining a meaningful and consistent notion of time [7]. How this problem is solved by HLA is beyond the scope of this paper. Briefly, a consistent view of time is maintained across the HLA federation by requiring that each federate explicitly request that its (local) time be advanced by the runtime infrastructure.  The Time Advance benchmark measures the rate at which the system can grant such requests. A specified number of time advances are requested each cycle. This process is repeated for a specified number of cycles to determine the amount of time advance grants per second that can be performed. For this test, 100 time advance requests per cycle were performed to determine an average and then this value was averaged over 10 cycles. One time advance grant per second is mandatory to maintain a real-time simulation, however, two grants per second will allow margin and is preferred. These thresholds are indicated on the plots below.The test starts out with the initiating federate and one reflecting federate. With each subsequent test, an additional reflecting federate is added. Licensing constraints limited the number of total federates to four for RTI B and C where a maximum of nine federates were used for RTI A and D. The proposed HTV/ISS simulation design has three federates, thus our discussion of the results focuses on the performance of federations with up to three federates.Time Advance Results (Internet)The Internet time advance results are shown in the following plot. Each RTI meets the minimum requirement of one advance per second, where as only RTI D failed to meet the preferred two time-advances per second.Figure  SEQ Figure \* ARABIC 8: Internet Time Advance ResultsRTI B’s performance exceeded that of the other RTIs for the single case that we ran. RTI A and RTI C are also well above the ideal two-time advances per second threshold. Time Advance Results (ISDN)The ISDN time advance results are shown in the following plot. Each RTI met the minimum requirement of one advance per second for three federates.Figure  SEQ Figure \* ARABIC 9: ISDN Time Advance ResultsOnly RTI D failed to meet the ideal two time-advances per second. RTI C out-performed the others for each case with up to four federates. RTI A and RTI B were also above the ideal two time advances per second threshold. Although RTI D had the most consistent performance, with almost no degradation for up to nine federates, it did not meet the ideal two time advances per second time advance rate. It appears that for a large number of federates RTI D would likely be the best performer.Compared to the Internet test with two federates, RTI B and RTI C performance is reversed.  The results for the ISDN testing are not as good as Internet test results. The time advance performance for configuration two, with the initiating federate running in Kamakura and the reflecting federate running in Houston, exceeded the results discussed above.  In this configuration, only the time advance request from the initiating federate has to travel a long distance as opposed to the requests from all of the reflecting federates. This shows that choosing where the RTI runs is an important decision in designing a distributed simulationVPN TestingThere were no significant performance differences between the four tested RTIs.  Thus, our performance studies were inconclusive. We did, however, reach some connectivity conclusions.The RTIs were able to tunnel through the VPN by specifying a port in the firewall. By default, multicast packets are not transmitted across routers, firewalls, and VPNs so for the multicast-capable RTIs, this feature was not usable. Most RTIs dynamically open ports and not all of the ports are known before runtime. In some situations where strict port filtering is required for security reasons, this might be a problem.Preliminary Dynamic SimulationsAlthough the benchmarks characterize RTI performance, they provide little insight into the effects of HLA on the design and execution of time-dependent simulations (dynamic systems).  Accordingly, we built a simple dynamic simulation using the same four RTI vendors discussed above.  This is discussed below.Dynamic Simulation BackgroundDesignThe objectives of this dynamic simulation were to gain experience with the HLA APIs, to begin integrating the APIs into Trick, and to investigate time effects associated with using HLA.Our long-term objective is to build a distributed simulation of the HTV and ISS spacecraft.  However, for this study we decided that the complexity inherent in spacecraft states could obscure otherwise straightforward time effects introduced by the HLA infrastructure.  Therefore, we decided to implement a distributed simulation of two pseudo-vehicles – objects whose time variation consists of simple analytical functions instead of orbit and attitude dynamics.  We still used the “HTV” and “ISS” terminology for the pseudo-vehicles; however, their dynamics were defined by the following sinusoidal functions.xISS(t) = AISS * sin(wISS*t + pISS)xHTV(t) = AHTV * sin(wHTV*t + pHTV)This approach simplified both the implementation of the software and analysis of the results.  In particular, the availability of an analytical truth model allowed us to easily identify time lags introduced by the distributed infrastructure.ConfigurationThe test involved the same network configuration as the ISDN tests described above and an HLA federation consisting of two federates: one running in Japan that was nominally the owner of the HTV pseudo-vehicle and another federate running in Houston that was the permanent owner of the ISS pseudo-vehicle.  Both federates were based on Trick. In the final simulation, it is likely that only the NASA federate will be Trick-based. As with the benchmark tests, we ran our dynamic simulations using four RTI implementations.The dynamic simulation test configuration is shown in the following figure.Figure  SEQ Figure \* ARABIC 10: Dynamic Simulation ConfigurationWith this configuration, we studied three different scenarios:simple simulationstime-managed simulationstime-managed simulations with ownership transferThe first scenario involved a simulation in which the Japanese and US federates were completely unsynchronized and the HLA infrastructure was used only to distribute data (i.e., no time advance coordination). This scenario was included in the test mainly as an incremental step in our development of the software.  The second scenario included time synchronization between the federates.   For distributed spacecraft simulations time synchronization will almost certainly be necessary. This scenario allowed us to study the effect of using the HLA time advance grant mechanism to synchronize time between the two remote federates.  Finally, the third scenario involved the transfer of ownership between the two federates.  We expect that this capability will be necessary during grapple and berthing when the sensitivity of the dynamics will rule out remote vehicle ownership due to the time lags.To study these scenarios, we ran simulations using each of the four RTIs.  In addition, for each RTI/scenario combination, we run simulations of varying duration (short, medium, and long). The following sections present our observations of these runs.Dynamic Simulation ResultsSimple, Unsynchronized Simulation ResultsThe following illustrates a typical plot of the results from the unsynchronized simulations.The main features of these results are as follows.Remotely generated data usually lag their true values (calculated using the analytical formula) by one data cycle.  For our pseudo-vehicle models, this lag showed up clearly as a phase shift in the sine waves.The lack of time synchronization leads to random variation of the observed time lag (phase shift).  We saw the value vary from 0-2 data cycles.Although we expected to see time lags due to the long term drift of the workstation clocks relative to each other, we saw no such effect.Figure  SEQ Figure \* ARABIC 11: Simple, Unsynchronized Simulation ResultsHowever, we did encounter enough “anomalies” in our results and variations due to RTI implementation that we intend to rerun the tests at some future date to make sure we fully understand the nature of unsynchronized simulations using HLA.  For the time being, given that we are fairly sure any HTV/ISS simulation will require HLA time synchronization; we postponed further investigation of these inconsistencies.Time-Managed Simulation ResultsThe following plot illustrates typical results of the time-managed simulations.The main features of these results are as follows.Remotely generated data always lag their true values by 1 data cycle.The random variation in this time lag that we observed in the unsynchronized scenarios is eliminated by the HLA time advance grant mechanism.  (The observed time lag is consistently 1 data cycle with no variation.)All four RTIs performed identically.Figure  SEQ Figure \* ARABIC 12: Time-Managed Simulation ResultsOwnership Transfer Simulation ResultsThe scenarios built into the simulation involved the transfer of HTV pseudo-vehicle ownership from the Japanese federate to the US federate and back twice during the run. The following two figures illustrate the effect of these transfers.The main features of these results are as follows.Giving up ownership of an attribute introduces an additional 2 data cycle time lag.  This lag is additive.As ownership is repeatedly transferred back and forth, the time lag increases by 2 data cycles each time a federate releases ownership of the attribute.All RTIs performed identically in this regard.This time lag due to ownership transfer is an important aspect of distributed simulation. In the implementations used in this study, no effort was made to compensate for this effect. Without any mechanism to compensate for this additive lag, ownership transfer would clearly have to be minimized.Figure  SEQ Figure \* ARABIC 13: Ownership Transfer Simulation Results (Japanese Federate)Figure  SEQ Figure \* ARABIC 14: Ownership Transfer Simulation Results      (US Federate)Independently Developed FederatesBackgroundWhen development of the ISS/HTV Federation begins, each space agency will independently develop federates representing their vehicle.  For this reason, we took the study a step further, by having NASDA develop the “HTV” part of the Dynamic Simulation.  The design mentioned earlier in this section was used for the development of this Federation.  However, only Time-Managed and Ownership Transfer tests were run.  The objectives of these tests were simple:To have the two federates connect,To have both vehicles propagate forward in time, andTo observe time effects during Ownership Transfers.The success criteria were also simple.  The results of these tests were to be compared to the results from the previous Dynamic Simulation tests.ConfigurationThe purpose of these tests was intended to provide a quick evaluation of independently developed federates.  For this reason and because of resource constraints, these tests ran over the Internet.  NASA used the previously described Trick-based ISS federate and ran it in Houston.  Using different development tools, NASDA developed a federate to represent the HTV, and ran it in Kamakura, Japan.  Since RTI evaluation was not an objective of this test, only the DMSO RTI was used.ResultsIn general, the tests ran successfully.  However, our assumptions in the timing scheme provided interesting results.   First, the Locally Simulated state was identical to the Remotely Received state.  In these tests, there were no time lags between the local and remote states.  The reason for this result is that NASDA was sending the state propagated one data cycle ahead. This timing scheme removed time lags normally introduced by transmission latency.  The output from the ISS federate in Figure 15 illustrates this result.  Figure 15: Ownership Transfer Simulation Results      (US Federate)The following plot is the output from the HTV federate.  By tying federation time to simulation time, NASA was not propagating the state a data cycle ahead.  These results show the phase shift in the Remote state due to transmission latency.Figure 16: Ownership Transfer Simulation Results      (Japanese Federate)Another interesting result due to the different timing schemes was seen during each Ownership Transfer.  Since the HTV federate was propagating the state one data cycle ahead, when the HTV state was transferred to the ISS federate, time of the state update jumped back one data cycle.  This result is illustrated in the following plot at 120 seconds, which compares the HTV and ISS time.Figure 17: Ownership Transfer Time Shifts         (Japanese Federate)After this observation, NASA proposed two approaches to compensate for the data lag.  One method would be to tie simulation time to real-time, but offset the federation time one data cycle in the past.  The second method would be to propagate the Remotely Received state by one data cycle to account for network latency.  Each of these approaches will be investigated in subsequent tests.ConclusionsThis paper presents a brief overview of the concepts, designs, work and results of the first phase of a study to assess the feasibility of creating a distributed simulation of the HTV and ISS.  Each phase of the investigation was designed as much to expand the knowledge base of the investigating team as it was to demonstrate the capabilities of the technologies.  While both the HLA and Trick technologies have been proven individually in their respective specialized areas, to our knowledge, they have not been utilized in this way.The benchmark tests demonstrate the base capabilities of the HLA infrastructure.  These test applications in conjunction with the various network configurations used in these investigations provided valuable insights into the HLA technology in general and performance metrics on specific vendor’s RTIs.  These results have been extremely useful in understanding simulation data limitation and will directly influence simulation architecture.  These results will also be useful in RTI selection.The dynamics simulation tests demonstrate key issues and behaviors associated with the real-time simulation of dynamical systems using HLA and Trick.  The test results are important in that they identify the need for time synchronized simulations and identify a fundamental time frame loss behavior of ownership transfer in time synchronized real-time dynamic simulations.  Each of these observations have important implications on simulation design and implementation.The independently developed federates demonstrate a joint understanding of Federation development.   They also provided an opportunity to identify potential problems in our federation design, specifically, differences in our concepts for simulations vs. federation time. Most importantly, these tests helped identify approaches to address the data lags introduced during the Ownership Transfers.While there is still a great deal of work left to do, initial results from this study indicate that distributed simulation technologies in general, and HLA and Trick specifically, have matured to the extent necessary to fulfill the requirements for a high fidelity coordinated simulation of two complex space vehicles.  Ironically, the two spacecraft, when in actual flight, will be closer to one another during their nominal rendezvous operations than their representative simulation federates during simulated operations.The next steps in the development of the distributed HTV and ISS simulation are to systematically expand both the knowledgebase of the team and the capabilities and fidelities of the constituent simulation components.  One of the next steps will be to replace the simple dynamics model for a more complex orbital dynamics model.  Another important step will be the identification of important simulation data to be exchanged between federates and the development of the Federation Object Model (FOM).  Other steps include the investigation of compensation mechanisms for the state lag and the frame losses induced by ownership transfer.AcknowledgementsThe authors would like to thank a number of people and organizations that made this work possible.  First, we would like to thank NASA for funding this work and creating such an interesting problem to solve.  Next, we would like to thank our colleagues at NASDA and Mitsubishi for work helping to setup and run many of the tests.  We would also like to thank Mitsubishi Corporation, Mäk Corporation and Pitch Corporation for providing evaluation copies of their RTIs.  We would also like to thank DMSO for their support in providing their RTI, HLA training and consulting.  Finally, we pay special thanks to Reed Little for his ability to explain HLA concepts, provide novel ways of looking at problems and his patience in countless meetings.References[1]	Defense Modeling and Simulation Office, “High-Level Architecture Rules Version 1.3”, U.S. Department of Defense, 20 April 1998.[2]	Defense Modeling and Simulation Office, “High-Level Architecture Object Model Template Specification Version 1.3”, U.S. Department of Defense, 27 July 1998.[3]	Defense Modeling and Simulation Office, “High-Level Architecture Federation Development and Execution Process (FEDEP) Checklists Version 1.5”, U.S. Department of Defense, December 1999.[4]	Defense Modeling and Simulation Office, “High-Level Architecture Run-Time Infrastructure – RTI 1.3-Next Generation Programmer’s Guide Version 4, U.S. Department of Defense.[5]	K. Vetter, “Trick User’s Guide 2003 Release,” NASA Technical Publication, NASA Johnson Space Center, September 2002.[6]	K. Vetter, “Trick Simulation Environment – User Training Material 2003 Release,” NASA Technical Publication, NASA Johnson Space Center, September 2002.[7]	Leslie Lamport, “Time, Clocks and the Ordering of Events in a Distributed System,” Communications of the ACM 21, 7   (July 1978).[8]	G. Lauderdale, E. Crues, D. Snyder, D. Hasan, “A Feasibility Study for ISS and HTV Distributed Simulation,” AIAA Modeling and Simulation Technologies Conference and Exhibit, Austin, Texas, 11-14 August 2003.Author BiographiesEDWIN Z. CRUES, PH.D is a senior principal engineer in the Astronautical Engineering Department at Titan Corporation in Houston, Texas.  He has over 20 years of software and simulation development experiences in the United States and Europe.  This experience ranges from trajectory optimization development for the European Space Agencies Ariane 4 and 5 rockets to simulation of the robotic systems on the Space Shuttle and International Space Station (ISS) to the development of a large scale Java based distributed computing system.  He has taught C++ at the University of Houston and developed numerous space based simulations for NASA.  His current projects include the development of the Trick Simulation Development Toolkit, a robotic grasping project, and an HLA based distributed simulation of the ISS and the Japanese HII-A Transfer Vehicle (HTV).DAVID A. HASAN has worked for ten years at Titan Corporation as an aerospace engineer and software developer.  During this time, he designed and developed NASA flight support software for use in the Mission Control Center, GPS-based navigation software for use in autonomous free flying space vehicles, avionics test-bed infrastructure software, and space vehicle simulation software.  He is currently employed at Sun Microsystems.GRACE D. LAUDERDALE is the software lead of the Automated Vehicles and Orbit Analysis group with the Flight Design and Dynamics Division at the Johnson Space Center. She has over 13 years of software engineering experience in the Mission Operations Directorate at NASA/JSC.  Her past software development work consists of planning and analysis tools and displays in the Mission Control Center for various flight control disciplines in Flight Design and Dynamics.  She has, also, lead the development of an Orbit Flight Controller Trainer that integrates a Shuttle simulator with current flight support tools for Flight Dynamics Officers and Rendezvous Guidance and Procedures Officers.  Her current activities involve leading the development of simulation tools and displays to be used in the training and analysis for Visiting Vehicles Operations. DANIELLE V. SNYDER is a software developer in the Automated Vehicles and Orbit Analysis group with the Flight Design and Dynamics Division at the Johnson Space Center. Her 6 years of experience consist of Space Shuttle, Crew Return Vehicle, and Russian Automated Vehicle Analyses.  Currently, she works as a Visiting Vehicle flight controller in the Mission Control Center - Houston, and performs software development tasks supporting Visiting Vehicle Operations. HLA is a series of specifications for distributed simulation developed by the Defense Modeling and Simulation Office (DMSO) of the United States Department of Defense. The RTI is the working component used to transfer data between the various participants in the simulation. It handles data delivery, time coordination, and various other bookkeeping tasks associated with the distributed simulation. For example, the underlying network medium, security and data delivery latencies. By leaving the development of the HTV model to the HTV developers (in Japan), a distributed simulation helps ensure the fidelity of the flight software. NASA and NASDA did not properly communicate their ISDN router configuration.  NASA had configured their router at 128 kbps and NASDA had configured their router at 64 kbps. An HLA attribute is a named component of some object that is being distributed between the participating members of the federation.  For example, “attitude” could be an attribute of an ISS object. HLA ownership is defined at the attribute level rather than for entire objects.  (Attributes are subcomponents of objects.)  Although this makes it possible for the behavior of an object to be controlled by different federates, we do not do so in our simulation.  We anticipate ownership of the HTV and ISS objects (i.e., all their attributes) to belong to one and only one federate at any particular time. The absence of multicast did not prevent the RTIs from working.  Multicast is used primarily for RTI discovery and is more of a convenience than a necessity. Trick is not a necessary component of a HLA based simulation.  However, Trick is widely used at NASA/JSC and will be used to implement the ISS component of any HTV/ISS simulation.  Because of this, it seemed wise to get some early experience integrating HLA into Trick. One of the advantages of HLA is that it enables construction of federates by different organizations using different software tools. In the final HTV/ISS simulation, NASA and NASDA will be free to select their own tools to implement HTV and ISS dynamics.  Our use of Trick for both pseudo-vehicles was simply a convenience. What the flight controllers see during training should be representative of the real mission, both vehicles need to follow a realistic overall time line relative to the other vehicle so that relevant events happen at a “consistent” time, in a “consistent” order. If the Japanese federate runs faster then the US federate, HTV events will occur before they should relative to the ISS; graphically the HTV would jump ahead instead of moving smoothly. A data cycle is the rate at which the Trick implementation schedules HLA send/receives. The data cycle was set to 1sec in our simulations, but this is a configurable parameter. The additive nature of this delay can clearly be seen on the US federate plot, where the initial delay (due to the fact that HTV data were initially owned by the Japanese federate) increases to three data cycles after the ownership transfer. Refer to Table1 and Table 2 for a description of the network and workstation used for the Internet tests.“Simulation Interoperability Standards Organization”Copyright © 2003 by Edwin Z. Crues, United Space Alliance, LLC and Titan Corporation.  Published by the Simulation Interoperability Standards Organization. with permission. These works presented in this paper are sponsored by the National Aeronautics and Space Administration under Contract NAS9-20000. The U.S. Government retains a paid-up, nonexclusive, irrevocable worldwide license in such materials to reproduce, prepare derivative works, distribute copies to the public, and perform publicly and display publicly, by or on behalf of the U.S. Government. All other rights are reserved by the copyright owners. EMBED Word.Picture.8   EMBED Word.Picture.8   EMBED Word.Picture.8   EMBED Word.Picture.8  