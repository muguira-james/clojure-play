A Survey of Simulation Interoperability for Application to OneTESSBradley C. SchrickerAT&T Government Solutions, Inc.11301 Corporate Blvd.Suite 110Orlando, FL 32817407-658-6908 HYPERLINK "mailto:bschricker@att.com" bschricker@att.comKeywords:OneTESS, interoperabilityAbstract:  With the birth of distributed simulation that came with the Simulator Networking (SIMNET) program in the 1980’s, came the concept of simulation interoperability.  Notionally described as the ability of two or more dissimilar simulators effectively connected together by some sort of network implementation to produce something larger than its parts, simulation interoperability, in actuality, has far more detail and impact.  While standards have been created to facilitate the accomplishment and sustainment of simulation interoperability, no overarching standard definition of the term has been agreed upon.  This paper does not attempt to offer such an overarching definition of such a profoundly nebulous concept, but instead wishes to use previous expressions of simulation interoperability to frame a potential definition for use within the context of the One Tactical Engagement Simulation System (OneTESS) program.  As such, this paper surveys the previous literature pertaining to simulation interoperability, organized into various conceptual categories.  Following the survey sections, this paper articulates a potential definition of simulation interoperability that might be most appropriate for the OneTESS program, followed by an explanation of why this definition might be the most useful within the stated context.                            IntroductionSince the proliferation of distributed simulation for use in a multitude of applications, simulation professionals have scrutinized the notion of simulation interoperability countless times.  At this point, a question can be reasonably asked:Does simulation interoperability mean the same thing for all simulation systems?Before anybody can address this question, a firm understanding of what interoperability intuitively means must be accomplished.  However, the underlying foundation of this idea lies with the concept of distributed computing, and must also be thoroughly appreciated.  Upon diving into these concepts and then the substantial body of literature pertaining to simulation interoperability, it should be easier to provide a potential definition that can apply to OneTESS.  The following paragraphs detail that journey.OneTESSOneTESS is the Army’s program for the next-generation of TESS.  For greater context, consider that live training for military purposes dates back millennia [1].  Hand-to-hand combat drills under highly constrained conditions and target practice likely have histories as long as that of warfare, itself.  With the introduction of the Multiple Integrated Laser Engagement System (MILES) in the 1970s, live, tactical training took a quantum leap forward.  For the first time, soldiers could conduct force-on-force training under safe and, at the same time, relatively unconstrained conditions, closely reflecting the conditions experienced during actual warfare.  The application of what was then state-of-the-art laser technology enabled this advance, but this technology now faces two significant disadvantages: Lasers cannot represent indirect fire, or Non-Line-of-Sight/Beyond-Line-of-Sight (NLOS/BLOS) engagements without additional support (such as what is provided by Simulated Area Weapon Effects – Radio Frequency (SAWE-RF)Opaque and translucent obscurants that do not stop bullets, such as foliage and fog, can block laser beamsAs such, OneTESS will support Force-on-Force (FOF) and Force-on-Target (FOT) training exercises at the Brigade level and below in all Battlefield Operating Systems at Homestation, maneuver Combat Training Centers, and deployed sites using technologies other than just lasers to pair shooters to the potential targets.  As part of these goals, OneTESS will simulate a multitude of different engagements, proper doctrines, and weapon capabilities as well as stimulate detectors, sensors, monitors and countermeasures [2].  As mentioned previously, in legacy TESS, the most common method of pairing the shooter to potential targets is with the use of infrared laser beams.  However, this paper has already identified weaknesses of this approach.  Thus, OneTESS will use a pairing method called geometric pairing (geo-pairing).  Geo-pairing uses a collection of data about the shooter, the target, and the terrain.  That data includes:Location of the shooterLocation of the targetTime of the trigger pullCharacteristics of the weapon and its ammunitionOrientation vector of the weaponAtmospheric conditionsTerrain dataWeapon orientation vectors, or rather the accuracy of such, greatly impact the accuracy with which a geo-pairing algorithm can pair a shooter to its targets.  The following section describes the orientation sensing equipment that likely would be used with TESS in general and OneTESS, specifically.FidelityNotional Concept of InteroperabilityDistributed simulation, a spin-off from distributed computing, involves the physical or conceptual connecting of two or more disparate simulations systems for the purpose of either sharing the computational load of the system or for optimizing different strengths and capabilities.  In addition to the advantages gained from such an approach, such as increased resources, increased capabilities, expanded systems, and new technologies, numerous pitfalls exist as well.  Among those are:Inconsistent representations of the worldInconsistent algorithmsInconsistent data representationsCommunication latenciesThese issues, and others, all categorize into one overarching issue – simulation interoperability.  According to the Merriam-Webster OnLine Dictionary [3], interoperability is defined as the: “ability of a system (as a weapons system) to use the parts or equipment of another system.”This definition, though, does not adequately explain how the term applies to simulation, its ramifications, and its challenges.  A more compelling, if not complete, definition of simulation interoperability is offered by Franceschini, et al., as connecting two different simulations in a way that ensures meaningful results [4].  This definition does provide a more genre-specific explanation of simulation interoperability, but it leaves one gaping hole – what does meaningful results mean?Perhaps, that hole is not as gaping as a first glance might suggest.  It could be that the definition needs further context to provide complete understanding.  Perhaps, meaningful results simply depend upon the application of the distributed simulation system.  For the purpose of this paper, that application is OneTESS.The following sections explore proposed definitions of simulation interoperability from selected literature, grouped into three areas:  data sharing, communications, and standard dependency.  This survey research attempts to nail down the salient points regarding simulation interoperability in an effort to parameterize the definition in a way that fits OneTESS most appropriately.Data SharingNumerous literature sources imply that simulation interoperability is largely a data sharing issue.  This group forces the onus of interoperability on whether two or more dissimilar simulations can connect and exchange data in a way that does not adversely affect the performance of either simulation.  This view of interoperability appears to establish a low threshold for success, but that is not necessarily the case.  Instead, it should be noted that for certain simulation systems, this definition is completely relevant.One way to consider this branch of interoperability thinking is that simply being able to communicate data from one simulation system to another without causing unwanted side-effects constitutes interoperability.  For instance, during an effort by the Joint Interoperability Test Command (JITC) to test various distributed simulation systems using a tool called the Joint Interoperability Evaluation System (JIES), it was found that the major challenges that they experienced for interoperability were:Tactical unit reporting responsibilityData link issuesIndividual C4I deficienciesPosition and location anomaliesAll of these issues revolve around the ability of systems to communicate data in a way that does not hinder the operations of the distributed simulations.  Clearly, in this context, the ability to share data has a tremendous impact upon interoperability and its underlying concepts [5].Another group of simulation researchers used this type of concept to detach the concepts of interoperability and performance.  Intuitively, there is an understanding that interoperability has a direct correlation to performance when considering a distributed simulation system.  But, Lorenzo, et al., did not see it this way.  This group goes on to say:“Correlation of daytime visual, sensor (e.g. IR), and computer generated forces terrain is a longstanding interoperability issue…”They add that in their experiments, they decide to distinguish between consistency – or their understanding of interoperability – and credibility – or their notion of performance.  By separating these two concepts, interoperability devolves into an issue that concerns data communication only [6].Similarly, Biddle and Perry contend that interoperability is the state of sharing portions of data between dissimilar simulations that are of different representations.  Specifically, they note that the different representations in question could be any of the following:High Level Architecture (HLA)Custom ProtocolsVoiceVideoInternet DataAny other format that can contain simulation dataTo that end, their effort revolved around the creation of an interoperability engine (IE).  An IE would serve as a type of information gateway between two or more simulations operating within the scope of the same execution.  Attaching a graphical user interface and other support features to the IE, this effort put forth a demonstration that showed some applicability to the interoperability issue, though the specifics are beyond the purview of this paper [7].Interoperability can be taken one small step further and defined not only as the communication of data between multiple simulations without disrupting the operations of either, but also as that communication of data to augment the functionality of the overarching simulation beyond the capabilities of the individual ones.  This approach is suggested by Tapp, et al., as they describe an process of data sharing between simulations.  This three step process is described as:Receive data from connected simulation systemTransform the received data into another data formatSend transformed data back outThis process takes the concept of interoperability as a simple level of communication a step further by defining how interoperability can apply.  Clearly, it dives into interoperability at a lower level than the previously described citations [8].Some simulationists have defined interoperability at a lower conceptual level than has been presented thus far in this paper.  More specifically, those researchers portray interoperability more of a two-way communications capability.  The following section describes two of these references in greater detail.CommunicationsOne way to look at simulation interoperability is to note that two-way communication is often a necessity.  Rarely do simulation professionals assemble distributed simulation systems with the intention that the data sharing will be a one-way street.  As such, the Free Online Dictionary defines interoperability as:“the ability of software and hardware and multiple machines from multiple venders to communicate [9].”However, this raises an important question of what communicate means.  The Merriam-Webster Online dictionary defines communicate as:“to transmit information, thought, or feeling so that it is satisfactorily received or understood [10].”Melding these two definitions together, it implies the two-way communication as the multiple software and hardware from multiple vendors must ALL be able to transmit information in a way that is understood in a meaningful way.  Gustavson, et al., take the position that the whole purpose behind protocols such as HLA and the Distributed Interactive Simulation (DIS) was to provide a medium for different simulation systems to communicate and, thus, provide interoperability.  They implied that if such a standard protocol were used, then the basic usage alone would promote two-way communication and interoperability [11].Sutton takes this viewpoint a step further by describing the necessity for specific services to provide this communication, delving to a lower level than Gustavson.  He begins by pointing out two critical definitions of interoperability that have been proposed specifically for the simulation community.  Those two definitions of interoperability are [12]:“The ability of the systems, units, or forces to provide services to and accept services from other systems, units, or forces, and to use the services so exchanged to enable them to operate effectively together.  The conditions achieved among communications-electronics systems or items of communications-electronics equipment when information or services can be exchanged directly and satisfactorily between them and/or their users [13].”“The ability of a model or simulation to provide services to and accept services from other models and simulations, and to use the services so exchanged to enable them to operate effectively together [14].”This serves as motivation and direction in Sutton’s work to describe services that would be necessary to facilitate the communication necessary for simulation interoperability.  Sutton carefully analyzed interoperability policy looking for like ideas, conflicts, and other items of note that might allow a deeper understanding of interoperability and its nuances.  He then took his findings and attempted to apply those to his experience with Command, Control, Communications, Computers, and Intelligence (C4I) and Modeling and Simulation (M&S) systems.  Through this, he produced a matrix that demonstrated the common and related ideas that proliferated through much of the interoperability literature up to that point.  This allowed him to generate a somewhat exhaustive database of the services that might be necessary to ensure that simulation interoperability can be achieved.  Many of those services include:CertificationCompatibilityDoctrineIntegrationInterface StandardsInteroperability Problem ReportingInteroperability RequirementsInteroperability Testing, OT&E, T&EMapping, Charting, Geodesy Data Standards and SpecificationsMission Need Statement and Operational Requirements DocumentInteroperability WaiversAccreditationCommon Databases and ToolsData Interchange Standards and Protocols EstablishmentData Validation, Verification, and CertificationFederationsHigh Level ArchitectureInternet Standard and Protocol EstablishmentNo-pay/No-play Deadlines for Architecture ConformanceObject Model Data DictionaryObject Model Template Data Interchange FormatRisk ManagementStandard Simulator Database Interchange FormatSynthetic Environment Data Representation Interchange FormatSutton’s work clearly showed the complex nature of interoperability, but also served as an extension of the notion of interoperability being a function of communications.The following section describes several of the specific standards involved in the study of and the attempts to provide simulation interoperability.StandardsNumerous standards already exist for facilitating simulation interoperability.  The following subsections describe the basics of four of the most widely known and used of those.Distributed Interactive Simulation (DIS)DIS supports virtual and live simulation for Force-on-Force (FOF) training exercises.  In short, virtual simulation is characterized by simulation systems that involve live humans interacting with other live humans and computer generated forces (CGF) within a synthetic natural environment.  Among the most well recognized examples of virtual training simulation is a group of flight simulators interoperating.  Conversely, live simulation is typically characterized by simulation systems that have human-human and human-agent interaction in a real location.  A fine example of this is tactical engagement training using the Multiple Integrated Laser Engagement System (MILES).DIS communicates data from one simulator to another through the use of the User Datagram Protocol (UDP) by broadcasting data through the network.  The responsibility for determining if the incoming data is relevant to a receiving simulator falls upon each receiving simulator.  That data is sent in the form of Protocol Data Units (PDU), a standardized set of packets that transfer different types of data.  Each PDU has a variety of bit fields that indicate to all other simulators on the network characteristics such as the PDU type, size, and other data that might be appropriate.  Table 1 shows a top-level breakout of an Entity State PDU, with field sizes in bits.  The fields that break down into further subfields are notated in bold and blue text.Field Name# of BitsPDU Header Record96Entity ID Record48Force ID Record8# of Articulation Parameters Field8Entity Type Record64Alternative Entity Type Record64Entity Linear Velocity Record96Entity Location Record192Entity Orientation Record96Entity Appearance Record32Dead Reckoning Parameters Record320Entity Marking Record96Entity Capabilities Record32Articulation Parameters Record128Table 1.  Entity State PDU fields and sizesDue to the networking characteristics of UDP, DIS is tremendously effective in supporting virtual and live simulation systems in real time.  UDP does not go through any filtering process and the data is broadcast to any other entity existent on the network, so data communicates from one simulator to another quickly.  This speed that DIS possesses makes it efficient in delivering time-sensitive data that other simulators rely upon to operate accurately.  One clear example of this advantage is demonstrated when using DIS to connect multiple flight simulators. Because of the speeds that aircraft travel at – particularly fighter aircraft that can fly at supersonic speeds – even small latencies can equate to travel distances of hundreds of feet.  When attempting to resolve missile engagements during a simulated dogfight, distances of that magnitude can easily be the difference between an engagement resolving as a hit or a miss [15].The following section provides a similar overview to the features of the Department of Defense’s High Level Architecture.High Level Architecture (HLA)HLA differs from DIS in a number of important ways, beginning with the primary terminology.  Each simulator within an HLA environment is called a federate, while a group of federates interoperating together is called a federation.  The data that each federate is interested in is contained in a data fragment called a simulation object model (SOM).  Each SOM is integrated into a single data file shared by all federates within a single federation called a federation object model (FOM).  Each federate publishes a subset of the data in the FOM and subscribes to another subset.  Incidentally, the two subsets can intersect.  Thus, a federate is only aware of data from other federates that it subscribes to and only sends out data from its own SOM that it publishes.  This creates a matrix of data communications properties that defines how the different federates interoperate.Unlike DIS, where no middleware is required to process the data being sent and received, HLA requires a software application called the Run-Time Infrastructure (RTI) to execute on the network before any federate launches.  Each federate must then have two components that communicate with the RTI called the RTI ambassador and the federate ambassador.  The RTI ambassador consists of function calls to the RTI while the federate ambassador acts as a receiver for incoming data.It is important to note, however, that HLA is not software.  Rather HLA is a specification and the RTI is the software implementation of that specification.  More specifically, HLA consists of:Interface specification – defines how HLA federates must interact with the RTIObject Model Template (OMT) – specifies what information shall be communicated and how it will be documented, encompassing the FOMHLA Rules – a set of ten rules that describe how HLA compliant federates must operateThe interface specification is divided into the following groups:Federation ManagementDeclaration ManagementObject ManagementOwnership ManagementTime ManagementData Distribution ManagementSupport ServicesUnlike DIS, where individual agents are referred to as entities, agents in HLA are referred to as objects and are described by a set of parameters.  The parameters are the actual data that is communicated back and forth while the objects are only a conceptual construct that contains the parameters.  The state of an object can change by sending an update for a single parameter, a set of parameters, or all parameters for that object [16].Test and Training Enabling Architecture (TENA)Testing and training ranges tend to stove-piped systems that do not lend themselves to interoperability.  As such, TENA is intended to establish an foundational architecture to allow interoperability within those testing and training ranges.  Further, TENA is expected to foster an environment of reuse within the community to help support the mission of interoperability.Six operational requirements have driven the development of TENA.  Those six requirements are:TENA must support the implementation of logical rangesTENA must support the joint vision 2010/2020TENA must support rapid application and logical range developmentTENA must support easy integration with modeling and simulationTENA must be gradually deployableTENA must support a wide variety of common range systemsIn addition to interoperability and reusability, TENA also has an objective to support composability, which is the ability to rapidly assemble, initialize, test, and execute a system from members of a pool of reusable, interoperable elements [17].While TENA strives to facilitate and promote simulation interoperability, its application is geared strictly towards test and training ranges, with little concern for the countless other venues that require strong interoperability.  Common Training and Instrumentation Architecture (CTIA)The Common Training Instrumentation Architecture (CTIA) is an architecture intended to implement the U.S. Army's Live Training Transformation (LT2) and leverage a high degree of commonality of requirements among the U.S. Army's instrumented ranges and home stations. CTIA strongly emphasizes commonality across all connected systems, which is thought to improve the quality of training while significantly reducing development, logistics, training, and maintenance costs. CTIA and any associated processes will be the basis for any subsequent LT2 product line members to leverage.Essentially, CTIA is expected to provide an interoperability framework for all systems expected to participate in any exercise or mission falling within the LT2 strategy.  In short, CTIA is:a U.S. Government owned, non-proprietary, open, component-based architecture that is the foundation of the U.S. Army's LT2 strategya common architecture for the development of CTC-IS ( NTC,  CMTC,  JRTC ),  MOUT, HITS, and Instrumented Range (DMPRC) systemsthe Processes, rules, standards and protocols for the development of common and unique components of LT2 products expected to have twenty years or more of longevityan LT2 prototypeUltimately, CTIA will be fielded as part of systems upgrades at Army Combat Training Centers (CTCs) and Home Stations [18].Interoperability for OneTESSOneTESS will be a complex system with dozens of different simulators connected at any given time during the course of a test or training exercise.  Because of this complexity and the numerous stated requirements for interoperability with various other systems, a clear understanding of interoperability must be determined.  Without that understanding, fulfilling those requirements and the expectations of the customer will be an arduous task, at best.However, it should noted that trying to devise a single overarching definition and concept of simulation interoperability and then attempting to apply that to OneTESS – or any other system under development – is not the correct approach.  Instead, it might be more productive to formulate a firm comprehension of interoperability at a high level and then, in an effort with contractors and customer, determine which portions of that concept apply to OneTESS.For instance, as suggested earlier in the survey portion of this paper, some simulation researchers have indicated that interoperability only concerns the exchange of data and should be a separate function from performance.  While this approach might work perfectly well for some distributed simulations systems, it might not suit OneTESS very well.One problem with this approach with OneTESS is that it has requirements to comply with HLA, TENA, and CTIA.  Just simply ensuring that OneTESS can transfer data throughout its entire scope by using these different architectures does nothing to ensure that the systems connected by these architectures will do anything meaningful with that data.  Instead, a more sensible approach to OneTESS might be to confirm that data representations are the same or as similar as possible among the different systems to interoperate with OneTESS.  Unfortunately, this puts the onus on the data side, which might not be practical from an implementation standpoint.Another necessity for OneTESS interoperability is to determine the levels of compliance with the different architectures.  CTIA, for example, has several different levels of compliance that range from simple connection to meaningful data exchange.Lastly, it should be noted that the notion of interoperability within a single system might change depending on the circumstances surrounding an exercise.  For instance, OneTESS will be deployed to sites with varying levels of communication infrastructure already established.  The communication infrastructures could set a bound upon the level of interoperability possible in those particular locations.  Therefore, the interoperability may not necessarily be a constant expectation, but rather a fluid one that is dictated by the environment surrounding a test or training exercise.Ultimately, the concept of interoperability will influence the design and implementation of OneTESS, making its definition and understanding critical to all parties involved.ConclusionClearly, when concerned about any distributed simulation system, the conversation must eventually turn to issues regarding simulation interoperability.  This concept has existed nearly as long as distributed simulation itself, but little accord has been achieved in settling upon several characteristics surrounding it:DefinitionMetricsApplicationVerificationValidationStandardizationDue to these ambiguous issues, resolving the meaning of interoperability and its entomological derivatives within system requirements becomes a nearly impossible task.  It has been the aim of this paper to provide a summary of interoperability literature for the purpose of making that task less arduous.In that sense, perhaps the most logical conclusion is that interoperability can not be adequately defined for Modeling and Simulation as a whole, but rather should be defined for each distributed simulation system that is created.  In fact, it is perfectly plausible that each individual program determine what interoperability is, to what degree standards will be adhered to, and how that interoperability will be measured.  This is not to say that work done in the field of simulation interoperability be ignored in favor of whatever works for a particularly program.  For instance, if a system has a requirement to comply with HLA, then it must comply with HLA to fulfill that particular requirement.  But, less well defined statements have built-in wiggle room that must be resolved by the individual programs, themselves.Most importantly, perhaps, in cases such as these might be documentation of the issues that arise, the different courses of actions investigated to resolve them, the resolutions, and their justifications.  One of the most critical aspects of distributed simulation is the idea of being able to augment a system with additional simulators, thereby expanding the capabilities of the original system.  Without thorough and clear documentation that explains how the concept of interoperability pertains to that system, adding any additional capabilities devolves into an onerous task.  The concept of interoperability may be fluid as a whole, but its individual applications should be more frozen in time.References[1]	Appian, “The Civil Wars”[2]	“One Tactical Engagement Simulation System (OneTESS),  HYPERLINK "http://www.peostri.army.mil/PRODUCTS/ONETESS/" http://www.peostri.army.mil/PRODUCTS/ONETESS/.[3]	“Interoperability,” Merriam-Webster OnLine Dictionary, 	 HYPERLINK "http://www.m-w.com/dictionary/interoperability" http://www.m-w.com/dictionary/interoperability, June 12, 2006.[4]	Franceschini, Robert, Tom Clarke, Brian Goldiez, Allison Griffin, Andre Huthmann, Guy Schiavone, and Brad Schricker, “A Survey of the Theory and Practice of Simulation Interoperability,” Proceedings of the Spring 2000 Simulation Interoperability Workshop, Orlando, FL, September 2000.[5]	Chi, Maxwell, Kenneth Thomas, and Mark Swift, “JITC ADS Efforts in Support of T&E and Interoperability Testing,” Proceedings of the Fall 2000 Simulation Interoperability Workshop, Orlando, FL, September 2000.[6]	Lorenzo, Maximo, Mike Pastore, Bill Riggs, and Mike Caruso, “Interoperability Versus Performance:  Applicability of Paint the Night Terrain Generation BCR IV Lessons Learned to Integrated Natural Environments,” Proceedings of the Fall 2000 Simulation Interoperability Workshop, Orlando, FL, September 2000.[7]	Biddle, Mark and Constance Perry, “An Architecture for Composable Interoperability,” Proceedings of the Fall 2000 Simulation Interoperability Workshop, Orlando, FL, September 2000.[8]	Tapp, Martin, Gabriela Nicolescu, and El Mostapha Aboulhamid, “Experiences with an XML Format & Syntax for Describing Interoperability,” Proceedings of the Spring 2006 Simulation Interoperability Workshop, Huntsville, AL, April 2006.[9]	“Interoperability,” Dictionary.com,  HYPERLINK "http://www.dictionary.com" http://www.dictionary.com, June 14, 2006.[10]	“Communicate,” Merriam-Webster OnLine Dictionary, 	 HYPERLINK "http://www.m-w.com/dictionary/communicate" http://www.m-w.com/dictionary/communicate, June 14, 2006.[11]	Gustavson, Paul L., Lawrence M. Root, and Steve Goss, “Achieving Rapid Interoperability For Both the M&S and B2B Worlds,” Proceedings of the Spring 2001 Simulation Interoperability Workshop, Orlando, FL, April 2001.[12]	Sutton, Paul W., “Interoperability Policy Roadmap,” Proceedings of the Spring 2000 Simulation Interoperability Workshop, Orlando, FL, April 2000.[13]	Chairman of the Joint Chiefs of Staff (CJCS) Instruction 6212.01A, “Compatibility, Interoperability, and Integration of Command, Control, Communications, Computers, and Intelligence Systems,” Enclosure A, June 30, 1995, p. A-3.[14]	Department of Defense Directive (DoDD) 5000.59, “DoD Modeling and Simulation (M&S) Management,” Enclosure 2, January 4, 1994, p. 1.[15]	Hardt, James and Kevin White, “Distributed Interactive Simulation,”  HYPERLINK "http://www.ece.engr.ucf.edu/~jza/classes/4781/DIS/project.html" http://www.ece.engr.ucf.edu/~jza/classes/4781/DIS/project.html, April 5, 2006.[16]	Defense Modeling and Simulation Office, “High Level Architecture,”  HYPERLINK "https://www.dmso.mil/public/transition/hla/" https://www.dmso.mil/public/transition/hla/, June 21, 2006.[17]	Powell, Ed, “The Test and Training Enabling Architecture (TENA) 2002 Overview,” Proceedings of the Fall 2002 Simulation Interoperability Workshop, Orlando, FL, September 2002.[18]	U.S. Army Program Executive Office for Simulation, Training and Instrumentation, “CTIA Portal,”  HYPERLINK "https://ssl.peostri.army.mil/CTIAPortal/index.jsp" https://ssl.peostri.army.mil/CTIAPortal/index.jsp, June 20, 2006.Author BiographiesBradley Schricker is a Software Engineer with AT&T Government Solutions, Inc., currently working on the Demonstration of Technology and System team of the One Tactical Engagement Simulation System (OneTESS) project.  He has eight years of experience in software engineering, focusing his efforts in the areas of distributed simulation, discrete event simulation, virtual environments, and behavior representation.  Mr. Schricker received his Bachelor of Science degree in Computer Science with a minor in Mathematics from Florida State University in 1998 and is currently pursuing a Master of Science degree in Modeling and Simulation from the University of Central Florida, projected to graduate in Summer of 2007.