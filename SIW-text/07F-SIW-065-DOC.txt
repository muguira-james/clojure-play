Applying the Mission Essential Competency Development Process toAn Emergency Operations CenterGeorge M. AlligerWilliam BaetzThe Group for Organizational Effectiveness, Inc,727 Waldens Pond RoadAlbany, New York 12203518-355-9252, 518- 371-2235george.alliger@groupoe.com, bill.baetz@groupoe.comDaniel NarigonAlion Science and Technology2300 D. StWright Patterson Air Force Base(937) 255-4951daniel.narigon@wpafb.af.milCapt. Kristen BarreraWinston Bennett, Jr.Air Force Research LaboratoryWarfighter Readiness Research Division6030 S. Kent StMesa, Arizona 85212480-988-6561 x254 / DSN 474-6254, 480-988-6561, ext 297 /DSN 474-6297 HYPERLINK "mailto:kristen.barrera@mesa.afmc.af.mil" kristen.barrera@mesa.afmc.af.mil, winston.bennett@mesa.afmc.af.milKeywords:EOC, Emergency Management, MEC, Mission Essential Competency. ABSTRACT: As part of a larger project for developing simulation-based training for a large Midwestern county’s Emergency Operations Center (EOC), and in order to help specify training requirements for that project, EOC Mission Essential Competencies (MECs) are being developed. The process for and outcomes of the MEC process have been developed and validated by the U.S. Air Force over the past 7 years, to provide a framework for training and simulation guidance for a wide variety of defense systems, including multi-position and multi-team systems. Although an EOC differs in substantial ways from previous systems to which MECs have been applied (e.g., an EOC is a non-military entity in which political and public considerations can be paramount; most operators are not assigned full-time to EOC), it appears that the MEC process and structure (e.g., knowledge and skills, supporting competencies, developmental experiences) are applicable and can act as rich information for training requirements. This paper details the initial MEC outcomes for the EOC, implications for broader civilian application and discusses how the MEC process needed to be adapted to work for this unique and critically important area. I. Introduction"Our cities must have clear and up-to-date plans for responding to natural disasters, disease outbreaks or terrorist attack, for evacuating large numbers of people in an emergency and for providing the food, water and security they would need.  In a time of terror threats and weapons of mass destruction, the danger to our citizens reaches much wider than a fault line or a flood plain.  I consider detailed emergency planning to be a national security priority…" 	President George W. Bush, 15 Sep 2005General BackgroundAn emergency can be defined as an unexpected, serious occurrence or situation that urgently requires prompt action.  Local, state, and federal government administrations have a clear interest and duty to make every attempt to prepare for emergencies, ameliorate the effects of emergencies, and address urgent and long-term needs that arise from emergencies. First responders (e.g., Firefighters, Police, medical personnel) are typically engaged with addressing the emergency at the very beginning and throughout its critical phase. Longer term rebuilding efforts may be primarily handled by various government agencies, companies (e.g., utilities), and contractors (e.g., building contractors). Central to any sizable administration’s effort to handle emergencies is the need to support first responders, plan and manage emergency recovery, keep the public informed of events and progress, and in general maintain political control and municipal (county, state, federal) services in the face of the myriad of difficulties that can accompany emergencies. In order to do this, some administrations put in place an entity known as the Emergency Operations Center (EOC). The EOC is a physically centralized location where coordination, communication and management activities are carried out that facilitate and enable emergency response and recovery. Often, an EOC has specialized equipment (e.g., computers/software, radios) that enable the staff to accomplish their various functions. Personnel in the EOC have carefully delineated roles and responsibilities, as reflected in the organizational chart below.Figure 1: A configuration of an EOC.  Note: ESF = Emergency Support Function; PIO = Public Information OfficerThe above depiction represents one of a number of potential configurations of an EOC – any given EOC may have more or fewer positions, or different hierarchy. One urgent need for the efficient functioning of any EOC is training. This is particularly the case because a) of the naturally sporadic, random, and unexpected nature of emergencies, meaning that there is no systematic way for EOC members to obtain regular or planned exposure to and job practice in emergencies, and b) the fact that many EOC members are not full-time, but rather are employees in some government role which provides them with useful knowledge that can be leveraged during and emergency; this means again that systematic training is difficult to obtain. Thus, for any given emergency, one too many EOC members may be operating in an EOC for the first time for that kind of emergency. II. Background of the Mission Essential Competency effort for Montgomery County Ohio.The state of Ohio published the following Homeland Defense Strategic Goals (Ohio.gov):Seek out and provide the training necessary to ensure state and local preparedness in response to large-scale emergencies and to ensure the ability to mount a swift and effective recovery. Assure awareness, preparedness, prevention, response, recovery, and mitigation plans are coordinated across all levels of the community. Ensure that the organizational structure for all response disciplines facilitates communication and supports a coordinated response regardless of jurisdiction or discipline. Provide for interagency coordination and cooperation, taking advantage of all available resources. Develop and implement exercise and training programs for Incident communications efforts.Problem StatementMilitary base command staffs and civil agencies do not have a capability to rapidly access, integrate and display current local information and area imagery to support training, rehearsal and threat-based effects simulation.  The Department of Defense (DoD), and specifically the Air Force Distributed Mission Operations (DMO) program, requires US and worldwide high resolution, integrated common imagery and simulation databases (common virtual world representations of mission and training areas) in order to do distributed team training for Homeland Defense, Global War On Terrorism as well as conventional mission training. Training transformation for expeditionary force preparation and training requires the rapid retrieval, synthesis of imagery and infrastructure data and response simulation of cities and areas globally. In addition, state and local emergency management agencies (EMAs) have stated the need for hazards-based simulation training capabilities. US Air Force Research Laboratory awarded a one year contract to Alion Science and Technology to develop the initial concept and integration architecture to provide an area image and logistics based all hazards emergency response training capability for Montgomery County and the USAF. Literature ReviewThe EOC training requirements research team was provided a copy of the Montgomery County Emergency Operations Plan. The plan provided a breakdown of the EOC responders and the offices they represent. A county EOC is staffed by responders from various local government offices and local agencies. The modeling and simulation training tools should support the multi-agency requirements and specific knowledge data contributions (Pollack, Falash, Ingraham and Gottsman, 2004). Jain and McClean (2003) observed that the benefits of emergency response simulation and modeling tools can be enhanced through integration of the tools to address multiple aspects of the emergency incident. After identification of the training audience the team needed to capture the training requirements within the EOC both individually and as teams.  The Montgomery County Emergency Operations Plan and the Federal Emergency Management Agency exercise plan outline a four year exercise cycle. Year one is individual task drills, year two is a table top training exercise, year three is a functional exercise and year four a field exercise. Each year the size and the complexity of the training increases. Year three, functional training, is the year the EOC responders are gathered together for combined team training. A large exercise support group provides the scenario, event insertions, simulates external agencies and provides exercise evaluation. Due to the training cycle, job rotation and personal schedules the number of times a responder receives the functional team training is minimal. During an actual emergency many of the responders may have had minimal on no functional team training. Jain and McLean (2006) stated that a major challenge confronting communities is the lack of training opportunities for the emergency responders and decision makers. The current training reality is on-the-job training during actual emergencies which, due to the infrequency of such events is unacceptable. The authors remarked that agencies have attempted to meet the training need through live exercises but live exercises are difficult to organize and expensive to conduct. Traditional functional exercises are also very expensive, require a large exercise support group and difficult to organize. The net result is that neither live nor full EOC functional exercises are conducted frequently enough to be prepared for an emergency.  Sticha, Campbell and Knerr (2005) stated that progress is needed in creating methods to guide virtual training tools design and development. Subject matter experts can assist in estimating the training needs and current effectiveness of training systems. The authors recognized that conducting a behavioral analysis of the events and activities to be trained is highly desired. Common sense dictates that identification of training requirements is necessary prior to developing a training tool or system. The EOC, as noted, previously is a complex environment, with individuals of varying experience representing various offices and agencies gathered together to respond as a team.The Air Force Distributed Mission Operations program is creating a distributed simulation training environment for aircrews, command and control operators, Air Operations Centers and decision makers to provide a training capability lacking in live fly training. The goal of team training is to experience the crew members in their war time mission without the risk, cost or planning demands of large live exercises. The Air Force recognized that experienced teams exhibit a level of competency above the individual tasks and skills. The Mission Essential Competency (MEC) Program was created to identify those critical competencies which need to be developed. The EOC training research team identified the MEC process as a promising way to perform the necessary training behavior analysis for the county EOC responders. The responders’ roles are similar to the aircrews and platforms. Each function has individual requirements which must be understood and completed to respond to the emergency. Each function must also work with team members within the EOC and external to the EOC to respond to the emergency. AFRL/HEA agreed to provide MEC analysis support to the Montgomery County Emergency Operations Center training requirements project. The EOC provides logistical support to the Incident Commanders (ICs) in the field. An EOC does not make tactical decisions but rather locates and provides response resources as required, manages the documentation, as well as contracts and financial aspects of the response. The EOC provides communication between agencies and jurisdictions, informs the public and the elected officials of key emergency and response details. Because of the limited amount of actual response experience of many of the EOC responders the team decided to do a two step MEC process. The first step was to gather MECs required in the EOC from experienced field responders and incident commanders. The second step was to vet the inputs from the subject matter experts (SMEs) with individuals currently assigned to respond to the EOC in the event of an emergency. The research project team identified several key emergency response experts in the local area to provide subject matter expertise. The lead SME is a nationally known expert in emergency response. He is a major metropolitan area fire chief, was an on site consultant in New York in response to the 9/11 attacks and was the FEMA Search and Rescue Emergency Support Function lead for Hurricane Katrina. Other SME’s include retired and current Dayton area fire chiefs, FEMA response team leads, hazardous material (HAZMAT) management and response leaders, Ohio Task Force 1 team lead, a current police detective and former SWAT sniper and an Ohio Rescue Force task force leader. The SMEs discussed the roles, responsibilities, knowledge, skills and experiences necessary and desired for the 15 EOC Emergency Support Functions (ESF; Montgomery County Office of  Emergency Management, 2003). The EOC provides support to the ICs in the field. The SME’s as former incident commanders and experienced field responders provided the experience and expertise to identify the skills, knowledge and experiences required at the EOC to effectively support emergency response.  The SME’s met for a two day MEC workshop to create the initial set of MECs and experiences. Following the SME lead workshop the county EMA arranged workshops with the individuals currently assigned to fill the various 15 ESFs in the event of an emergency or training exercise. The workshop attendees provided inputs to the documents created from the SME inputs.III. Background on Mission Essential CompetenciesA. The Elements of the MEC modelMission Essential CompetenciesMission Essential Competencies are high level functions, job-contextualized and less general in most cases than competencies found in typical business environments (Colegrove & Alliger, 2002).  The term MEC has been formally defined as a “higher-order individual, team, and inter-team competency that a fully prepared pilot, crew, flight, operator, or team requires for successful mission completion under adverse conditions and in a non-permissive environment.” Note the conditions of performance specified in this definition.  The USAF has not previously used combat conditions to define standards of warfighter performance. This definition has also been applicable to other high stress situations, such as local fire, police, and city personnel handling major disasters in an EOC. Interestingly, the high standard explicit in this definition is in accord with one of the central characteristics of competencies as originally conceived; specifically, standards of “success,” and that in adverse conditions, is inherent in the nature of the MECs.Each MEC is a brief statement, with clarifying text as appropriate. It also has a stipulated start, end, and purpose statement. Example MECs, the first for Airborne Warning And Control System (AWACS) and the second from the EOC are: Detects entities in Area of Interest – Includes all air and surface tracks, and emitters of interest. Start: When systems operational Stop: When systems powered down Purpose: Assist in contributing entities to Single Integrated Operational Picture (SIOP) (e.g., using onboard and offboard sensors) On-going Incident Monitoring and Planning – Monitor and evaluate all available information sources (e.g., media, incident command, field reps); seek information via all appropriate means; maintain open communications with response partners (e.g., ICs); integrate information; create and maintain GIS displays/maps; build and maintain “big picture” of incident(s) as emergency develops. To degree possible, anticipate how incident may unfold. Assess need priorities; develop EOC shift work plan; continue risk analyses; identify big picture issues (e.g., how developing weather conditions could affect responders). Develop EOC Incident Action Plan; Adjust level of EOC activation as needed.	Start: On activation of EOC	Stop: On closing of EOCPurpose: To obtain and maintain a clear understanding of what is occurring in incident and communicate to all relevant parties; manage EOC activation levelOften, the entire set of MECs that are defined by subject matter experts for a given weapon system reflect a broad chronological order, arising from the nature of the mission in question. For example, from an analysis of the tasks carried out by fighter pilots, MECs such as Detect, Target, Engage, as well as others usually emerge – the roughly sequential nature of these functions is mirrored in the MECs, so that one MEC may have as its start the end of another.  However, this is not always the case – some MECs may be temporally parallel, while others may be continuous or on-going throughout the course of the performance of a job. Supporting Competencies There are broad, high-level skills and knowledge that underlie the successful development and performance of the MECs. Termed “Supporting Competencies” (SCs), these may include classic organizationally relevant competencies such as Decision Making or Adaptability, as well as more USAF-specific competencies such as Situation Awareness. SCs tend to have a similar nature to competencies typically developed in industry (that is, high-level and more or less context-free), as opposed to the MECs, which are highly contextualized job functions. Typical SCs include Situational Awareness, Leadership, Adaptability/Flexibility, and Information Management.Knowledge and Skills At a “lower” level of analysis than either MECs or Supporting Competencies are Knowledge and Skills (KS). These are deliberately elicited at the level of natural language – they are couched in terms and at an interpreted level of action clustering that is usual or common among job holders. This is intentional, both because it is deemed desirable to use the level of KS “chunking” that is common among warfighters since this facilitates data collection and ensures comprehension by the warfighter community, and because the USAF already has Training Task Lists (TTLs) that are written at a more basic level of analysis. Research linking existing TTLs to KS developed in the MEC project has begun.  Knowledge is defined as “information or facts that can be accessed quickly under stress,” and skill can be defined as “a compiled sequence of actions that can be carried out successfully under stress.” Since the emphasis is on performing under combat or highly stressful conditions, the use of the word “stress” in defining K/S is highly important, and a baseline of initial training is assumed during the knowledge and skills elicitation process.  Below are some example knowledge statements (from Close Air Support (A-10)):Environment Effects – Understands the effects of environmental factors on the mission (e.g. terrain, smoke, vegetation)Systems/Weapons Capability – Understands the capabilities of own and supporting aircraft and their weapons; knows penetration aidsSome example Skills (also from Close Air Support (A-10)) are:Identifies Targets/Threats – Interprets the visual cues/system indicators that identify various targets/threats Assesses Risk – Identifies and assesses risks related to mission accomplishment If MECs are being developed for a multi-person system or team, not every KS will apply to every position on that team. For example the AWACS skill “AWACS employment: Positions AWACS to optimally meet mission tasking,” actually applies only to the Mission Crew Commander and those other positions that have the responsibility for obtaining the best possible radar picture, given constraints and objectives. Thus, a position-by-Knowledge and Skill matrix showing these dependencies is developed. The SME-stipulated required level of KS is shown for each position, such that a given position may be required to have a Basic, Intermediate, or Advanced level for a given KS. In addition, some KS may be “not applicable” – that is, not required for that position. Experiences An element that is unique to the MEC model is Experience. Experiences are captured during the MEC process as another measure related to the events in the life of job incumbents that can be manipulated in training (either live or simulated). An Experience can be defined as a developmental event that occurs during training and at various times across the career of an incumbent that facilitates learning a KS or practicing a MEC or SC under operational conditions. There are essentially three types of Experiences that are identified by SMEs:  1) an event that occurs to or situation encountered by, 2) an action that is performed by, or 3) an operation for a pilot, crew, team, or flight and that may be helpful in gaining the competencies required for successful mission completion under adverse conditions and in a non-permissive environment. An Experience is thus an identifiable event that is a facilitator of combat mission readiness. An Experience can occur in any environment, training or actual combat/work operations. Examples of the Experience include (all examples from the MEC model for Air-to-Air (F-15C): Flying where there are operating area restrictions (e.g., geographic, altitude, or political)Using chaff/flare to deny/defeat enemy radar/weaponsOperations against air or ground adversary jamming	Experiences form the basis of most MEC surveys; they are crossed with MECs or training environments or mission types to answer particular questions (the surveys are discussed in more detail later).B. The MEC Development ProcessSME involvement is a critical factor in the development of the elements of the MEC models, it is essentially a SME-centered process. Specifically, development involves a) detailed facilitated workshops with SMEs identified by the operational customers according to stipulated criteria, b) data gathered from the broader operational community via surveys, c) a detailed analysis and organization of the survey results, and d) facilitated workshops where SMEs view, interpret, and make recommendations based on the survey data. Thus, the initial set of draft MECs are developed following a workshop wherein SMEs provide information about the structure of their unit, missions and specific tasks performed, KSs and SCs.  The second workshop provides a validation of the findings from the first workshop (the MECs and SCs) and allows the facilitators to delve deeper into the more detailed Knowledge, Skills, and elicit Experience components of the MEC model.  Following the second workshop, an extensive database of expert knowledge about a career area exists.  This information is organized into surveys which are presented to the broader operational community for that particular weapon system.  After collecting and compiling the data, a comprehensive analysis of the weapon system and associated career field training status is performed, again via a facilitated, SME-centered workshop. The final step is the utilization of the results to revise and enhance training.Identification of SMEs.  The MEC process is radically SME-centered, by which we mean that SMEs are involved in each step. SMEs are chosen based on their level of experience with the system under review. Generally, individuals with purely “academic” experience (e.g., course designers) are avoided in favor of operators (who may also have had instructional experience).  The number of SMEs required for a workshop depends on the nature of the system. MEC Workshop 1: Mission Review, Task Identification, KS and SC GenerationIt has been noted that one of the weaknesses of competency modeling is that is often not as thorough as traditional job analyses, and SMEs involved in competency development do not have job analysis information available to them (e.g., Lievens, Sanchez, & De Corte, 2004).  The first MEC workshop is in part a task analysis, so that although the task listings are not a formal MEC product, the SMEs generate a listing of tasks. The way this is done is to review and identify the tasks involved in how they perform their job (either through identifying the basic processes and work flow utilized in their work or through identifying the missions they perform of varying complexity).  Task Identification. After gathering this mission or process-level information, these were then cycled through to produce a complete task list. The level of tasks elicited in this manner is meant to be at a level at which it is natural for SMEs to speak. The process/mission framework and the task list are only intermediate outcomes, but are nonetheless fairly complete and substantive. Their role during the workshop, however, is simply to serve as stimulus for generation of KSs.	KS Generation. After identifying tasks, the SMEs have available to them an outline of their process/missions and tasks. With this in front of them, they are asked to generate knowledge and skills that are required to carry out the missions/process.  The goal is to obtain a list of knowledge and skills that are again written at a level of language that is natural for the SMEs.  In general, this results in KSs that are of a moderate level of complexity (e.g., SMEs usually prefer to gather the various sub-skills for employing a particular weapons system – such as a bomb or rocket – under a single heading for that system).  The SMEs are told that these are draft KSs, which will be reviewed by them and/or similarly-qualified individuals. Developing Draft MECs	After the first workshop, the facilitators review all the material gathered from the SMEs in that workshop.  Taking into account the missions/processes, tasks, and the draft KSs, MECs are drafted. Guidelines for constructing the MECs include: a) they should be high-level, representing major functions or job responsibilities, b) they should represent combat-level performance, c) they should be in the SMEs own language and reflect functions understandable and usable by them, and d) they should not be abstract or general, but actual contextualized functions or responsibilities.  Note that “a)” effectively limits the number of MECs. Usually they range from five to ten in number.	MEC Workshop 2: Confirmation/Revision of MECs and Workshop 1 Outcomes, Generation of Experiences	Workshop 2 further develops the MEC model by having SMEs review the MECs and KSs and revise as needed. This is an important aspect of the content validation of the elements of the MEC model.  In addition, it is during Workshop 2 that the Experiences are generated. Guidelines have been developed over time to facilitate the process of elicitation of developmental experiences. Specifically, it is important for experiences to be worded in a way that permits them to be easily understood, without confusion or misinterpretation. There are two main rules that if followed will result in well-written experiences. First, in general, an experience should be single rather than compound. Second, Experiences should be unambiguous and sufficiently clear to avoid misunderstanding.The MEC SurveysFor each MEC effort, custom surveys are developed, so that surveys for each system differ in MECs, KSs, SCs, and Experiences. In addition, there are other system differences and the surveys are adapted accordingly. For example, different systems have different learning environments.  Learning environments are defined as those locations or events where training and learning are accomplished. The learning environments form the basis of one of the surveys used in the MEC process and model. Beyond this, surveys may differ somewhat from system to system depending on the particular needs of the community, the missions that are performed, and the learning environments that are available. The COMMAND Workshop: SME interpretation of survey results	In the final workshop, the survey results are presented to a set of SMEs, who interpret the findings and identify training gaps.  The data are formatted in a customized spreadsheet display, which is computer projected so that all SMEs can view it simultaneously. After a review of all of results from each of the separate surveys, the SMEs are presented with the COMMAND worksheet. This worksheet is formatted to present the results from several surveys experience by experience. Specifically, the SMEs see, for each experience, results that permit them to answer the questions:How important is the experience in developing the MECs?How effectively are operators taught to handle the experience in current training?In what environments (e.g., Exercises, Simulator, Classroom) can the experience be provided?How often in the past year are operators receiving the experience in each environment?What conclusions/gaps can we identify based on this process? Using these results, the SMEs work through one experience at a time, considering what the results say about each experience as reflected in the responses to each survey. They answer the five questions and their responses (after discussion and consensus) are recorded real-time into the COMMAND worksheet. In this way, each experience is reviewed and conclusions about it are recorded.  Typically, to run a COMMAND session for a given system requires two days.IV. Applying MECs to the EOC A. MECs and the EOCWorkshops I and II OutcomesThe first two MEC workshops for the Montgomery County, Ohio, EOC were conducted as described above. There are ten MECs for the EOC:Pre-incident ReadinessEOC Activation On-going Incident Monitoring and PlanningField Support Internal EOC CoordinationCommunication with PublicCoordination with Administration and Other Emergency Management (EM) AgenciesFinance/Contracts/DocumentationAfter Action Reporting Recovery Pre-incident Readiness: Maintain currency of plans for EOC (e.g., Emergency Operations Plan and EOC Standard Operating Guidelines, risk analyses, legal issues, back-up for EOC); maintain readiness and capability of EOC (e.g., appropriate staffing and staff readiness) via training; maintain currency/completeness of contact lists (including redundant contacts and contact numbers) and contact plans; understand capabilities, limitations, and availability of assets; ensure EOC facility operational (e.g., computers, phones, software, radio interoperability) and staff familiarity with technology in EOC; understand authority structure; work to maintain appropriate level of public and government awareness of EOC capabilities and role. 	Start: On-going	Stop: On-going	Purpose: To maintain readinessEOC Activation: Activate based on appropriate plan for current or approaching incident; activate appropriate EOC staff; establish priorities; determine administration intent; initiate intelligence gathering; make go-no go decision; perform initial risk analyses; ascertain media comments and frame developing situation for public via media; setup initial shift scheduling; establish initial contacts with Incident Commander(s) and other agencies; identify incident-relevant experts needed to supplement EOC expertise. [Note: activation begins first with assessment and continues with operations]	Start: At first indication of incident or impending incidentStop: When initial appropriate level of EOC activation is accomplished (e.g., Assessment Room, partially staffed EOC, fully staffed EOC)	Purpose: Timely response supportOn-going Incident Monitoring and Planning: Monitor and evaluate all available information sources (e.g., media, incident command, field reps); seek information via all appropriate means; maintain open communications with response partners (e.g., ICs); integrate information; create and maintain GIS displays/maps; build and maintain “big picture” of incident(s) as emergency develops. To degree possible, anticipate how incident may unfold. Assess need priorities; develop EOC shift work plan; continue risk analyses; identify big picture issues (e.g., how developing weather conditions could affect responders). Develop EOC Incident Action Plan; Adjust level of EOC activation as needed.	Start: On activation of EOC	Stop: On closing of EOCPurpose: To obtain and maintain a clear understanding of what is occurring in incident and communicate to all relevant parties; manage EOC activation levelField Support: Locate, alert, allocate, track, and reallocate assets as requested by/required for Incident Command(s), respond to field requests, keeping Incident Commander(s) and field operatives informed of support picture. Match assets to needs; recommend/provide appropriate substitutes as needed. Handle unreasonable requests and unsolicited resources. Maintain accountability of resources. 	Start: On activation of EOC Incident Action plan	Stop: On closing of EOC	Purpose: Enable effective resource support and coordination for respondersInternal EOC Coordination: All functions communicate as needed with other functions and management (e.g., EOC Director); establish/negotiate inter-functional support priorities; work together to solve problems.	Start: On Activation of EOC	Stop: On closing of EOC	Purpose: Efficient functioning of EOCCommunication with Public: Contact media as point of contact, craft messages for public and verify information, work with other public information officials (e.g., with JIC or information sharing system on public information), brief administration and public officials, manage press briefings and prepare public officials and staff for press briefings and identify questions and answers, provide bullet points; manage potential VIP attendance; set-up hotlines and rumor control as needed.	Start: On alerting of Public Information Officer	Stop: On closing of EOC	Purpose: Efficient functioning of public information systemCoordination with Administration and Other EM Agencies: Communicate with administration and public officials, and other Emergency Management Agencies; ensure that administration is kept informed, and that administration requests/priorities are responded to; recommend/initiate Disaster Declaration Process if advisable; communicate and coordinate with other EM Agencies such as EOCs, Incident/Unified Command(s), EPA, JFO. 	Start: On assessment phase of EOC activation	Stop: On closing of EOC	Purpose: Good intergovernmental coordination to optimize responseFinance/Contracts/Documentation: Ensure authority for spending to operate; populate accounts (e.g., surge account), address legal issues (e.g., property damage, worker’s compensation); initiate/negotiate contracts and ensure compliance; track expenses and reimbursables and maintain chronology of all incident events.	Start: On activation	Stop: On completion of recovery phase	Purpose: To maintain financial accountability and recovery reimbursementAfter Action Reporting: Derive lessons learned, hold formalized debriefings, and develop/implement corrective action plans; provide data, documentation, and reports including final report to management. Recovery: Follow recovery plan(s); ensure all recovery tasks completed or appropriately transitioned; ensure completion of contracts; continue to inform/educate public as required; transition of responsibilities to local jurisdiction or Joint Field Office if appropriate.We have identified eleven SCs that support the attainment of the MECs. Some of these SCs support a specific MEC, while others support multiple MECs:  Multi-Tasking – Correctly prioritizes and handles the requirements of multiple tasks simultaneously.Stress management – Maintains emotional stability and performs effectively under stress, and manages others to limit stress.Situational Awareness: Ability to assimilate information to develop and maintain a big picture perception of current activities and events scaled to individual responsibilities; ability to recognize deviations from plan or expected course of events. Decision Making/Time Management – Prioritizes and makes timely and appropriate decisions based on available information/constraints.Information Management – Recognizes, filters, assimilates, and prioritizes gathered information. Documents and annotates key information, captures events and uses notes effectively both real-time and for later briefing.Solution Focus: Identifies and balances needs and requirements of various parties and obtains consensus on solution. Perseverance: Ability to stay engaged to accomplish mission. Interpersonal Communication and Influence: Ability to communicate in clear, concise, and timely manner; ability to persuade/influence others.Teamwork: Ability to work well with others; follower-ship.Management: Ability to assign and delegate tasks, resolve conflict, assess performance, and take corrective actions as required.Planning: Ability to create, communicate and adapt plans; develop contingent courses of action.There are 39 identified Knowledge statements, and 30 Skills. For each position in the EOC, the level of knowledge or skill required for the position is rated based on the following scale:Basic (B):Has the minimum knowledge or skill expected of less experienced personnel to perform the job Intermediate (I): Understands important details and is currently applying the knowledge or skill but may need to seek direction and guidanceAdvanced (A):Exhibits expert knowledge or skill and serves as a source of information for the knowledge or is able to assist others in developing the skill  Not Applicable (N/A):  The knowledge or skill is not applicable for the positionTable 1: Minimum knowledge and skill requirement standardsSome example Knowledge statements are:Accounting - Understand accounting procedures and standardsAcronyms - Know meaning of EM-related acronymsUnsolicited assets - Understand how to use/manage unsolicited assets and organizationsAppropriate contacts - Know appropriate individuals, organizations, and agencies to  contact, how to contact themCommunity Support - Understand distribution and re-supply of fuel, food, and other resourcesSome example Skills are:Computer and communication technology skills - Operate computers and appropriate software (e.g., Outlook, EOC-specific software, cell phone, radio)Debriefing/wrap up - Gather critical information, determine what still needs to be doneDiplomacy in dealing with external resources - Show diplomacy in dealing with external resources/organizations (e.g., Red Cross, unsolicited assets, National Guard)Follow-up - Ensure that own and delegated tasks are completed and events in field occur as expectedForecasting - Predict how incident will unfoldThe minimum requirement ratings are illustrated below:EOC KNOWLEDGEEOC DIRChiefsESFLogPlanOpsAdm/ FinPIO123456789101112131415AccountingUnderstand accounting procedures and standardsIIIIA BBBIBBBIBBBBBBABAcronymsKnow meaning of EM-related acronymsAAAAAABBBIIBBBIBBBBBIUnsolicited assetsUnderstand how to use/manage unsolicited assets and organizationsAAAAAABBAIBAAIIIIBBIBTable 2: Illustration of minimum knowledge requirements across EOCA few example Experiences derived for the EOC were:ExperiencePurpose or ValueWorked in an EOC previously as an ESFExposes to the dynamics of the operationParticipated in an annual LEPC drillFirst hand knowledge of proper LEPC procedures (field skills)An actual natural disaster (e.g., flood) as an EOC memberPersonal experience for back-ground knowledgeEOC activation and set-upKnowing how the EOC is set upAn actual natural disaster (e.g., flood) as a low-level responderUnderstand the role of a responderTable 3: Example EOC ExperiencesB. How MEC process adapted to meet special situational constraints/opportunitiesAs mentioned earlier, the individuals that would be asked to fill the individual functions within the EOC during an emergency do not work for the EOC full-time and typically have had very limited exposure to the EOC. This proved to be a challenge during the EOC MECS process in two ways – scheduling the SMEs and finding SMEs that had enough exposure to the EOC to provide meaningful feedback. Unlike the USAF environment, where the SMEs were typically working full time in their roles and could invest more of their time in the workshops, the EOC SMEs were typically available for a limited amount of time during the workshops in order to minimize the time away from their regular jobs. For example, in workshop 2, the majority of the SMEs were only scheduled for a three hour block for each morning of the two-day workshop. Thus, the composition of the SMEs during the workshop continually changed based on who was available. In addition, because of the lack of SMEs during the afternoon of the second day, we needed to schedule a follow-up session to complete the workshop 2 tasks. We were able to address both the SME availability issue and the SME expertise issue by utilizing a small core of SMEs that had exposure to the wide variety of functions in the EOC to supplement the function-specific SMEs that were only available for limited amounts of time. This small core of SMEs was available for either all or for the majority of the time in the workshops. They provided continuity during the workshops and were able to provide feedback on EOC positions that were not represented by SMEs in the workshops. In a departure from the work we did with the USAF, this core group of SMEs was drawn from key positions in the field responder team, not from the EOC itself. This choice was made due to the sporadic, irregular nature of the use of the EOC. As “customers” of the EOC, the field responders had more experience working with an EOC than most of those individuals that have worked in an EOC. In addition, the field responders had a broader knowledge of the EOC than individuals who would fill a specific functional role in the EOC. Thus, our approach was to use this core team of SMEs and supplement them with SMEs that have had functional experience within an EOC to provide a fuller perspective. Another important consideration in working with the EOC was the fluidity of the EOC structure itself. During the initial planning session, it became clear that because of the evolution of the federal NIMS model that the current structure of the Montgomery County EOC may be different at the end of the three year project. Since an important goal of the overall project is the generalizability of the EOC MEC work to EOCs in counties other than Montgomery County, we chose to start the MEC process by working with the SMEs to identify an EOC structure that would be consistent with the direction of the federal model. As a result, we applied the MEC process to a combination of positions within the EOC that currently exist as well as new EOC positions that currently do not exist. Because we were focusing on a single county, it did not make sense to do a survey after the second workshop. The limited size and limited exposure to the EOC of the target population for the survey did not warrant the use of a survey. If the project is expanded to other EOCs (e.g., at the local, county, and state level), then a survey would be an effective way to gather additional feedback on the MECS. In a departure from our previous MEC work, we did not utilize a COMMAND workshop as the final step of the MECS process. Instead we chose to have a final meeting with the SMEs to discuss and validate the MEC findings. In addition, we chose to invite political leaders to the final meeting. As a county agency, the EOC is embedded in a political environment, and in order to build the necessary political support in the county government to ensure the overall success and ongoing support for the project, we felt it was important to involve key political leaders early in the process. These political considerations can help ensure the long term viability of the project in the civil sector were not as much of an issue in the USAF environment. In terms of the actual elements of the MEC model, the results for the EOC are much like those derived for military applications, at least in terms of number of MECs, KSs, SCs, and Experiences.  Of course, the particular nature of the MECs and supporting elements for the EOC reflect its particular nature and characteristics.V. ConclusionsLesson learned from Hurricanes Katrina and Rita are “… important to all levels of government, but should be of prime interest to the Department of Homeland Security, as it continues to develop its organizational structure and refine its procedures for disaster response. …  In retrospect, command post exercises would have helped to identify responsible actors for critical elements of the plan, as well as deficiencies in planning and resources.” Lawrence P. Farrell Jr., President, National Defense Industrial Association, Nov 2005As Farrell points out in the quote above, command post (that is, EOC) exercises can be of great benefit in assuring the disaster readiness of a municipality, county, state, or county. This is part of the reason that the US Air Force Research Laboratory awarded a one year contract to Alion Science and Technology to develop the initial concept and integration architecture to provide an area image and logistics based all hazards emergency response training capability for Montgomery County and the USAF. The MECs are part of that effort – to assist in the development of EOC training. Also, it was of interest to discern the degree to which MECs, hitherto used in a military setting, could be applied to a civilian Command and Control – type entity. Early results, as documented in this paper, suggest that the MECs can be usefully employed in such a situation, adapting somewhat to meet particular circumstances, but not losing the core of what make MECs useful: the clear, contextualized description of work that enables operators, training developers, and decision-makers, to create a training environment that appropriately and effectively focuses on work under real-world constraints and conditions. VI. ReferencesBush, G.W. (2005). President discusses hurricane relief in address to the nation. Retrieved June 28, 2007 from http://www.whitehouse.gov/news/releases/2005/09/20050915-8.htmlFarrell, L.P.Jr (2005). Preparation is key to disaster response. National Defense Industrial Association. Retrieved June 28, 2007 from  HYPERLINK "http://www.ndia.org/Template.cfm?Section=Presidents_Corner2&Template=/ContentManagement/ContentDisplay.cfm&ContentID=11078" http://www.ndia.org/Template.cfm?Section=Presidents_Corner2&Template=/ContentManagement/ContentDisplay.cfm&ContentID=11078Jain, S. & McLean, C.R. (2003). A framework for modeling and simulation for emergency response. Proceedings of the 2003 Winter Simulation Conference. Retrieved June 26, http://www.informs-sim.org/wsc03papers/132.pdfJain, S. & McLean, C.R. (2006). Integrated gaming and simulation architecture for incident management. National Institute of Technologies, NISTR7295.  Retrieved June 28, 2007 from  HYPERLINK "http://www.mel.nist.gov/msidlibrary/doc/NISTIR_7295.pdf" http://www.mel.nist.gov/msidlibrary/doc/NISTIR_7295.pdfMontgomery County Office of Emergency Management (MCOEM), (2003). Montgomery County Emergency Operations Plan. Ohio Homeland Defense Strategic Goals (2006). Ohio Homeland Security Strategic Plan.  Retrieved 24, 2007 from  HYPERLINK "http://www.homelandsecurity.ohio.gov/State%20Strategic%20Plan.pdf" http://www.homelandsecurity.ohio.gov/State%20Strategic%20Plan.pdfPollack, E., Falash, M., Ingraham, L. & Gottesman, V. (2004). Operational analysis framework for emergency operations center preparedness training. Proceedings of the 2004 Winter Simulation Conference. Retrieved June 24, 2007 from http://www.informs-sim.org/wsc04papers/105.pdfSticha, P.J., Campbell, R.C., & Knerr, C.M. (2005). Individual and collective training in live, virtual and constructive environments-training concepts for virtual environments. Human Resources Research Organization, United States Army Research Institute for the Behavioral and Social Sciences. Retrieved June 23, 2007 from  HYPERLINK "http://www.hqda.army.mil/ari/pdf/sr2002-05.pdf" http://www.hqda.army.mil/ari/pdf/sr2002-05.pdfPAGE  PAGE  5Applying the MECs Development Process to an EOC