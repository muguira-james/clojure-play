Advancing the Federation Development and Execution Process (FEDEP)for Simulation Based Acquisition (SBA)Katherine L. Morse, PhDSAIC HYPERLINK "mailto:KATHERINE.L.MORSE@saic.com" Katherine.L.Morse@saic.comPaul N. LoweThe Boeing Company HYPERLINK "mailto:Paul.N.Lowe@boeing.com" Paul.N.Lowe@boeing.comABSTRACT:  Future Combat Systems has been engaged in a mapping of the Federation Development and Execution Process (FEDEP) to the Spiral Lifecycle Model(SLM) for one incremental phase in a multi-phase lifecycle to show how these two paradigms can work together, but more importantly, to illuminate the need to treat event federations as first-class objects with their own program artifacts and resources.  The tailored FEDEP will be shown to lay out the basis for identifying critical dependencies.  Importantly, this tailoring shows a mapping between event milestones, and the FEDEP.The FEDEP was designed for individual events where the program is focused on acquiring the federation and the results of an individual federation execution.  We’re focused on acquiring multiple systems, neither the federation nor the results of a single federation execution.  As such, our use of the FEDEP can only address individual events.  There must be an overarching approach that coordinates the relationship between FEDEP ‘iterations’, e.g. the reuse of activities and outcomes that don’t need to be repeated.  To achieve such a coordinated approach, we’re performing both top-down and bottom-up reviews.  The top-down review looks at program planning conferences and anchor points as sources of inputs to the event federations.  The bottom-up review looks at the current availability of FEDEP artifacts. The top-down and bottom-up review results are stitched together through a mapping containing the planning conferences, anchor points, and FEDEP inputs, providing a useful tool for managing the planning conferences, especially the exit criteria.  The final outcome of the mapping is a list of gaps in our federation engineering approach and recommendations for filling those gaps.  This paper reports the results of that analysis, and makes preliminary recommendations for the use of FEDEP in large SBA programs that build and execute multiple federations. Introduction	Learning lessons and documenting them throughout the lifecycle of a program phase in an iterative SBA program, rather than just at the end of the work, provides a source of reference for more well-informed processes to be applied to similar tasks in later program phases and in other programs.  When decisions are made formal throughout the lifecycle, it is not sufficient to merely record the decisions as part of the team’s engineering notebook, but including the processes by which those decisions were made invariably proves of meritorious worth when the original decision makers are no longer available, e.g. the selection of some federate over another to meet the requirements of a particular iteration.  Applying this same concept to the application of the FEDEP [1] over a series of phases within a program not only creates a collection of guidance for future phases and programs, but over time serves to mitigate the cost of repeating work that has been performed previously as the FEDEP is utilized for multiple events within a program.Tailoring the FEDEP to capitalize on repeated work when creating multiple federations for similar purposes, mitigating cost, is a multi-step process.  In an earlier paper [2], we demonstrated work done to map the FEDEP from a top-down perspective, mapping the FEDEP to the anchor points of an SLM [3].  We were able to show a reasonable mapping in place that identified reused and modified artifacts.  In this paper, we have done a bottom-up mapping of the FEDEP inputs, outcomes, and recommended tasks to the anchor points of an SLM.  In the process, we completed the mapping all the way back through the SLM anchor points.  A result of this tailoring work is the identification of the points at which the FEDEP touches the System-of-Systems (SoS) systems engineering processes.  The other key result of this mapping is identification of those FEDEP steps at which an iterative SBA program can expect to achieve efficiencies through reuse of artifacts from preceding iterations.FCS Guidance on the ProcessTo understand the original motivation for this effort, we provide the original program guidance we received:Identify the program current artifacts and activities consistent with the FEDEPBoth bottom-up (from FEDEP activities and artifacts) and top-down (from planning conferences and anchor points)Identify obvious gapsIdentify POCs for verifying the gap analysisMake recommendations for filling the gaps to ensure successful federation development, integration, and executionImprove the process by incorporating lessons learned into the next iterationAlign with Systems Engineering Requirements Flowdown effortThe Modeling & Simulation Office is not solely responsible for each event FEDEP, only for management of the FEDEP itself and artifacts/tasks specifically identified.This really is a mapping, i.e. not only do inputs come in from multiple sources, but outputs go out to multiple sinks. The FEDEP was designed for individual events where the program is focused on acquiring the federation and the results of an individual federation execution.  We’re focused on acquiring multiple systems, neither the federation nor the results of a single federation execution.  As such, our use of the FEDEP can only address individual events.There must be an overarching approach that coordinates the relationship between FEDEP “iterations,” e.g. the reuse of activities and outcomes that don’t need to be repeated.While the effort is specifically targeted at meeting FCS’ systems engineering needs, this paper reports results that are broadly applicable to iterative SBA programs, without addressing specifics of the FCS.Findings from the Bottom-Up MappingBecause FCS is such a large program and the M&S activities were not originally aligned with the FEDEP, this bottom-up mapping process was very time consuming and required considerable attention to detail.  To simplify this process, we agreed that content identified as being in a single artifact in the FEDEP does not necessarily have to be in a single FCS artifact.  Furthermore, if important FEDEP content is identified as missing, we will endeavor to include it in an existing document rather than creating a completely new document, at least where this is logically feasible.Without exception, the most important thing we discovered is that the FEDEP should be applied from the very beginning.  While this seems obvious to us as M&S practitioners, it’s not always obvious to program managers who don’t have experience with the unique requirements for M&S and building a federation.  This is not to say that the FEDEP should be a process outside the program systems engineering processes, just the opposite in fact.  It should be an integrated engineering process just as security engineering is.It’s not enough to record the decisions that are made. We must document the processes by which decisions are made because we may have to revisit those decisions later, e.g. selection of existing federates to meet the requirements of a particular iteration. Many of our “plans” tell what we will do, but not how we will do it.  For federations that are only going to be built and executed once, this isn’t as much of an issue.  For an iterative program, the process must be repeatable in later iterations to effect increasing efficiency across iterations.Program level guidance needs to be translated into executable, M&S specific-guidance.Most of the testing plans focus on testing the SoS using the federation, but there is very little information on testing the federation.  This is another key finding for the FEDEP within an SBA program and is consistent with our position that the federation itself needs to be a “first-class object.”  The tested federation, the output of activity 5.3, must be a deliverable itself complete with testing plans, test criteria, test reports, and problem reports/change requests.Consistent with the lack of recognition of the federation as a first-class object is the absence of several outcomes and tasks that are federation-specific including:Integration plan component of the development and execution planNeeds statementFederation agreements Implemented federation infrastructureAgreements on authoritative data sourcesThere should be a mechanism for viewing a consolidated collection of the federation requirements separate from SoS requirements.  To maintain correct configuration management and requirements traceability, this mechanism is best created through a requirements management tool.  It could be managed via separate documents with traceability from the federation requirements document to the SoS requirements document, but the risk of inconsistency with this approach is very high. In addition, there should be continuous requirements management because delays in delivery of operational software may require filling in with M&S, but that too takes time.Several documents are repetitive of processes and products in other documents, causing a proliferation of documents in the mappings without significant content addition.  This is a general systems engineering issue resulting from the size of the program and not completely confined to M&S.  However, the lack of an M&S thread through the program document tree exacerbates the issue for M&S.Recognize where M&S is the same and where it’s different from your operational software.  For example, non-operational M&S may not need as rigorous testing as operational software, but the same CM and documentation standards probably apply.  Embedded M&S is operational software and should be treated as such.  However, consider the global implications of relaxing standards for M&S because it may have broader implications, e.g. reducing the level of testing for M&S may reduce your ability to fully test operational software that depends on M&S.M&S can solve your representation shortfalls, not your interface ones.  M&S has to have interfaces too, preferably the same ones used for operational systems so operational code can be dropped in readily later.Preliminary Findings from the Top-Down MappingTying into the System-of-Systems Engineering ApproachesOne of the key goals of this paper was to identify how the FEDEP might be used in large SBA programs such as FCS.  Key to this is understanding how systems engineering processes interact.  We have begun a detailed refinement of the top-down mapping, specifically mapping the SLM anchor points to recommended tasks and outcomes. One of the results of this effort is the realization that the anchor points don’t produce outcomes (with one or two exceptions); they produce concurrence with outcomes produced by the FEDEP.  Therefore, the anchor points represent gating conditions or controls on the FEDEP.  The updated top-down mapping will reflect this new understanding.  We expect to discover more as we complete the top-down mapping.  However, we have identified the following concurrence points with activity outcomes (and a few recommended tasks):1.1 - Identify User/Sponsor NeedsAny known constraints which may affect how the federation is developed and executed (e.g., due dates, security requirements).1.2 - Develop ObjectivesAssess federation feasibility and risk.Define and document an initial federation development and execution plan.Develop initial planning documents, including:  Federation development and execution plan showing an approximate schedule and major milestones.2.1 – Develop scenario(s)Federation scenario(s)2.2 - Develop federation conceptual modelFederation conceptual model.2.3 - Develop federation requirementsFederation requirements.Federation test criteria.3.2 - Prepare federation designFederation designFederation architecture (including supporting infrastructure design).Implied requirements for federate modifications and/or development of new federates.3.3 – Prepare planIntegration plan.4.1 - Develop FOMFOMFED/FDD5.3 – Test FederationTested (and if necessary, accredited) federation7.2 - Evaluate and feedback resultsLessons learned.Final report.Reusable federation products.As we developed this list, we were struck by how closely it aligns with our findings, see Section 2.  For example, finding 2, translating program level guidance into M&S specific guidance, touches this list at nearly every one of the preceding points.  These all represent points where the federation touches the SoS, but where M&S specific guidance is needed, e.g. where the federation scenario has to align with the scenario for the SoS under test, but the federation scenario may require additional detail not provided in the program scenario, or where the federation integration plan clearly has to align with the overall program plans.  Finding 3 clearly touches federation test criteria and the tested federation.  Finally, finding 5 is related to activities 2.3 and 3.2.Level of Rework MetricsThe other key goal of this paper was to identify where efficiencies might be achieved in the FEDEP in subsequent iterations through the lifecycles of an iterative SBA program. We reviewed all the recommended tasks to determine how much relative effort would be required in iterations after the first one.  We assigned values to each task according to the following scale:1 (green) - little to no rework in subsequent iterations. Either program level documents remain essentially unchanged or a program process is already in place that minimizes effort. 2 (yellow) - some rework, but not a substantial engineering effort.  Additional or updated entity or scenario representations necessitate engineering effort that ripples throughout federate and federation engineering. 3 (red) - significant rework.  The actual federate and federation engineering required to implement new functionality that represents the core of the iteration intent.Table 1 shows our specific assignment for each recommended task.  Not surprisingly, step 1 is pretty easy because it represents the program level decisions, most of which were made in the first iteration.  Note that most of the hard work indicated in red occurs in steps 2 – 4 because that’s where the federate and federation engineering really happens.  Most of the rework in steps 5 – 7 is the ripple effect of changes to federate and federation re-engineering, although the effort is declining again in step 7 due to presumed reuse of data analysis methods.  Program processes mitigate the amount of rework, but changes still have to be documented and tested. REF _Ref43889440 \h  \* MERGEFORMAT Figure 1 through  REF _Ref43889446 \h  \* MERGEFORMAT Figure 8 illustrate the summary information for each step and for the FEDEP overall.  While they’re not individually exciting, they do track with our initial hypothesis that subsequent iterations should be less work due to reapplication of artifacts and processes defined in preceding iterations.  One final note of caution about these results:  the metrics are a straight average, so the amount of rework necessary for one task in an activity may overwhelm the lack of rework necessary for another, e.g. defining representative vignettes in 2.1, “Develop scenario,” vs. choosing the appropriate tools for development of the scenario.  Such detailed assessments are really only possible for a specific iteration on a specific program.  A detailed analysis of several such programs might produce a better general quantization, but such an analysis is outside the scope of this effort.   It is encouraging to note that the successful execution of the FEDEP in the first iteration resulted in none of the steps required extensive rework in subsequent iterations; hence, no blocks are colored red.Figure  SEQ Figure \* ARABIC 1.  Step 1 - Define Federation ObjectivesFigure  SEQ Figure \* ARABIC 2.  Step 2 – Perform Conceptual AnalysisFigure  SEQ Figure \* ARABIC 3.  Step 3 – Design FederationFigure  SEQ Figure \* ARABIC 4.  Step 4 – Develop FederationFigure  SEQ Figure \* ARABIC 5.  Step 5 – Plan, Integrate, and Test FederationFigure  SEQ Figure \* ARABIC 6.  Step 6 – Execute Federation and Prepare OutputsFigure  SEQ Figure \* ARABIC 7.  Step 7 – Analyze Data and Evaluate ResultsFigure  SEQ Figure \* ARABIC 8.  FEDEP Top-Level ViewNext StepsWe had hoped to complete the top down mapping in time for this paper, but the bottom-up mapping proved to be more time consuming than anticipated.  This is yet another indication that you should apply the FEDEP from the beginning, avoiding this very time consuming process. The final top-down mapping will also include the relationship to the M&S-specific guidance for planning conferences listed below.Initial Planning ConferenceDefine the scenario:  Terrain, ORBAT and Campaign PlanDefine command and control (Exercise Control Cell)Define manning for exercise players, response cells, control and supportDefine C4I requirementsDevelop the training planEstablish database milestones and begin buildDetermine real-world logistical supportDraft Memorandum of Agreement (MOA) or Pro FormaSchedule supporting training events:Site survey. (Pre-MPC)Database builds (including ‘Good Idea Cut-off Time’)Scenario Development (Pre-MPC) and scripting (Post-MPC)‘Train-the-trainer’ for the model and ABCS (Post-MPC)Joint and outside agency participationMid (Main) Planning ConferencePresent coordinated Exercise Plan to the exercise director and senior reps from key organizations:training objectivesexercise objectivesorganizations involved and roles/responsibilitiesexercise directive (specified tasks and coordinating instructions)planning timeline, tasks required and tracking statusscenario progress, ‘Road-to-War’, inject requirementstechnical plan, database requirements, simulation workarounds, budget and contract requirementslogistical supportcell structure and manning requirementscommunications planO/C, AAR and collection planIdentify cell OICsFinal Planning ConferencePresent final coordinated plan Publish FRAGO if requiredReview MOA milestones, update statusResolve outstanding issuesReview training objectivesReview manningReview conduct of the exercisePublish Exercise Control GroupReview exercise budget versus changes to projected costsCell OICs present and provide backbriefsReview training requirements (O/C, unit, operator) prior to exerciseOPFOR reviewFinally, it is still our intention to consolidate all of the lessons learned from both the bottom-up and top-down mappings, primarily the latter, to provide guidance to the FEDEP update on “hooks” that should be introduced to the FEDEP to support iterative SBA programs such as FCS.RecommendationsPrevious RecommendationsIn our previous paper, we provided the following recommendations for the FEDEP update.  We include them here for completeness.One of the recommended tasks in activity 3.3, “Prepare plan,” is to revise test plans.  However, there is no test plan input but rather test criteria.  This may be a case of inconsistent wording or may indicate the need for a recommended task to prepare the test plan based on the test criteria. Although the federation requirements are an input to step 3, “Design federation,” they aren’t an input to activity 3.1, “Select federates.” Activity 1.1 has a recommended task to analyze program objectives.  Federation objectives are developed in activity 1.2.  There appear to be two disconnects here.  The program objectives aren’t identified as an input to activity 1.1 although they’re referenced.  It also seems logical that the program objectives should be an input to the federation objectives developed in activity 1.2.Activity 2.1, “Develop scenario,” lists federation conceptual model as a potential input.  However, the first conceptual model is an output of activity 2.2, “Develop federation conceptual model.”  This may be an error, or it might have been intended to indicate existing conceptual models.  If it is the latter, it should also be included in figure 4 which it isn’t currently.New RecommendationsCompleting the bottom-up mapping forced us to look back and forth through all of our artifacts and processes, and try to map them to FEDEP outcomes and tasks.  As a result, we identified the following additional questions and inconsistencies.One of the recommended tasks in activity 1.2, “Develop objectives,” is assess federation feasibility and risk.  However, there is no obvious place where the results of this task are recorded.Activity 1.2 also has as an outcome an initial planning document including a federation development and execution plan showing an approximate schedule and major milestones.  The federation development and execution plan isn’t listed as an output until activity 3.3, “Prepare plan.”  In our experience, producing this initial plan at this point is a good idea, so it should probably be listed here explicitly.Federation test criteria are listed in the outcomes of activity 2.3, “Develop federation requirements,” but the recommended tasks for this activity don’t specifically include their development.We recommend splitting the single outcome of activity 3.1, “Select federate” into two separate outcomes:  federate selection rationale (criteria) and the list of selected federates with their scores against the criteria.  In an iterative development environment such as FCS, selection criteria may change between iterations, so a record of both the decision and the decision process in the preceding iteration is critical to efficient iteration on this decision.Activity 3.2, “Prepare federation design,” includes a recommended task to refine the initial security risk assessment and concept of operations.  Where are the initial versions of these artifacts?  Should they be included in the initial planning documents from activity 1.2, “Develop objectives?”  If so, activity 1.2 should include a task to produce them.  There is currently a suggestion that these artifacts were intended to be in activity 1.2 because there is a task to assess federation feasibility and risk, and an outcome for identification of security needs.  These relationships may just need to be clarified and more consistent language used.Related to the preceding comment, activity 5.1, “Plan execution” includes a task to identify risks and take action to reduce them.  There is no associated activity outcome.  Perhaps a risk/security/feasibility document should be identified, in which case this task would update that document.References[1]	Robert Lutz, Roy Scrudder, Reed Little, and Katherine L. Morse: IEEE 1516.3: The HLA Federation Development and Execution Process (FEDEP), Proceedings of the Spring 2003 Simulation Interoperability Workshop, March 2003.[2]  Paul N. Lowe, Katherine L. Morse, Gary Fuller, and Mark Riecken: Enhancing the Simulation Based Acquisition Process Using a Spiral Lifecycle Model based Federation Development and Execution Process, Proceedings of the Spring 2007 Simulation Interoperability Workshop, March 2007. [3]  Boehm, Barry, et. al.: Spiral Acquisition of Software-Intensive Systems of Systems, April 19, 2004.BiographiesDR. KATHERINE L. MORSE is the FCS M&S chief software engineer. She received her B.S. in mathematics (1982), B.A. in Russian (1983), M.S. in computer science (1986) from the University of Arizona, and M.S. (1995) and Ph.D. (2000) in information & computer science from the University of California, Irvine. Dr. Morse has worked in the computer industry for over 20 years, specializing in the areas of simulation, computer security, compilers, operating systems, neural networks, speech recognition, image processing, and engineering process development. Her Ph.D. dissertation is on dynamic multicast grouping for data distribution management, a field in which she is widely recognized as a foremost expert. PAUL N. LOWE is the FCS integration simulation & test deputy chief software engineer.  He received his B.S. in mathematics (1979), and his M.S. in geography (1984) from the University of California, Riverside.  Paul has worked in the computer industry for over 30 years, specializing in the areas of high performance computing, simulation, image processing, geographic information systems, database management, and knowledge management. Table  SEQ Table \* ARABIC 1.  Rework MetricsFEDEP StepsDescriptionIteration Rework Metric1Define Federation ObjectivesDefine and document a set of needs that are to be addressed through the development and execution of an HLA federation and to transform these needs into a more detailed list of specific federation objectives11.1 Identify User/Sponsor NeedsDevelop a clear understanding of the problem to be addressed by the federation 1.1.2Recommended tasks11.1.2.1Identify program objectives that motivate federation development11.1.2.2Identify available resources and known development and execution constraints21.1.2.3Document this information in a needs statement11.2 Develop Objectives  1.2.2Recommended Tasks1.2.2.1Analyze the needs statement.11.2.2.2Assess federation feasibility and risk.21.2.2.3Define and document a prioritized set of federation objectives, consistent with the needs statement.11.2.2.4Meet with the federation sponsor to review the federation objectives, and reconcile any differences.11.2.2.5Define and document an initial federation development and execution plan.21.2.2.6Identify potential tools to support the initial plan.12Perform Conceptual AnalysisDevelop an appropriate representation of the real world domain that applies to the federation problem space and to develop the federation scenario.22.1 Develop scenario(s)Develop a functional specification of the federation scenario. 2.1.2Recommended Tasks22.1.2.1Choose the appropriate tool(s)/technique(s) for development and documentation of the federation scenario(s).12.1.2.2Identify, using authoritative domain information, the entities, behaviors, and events that need to be represented in the federation scenario(s).32.1.2.3Define one or more representative vignettes of federation events that, once executed, will produce the data necessary to achieve federation objectives.32.1.2.4Define geographic areas of interest.22.1.2.5Define environmental conditions of interest.22.1.2.6Define initial conditions and termination conditions for the federation scenario(s).32.1.2.7Ensure that an appropriate scenario (or scenario set) has been selected, or if new scenario information is to be developed, ensure with the stakeholder that the new scenario(s) will be acceptable.32.2 Develop federation conceptual modelProduce a conceptual representation of the intended problem space based on their interpretation of user needs and federation objectives. 2.2.2Recommended Tasks22.2.2.1Choose the technique and format for development and documentation of the federation conceptual model.12.2.2.2Identify and describe all relevant entities within the domain of interest.22.2.2.3Define static and dynamic relationships between federation entities.32.2.2.4Identify events of interest within the domain, including temporal relationships.32.2.2.5Document the federation conceptual model and related decisions.22.2.2.6Working with federation stakeholders, verify the contents of the conceptual model.22.3 Develop federation requirementsAs the federation conceptual model is developed, it will lead to the definition of a set of detailed federation requirements. 2.3.2Recommended Tasks22.3.2.1Define required behaviors of federation entities and required characteristics of federation events.32.3.2.2Define requirements for live, virtual, and constructive simulations.32.3.2.3Define human or hardware in-the-loop requirements.22.3.2.4Define federation performance requirements.22.3.2.5Define federation evaluation requirements.22.3.2.6Define time management requirements (real-time versus slower or faster than real-time).12.3.2.7Define host computer and networking hardware requirements.12.3.2.8Define supporting software requirements.12.3.2.9Define security requirements for hardware, network, data, and software.12.3.2.10Define federation output requirements, including requirements for data collection and data analysis.22.3.2.11Define execution management requirements.12.3.2.12Ensure that federation requirements are clear, unique, and testable.22.3.2.13Demonstrate traceability between federation requirements and program objectives, federation objectives, federation scenario(s), and federation conceptual model.22.3.2.14Document all federation requirements.23Design FederationProduce the design of the federation that will be implemented.23.1 Select federatesdetermine the suitability of individual simulation systems to become members of the federation. 3.1.2Recommended Tasks13.1.2.1Define criteria for federate selection.13.1.2.2Determine if an existing, reusable federation meets or partially satisfies the federation requirements.23.1.2.3Identify candidate federates, including predefined federation participants.13.1.2.4Analyze the ability of each candidate federate to represent required federation entities/objects and events.23.1.2.5Review federation purpose and objectives with respect to selected federates and availability of resources.13.1.2.6Document rationale (including assumptions) for selection of federates.13.2 Prepare federation designPrepare the federation design and allocate the responsibility to represent the entities and actions in the federation conceptual model to the federates. 3.2.2Recommended Tasks23.2.2.1Analyze selected federates and identify those federates that best provide required functionality and fidelity.23.2.2.2Allocate functionality to selected federates and determine if federate modifications are necessary and/or if development of a new federate(s) is needed.23.2.2.3Develop design for needed federate modifications.33.2.2.4Develop design for new federates (as necessary).33.2.2.5Ensure that earlier federation decisions do not conflict with selected federates.23.2.2.6Evaluate alternative federation design options, and identify the design that best addresses federation requirements.33.2.2.7Develop design for federation infrastructure.23.2.2.8Develop design of supporting databases.33.2.2.9Estimate federation performance, and determine if actions are necessary to meet performance requirements.23.2.2.10Analyze, and if necessary, refine initial security risk assessment and concept of operations.23.2.2.11Document the federation design.23.3 Prepare planDevelop a coordinated plan to guide the development, test, and execution of the federation. 3.3.2Recommended Tasks23.3.2.1Refine and augment the initial federation development and execution plan, including specific tasks and milestones for each federate.23.3.2.2Identify needed federation agreements and plans for securing these agreements.23.3.2.3Develop approach and plan for integration of the federation.23.3.2.4Revise (as necessary) VV&A and test plans.23.3.2.5Finalize plans for data collection, management, and analysis.23.3.2.6Complete selection of supporting tools, and develop plan for acquiring and installing the tools.13.3.2.7Develop plans and procedures for establishing and managing configuration baselines.13.3.2.8Translate federation requirements into plans for federation execution and management.33.3.2.9If required, prepare design of experiments.24Develop FederationDevelop the FOM, modify federates if necessary, and prepare the federation for integration and test (database development, security procedure implementation, etc.).24.1 Develop FOMUsing federates identified to meet federation requirements, and the allocation of responsibilities for representation of entities and actions in the federation conceptual model across these federates, the FOM is developed to support the data exchanges required among the federates to meet the federation objectives. 4.1.2Recommended Tasks14.1.2.1Choose a FOM development approach.14.1.2.2Identify appropriate OMs or OM subsets for reuse.14.1.2.3Review applicable data dictionaries to identify relevant OM elements.14.1.2.4Develop and document the FOM using an appropriate tool.24.1.2.5Verify that the FOM conforms to the federation conceptual model.24.2 Establish federation agreementsAlthough the FOM defines and documents the full set of data that is exchanged among federates to achieve federation objectives, there are other operating agreements that must be reached among federate developers and management (prior to implementation) that are not necessarily documented in the FOM. 4.2.2Recommended Tasks24.2.2.1Decide the behavior of all federation objects and how they should interact during execution.34.2.2.2Identify the necessary software modifications to selected federates, not previously identified.34.2.2.3Decide which databases and algorithms must be common or consistent.34.2.2.4Identify authoritative data sources for federate and federation databases.24.2.2.5Build all required federate and federation databases.34.2.2.6Decide how time should be managed in the federation.14.2.2.7Establish synchronization points for the federation.24.2.2.8Establish procedures for federation initiation.24.2.2.9Decide strategy for how the federation should be saved and restored.24.2.2.10Decide how data is to be distributed across the federation.14.2.2.11Transform the functional scenario description to an executable scenario [scenario instance(s)].34.2.2.12Review security agreements, and establish security procedures.14.3 Implement federate designsImplement whatever modifications are necessary to the federates to ensure that they can represent assigned objects and associated behaviors as described in the federation conceptual model. 4.3.2Recommended Tasks24.3.2.1Implement federate modifications to support allocated functionality.24.3.2.2Implement modifications of, or extensions to, the HLA interfaces of all federates.14.3.2.3Develop the HLA interface for non-HLA-compliant federates.24.3.2.4Implement design of new federates as required.34.3.2.5Implement design of supporting databases and scenario instance(s).34.3.2.6Complete HLA compliance certification process (if required).14.4 Implement federation infrastructureImplement, configure, and initialize the infrastructure necessary to support the federation and verify that it can support the execution and intercommunication of all federation components. 4.4.2Recommended Tasks24.4.2.1Prepare integration/test facility, including: Ensure basic facility services (air conditioning, electric power, etc.) are functional and available.14.4.2.2Ensure availability of required hardware/software in integration/test facility.24.4.2.3Perform required system administration functions (establish user accounts, establish procedures for file backups, etc.).24.4.2.4Implement infrastructure design, including: Install and configure required hardware elements.24.4.2.5Install and configure RTI and other supporting software.14.4.2.6Test infrastructure to ensure proper operation.25Plan Integrate and Test FederationPlan the federation execution, establish all required interconnectivity between federates, and test the federation prior to execution.25.1 Plan executionFully describe the federation execution environment and develop an execution plan. 5.1.2Recommended Tasks25.1.2.1Refine/augment federation development and execution plan in the areas of VV&A, test, and security, as necessary.25.1.2.2Assign federation components to appropriate infrastructure elements.15.1.2.3Identify risks, and take action to reduce risks.25.1.2.4Document all information relevant to the federation execution.25.1.2.5Develop detailed execution plans.25.2 Integrate FederationBring all of the federation participants into a unifying operating environment. 5.2.2Recommended Tasks25.2.2.1Ensure that all federate software is properly installed and interconnected.25.2.2.2Establish method for managing known software problems and “workarounds.”15.2.2.3Perform incremental federation integration according to plan.25.3 Test FederationTest that all of the federation participants can interoperate to the degree required to achieve federation objectives. 5.3.2Recommended Tasks25.3.2.1Perform federate-level testing.25.3.2.2Perform federation-level connectivity and interoperability testing.35.3.2.3Analyze testing results (i.e., compare against test criteria).25.3.2.4Review test results with federation user/sponsor.16Execute Federation and Prepare OutputExecute the federation and to pre-process the output data from the federation execution.26.1 Execute federationExercise all federation participants in a coordinated fashion over time to generate required outputs, and thus achieve stated federation objectives. 6.1.2Recommended Tasks26.1.2.1Perform identified executions and collect data.26.1.2.2Manage the execution in accordance with the federation development and execution plan.26.1.2.3Document detected problems during execution.16.1.2.4Ensure continued secure operation in accordance with certification and accreditation decisions and requirements.16.2 Prepare federation outputsPre-process the output collected during the federation execution prior to the formal analysis of the data in Step 7. 6.2.2Recommended Tasks26.2.2.1Merge data from multiple sources.16.2.2.2Reduce/transform raw data.26.2.2.3Review data for completeness and possible errors.27Analyze Data and Evaluate ResultsAnalyze and evaluate the data acquired during the federation execution (Step 6), and to report the results back to the user/sponsor.27.1 Analyze dataAnalyze the derived outputs from Step 6. 7.1.2Recommended Tasks17.1.2.1Apply analysis methods and tools to data.27.1.2.2Define appropriate presentation formats.17.1.2.3Prepare data in chosen formats.17.2 Evaluate and feedback resultsDetermine if federation objectives have been met and to archive reusable federation products. 7.2.2Recommended Tasks27.2.2.1Determine if all federation objectives have been met.27.2.2.2Take appropriate corrective actions if deficiencies are found.27.2.2.3Archive all reusable federation products.2 Databases are indicated in blue We’re indebted to the Army’s FA-57 program for providing this very helpful information.Approved for Public Release, Distribution Unlimited, PM FCS 10 JUL 2007, case 07-194