ProtoCore: A Transport Independent Solution for Simulation Interoperability Keith SnivelyDynamic Animation Systems12015 Lee Jackson Hwy.Suite 200Fairfax, VA 22033HYPERLINK "mailto:ksnively@d-a-s.com"ksnively@d-a-s.comPhilip Grim, IISAIC5971 Kingstowne Village Pkwy.Suite 410Kingstowne, VA 22315HYPERLINK "mailto:Philip.A.Grim@saic.com"Philip.A.Grim@saic.comKeywords:HLA, TENA, interoperabilityABSTRACT: One of the challenges in the modeling and simulation community is the plethora of architectures available upon which to build models.  The most common architectures in use today are the High Level Architecture/Run-Time Infrastructure (HLA/RTI), the Test and Training Enabling Architecture (TENA), and Distributed Interactive Simulation (DIS).  Additionally, the Future Combat System (FCS) program uses a family of communications protocols known as the System of Systems Common Operating Environment (SoSCOE) to communicate between live and virtual systems in its testing facilities.  In order to deal with these differing architectures, typically models are refactored to operate in each individual environment or gateways are created to bridge the varying environments. These solutions add cost to the maintenance and/or overhead in running simulations which require multiple environments to be stood up and bridged.The ProtoCore is an alternative solution which provides an Application Programming Interface (API) and toolset aimed at solving these interoperability problems.  Using a plug-in architecture and code generation, the ProtoCore presents an interface to an arbitrary object model and to transport-independent simulation services.  This allows developers to code to a consistent API and run the resultant application directly on whichever transport architecture is required.  This paper discusses the abstractions and idioms used to present a common interface for running over the varying distributed simulation architectures and the the techniques used to handle the differing capabilities of the underlying distributed simulation architectures.  The paper also presents some of the limitations involved with this type of abstraction layer and tradeoffs with other solutions.  Finally, directions for future study and work are discussed.IntroductionThe number of communication infrastructures used within the Modeling and Simulation community has continued to grow rapidly.  The High Level Architecture (HLA) replaced previous communication infrastructures, DIS and ALSP, as the most widely used middleware for distributed simulation.  However, DIS continues to be used extensively in some areas and even ALSP use continues.  Now HLA, which allowed users to define their own object models, is being challenged by the Test and Training Enabling Architecture (TENA) and soon the OneSAF Objective System (OOS), which support more object oriented programming paradigms.  Each of these infrastructures has its pros and cons, and each is or will be used extensively within certain segments of the Modeling and Simulation community for the foreseeable future. This situation poses real challenges for organizations with subject matter expertise in a given area that need to develop a simulation model for wide use within the community.  Developing the application only to a particular infrastructure and object model will limit the model’s usability.  Nevertheless, resource limitations have often dictated this approach with the view that the model can be ported to other infrastructures later as needed.  This path leads to a situation where more resources are spent on porting the application to various transport protocols rather than improving the model.The MATREX program has found itself in a similar position.  The existing MATREX reference releases have been based upon the DoD HLA 1.3.  These releases are intended to be a framework to support system of systems simulation in varying levels of fidelity.  Users can use this framework to create a simulation specific to their needs and to develop new models.  These models need to support the acquisition process, from concept exploration to test and training.  The environment in which these models will need to run is dependent upon the point it is used within the process.  During initial concept exploration and prototyping, existing simulation infrastructure is based upon HLA and DIS.  In the test and training phases, the distributed environment is based upon the TENA.  The models must be able to operate within each of these environments.  MATREX must then become flexible regarding the communication infrastructure used for a specific application of its tools.The MATREX program developed the ProtoCore in order to address this need.  The ProtoCore is an abstraction system that allows simulation developers to write to a single API and object model, and run the simulation on a variety of network transport subsystems.  The translation to a specific protocol is handled within a plugin library in the same process.  This paper discusses the concepts behind the ProtoCore as well as design decisions and intended use.  We also discuss the tradeoffs of the ProtoCore design with alternative approaches.Design overviewIn the simulation infrastructures currently available, a number of common concepts have emerged.  HLA, DIS and TENA all have concepts for a collection of simulators communicating through a common object model.  Under HLA this is a Federation and under TENA an Execution.  Each also has a representation for a unit of participation within this collection.  In DIS such participants are identified with a site host pair; under HLA as a Federate.  These common abstractions extend to the object models, from persistent objects with state to transient events within the simulation.  In addition, all these infrastructures typically support some form of anonymous publication and subscription mechanism.The ProtoCore captures these abstractions within its API.  The API contains classes which represent both the static concepts, such as a Federate or Federation, and object model specific components.  A code generation system, which takes the object model as input, creates the object model specific components.  These classes are contained within the Application Programming Interface (API) layer.  Instantiations of these classes can represent persistent objects within a simulation, such as a federate or entity, as well as transient events in the simulation, such as an entity state snapshot or interaction.  In addition, translation libraries are generated which allow an application written to the API to run over a particular infrastructure.   REF _Ref140051968 \h Figure 1 shows a diagram of the ProtoCore Architecture.Figure  SEQ "Figure" \*Arabisch 1:  ProtoCore ArchitectureThe rest of this section discusses the components of the ProtoCore.  Application Programming Interface The API is designed to capture the simulation abstractions at a high level, which can be directly used by the application.  The API takes advantage of the features of the programming language itself, such as providing type safety within C++ and Java and using object lifetimes to manage objects within the simulation.  All objects are held using a reference counted pointer mechanism.  Java supports this capability inherently.  In C++, reference counted pointers are used, specifically boost::shared_ptr.  (See HYPERLINK "http://www.boost.org/"http://www.boost.org)  This mechanism allows a reference to be held to the same object in multiple places simultaneously and guarantees the object will exist as long as any reference is held.  This also allows these references to be safely stored in containers and to support polymorphism. Persistent objects automatically instantiate a corresponding object in the simulation upon construction and remove it from the simulation upon destruction.  For example, creation of an object of type Node, which corresponds to a Federate under HLA, will join an application to the simulation.  Similarly, creating an object of a class type defined in the object model instantiates that object within the simulation.  Destroying these objects removes them from the simulation.  In the case of a Node, the application is resigned from the simulation.  In C++, destroying an object is simply handled by letting all references go out of scope.  Java however does not support deterministic destructors since it relies upon a garbage collector to free memory resources.  Thus persistent objects should be destroyed explicitly in order to release the simulation resources.  These strategies reduce the work an application must perform in initializing and cleaning up its simulation and reduces potential for mistakes.Note that in the above example, the entity object requires that the Node object under which that object was created continues to exist throughout its lifetime.  To insure this, a persistent object that requires another to exist will hold a reference to it to make sure the two are not destroyed in an improper order.  For example, the entity object holds a reference to the Node object.  This strategy is colloquially referred to as the "last one out shuts off the lights" policy.  As long as any instantiated persistent object exists, the Node to which it belongs will continue to exist, even if the user application no longer holds a reference to the Node.  This strategy helps prevent order of destruction errors in user applications and reduces the need for error checking and handling code.Transient objects are dealt with in much the same manner as persistent objects.  Typically they are passed around and held using reference counted pointers.  The difference is that they do not depend on the lifetime of any other object and represent a snapshot of the simulation or event.  Such classes include interactions and simulated object states.  These objects can be held as long as desired and will not affect the lifetime of any other objects.  They can even be held and used after the corresponding Node has been destroyed.  The contained data does not change as they represent the state or event that existed or occurred at the time of creation.The design of the API makes it easier to use and less error prone then the native API of some of the supported protocols.  While the TENA API is already object oriented and typesafe, the HLA interfaces are not.  The HLA interfaces, 1.3 or 1516, both require a lot of bookkeeping on the part of applications to maintain handles for object model components and for simulated objects themselves.  The underlying data structures cannot be directly accessed or modified.  The HLA API can also be error prone.  For example, applications must publish attributes before registering objects.  Failure to do so will result in those attributes not published being unowned.  By leveraging the Object Oriented capabilities of C++ and Java, many of these errors can be avoided.  For instance, creating a simulated object in the ProtoCore automatically handles publishing any attributes as necessary.  Un-publishing also automatically occurs when no other objects of that type exist.  Plugin ArchitectureUsing a common API for the various infrastructures allows a model to be executed on supported infrastructures without any code modifications.  However, this still does not ensure an application can be executed without recompiling or relinking.   This feature is provided by the plugin architecture for ProtoCore.  The plugin library is also where all the real translation work is performed.  The ProtoCore API layer is simply a façade to the underlying plugin.  In fact, the vast majority of the API layer is template classes or inline methods.  Since the plugin libraries are loaded at runtime, the application does not choose which protocol to use until runtime.  Thus a single application binary is capable of utilizing any protocol for which a suitable plugin exists.      However, there are some limitations on using a plugin approach.  First, there is no standardized API across operating systems or really any mention of   the dynamic loading and unloading of libraries under C++.  This becomes problematic, especially in the presence of atexit handlers or destruction of scoped static variables created in the plugin.  On Linux, unloading a plugin library which created a scoped static variable can cause a segmentation violation when the program exits and attempts to destroy that variable.  Another problem is that a program will not necessarily hide symbols between two dynamically loaded libraries in a given process.  Thus, two plugin libraries with conflicting symbols cannot be loaded into the same process safely, at least under Linux.  This can limit ProtoCore applicability for gateway applications.Still, the plugin architecture does allow for simpler deployment of models, as only a single binary is needed.  It also provides an upgrade path for the model as it can easily be moved to new infrastructures for which a plugin is available.  Providing for this type of model portability one of the primary goals of the ProtoCore. Alternative ApproachesDesigning applications that will need to run in various environments is, of course, not a new problem.  Ever since DIS began replacing SIMNET, developers have been creating ways to make their models more portable.One of the typical solutions to this problem relies upon a separate gateway process to translate between the model’s native environment and object model into the different environment and object model.  The gateway removes the need to modify the model for each environment and object model.  Generally gateways can handle translating for multiple models simultaneously meaning only a single gateway is needed to translate between each pair of distributed environments.  This also allows models to be written directly upon a single distributed communication protocol without worrying about portability to other architectures.  However, the gateways incur their own overhead in the translation and relay chain for model data.  Data must be read and written at least 2 times when passing from one model to another model in a different environment.  This may produce performance problems between two models which require low latency interaction.  The gateways also become potential bottlenecks within the simulation.  While it is straight forward to write a basic gateway between two environments (with relatively compatible object models), it is difficult to write gateways that scale well and support data segmentation.  Thus if either environment is pushed to higher scales, the gateway can fail.Gateways also tend to complicate the runtime setup and monitoring.  Multiple infrastructures must be configured and initialized.  Debugging connection issues becomes more complex as each transport protocol and implementation has its own communication characteristics.  There are few if any tools to manage such a heterogeneous environment from a single interface.  Should data errors occur, tracing the source can be much more complex as it may be an application in using a different infrastructure or a gateway itself.One way to reduce dependencies on gateways is to take the interface for a given distributed infrastructure and translate it to another infrastructure.  For instance, an implementation for the DoD HLA 1.3 RTI can be developed over an IEEE HLA 1516 RTI implementation.  This approach eliminates the need to modify existing models and allows them to run on the newer infrastructure.  This technique frees up developers of new applications to develop them using the newer infrastructure without sacrificing legacy capabilities.  This approach also offers the efficiency of a single process solution.  Data need only be read and written once to a network and typically allows for easier data segmentation and better scalability.  However, this approach may not work well when the transport protocols are more disparate in capabilities and abstraction levels.  Attaching the HLA API (1.3 or 1516) to TENA would be awkward at best.  TENA uses code generation based upon an object model to present a type safe API that removes many chores required by HLA, such as data marshaling.  This design stands in contrast to the HLA, which has a static API and treats all user data as opaque byte arrays.  Such a translation would require decoding this opaque data and placing it in data structures from the TENA generated code.  Thus data is encoded, decoded, and translated all before getting to the underlying transport protocol.  Any such translation would also be dependent upon which object model was being used in TENA.  HLA also contains services which TENA does not support.  There is no clear separation in the HLA API between these services, most of which are contained on two monolithic ambassador classes.  The translation code can always throw exceptions, but this can present usability problems for the application.  The RTIambassador alone presents the application with at least 111 unique opportunities to get a “not implemented” exception REF _Ref140285451 \n \h 6.However, both the gateway approach and the translating of older infrastructures to newer ones allow new applications to be developed to the newer infrastructure and executed over it.  They also allow legacy application to utilize the newer infrastructure without modification.  This particular feature is not supported by the ProtoCore.  It does nothing to help legacy applications that are no longer under development.  Newer application can interoperate with these applications, but only by running on the older infrastructure.  The strength is the case where there are multiple contemporary environments, such as TENA, OOS and HLA 1516 Evolved.  In this case, it is more difficult to choose which interface will be translated.  The ProtoCore concept will allow the application to run natively in any of the environments without forcing that decision.  However, the need to incorporate legacy models and utilize newer infrastructures will likely mean that a combination of the above approaches will be used in larger simulations.  This fact is evident in such past events as Distributed Test Event 5 (DTE5)  REF _Ref140285329 \n \h 6.Of course, the final word on creating models which can seamlessly interoperate using differing communication infrastructures would come from the Object Management Group (OMG) in the form of Model Driven Architecture (MDA).  Though MDA is term has been used to refer to many differing approaches to software development (including the ProtoCore), MDA is a trademarked standard created by the OMG.  MDA uses Unified Modeling Language (UML) and MOF (Meta Object Facility) in order to build a Platform Independent Models (PIMs) for the domain and Platform Specific Models (PSMs) to translate models written in the PIM to a specific platform and deploy the model.  MDA allows for a rather general definition of a platform, in this case the transport protocols would serve as the platforms.  However, tools which support this methodology remain rare with high learning curves.  These tools also tend to employ proprietary extensions on order to handle the full PIM to final implementation translation.  The syntax for Action Semantics, often used in the translation, is not specified and vendor specific.  There are several experts who were heavily involved in the development of UML that remain skeptical of MDA based upon its reliance on UML and MOF REF _Ref140282038 \n \h 6.  There are of course many proponents of this approach, which is utilized to some extent within the SIAP.  Still, MDA’s focus on models for driving the design is certainly a spirit shared by the ProtoCore.  Future efforts will focus on how to leverage MDA techniques for specifying the simulation object model and then generate ProtoCore API and plugins from that object model using MDA tools.  StatusCurrently, the ProtoCore supports a growing subset of the HLA 1.3 and HLA 1516 functionality and a very basic TENA functionality.  The ProtoCore Object Model (PCOM) API, the object model specific portion of the API, is generated from an HLA 1.3 Federation Object Model (FOM).  The RTI1.3 plugin and the TENA plugin (if applicable) are also generated from the FOM.  Applications using the ProtoCore in its current state are able to join a simulation, publish and subscribe to objects and interactions, send and receive object and interaction data, and exit the simulation.  These functions are supported in both the RTI and TENA plugins.  A demonstration of these capabilities was created using a small subset of the MATREX FOM.  A TENA Definition Language (TDL) file was created to match the demo FOM and was submitted to the TENA SDA website to be turned into a TENA object model.  The PCOM API, RTI1.3 and TENAMW plugins were generated from the demo FOM.  Finally, a demo application was written using the ProtoCore and PCOM API.  This application was demonstrated to work on either an RTI1.3 federation or a TENA execution with no changes to the application; in fact, the application could be switched back and forth between the two simulations without exiting the process at all.As of the latest release of the ProtoCore, the concept of transport-specific extensions has been included.  This is an attempt to provide access to certain functionality that is not common between supported transport architectures.  Specifically, the latest release of the ProtoCore supports HLA Synchronization Points, a concept that does not exist in TENA.  Therefore, an application that makes use of this portion of the API will be successful if the RTI plugin is loaded, but will receive an exception if the TENA plugin is in use.  This is not an optimal solution, but allows access to non-common features in a controllable and consistent manner.  When and if features such as synchronization points become available in other transports, these extensions will be moved into the main body of the ProtoCore API.Future WorkFuture planned work on the ProtoCore falls into three main areas:  implementing a metamodeling system from which to create the simulation object model, to expand the capabilities of the current API, and to create plugins for additional transport types such as DIS, SosCOE, and OOS.MetamodelingThe main focus of future efforts will be to expand the metamodelling capability with ProtoCore.  Currently, the ProtoCore code generation system reads an HLA1.3 Federation Object Model to generate the API classes.  The goal is to have a system that allows object model developers to use a UML tool to create an object model that the ProtoCore will use to generate code.  At that point, implementation-specific object models such as the FOM or the TENA TDL can be generated along with the API code.  This ensures a consistent object model and facilitates interoperability.Expanded capabilitiesAdditional capabilities that are planned in the near future include dynamic data distribution management, time management, object ownership management, and remote method invocation.  Note that some of these capabilities fall into the category of transport-specific extensions at the momemt.Additional pluginsPlugins are planned for the following architectures:DISSosCOEOOSReferences“Developing Distributed Applications Rapidly and Reliably using the TENA Middleware” Noseworthy, J Russell  MILCOM, October 2005.“The TENA Architecture Document” HYPERLINK "https://www.tena-sda.org/download/attachments/6750/TENA2002.pdf?version=1"https://www.tena-sda.org/download/attachments/6750/TENA2002.pdf?version=1, The Foundation Initiative 2010 Program Office, 2002.“MDA Explained: Model Driven Architecture - Practice & Promise” Warmer, Kleppe & Bast Addison-Wesley, 2003.“MDA: Nice Idea, Shame About the…”  Haywood, Dan http://www.theserverside.com, May 2004.“High Level Architecture Interface Specification Version 1.3” U.S. Department of Defense, April 1998.“IEEE P1516.1 High Level Architecture- Federate Interface Specification”, 2000“A Mixed Architecture for Joint Testing” O’Connor, Michael J  06S-SIW-074, Spring 06 Simulation Interoperability Workshop, April 2006.  