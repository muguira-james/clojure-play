Representing Goal-Oriented Human Performance in Constructive Simulations:  Validation of a Model Performing Complex Time-Critical-Target MissionsAuthors:David G. HoaglandEdward A. Martin, PhDMartin Anesgart, PhDAir Force Research LaboratoryAFRL/HECI2210 Eighth StreetWright-Patterson Air Force Base, OH 45433-7511937-656-7013, 937-255-8072, 937-656-7214david.hoagland@wpafb.af.mil, edward.martin@wpafb.af.mil, martin.anesgart@wpafb.af.milBryan E. BrettScience Applications International Corporation4031 Colonel Glenn HighwayBeavercreek, OH 45431937-431-4390Bryan.e.brett@saic.comNils D. LaVineSusan ArcherMicro Analysis & Design, Inc.4900 Pearl East Circle, Suite 201EBoulder, CO 80301303-442-6947nlavine@maad.com, sarcher@maad.comKeywords:CART, goal orientation, human performance modeling, task network models, time critical targets, verification & validation, constructive simulations, JIMM, HLA, simulation-based acquisition.ABSTRACT:  Inadequate representation of human behavior can lead to significant limitations in the validity and utility of conclusions flowing from constructive simulations.  This practice persists, in part, due to the lack of modeling tools that permit development of dynamic, goal-oriented human models that can be tailored to different analytical fidelities and then seamlessly integrated with constructive simulations.  To address this need, the Air Force Research Laboratory’s (AFRL) Human Effectiveness Directorate undertook the Combat Automation Requirements Testbed (CART) program to develop and demonstrate a human performance modeling environment that will provide a means for modelers and analysts to represent human decision making and tactics in a model that can interact with other simulations using the High Level Architecture (HLA).  An experiment was conducted (called a Case Study) to demonstrate the feasibility of CART’s goal-oriented approach to modeling human behavior.  The CART team evaluated an operator model against pilot-in-the-loop performance for a time critical target (TCT) scenario.  The overall kills of ground targets in the time critical scenario was virtually the same for both the model and pilots (100% and 98%, respectively).  Over 60% of the variability in pilot behaviors was accounted by the behavior of the CART-developed operator model across six different TCT scenarios.  The results lead us to the conclusion that the operator model matched pilot performance with good strength.  This paper discusses the problems with human representation in constructive simulations, need for the CART technology, the steps taken to accomplish Case Study 1, and final results.  The paper also discusses additional findings coming out of Case Study 1 that indicates how human modeling tools can improve constructive simulations by capturing and feeding back operator tactics.1. IntroductionGiven budget and resource constraints in the current acquisition environment, analysts and decision-makers are relying more heavily on constructive simulation of systems to help translate warfighter mission needs into system performance requirements.  Within these constructive simulations, sensitivity analyses are conducted to identify key subsystem attributes that yield desired levels of mission performance - thus providing the basis for performance-based specifications for system design.  While it is generally agreed that the most critical - and most complex - component of a weapon system is the operator, constructive simulations typically focus upon the representation of hardware and software components with little emphasis on the human.  Inadequate representation of human behavior can lead to significant limitations in the validity and utility of conclusions flowing from these simulations.  This practice persists, in part, due to the lack of modeling tools that permit development of dynamic, goal-oriented human models that can be tailored to different analytical fidelities and then seamlessly integrated with existing constructive simulations.  To address this need, the Air Force Research Laboratory’s (AFRL) Human Effectiveness Directorate undertook the Combat Automation Requirements Testbed (CART) program to develop and demonstrate a human performance modeling environment that will provide a means for modelers and analysts to represent human decision making and tactics in a model that can interact with other simulations using the High Level Architecture (HLA).  The overall technical goals and objectives of the CART program were presented at several past Simulation Interoperability Workshops (SIW) and will be briefly discussed here.[1][2]  This paper primarily discusses the initial results of CART’s first operator model implementation which was developed and validated using goal-orientation as the basis for generating realistic, dynamic operator models sensitive to the problem of locating and destroying time critical targets, i.e. Scud hunting.  2. Overview of the CART Program2.1 Program Vision, Goal, and ObjectivesThe vision of CART is to provide the Air Force with the capability to maximize total human-system performance while saving time and money in acquisition using realistic human performance models.  To achieve this vision, the CART team is developing and demonstrating an advanced human-centered modeling and simulation (M&S) technology capable of establishing objective, performance-based crew system interface requirements.  The top-level technical objectives are to:  (1) develop tools that enable creation of realistic operator models based on goal orientation, (2) develop methods that connect operator models to a joint constructive environment, (3) demonstrate the technology via Case Studies using warfighter domains, and (4) transition the technology to the warfighter, acquisition and industry.2.2  Goal Orientation and Example[3]CART helps analysts, operation researchers, and engineers develop human performance models (HPMs) that interact with other mission and engineering level simulations.  Rather than begin anew, CART was built upon the Army's proven Improved Performance Research Integration Tool (IMPRINT) human-performance modeling environment.[4]  This environment provides users with an indication of the effect that operator performance has on system lethality and survivability.  The hierarchy of goal-to-task is key to CART’s translation of real-world actions and events into useable operator models.  CART permits the user to decompose a mission into high-level goals (perform mission, threat evasion, attacking a target, etc).  Once goals are established, the user can create a high fidelity HPM which includes detailed operator tasks that support each higher level goal.  Creation of lower level tasks in the model can be based on real world experience, engineering analysis, interviews with subject matter experts, or simply assumptions about how the operator will interact with the crew interface and/or the external environment.One example of how CART might be used is for the development of requirements for a new threat warning system (that includes pilot performance).  An analyst or engineer might be very concerned about how the capabilities of the new threat warning system affects pilot performance, and vice versa.  In this scenario, the mission is to locate, identify, and destroy ground targets.  If, during the course of the mission, a surface threat tracks and launches against our pilot, then he will probably interrupt his current goal (perform mission) and take the necessary steps to evade the threat - in effect switching to another, more important goal (evade threat).  Once the evade threat goal has been activated, lower level tasks in the goal execute (e.g. make a hard turn, release chaff and flares).  The distance at which the threat launches may affect the point in the mission where the pilot begins the evasion, and consequently, the time available and probability to successfully evade the threat.  If the operator model successfully evades the threat in the simulation, the model’s goal is oriented (or switched) back to a previous goal (perform mission).Likewise, if an analyst wishes to derive a set of requirements for a new radar system capable of locating and attacking ground targets at great distances, then CART could be used to create a detailed operator model that interacts with the new radar display.  In this case, a new goal (attack) would be created along with a detailed model of radar interface tasks.  As in the real world, and in most simulations, surface threats pop-up unexpectedly.  Now the analyst may be interested in understanding the combined effect of the new radar system and the new threat warning system on system effectiveness and lethality.  In this case, the top-level mission would be interrupted if either of the two competing goals are triggered (evade threat or attack target) based on state variables coming from the constructive simulation environment.These goals have an inherent priority (evading the threat is much more important than attacking the target) and their impact on the mission and each other is complicated by the environment (i.e., whether the pilot attempts to resume the mission after evading the threat depends on his current position and how much time is left to perform radar tasks in order to attack the ground target).  In order to represent this, the analyst can use CART’s point-and-click Graphical User Interface (GUI) to draw three independent task network models for each of the three goals.  The first one represents tasks that support the goal “perform mission” (see Figure 1).Figure 1. “Perform Mission” Task NetworkAlthough Figure 1 is simplistic, the task network must be sufficiently complex to include parameterization of environmental aspects.  For example, the network and its associated logic must be powerful enough to estimate changes in pilot and system performance based upon different environmental conditions such as weather, target availability, etc. but not be so unpredictable that it would invalidate assumptions concerning the capabilities and employment of the radar and threat warning systems.Figures 2 and 3 below show the task networks that represent the two competing goals (evade and attack) that influence the model’s behavior.  Figure 2. “Evade” Goal Task NetworkFigure 3. “Attack” Goal Task NetworkSimilar to the perform mission task network, each goal network above must be sophisticated enough to represent the range of actions that pilots might select when the goal is triggered.  A key to producing realistic pilot behaviors in simulation becomes the prediction of when goals are triggered, and then the representation of the impact of the newly triggered goal on other actions the pilots need to take.  The interaction of goal-oriented operator models, models of weapon subsystems, and the simulated world provides CART users with a whole new range of analysis fidelity and tailorability previously unavailable.3. Case Study 1 Development3.1 ObjectivesCase Studies are a key activity of the CART program to demonstrate the feasibility of its goal-oriented approach (see Figure 4 next page).  Primary objectives include:  (1) successfully developing and integrating an HPM into a constructive simulation environment; (2) evaluating the operator model’s performance against human-in-the-loop (HITL) performance in the same scenario; and (3) using the Case Study results to address issues of interest to the participating acquisition program.Figure 4. Case Study ApproachRelating back to CART’s vision discussed in section 2.1, the underlying assertion is that if these objectives are achieved and HPM performance is shown to approximate that of the pilot, it would suggest that HPMs could be used effectively to represent human behavior early in acquisition, thereby reducing the time and cost associated with assessing weapon system requirements through repeated HITL testing.3.2 ScenarioFigure 5.  Time Critical Target ScenarioThe scenario for which constructive and virtual simulation trials were run consisted of a strike mission against a time critical target (TCT, or Scud hunting).  A part-mission scenario, in which only the acquisition, attack, and egress legs were flown, was developed based on prior virtual simulation exercises.  The scenario called for the HPM and pilots to fly at medium-to-high altitude, and employ a simulated Joint Strike Fighter (JSF) sensor suite in an effort to acquire and attack high value, mobile TCTs.  In addition, it required the HPM and pilots to react and avoid pop-up surface-to-air missile (SAM) threats.  Target acquisition sensors available to the HPM and pilots included synthetic aperture radar (SAR) with a ground moving target indicator (GMTI) overlay and a targeting infrared (TIR) imaging system.  Figure 5 shows the basic elements of the TCT mission in Case Study 1.  During ingress to the target area, both the HPM and pilots employed the aircraft sensors in order to detect and identify the actual target of interest.  The sensors used included real-beam and SAR with GMTI overlaid on cockpit displays, giving the pilot the locations of moving targets in the area.  The planned route that the aircraft flew considered the aircraft’s radar signature and other factors relative to the expected threats or electronic order of battle (EOB).  While enroute to the target area, the aircraft was threatened by pop-up threats requiring the HPM and pilots to use countermeasures and take evasive action.  During the mission, the HPM and pilots were provided updates to the original target coordinates via an off-board data source.Six different variations of the TCT scenario were constructed.  While similar, the scenario variations differed slightly in terms of target location, the locations of other movers, the locations of pop-up threats, and the mission route.  These variations provided methodological benefits to both the model and HITL tests.  For the constructive model trials, having several scenarios provided the ability to demonstrate the robustness of the HPM.  For the HITL trials, the different scenarios provided some controlled variation so that pilots did not have the opportunity to learn the specific mission performance demands, and consequently, artificially modify their behavior.3.3 Simulation EnvironmentCase Study 1 was conducted using the Wright-Patterson Simulation and Analysis Facility’s (SIMAF) Virtual Strike Warfare Environment (VSWE) environment established by the JSF program for their simulation evaluations.  This environment was developed to conduct various HITL simulations of JSF missions in an effort to study cost/performance tradeoffs associated with different weapon system capabilities.  The VSWE environment consists of an aircraft simulation with a human-in-the-loop cockpit (supported by software called the Fighter Requirements Evaluator Demonstrator, or FRED), and a mission-level constructive simulation called the Joint Interim Mission Model (JIMM) that provides the mission environment (terrain features, threats, targets, etc.) in which the HPM and pilots interact.  JIMM is based largely on the Synthetic Warfare Environment Generator (SWEG) and includes capabilities native to SUPPRESSOR, the Air Force’s long standing mission-modeling environment.  The SIMAF’s capabilities provided the CART team with a relatively inexpensive way to run HITL subjects in a high fidelity simulation environment and collect data for performance comparison purposes.3.4 Human Performance ModelCART was used to develop an HPM specific to the time critical target (TCT) scenario described above using simulated sensors on board a notional JSF platform.  The HPM was linked to the aircraft simulation via an HLA interface through which it monitored data coming from the cockpit displays, and then commanded control inputs as required by events during the simulation.  Key activities the HPM performed included navigation, threat avoidance, target acquisition, and target attack.  In order to ensure the realism of the HPM’s goals and tasks, Air Force pilots with relevant experience were interviewed during the model’s mission decomposition stage.4. Case Study 1 Variables4.1 Experimental Question and Independent VariableThe key question was whether a CART-developed HPM could interact with aircraft models and a simulation environment to produce mission, function, and task performance levels comparable to that observed during human-in-the-loop simulation.  The null hypothesis was that the HPM’s performance was statistically the same as actual pilots in the HITL condition.  Therefore, the independent variable for Case Study 1 was Operator Type (i.e., HPM vs. HITL).  In the HITL condition, pilots flew the aircraft simulator, while in the HPM condition, the aircraft simulator was controlled by data inputs from the HPM.4.2  Dependent VariablesThe dependent variables for Case Study 1 are listed in Table 1.  These measures are goal oriented and were selected using Rasmussen’s Means-End Abstraction Hierarchy during the of decomposition mission tasks.[5]  Thus, the overall mission task (the end:  kill TCTs) was decomposed into lowerlevel goals (the means:  navigation, threat evasion, target attack, and others) that supported that end.[6]  In like fashion, the goals were further decomposed into the tasks and notional system attributes supporting the courses-of-action associated with the tasks.  This means-ends decomposition provides visibility into the way performance at the lower levels “bubbles” upward through all levels of the decomposition, and enables the identification of particular tasks or operator performances that most directly influence the higher, mission-level outcomes.  .5. Case Study 1 Methodology5.1 Experimental DesignThe experimental design in Case Study 1 was a mixed design where Operator Type was the between-subjects factor and the scenario was the within-subjects factor.  The test matrix is shown in Table 2 which demonstrates a counter-balanced scheme for ordering subject exposure to scenarios that controlled order effects.  The HPM performed six repetitions within each TCT scenario while the pilots in the HITL condition performed six repetitions across the same six scenarios.5.2 SubjectsEight fighter pilots (six F-16 and two A-10) familiar with the air-to-ground strike TCT mission served as subjects during the HITL trials.  Training was needed for some of the pilots unfamiliar with the specific make-up of the SIMAF cockpit displays, symbology, and mechanization (discussed later).5.3 Apparatus: CART HPMJIMM provided the simulation environment for the HPM trials.  The cockpit environment was tailored to incorporate only those components required for use with the HPM.  One component was the FRED software, which provided the basic representation of the aircraft and cockpit interfaces.  Additional capabilities were added to FRED to pass state data to the HPM from JIMM and reflect control inputs received from the HPM back to the JIMM.  A second FRED capability retained for the HPM trials was a real-time in-flight route replanning system, which was employed to pass in-flight replanning data to the HPM.  In the HPM trials, the probability of target detection and identification were calculated as a function of sensor, target range, the location imaged, and the size/type of object within different fields-of-view.5.4 Apparatus:  HITL SimulationMission EnvironmentAs in the HPM trials, JIMM provided the mission environment generator in which the pilot subjects and simulated aircraft flew.  JIMM is an event-stepped, object-oriented, general-purpose conflict simulation capable of participating on a network with other simulations, simulators, hardware, and human-in-the-loop systems.  The JIMM model ran the Generic Composite Scenario (GCS) using a three processor (R10000) Silicon Graphics workstation with 256 MB RAM and 9 GB disk.Cockpit SimulationThe Mission Interactive Combat Station (MICS) is the SIMAF’s reconfigurable cockpit simulator that served as the cockpit environment for Case Study 1.  Its software is comprised of the FRED software, the Camber radar toolkit for SAR, and Paradigm’s Vega for Out-the-Window (OTW).  In addition, an integrated moving map capability and an effects-level infrared model for targeting were implemented (see Figure 6 next page).The MICS is powered by an SGI ONYX 2 dual rack with 14 R10000 CPUs, two Infinite Reality Pipes (64MB and 128MB texture memory), 890 MB RAM and 18 GB data storage.  The cockpit consists of a 29-inch monitor with touchscreen overlays and an F-16 Block 50 stick and throttle.  The single channel OTW imagery is projected on a screen in front of the cockpit.  Communication capabilities are integrated between the cockpit and test director area.  Audio is generated by the FRED software and I/O boards are installed on each ONYX.  During the HITL trials, two cockpits were used to provide data collection from two pilots flying different TCT scenarios simultaneously.Figure 6:  Case Study 1 Cockpit EnvironmentInterface Support SoftwareThe interface support software acted as an intermediary between FRED/JIMM and the HPM.  It obtained the current aircraft simulation data, passed those data to the HPM, and then updated FRED/JIMM with information as commanded by the HPM.  The data exchanges occurred via HLA’s run time infrastructure (RTI 1.3v6).5.5 ProcedureHPM TrialsFor the HPM trials, the HPM was run through each of the six scenarios in order to assess variability whereby the HPM processed data from the mission environment and commanded inputs to the simulated aircraft.  Trials were terminated according to the same conditions as for the HITL trials (target destroyed, HPM replanned to base, etc.).TrainingThe training phase began with an overview briefing.  The overview covered the purpose of the study, the types of missions the pilots would be expected to conduct, and the tactics that would be employed during various phases of the scenarios.After a short question and answer period, the pilots were immersed in the MICS for familiarization training.  Familiarization training reviewed interaction with displays and controls in the cockpit - focusing on only those features and capabilities that were needed in the study (i.e., stick and throttle usage, sensor manipulation, use of the replanner).  During this segment of training, pilots were in a cockpit and instructors led them through a series of exercises designed to demonstrate the cockpit switchology.When both the pilots and instructors were satisfied that their knowledge of the switch and display interaction was adequate, they “graduated” to part-task rehearsal.  During this segment of training, each pilot rehearsed sensor management activities and evasion tactics within small segments of a unit interdiction (UI) mission.  The UI mission was similar to the TCT mission, except that the target was an armored column.  One of the elements in the armored column was replaced with a SCUD to expose pilots to the intended target later used during data collection scenarios.Finally, each pilot integrated the elements of the part-task rehearsal into a full mission rehearsal exercise using the same UI mission that was used during part-task rehearsal.  During the full-mission rehearsal, each pilot flew a full mission similar to those later experienced in data collection.  Once the instructors determined that each pilot was proficient in the conduct of the strike mission, the training phase was completed and data runs were begun.  Each pilot flew six data collection trials (for each scenario) with the order of the trials randomized as shown in Table 2.6. Case Study 1 Results and Discussion6.1 Overall AnalysisThere were two measures used to assess the overall ability of the HPM to accurately represent the performance of the pilots in the HITL simulation.  The first was to simply count the number of ground targets destroyed by the HPM and compare it to the HITL case.  For Case Study 1, the number of targets destroyed by the HPM was 36 out of 36 trials, or 100%.  In the HITL condition, pilots destroyed 47 targets out of 48 trials, or about 98%.For the second measure, an overall assessment called a “congruency ratio” was used to compare the intercorrelation of the dependent variables between the HPM and its counterparts for the HITL case.  Developed by the Department of Psychology at the University of Akron in the 1980’s, the congruency ratio can be calculated as illustrated using the data in Table 3.Table 3.  Example for Determining Congruency Ratio In this example, four dependent measures are represented, resulting in six possible correlations among the measures.  The six correlations for two groups are arranged into two columns and the sum of the cross products is calculated (0.16).  Each correlation is squared and summed for each of the two groups (1.12 and 0.98, for Groups A and B, respectively) and the square root is taken of the resulting values.  Finally, the sum of the cross products value is divided by the product of the two square roots multiplied together, (i.e.,  0.16 / [ sq. rt (1.12) x sq. rt (0.98)]).  The result is 0.1814, the congruency ratio, and represents an index of correlation for all possible correlations put together in a single value – in effect a “meta-correlation.”  The square of this ratio is 0.0329 and is similar to a coefficient of determination.  When multiplied by 100, the coefficient in this example indicates that Group A accounts for 3.29 % of the variation in Group B.In Case Study 1, given eight dependent variables, there were 28 possible correlations for the HPM and 28 for the HITL.  Using the methodology in the previous example, the congruency ratio was calculated to be 0.7799.  The square of this ratio provides an indication of the amount HPM behavior (the variability) which accounts for behavior observed in the HITL trials.  In the case of Case Study 1, the HPM accounted for 61 % of the behavior of the pilots in the HITL condition.6.2 Univariate AnalysisSPSS v.10 was used to conduct the statistical analysis for Case Study 1.  As an initial assessment, an univariate analysis was accomplished to determine if a statistical difference existed for each of the eight DVs across all scenarios without consideration of correlations.  As can be seen in Table 4, three of the eight DVs had a significant difference between the HPM and the HITL (p<.05).  The three were DV3, DV4 and DV6.  However, the strength of the effects in the population (eta-square index) was low to moderate for these three DVs (less than 0.70).Table 4.  Results from Univariate Analysis6.3 Multivariate Repeated Measures AnalysisA multivariate repeated measures analysis was completed in order to account for the correlation between DVs.  This analysis provides a more accurate depiction of the differences between the HPM and HITL conditions.  Given that there were significant (p < .05) correlations among the dependent variables taken as a whole (HPM and HITL combined), the true test of the relationship between independent variable (model vs pilot) and the eight DVs required a doubly multivariate analysis.  There were three sets of DVs wherein each variable was correlated significantly with each other across all six scenarios, thus resulting in three doubly multivariate models as shown in Table 5.  All three models demonstrated fairly strong differences (eta-squares of approximately 0.70 or greater) between the HPM and HITL.  However, post-hoc analysis revealed that significant differences (p <. 05) occurred only for DV4 and DV6 between the HPM and the HITL condition.  These differences were associated with outliers for certain pilots and scenarios.Table 5.  Results from Multivariate Analysis6.4 Differences Between HPM and HITL Results In Terms of RanksClassified data were obtained during the course of the trials and are not reported here for obvious reasons.  However, classified data can be easily translated into “ranks” to illustrate the differences between the HPM and HITL without exposing capabilities of the simulated aircraft and threat environment.  How the data were translated into ranks is illustrated using notional data in Table 6.Table 6.  Example for Determining RanksIn this example, there are four values for Group A and four for Group B for the same DV.  All eight values are then arranged in ascending order without regard to their original group.  These eight values are each given a ranked position, termed a “mean rank,” one of several ranking options provided by SPSS.  The value ”1” is the lowest rank and “8” is the highest rank.  In the case of values that are equal (or tied) as highlighted in the example, the ranked positions are summed and then divided by the number of ties.  In the case of no tied values the ranked position is the same as the mean rank.  The eight mean ranks are then substituted for the original values as shown in the far right column.For Case Study 1, the mean ranks were calculated for each of the eight dependent measures and treated as original values in subsequent descriptive analyses.  The “average” ranks associated with DV4 and DV6 in the discussion below simply represents an average of the mean ranks across all scenarios, or a “mean of means.”  DV4 and DV6 were found to be significant in the post hoc analysis.  For DV4, more threat replans were accepted by the HPM (average rank of 48.25; range of 6.5 to 77) than the HITL (average rank of 38.19; same range).  With DV4, the HPM had a higher average rank as compared to the HITL for four scenarios; a lower rank in one scenario; and the same rank in the remaining scenario.  For DV6, the HITL had the greater number of launches against own ship (average rank of 46.54; range of 2 to 84) as compared to the HPM (average rank of 37.11; range of 2 to 81).  With DV6, the HITL had a higher average rank in three scenarios, while the HPM had a higher average rank in the remaining three scenarios.  While post hoc analysis continues, it is felt the cause for these differences were differences associated with outlier data and for one scenario that seemed to produce the most variability.6.5 Additional FindingsWhile it is important to remember that the objective of the CART program is to demonstrate the feasibility of applying and maturing goal-oriented modeling of human behavior, it should also be noted that other important findings were made.  Initially, the CART team developed the Case Study 1 model with the use of subject matter experts from the JSF program office and the SIMAF who had previously employed a limited set of tactics used in a prior VSWE exercise.  CART model testing was initially completed using these tactics and results revealed a limitation in system effectiveness (low probability of finding and ultimately destroying ground targets).  With these results in hand, the team quickly developed a new tactic using the same crew interface, but instead with an emphasis on the coordinated use of the cockpit’s SAR and TIR displays together.  The HPM predicted that the new tactic would result in a much higher probability of detection, identification, and destruction of targets for all six scenarios.  Later, during our pilot trials, subjects were trained on the new tactic and actual performance was found to be higher than previously experienced using the old tactic - and also was closely aligned with HPM results.  The implication of this discovery is tremendous for the warfighter as CART can be employed as a tool not only to develop, analyze, and establish traceable crew system requirements, but also as a means to optimize tactics of current and conceptual aircraft systems.In addition, discussions with the M&S community and those involved with Simulation-Based Acquisition (SBA) led us to the finding that CART can serve the constructive simulation community by “feeding back” virtual-based models of human decision making.  The idea is to capture tactics and pilot behaviors in an operator model during human-in-the-loop simulations (including tactic variances and excursions).  Once the operator model is completed, it can eventually improve the realism of constructive simulations over time.  Iterative runs using virtual-based operator models can winnow out less effective system concepts prior to conducting follow-on virtual simulation effort, thereby saving time and money.  Over time, continued development and creation of high fidelity operator models will reduce an organization’s operating costs and schedule lengths.  “Standard” operator models can be re-used by other simulation projects dealing with similar scopes for which the operator model is built.In summary, it is very conceivable that CART can be used to model and assess the performance impacts of alternative tactics, as well as improve the realism of constructive simulations currently used in the DoD by re-using operator tactics captured during the course of conducting virtual simulations.7. ConclusionsAs a first experiment using goal-oriented models that can interact dynamically with mission-level simulations, the results of Case Study 1 boded well for the ability of the CART HPM to represent pilot behaviors observed in the HITL condition.  The overall proportion of kills of ground targets in a TCT scenario was virtually identical for both the model and pilots (100% and 98%, respectively).  Over 60% of the variability in pilot behaviors was accounted for by the behavior of the HPM.  The multivariate analysis suggested that for just two of the eight dependent measures were there significant differences between the HPM and the HITL.  However, the direction of the differences was not the same for all scenarios.  Moreover, when those scenarios failing homogeneity of variance tests were excluded from the analysis, the difference between the two operator types (HPM and HITL) were reduced.  The CART team demonstrated an advanced human-centered technology capable of creating realistic operator models based on goal orientation, developed methods to connect operator models to a joint constructive simulation environment using the HLA, and demonstrated the technology via an extensive Case Study using a TCT application.  The CART team evaluated the operator model’s performance against human-in-the-loop performance in this scenario and used the project’s results to address issues of interest to the participating acquisition program.  The results thus far on the CART program lead us to the conclusion that our goal-oriented operator model matched pilot performance with good strength.The results of this project support the CART vision to provide the Air Force with the capability to maximize total human-system performance while saving time and money in acquisition using realistic human models.8. References[1]  Hoagland, D. G., E. A. Martin, & B. E. Brett,  “The Combat Automation Requirements Testbed (CART) Program:  Improving the DoD's Requirements Process Through Inclusion of Realistic Operator Performance,” Simulation Interoperability Workshop Paper Number 99S-SIW-129, Spring 1999.[2]  Hoagland, D. G., E. A. Martin, B. E. Brett, J. A. Doyal, N. D. LaVine, & R. A. Sargent,  “The Combat Automation Requirements Testbed (CART) Program: Results and Lessons Learned from Recent Testing of Advanced Human Performance Models Interacting with DoD Constructive Simulation,” Simulation Interoperability Workshop Paper Number 00F-SIW-023, Fall 2000.[3]  Archer, S., N. D. LaVine, “Modeling Architecture to Support Goal Orientation,” Interservice/Industry Training, Simulation and Education Conference, November 2000.[4]  US Army Research Laboratory, Human Research and Engineering Directorate, Aberdeen Proving Ground, MD, “Improved Performance Research Integration Tool (IMPRINT) User’s Guide Version 4.0,” April 1998.[5]  Rasmussen, J., A.M. Pejtersen, & L.P. Goodstein,  “Cognitive Systems Engineering,” John Wiley & Sons, New York, 1994.[6]  Martin, E. A., B. E. Brett, & D. G. Hoagland, “Tools for Including Realistic Representations of Operator Performance in DOD Constructive Simulations,” Proceedings, AIAA Modeling and Simulation Technologies Conference and Exhibit, Portland OR, August 9-11, 1999.Author BiographiesDAVID G. HOAGLAND currently serves as Manager for CART Program in the Air Force Research Laboratory (AFRL).  He received his Bachelor's of Aeronautical and Astronautical Engineering degree from the Ohio State University in 1985, where upon he joined the US Air Force as a civilian engineer at Wright-Patterson AFB.  As a crew systems engineer working in the Aeronautical Systems Division, he was involved in the design, development, testing and acquisition of major weapon systems, namely the F-16 Fighting Falcon, the 767 AWACs, the F-117 Stealth Fighter, and the E-3 JSTARs.  He moved to AFRL in 1995 as a plans and programs engineer, and later became the deputy program manager for the Crew-Centered Design Technology (CCDT) Advanced Technology Demonstration program.  He has served on numerous unmanned vehicle initiatives in the Air Force including the 1996 SAB UAV Summer Study team and the DARPA/AFRL UCAV program.EDWARD A. MARTIN is a biomedical engineer in the Air Force Research Laboratory's Human Effectiveness Directorate where he is currently Technical Director of the CART Program.  He earned his MS in Electrical Engineering from Syracuse University in 1971, and a PhD in Biomedical Engineering from the Ohio State University in 1985.MARTIN ANESGART currently works in the Crew Systems Interface Division within the Air Force Research Laboratory and provided statistical analyses and data for the CART program.BRYAN BRETT received a Bachelor degree in Psychology and a Masters degree in Experimental Psychology, both from the University of Florida.  He currently manages the Crew Systems and Simulation Business Area of SAIC's Aeronautical Systems Division in Dayton, OH.  He has experience as a senior analyst, principal investigator, and currently serves as Chief Scientist for the CART Program.NILS LAVINE is a Principal Systems Engineer at Micro Analysis & Design, Inc.  He is the Program Manager for the CART project, as well as for several projects that predict the effects of Nuclear, Biological and Chemical (NBC) agents on human performance.  He has been instrumental in linking the Micro Saint discrete event human performance modeling engine to other simulation environments.SUSAN ARCHER is the Director of Operations at Micro Analysis & Design, Inc.  In addition to her responsibilities in that capacity, she is also the program manager and technical lead of the Army Research Laboratory’s Improved Manpower and Personnel Integration Tool (IMPRINT) effort.  This is a software development effort to develop an advanced integrated Manpower, Personnel and Training (MPT) analysis tool for the Army.  She was also the Program manager for HARDMAN III, the predecessor to IMPRINT.  Ms. Archer manages several contracts involving Human Systems Integration (HSI) efforts associated with advanced command and control concepts.PAGE  7PAGE  7Table 1: Case Study Dependent Variables (DVs)Navigation GoalDV1 = number navigation error replans generatedDV2 = number navigation error replans acceptedDV3 = number threat-based replans generatedDV4 = number threat-based replans acceptedThreat Evasion GoalDV5 = number threat locks on ownshipDV6 = number threat launches at ownshipDV7 = percent threat missiles defeated by ownshipTarget Attack GoalDV8 = range at weapon release EMBED PowerPoint.Slide.8  Table 2.  Case Study 1 Test MatrixFactorsOperatorTypeScenario 1Scenario 2Scenario 3Scenario 4Scenario 5Scenario 6HPM 12Trial 1Trial 6Trial 4Trial 2Trial 5Trial 3HPM 22Trial 4Trial 1Trial 6Trial 3Trial 2Trial 5HPM 32Trial 6Trial 3Trial 2Trial 5Trial 4Trial 1HPM 42Trial 2Trial 5Trial 3Trial 1Trial 6Trial 4HPM 52Trial 5Trial 4Trial 1Trial 6Trial 3Trial 2HPM 62Trial 3Trial 2Trial 5Trial 4Trial 1Trial 6HITL 11Trial 1Trial 5Trial 3Trial 6Trial 2Trial 4HITL 21Trial 5Trial 3Trial 4Trial 2Trial 6Trial 1HITL 31Trial 3Trial 4Trial 2Trial 5Trial 1Trial 6HITL 41Trial 6Trial 2Trial 1Trial 4Trial 5Trial 3HITL 51Trial 2Trial 1Trial 6Trial 3Trial 4Trial 5HITL 61Trial 4Trial 6Trial 5Trial 1Trial 3Trial 2HITL 71Trial 4Trial 2Trial 6Trial 1Trial 5Trial 3HITL 81Trial 3Trial 5Trial 6Trial 2Trial 4Trial 1