Bradley Fighting Vehicle (BFV) A3 Synthetic Environment Live Fire (SELF) Results for Limited User Test (LUT) 1 and LUT-2Ms. Angela Maria AlbanUnited Defense, 12461 Research Parkway, Suite 500, Orlando, FL 32826(407) 737-9152, Fax: (407) 207-5444, angela_alban@udlp.comMs. Alesya PaschalU.S. Army Simulation, Training, and Instrumentation Command (STRICOM), Orlando, FL 32826(407) 384-3867, DSN 970-3867, Fax (407) 384-3830, alesya_paschal@stricom.army.milMs. Irene JohnsonUS Army Materiel Systems Analysis Activity (AMSAA), Attention AMXSY-CD367 Hopkins Road, Aberdeen Proving Grounds, MD 21005-5071278-2143, DSN 298-2143, Fax (410) 278-5191,  HYPERLINK mailto:mmccarth@arl.mil  mackin@arl.mil Mr. Louis SantoneU.S. Army Operational Test and Evaluation Command (OPTEC),4501 Ford Avenue, Alexandria, VA 22302-1458(703) 681-, DSN 761, Lou_Santone@mail.amsinc.comKeywords:SELF, BFV A3, Live Fire Testing, Limited User Test, BATSABSTRACT: Live Fire Testing (LFT) legislation, initially passed in 1986, requires realistic testing of weapon systems in their combat configurations against realistic threats.  This paper discusses the design, execution, and analysis of the Synthetic Environment Live Fire (SELF) Limited User Test (LUT) 1 and LUT-2 for the Bradley Fighting Vehicle (BFV) A3.   In an effort to investigate the possibility of augmenting LFT in the SE, actual BFV A3 LUT-1 and LUT-2 test scenarios were replicated in the SE, utilizing the Bradley Advanced Training System (BATS), the BVF A3 training device.  The results obtained during testing were then compared to the actual data collected for the same tests.  The SELF effort focuses on the BFV A3 for the data comparison because this vehicle is currently in the testing phase of the acquisition cycle.  The SELF tests concentrate on the gunnery aspects of BFV A3 testing to explore SE approaches to augmenting operational tests, while refining the implementation of lethality in the SE.  Although the BFV A3 was used as an example platform in the initial investigation, SELF strives to establish an infrastructure capable of lending itself to testing other platforms for the future.The SELF infrastructure consists of the BATS, the BFV A3 training simulator being concurrently with the vehicle, synthetic flat panel targets generated by Modular Semi-Automated Forces (ModSAF), and The United States (U.S.) Army Materiel Systems Analysis Activity (AMSAA) ballistic models. AMSAA verified and validated (V&V) this SE infrastructure prior to SELF testing.  SELF LUT-1 was conducted in November, 1997 at Fort Benning, Georgia and SELF LUT-2 followed in Septemberember, 1998 at Fort Hood, Texas.  Both tests were conducted using the BATS which replicated the same geographical location as the actual test, and the same crews were used for both tests.  For each LUT, synthetic test data was collected to satisfy BFV A3 Measures of Performance (MOPs) that focus on the ability of the vehicle to perform target acquisition and delivery accuracy.  The U.S. Army Operational Test and Evaluation Command (OPTEC) then compared each set of data generated in the SE to the actual LUT test data and assessed the value of the SE for operational testing.This paper reviews the steps required to utilizing a training device to conduct Bradley SELF testing to perform the required data analysis.  It also discusses how training devices can be used to augment operational testing and the SE improvements needed for future Test and Evaluation (T&E) support.Background And IntroductionThe SELF effort investigates how training devices in a synthetic environment (SE) can augment Live Fire Tests (LFT), while recognizing the limiting constraint of the Live Fire Test legislation, initially passed in 1986, that requires realistic testing weapons platforms in their combat configurations against realistic threats. Due to many advances in the SE, this effort investigates how LFT can be effectively augmented.  This was done by simultaneously creating a SE to mirror the Live Fire Test environment.  This effort followed the efforts demonstrated previously in the Advanced Armor Technical Demonstration (A2ATD) where the Abrams tank was evaluated in the SE.  SELF has conducted a series of tests in parallel with the Bradley A3 live tests to provide the test community with data to evaluate the test support capabilities of the SE.SELF testing for the A3 is sponsored by Office of the Secretary of Defense (OSD) and Live Fire Testing and Evaluatio7n (LFT&E) and is executed by the US Army Simulation, Instrumentation, and Training Command (STRICOM). Verification and validation is provided by the Army Materiel Systems Analysis Activity (AMSAA) and oversight and evaluation is provided by the Operational Test and Evaluation Command (OPTEC).  This effort investigates opportunities to address LFT issues in the SE, including the ability of the SE to provide crew training to enhance the effectiveness and efficiency of actual LFT exercises.  While it is realized that the SE cannot replace Live Fire testing, the SE can provide additional data, insight into future test events, enhanced crew training and efficiency, and an infrastructure in which to introduce variables without interfering with the developing system schedule.  The SELF effort explores SE approaches to testing lethality issues by utilizing the Bradley A3 development to illustrate the opportunities.SELF investigates ways a SE can augment Live Fire Test by synthetically recreating the M2/M3A3 Gunnery Tests and comparing the SE results to the actual Gunnery Tests.  The SELF used the Bradley M2/M3A3 program for the comparison since the M2/M3A3 is currently in the testing phase of the acquisition cycle and due to the extensive used of simulation throughout the A3 development.  The SELF tests address the gunnery exercises of the M2/M3A3 to explore SE approaches to augmenting test data while refining the implementation of lethality in the SE.  Although, the M2/M3A3 was used as an example platform in the initial investigation, SELF strives to establish an infrastructure capable of lending itself to testing other platforms for future SE LFT.  The focus of the SELF program is to conduct a series of tests in the SE, using a SE of the updated Bradley’s ability to acquire and target an enemy vehicle.  The SELF specifically addresses crew proficiency of gunnery test.  This is the ability of the vehicle to acquire a target, generate a fire control solution, project its ordnance onto the target, and destroy the target.  The aspects of the A3 test are ideally suited for assessment in a SE since the digitized traffic is the primary source for internal communication.  The SELF program is significant in many ways, not the least of which is that it marks the use of existing training devices to support not only crew training, but also real world exercises, analysis of design modifications, and early testing of new tactical hardware and software prior to deployment.  As military budgets become more constrained, the ability to use training devices to support weapon system enhancements, minimize the number of required live fire tests, and act as an integral part of the development process can be expected to yield significant benefits.  In addition to cost, the use of the SE and training devices offers the potential to increase the quality and accuracy of decisions made relative to the design and development of new weapon systems capabilities.Requirements DefinitionTo determine what the SELF should evaluate for LUT-1/2, the actual Bradley Fighting Vehicle (BFV) A3 System Evaluation Plan (SEP) was reviewed.  The four hundred seven (407) MOPs were divided into those related to LFT, amenable to testing in the SE, and relevant to the two (2) LUTs.  This analysis resulted in the thirty (30) SELF MOPs that could be tested in the SE during LUT-1 and LUT-2.   Once the measures were established, the BFV A3 Event Design Plan (EDP) was reviewed to understand the scope of the each test activity.  This document contains a synopsis of the test plans as well as the list of target MOPs and data elements for which the data would be collected.  Although an EDP was not developed for the SELF tests, 2 documents were developed in preparation for the SELF tests: a Pattern of Analysis (POA) and a Detailed Test Plan (DTP).  The POA lists the target MOPs and data elements for SELF LUT testing.  The DTP discusses the SELF test events and expected results.  In addition to developing this documentation, testing details were coordinated with OPTEC, TEXCOM, and TSM Bradley.  For LUT-2, details regarding data elements and data management were refined from the lessons learned for the LUT-1 test execution.  In addition to actual test preparation, STRICOM and the U.S. Army Materiel Systems Analysis Activity (AMSAA) co-developed the Verification and Validation (V&V) Plan for the SELF infrastructure.Infrastructure and EnhancementsThe SE was originally integrated to support  SELF LUT-1 and then modified for SELF LUT-2 testing; the infrastructure was composed of the Bradley Advanced Training System (BATS), the BATS Instructor Operator Station (IOS), ModSAF, the Simulation Analyzer (Simulyzer),  and AMSAA ballistics models.  The Verification, Validation, and Accreditation Test Tool (VVATT), the BATS IOS, and the Simulyzer were used for data collection and analysis during the V&V and LUT tests.The SELF LUT-2 infrastructure built on the SELF LUT-1 infrastructure.  The BATS improvements included enhanced visuals, that  provided a more realistic visual scene with more clutter and contrast.  The use of simpler targets and visual scenes during SELF LUT-1 produced target detection probabilities significantly higher than those observed in the actual gunnery tests.  In addition to the enhanced visuals, AMSSA ballistic models provided a higher fidelity fly-out simulation and error modeling, therefore increasing its fidelity relative to the real world system.  Bradley Advanced Training System (BATS)The BATS functioned as the vehicle under test (VUT) since its crew station and software are representative of the Bradley A3.  BATS is a complete gunnery training system that consists of a high fidelity gunner and commander's weapon station, and an Instructor Operator Station to control gunnery exercises and provide After Action Reporting (AAR).  The BATS employs a visual and computational system that provides the images required to develop and sustain crew members’ gunnery skills for the BFV A3.   The computational system also utilizes tactical software that closely replicates actual fire-control functions and capabilities of the BFV A3.  The BATS provides the BFV A3 physical and functional fidelity. Because the simulator uses actual vehicle hardware and software, hence accurately representing the A3, it provides an easier to link into other simulations while reducing the number of variables that can affect fidelity with respect to the live environment.  This is a more acceptable alternative to physically cabling a moving vehicle. To support the SELF LUT-2, the BATS included simulation of the vehicle dynamics, weapons, fire control and sensors, survivability, communication, and navigation of the BFV A3.  The BATS design goal was to minimize the required unique simulator/trainer software and hardware by using actual BFV A3 components (hardware and software).  Figure 3.0 – 1 is a picture of the BATS crewstation. Figure 3.0 - 1 BATS Crew StationFigure 3.0 – 2 is a picture of BFV A3 vehicle #4 taken of the same section of the crew compartment depicted in Figure 3.0 –1.Figure 3.0 – 2  BFV A3 Crew CompartmentTargetsFlat Panel TargetsFlat panel targets were used for SELF LUT-1.  These targets were modeled after the actual plywood thermal targets described in the Bradley Gunnery Field Manual 23-1.  They were used to replicate those targets found on Hastings Range in Fort Benning, Georgia, which is the range where the BFV A3 LUT-1 gunnery tests were conducted.  The panel targets on Hastings Range vary among a frontal view BTR, a flank view BTR, a frontal view BMP, and a flank view BMP.  These models were developed using the Night Vision Lab (NVL) Paint the Night (PTN) texture files as a guideline. Figure 3.1.1 - 1 depicts the flank view of a BMP panel target. EMBED MSPhotoEd.3 \sFigure 3.2.1 - 1  Flank BMP Panel TargetFigure 3.2.1 - 2 depicts the frontal view of a BMP panel target. Figure 3.2.1 - 2  Front BMP Panel TargetModSAF TargetsThe targets used for SELF LUT-2 testing were three-dimensional (3-D) targets generated by ModSAF.  These were used instead of the 2-dimensional (2-D) flat panel targets used in LUT-1 because the IPT determined that the 3D realism would not hamper the test results.  Figure 3.2.2 – 1 depicts the 3-D representation for a BFV A3, although BTRs and BMPs were the targets used during the SELF tests.Figure 3.2.1 - 1  3-D BFV A3 ModelError ModelingAMSAA algorithms were implemented into the BATS software although the A3 Ballistic Software Solution (BSS) provides for scant error correction and environmental parameters. In addition, three different round dispersion tables were used throughout testing.  These tables generated a random dispersion of shots based on the first shot.  Analysis Tools Verification, Validation, and Accreditation Test Tool (VVATT)For SELF LUT-1, the Verification, Validation, and Accreditation Test Tool (VVATT) was used prior to SELF testing to collect data during the target acquisition verification and validation (V&V) tests.  The VVATT, developed for A2ATD, allows the user to generate reports necessary to assess the simulators target generation capabilities.  SimulyzerThe Simulation Analyzer (Simulyzer) was used during SELF LUT-1 to collect Distributed Interactive Simulation (DIS) Protocol Data Units (PDUs) from the network.  These PDUs provided information such as shot, hit and kill statistics, intervisibility over time, an engagement timeline, and vehicle information.  Simulyzer displayed the data being collected in graphical format during the V&V and SELF LUT-1 exercises.  A software module was added to Simulyzer that parses the logged data file and populates a database later used for data analysis. BATS IOSThe BATS IOS was used during SELF LUT-2 to collect the DIS PDUs, therefore eliminating the use of Simulyzer.  The IOS provides the operator an interface into the crew station, which allows an Instructor Operator to:Initialize the simulator and its associated subsystems,Control the sequence of instructional events,Automate exercise generation,Serve as a role player (e.g., Driver), Monitor and analyzes the students’ performance during an exercise,Provide trainers with the ability to manage the training environment (user account management, crew record management, environmental parameters management), and Provide an interface to the simulator Commanders’ Tactical Display (CTD) using Variable Message Format (VMF) digital messaging.This same system was used to collect and analyze the data being generated by the crews under test.  The data was then provided to an analysis module to create the final data base for OPTEC’s review.  Figure 3.4.3 – 1depicts and operator at the IOS during testing.Figure 3.4.3 – 1  Instructor Operator StationRemote Monitoring System (RMS) AssemblyThe RMS Assembly includes displays and video switching equipment for remote monitoring functions before, during, and after training.  The RMS allows the instructor to view an on-going exercise or review previous exercise information on a set of displays for crew pre-brief and After-Action Review (AAR).  The RMS, in conjunction with the IOS, provides the full instructional support capabilities of the simulator for gunnery testing and training.Verification and ValidationPrior to both tests, AMSAA led a verification and validation (V&V) test of the SELF infrastructure hardware and software.  The V&V focused on three areas: form, fit, and function, target acquisition, and delivery accuracy.For SELF LUT-2, the LUT-1 assessment was used as a baseline, although AMSAA verified and validated those infrastructure components that had changed in the in the transition from LUT-1 to LUT-2.FORM, FIT, AND FUNCTIONThe test of form, fit, and function consisted of 2 parts: use of the simulator by soldiers (accompanied by interviews with the soldiers), and testing of the simulator by test personnel.  The issues that were addressed can be divided into three categories: crew station layout, sensor views, and sound system.Test DescriptionFor SELF LUT-1, after each use of the simulator by soldiers, test personnel conducted crew interviews to gather data on the operation and ease of use of the simulator controls, the quality of the sensor views, and the appropriateness of the sound system.  A total of six (6) soldiers were interviewed: 2 subject-matter experts (SME) who helped to conduct crew training on the system and four crewmen who had completed training on the system and participated in the SELF LUT-1 test.  For SELF LUT-2, interviews were conducted of the crew to gather data on the operation and ease of use of the simulator controls, the quality of the sensor views, and the appropriateness of the sound system.  A total of five crews of ten (10) soldiers were interviewed.Evaluation of form and fit relied primarily on documentation of the contractor’s development process, which used the system design to guide the layout of the BATS.  Test personnel examined the BATS simulator, test controls, and switches for functionality; measurements for form and fit were only taken if the soldier interviews revealed a potential problem.Testing of the operation and ease of use of the simulator controls had the following goals:Crew Station (Layout).  Verify that the controls, displays, instruments, placards, and handgrips are in locations in accordance with the specification.Controls and Switches (Operation).  Verify that the correct inputs and outputs are provided to and from the switch.  Verify that the control or switch provides the correct state change.  Verify that the state changes occur in the time required after switch or control activation.Controls and Switches (Location).  Verify that the location of the control or switch is in accordance with the System Requirements Document.Controls and Switches (Type).  Verify that the control or switch represents the required type (such as push-button or toggle).Controls and Switches (Simultaneous Operation).  Verify that simultaneous actuation of multiple controls or switches does not affect the operation of the simulator and that the required hierarchy is followed.  (Limited verification was done in this area, demonstrating only functions that have a likelihood of simultaneous actuation.)Instruments (Operation).  Verify that the instruments included in the simulation in support of crew operation provide the functions described in the specification.  Verify that the instruments are provided the correct inputs from the simulator.During SELF LUT-1, for the evaluation of the sensor views, test personnel fired 25-millimeter ammunition from the BATS at short, medium, and long ranges; observed other entities firing weapons; observed the motion of other entities; and observed the motion of the BATS simulator.During SELF LUT-2, for the evaluation of the sensor views, test personnel fired 25-millimeter ammunition from the BATS at short, medium, and long ranges; observed other entities firing weapons; observed the motion of other entities; and observed the motion of the BATS simulator.Testing of the sensor views had the following goals:Munition Impact.  Verify that the munition impact signature appears, for both hits and misses, for each sensor view;Detonation.  Verify that the detonations of other weapons appear, for each sensor view;Motion of Other Entities.  Verify that the motion of other entities is appropriately smooth, for each sensor view;Motion of Simulator.  Verify that the motion of the simulator (both as the vehicle moves and as the turret slews) is appropriately smooth, for each sensor view;Changing Field of View.  Verify that the simulator changes Field Of View (FOV) at the same rate as the actual system.For form, fit, and function, the sensor views were evaluated to ensure that munition firing and motion are represented realistically.  A more detailed evaluation of the sensor views was conducted during the image generation and target acquisition evaluation.For evaluation of the sound system, test personnel listened at each situation where sound should be transmitted to verify that a sound is provided.Limitation and AssumptionsForm and fit were not comprehensively assessed through taking measurements and comparing these to the system specifications.  As a result, all differences between the BATS and the actual system may not have been noted; however, by interviewing the soldiers after each use of the simulator, those differences detectable during use of the simulator are likely to have been captured.  Generally, one purpose of the sensor view test is to judge the ability of the computer image generator (CIG) to continue to present smooth images during an intense battle.  Since the scenarios were limited to 2 targets at a time, that aspect was not addressed.   The measurement of the sound system was highly subjective.Observations and EvaluationFor the capabilities addressed in the SELF LUT-1 test, the assessment was that the BATS simulator generally looks, feels, and functions like the actual system.  The sensor views presented by the BATS are smooth and appropriate, and the sounds produced by the BATS are appropriate. For the capabilities addressed in the SELF LUT-2, the assessment was that the BATS simulator generally looks, feels, and functions like the actual system.  The sensor views presented by the BATS are smooth and appropriate, and the sounds produced by the BATS are appropriate. TARGET ACQUISITIONThe Bradley sensor view is displayed to the gunner and commander through a CIG.  The display must allow the soldier to detect, recognize, and identify targets in a manner consistent with system characteristics.  This implies that the CIG must portray targets consistent with their infrared and visual signatures.  Thus, the evaluation of the target acquisition representation of the Bradley simulator must include an evaluation of the Bradley CIG.The Bradley employs the following sensors:Direct-View Optics (DVO),Improved Bradley Acquisition System (IBAS), equipped with a Forward-Looking Infrared (FLIR) sensor and a Day Television (TV) Camera,Commander’s Independent Viewer (CIV),  also equipped with FLIR and Day TV, and Vision blocks (periscopes).The target acquisition test consisted of three phases: use of the simulator by soldiers (accompanied by interviews with the soldiers), use of the simulator by test personnel, and stationary target acquisition.  After each use of the simulator by soldiers, test personnel conducted crew interviews to gather data on the target acquisition capability of BATS. For SELF LUT-1, a total of 6 soldiers were interviewed.   For SELF LUT-2, a total of 10 soldiers were interviewed.  During target acquisition testing test personnel checked the following:Verify that the proper sequence of control actions must be performed before target acquisition is allowed.Verify that a second target may be acquired while one target is being tracked.Verify that the proper symbols are displayed at the appropriate times during target acquisition.For SELF LUT-1, 2 soldiers participated in a stationary target acquisition test.  The soldiers were presented with a series of stationary targets on National Training Center terrain.  The 6 targets presented were a Blue tank (M1A2), a Red tank (T72), a Blue armored fighting vehicle (M2A3), a Red armored fighting vehicle (BMP-2), a Blue wheeled vehicle (HMMWV), and a Red wheeled vehicle (BTR-60).  The ranges were short, medium, and long; these ranges are representative of the ranges used during the SELF LUT-1 test.  Each soldier observed a total of 54 targets during a test, plus four null targets (scenes where no target was presented).  The test was conducted with each soldier using the IBAS FLIR in wide FOV, the IBAS FLIR in narrow FOV, the IBAS Day TV in wide FOV, and the IBAS Day TV in narrow FOV. Figure 4.2 – 1 shows a BFV A3 commander during target acquisition V&V testing. Figure 4.2 –1  Target Acquisition V&V  TestThe SELF LUT-2 test was executed using 3-D target representations while the real LUT still used flat panel targets.  Since target boards were used for LUT-1 as well as vehicle representation, no appreciable differences were noted and so the target panels were not used for SELF LUT-2. Using a mixed set of vehicles would likely have given the soldiers an additional cue for those 2 vehicles, so vehicles were used for all 6 targets to ensure consistency.DELIVERY ACCURACYPrior to the SELF LUTs, the standard Army algorithm for delivery accuracy was implemented in the BATS. Test personnel fired several rounds at targets to verify that the simulator interfaces with the Ballistic Software Solution (BSS) properly, and test personnel conducted testing to check the following:Verify that fratricide is possible by engaging a friendly target.Verify that the simulator cannot engage targets successfully beyond a maximum range.Verify that the simulator cannot engage targets successfully within a minimum range.Verify that the simulator will miss a target when it is aimed away from that target.Verify that the simulator cannot fire at a rate faster than the BFV A3 system.Although the methodology for a moving shooter was implemented in the BATS, it was not tested.  This methodology adds an additional dispersion when the shooter is moving.  No testing of the TOW missile system capability was conducted.The results of these LUT tests indicate that the BATS has the standard algorithm for delivery accuracy correctly implemented.  No problems were noted.Self Lut-1 Test ExecutionThe SELF LUT-1 was conducted at the Collins Training Center, Fort Benning, Georgia on 18-20 November 1997.  Testing was conducted at Fort Benning, Georgia, where both the simulator and the BFV A3 trained crews were located prior to LUT-1. The SELF LUT-1 tests replicated the gunnery tests planned for the BFV A3 LUT-1. These gunnery exercises planned for the BFV A3 LUT-1 were carried out in the SE 2 weeks prior to actual LUT-1 tests.  Data was collected to satisfy 30 MOPs that focused on the ability of the BFV A3 to perform Target Acquisition and Delivery Accuracy.  The SELF LUT-1 explored the Bradley’s lethality, not its vulnerability.The End-to-End Data Run was conducted on Monday, 17 November 1997, and Record Tests were conducted from 18-20 November 1997. Two qualified gunners and commanders were presented with eighty two (82) moving targets and three hundred eighty one (381) stationary targets (using 5 round or fewer bursts only).  They used the FLIR, DVO and Day TV sights.  A BFV A3 trained commander and gunner (TEXCOM LUT-1 Crew #5 and Crew #1) ran through a series of scenarios that required target detection and engagement.  These day and night engagements were developed to generate the data necessary to satisfy MOPs concerning target acquisition, target tracking, and delivery accuracy of rounds.  The crew's actions were recorded by the BATS Instructor Operator Station (IOS) and analyzed as DIS PDUs by the Simulyzer. These scenarios allowed the test team to evaluate how well the vehicle under test met the requirements stated in the BFV A3 MOPs.  Test personnel noted that this system captured all the relevant data that is not always possible in the field.  It also provided a controlled environment to assess the system under test.  The SELF data was provided to the data analysts supporting  the actual BFV A3 LUT-1 in December 1997.  The data was compared to the data collected on Hastings Range and OPTEC developed the SELF System Assessment in May 1998.Self LUT-1 Test Data AnalysisThe SELF LUT-1 comparison assessed the simulated LUT-1 conducted at the Collins Training Center in Fort Benning, Georgia on 18–21 November 1999 and the actual LUT-1, conducted at Hastings Range in Fort Benning, Georgia in early December 1999.  Both tests used qualified gunners and commanders.  The SELF LUT-1 had 2 crews (alternative test crew #5 and test crew #1) that were presented 82 Moving Targets and 381 Stationary Targets (5 round or fewer bursts only), using FLIR, DVO and Day TV Sights.  In contrast, the actual LUT-1 had four qualified crews (Test Crew 1, Test Crew 2, Test Crew 3,and Test Crew 4) that were presented 117 Moving Targets and 315 Stationary Targets using the FLIR, DVO and Day TV Sights.  The SELF LUT-1 used a simulation of flat panel targets used in live gunnery.  The actual LUT-1 used Plywood thermal targets (front and side view representations if the BMP and BTR).  Both systems ran BFV A3 software version 1.1.  The SELF LUT-1 system used 2 different round to round dispersions to compensate for the lack of weather effects.SELF LUT-1:  Engagement Probability of engagement is defined as the presentation of targets engaged divided by the number of targets presented.  For the probability of engagement, DVO Long Range with No NBC, DVO Short Range with No NBC, and all Short Range showed good correlation between SELF and LUT-1 results.  But for FLIR Long Range with NBC and TV Long Range with NBC, there was no correlation between SELF LUT-1 and LUT-1 results.  This low correlation is in part due to the representation of the terrain database in the BATS.  At the time of SELF LUT-1 testing, BATS had a low-cost image generation system that provided minimal scene clutter.  Also, the SE did not replicate the identical terrain elevations.  The SE selected a portion of an existing NTC terrain database that closely represented the terrain, but did not have foliage or terrain masking.  Had a terrain database of the actual LUT-1 area been developed these differences may have been minimized.  This development was not pursued due to cost constraints.  Additionally, the optic scenes of the BATS were not calibrated with the optic scenes of the BFV A3, causing contrast issues.  This is a minor and low cost adjustment that was corrected for SELF LUT-2. SELF LUT-1: Hit Given PresentationHit given presentation is defined as a target hit by at least one round out of a burst of five or fewer rounds over targets presented.  For hit given a presentation, DVO Long Range with No NBC had excellent correlation while TV Long Range with NBC, TV Medium Range with NBC, and TV Short Range with No NBC had no correlation.  This was probably also due to the differences in visual scenes between the SELF LUT-1 and the BFV A3.  Some of the SELF LUT-1 bursts had more than 5 rounds, while less than 1% of LUT-1 engagements had more than 5 rounds.  This situation lowered the actual number of SELF LUT-1 samples available so that some of the correlations were skewed due to small sample sizes.  This was not an issue for SELF LUT-2 since the definition of a hit will be three rounds striking the target and the number of rounds per burst or number of bursts allowed per engagement was not be controlled.During the SELF LUT-1, the targets were randomly displayed to the crew in an effort to not reveal the order of the live tests.  This order was determined after the fact to be unrealistic in presentation and caused additional time for the crew to acquire and engage the second target in a 2-target engagement.  Time to engage given presentation for the first target was comparable between the test environments, but the time to engage the second target was considerably less for LUT-1, when compared to SELF LUT-1 data.  While some of the difference may be due to visual scene representation differences, the SELF LUT-1 time may have time stamp problems.  During SELF LUT-2, the target order were arranged in a more realistic representation of how the actual LUT-2 gunnery targets are presented.  SELF LUT-1: Hit Given EngagementHit given engagement is defined s the number of targets hit (by one or more rounds out of five fired) over the number of targets engaged (fired upon).  For hit given an engagement, DVO Long Range with No NBC the correlation probability was 0.89.  For FLIR Long Range with No NBC the probability was 0.69.  For TV Long Range with No NBC the probability of correlation was 0.70  (note: Small Sample Size).  For FLIR Medium Range with No NBC the probability of correlation was 0.0.  This indicated that once the target was engaged, the Hit probabilities in the SELF LUT-1 correlated well with the actual  LUT-1.  If one considers that gunnery engagement and the determination of hit given engagement is a high cost driver for Live Fire Test, the SE may yield significant savings. SELF LUT-1 ConclusionsThe SELF infrastructure proved capable of supporting gunnery testing (similar to live gunnery).    SELF LUT-1 reliability was also excellent with only one failure incident in which the system was unavailable for a short period of time in four days of testing.  SELF LUT-1 also showed that it was capable of allowing gunners to practice test scenarios.  Additionally, SELF LUT-1 data was collected more efficiently than in the LUT-1.  However, this data did require post processing to translate from the SELF PDU database format to the OPTEC evaluation database format.SELF LUT-1 illustrated that the SE can be used to aid in LFT by practicing the gunnery scenarios, pre-testing the gunnery exercise, and executing the test to collect and analyze data.  With this additional support to LFT, an enhanced testing process with more robust data can be performed and obtained.Self LUT-2 Test ExecutionThe SELF LUT-2 was conducted at the SimNET/Applique Warfighting Facility in Fort Hood, Texas on 21-25 Septemberember 1998.  Testing was conducted at Fort Hood, Texas, where both the simulator and the BFV A3 crews were located prior to the BFV A3 LUT-2.  Data was collected to satisfy 30 MOPs that focused on the ability of the BFV A3 to perform Target Acquisition and Delivery Accuracy.  The SELF LUT-2 also explored the Bradley’s lethality, not its vulnerability.The End-to-End Data Run was conducted on Monday, 21 September 1998, and the Record Tests were conducted from 22-25 September 1998.  All five qualified gunners and commanders were assessed and were presented XX  Moving Targets and  XXStationary Targets (5 Round Or Fewer Bursts Only).  They used FLIR, DVO And Day TV Sights. The Bradley A3 trained commander and gunner ran through a series of scenarios that required target detection and engagement. These day and night engagements were developed to generate the data necessary to satisfy MOPs concerning target acquisition, target tracking, and delivery accuracy of rounds.  The crew's actions were recorded by the BATS Instructor Operator Station (IOS) and analyzed as DIS PDUs. These scenarios allowed the test team to evaluate how well the vehicle under test meets the requirements stated in the BFV A3 MOPs.  It also provided a controlled environment to assess the system under test.   The data was later used by OPTEC to develop a System Assessment for SELF LUT-2.  Figure 7.0 – 1 is a picture taken during SELF LUT-2.Figure 7.0 –1  SELF LUT-2 at Fort HoodSELF LUT-2 TEST DATA ANALYSISThe comparison assessed the simulated LUT-2 conducted at the SimNET/Applique Warfighting Facility in Fort Hood, Texas on 21-25 September 1998 and the actual LUT-2, conducted at Fort Hood, Texas in October 1998.  Each used the four qualified gunners and commanders to execute the test while the SELF also used the alternative test crew for its data collection.  For SELF, the crews were presented XX moving targets and  XX stationary targets (5 round or fewer bursts only), using FLIR, DVO and Day TV Sights.  In contrast, the actual LUT-2 crews were presented XX moving targets and XX stationary targets using the FLIR, DVO and Day TV Sights.  The SELF LUT-2 used a simulation of 3-D  targets created by ModSAF.  The actual LUT-2 used Plywood thermal targets (front and side view representations if the BMP and BTR).  Both systems ran BFV A3 software version 3.0. The SELF LUT-2 system used 2 different round to round dispersions to compensate for the lack of weather effects.SELF LUT-2:  Engagement Probability of engagement is defined as presented targets engaged divided by the number of targets presented.  For the probability of engagement, DVO Long Range with No NBC, DVO Short Range with No NBC and all Short Range showed good correlation between SELF LUT-2 and LUT-2 results.   This was also true for FLIR Long Range with NBC and TV Long Range with NBC. SELF LUT-2:  Hit Given PresentationHit given presentation is defined as a target hit by at least one round out of a burst of five or fewer rounds over targets presented.  For hit given a presentation, DVO Long Range with No NBC had excellent correlation as well as TV Long Range with NBC, TV Medium Range with NBC, and TV Short Range with No NBCSELF LUT-2:  Hit given engagementHit given engagement is defined as the number of targets hit (by one or more rounds out of five fired) over the number of targets engaged (fired upon).  For hit given an engagement, DVO Long Range with No NBC the correlation probability was 0.9.  For FLIR Long Range with No NBC the probability was 0.9.  For TV Long Range with No NBC the probability of correlation was 0.9.  For FLIR Medium Range with No NBC the probability of correlation was 0.9.  This indicated that once the target was engaged, the Hit probabilities in the SELF LUT-2 correlated well with the actual LUT-2. SELF LUT-2:  ConclusionsThe SE infrastructure was demonstrated as capable of supporting gunnery testing.  SELF LUT-2 reliability was also excellent with no failure incident where the system was unavailable.  SELF LUT-2 also showed that it was capable of allowing gunners to practice test scenarios and was used for the actual training of the test crews.  Additionally, SELF LUT-2 data was collected more efficiently than in the LUT tests. The SELF reaffirms that the BATS (and other gunnery training devices) can provide gunnery training to crews.  It was demonstrated that a SE can provide target acquisition and hit probabilities similar to live fire test results. The SELF LUTs also illustrated that the SE can be used to aid in LFT by practicing the live fire test scenario, pre-testing the live fire exercise, and executing the LFT to collect and analyze data.  With this additional support to LFT, an enhanced testing process with more robust data can be performed and obtained.  Future PlansThe SELF program will be completed in the Spring of 1999, when a Final Report is provided by STRICOM.  This report will summarize the findings and conclusions of the SELF tests.  This report will be available on the SELF web page, which is located at:http://www.stricom.army.mil/PRODUCTS/SELF/home.html.Author BiographiesANGELA ALBAN is a Simulation Engineer at United Defense, in Orlando, Florida.  She is the lead engineer for the SELF and Bradley Desktop Trainer programs.  Ms. Alban has been working in the modeling and simulation industry since receiving her Bachelor of Science degree in Mathematics and Computer Science from Emory University in Atlanta, Georgia.  She is currently completing a Masters of Science degree in Computer Engineering from the University of Central Florida in Orlando, Florida.ALESYA PASCHAL is a Systems Engineer at the U.S. Army Simulation, Training, and Instrumentation  Command (STRICOM) in Orlando, Florida.   Ms. Paschal received a Master of Science degree in Industrial Engineering from Texas A&M  University and a Bachelor of Science degree in Industrial Engineering from University of Tennessee.  Ms. Paschal’s research interests include the simulation of C4I systems and Simulation Based Acquisition. MS. IRENE JOHNSON has worked as an Operations Research Analyst at the U.S. Army Materiel Systems Analysis Activity (AMSAA) for the past ten years, since receiving a Bachelor of Science degree from University.  Her experience includes leading one of the Anti-Armor Advanced Technology Demonstration experiments; participating in each of the Rapid Force Projection Initiative experiments; and working with constructive combat models such as Vector-in-Commander and the AMSAA Division-Level Wargame.LOUIS SANTONE is employed by American Management Systems, Inc, (AMS) based in Fairfax, Virginia on a subcontract to VRC Corporation of Alexandria, Virginia, supporting Operational Evaluation Command (OEC).  After receiving a Bachelor of Science degree in Education from Millersville University, he began his career at Aberdeen Proving Ground (APG) performing aerodynamic analyses for the Ballistic Research Laboratory. He then worked at Frankford Arsenal at Philadelphia, Pennsylvania and received a Master of Science degree in Mathematics from Temple University.  After ten years at Frankford Arsenal, where he was a weapons systems analyst for systems ranging from small arms to recoilless rifles to anti-ballistic missile defense system, he joined the staff of the Strategy and Tactics Analysis Group (now Concepts Analysis Agency).  Mr. Santone left military agencies for civilian agencies by joining the National Bureau of Standards. He retired from the Department of Commerce and joined AMS where he has worked in support of OEC and its predecessor OTEA for the past 14 years.PAGE  