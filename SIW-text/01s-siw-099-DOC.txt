Threat Modeling and Simulation In Support of Test and EvaluationJoseph G. MoroscoDefense Intelligence AgencyMissile and Space Intelligence CenterThreat Systems Office2001 N. Beauregard St., Suite 758Alexandria, VA 22311Jmorosco@dote.osd.milKEYWORDSTest and Evaluation; JRAAC; threat models; networking; distributed mission testing; intelligence; JADS; TMAPABSTRACT:  A tester’s ability to produce the most accurate assessment of a system’s operational effectiveness largely depends upon the ability to test a system within the most realistic threat environment possible.  To maximize test realism, this threat environment must pursue a concept of operations that will lead to the networking of multiple threat resources with blue system representations to support system-of-system assessment.  The success of such a concept of operations can be furthered through a networked access, for test purposes, to threat modeling and simulation resources within the scientific and technical intelligence community, and a clearly defined process for rapid insertion of new intelligence data into existing threat representations.  A distributed mission testing capability is necessary to provide the tester access to the latest in threat modeling and simulation resources such as the Joint Research Analysis and Assessment Center (JRAAC) located at the Missile and Space Intelligence Center and the Threat Software Analysis Facility (TSAF) at the National Air Intelligence Center (NAIC).  Using the High Level Architecture standard, the JRAAC can link to other modeling and simulation databases at the test ranges to provide a real time analysis tool integrating existing blue system models with a limited number of threat representations.  A threat model’s value to test and evaluation is dependent upon whether it reflects the most current intelligence data on a given system.  For this reason, it is important that new intelligence data be disseminated to the tester in a rapid manner to determine whether the change in threat system capability will impact the test event, and so that required updates to the model can be made.1. IntroductionThe complex and dynamic nature of today’s threat environment introduces substantial challenges to our nation’s ability to test and evaluate our weapon systems against an increasingly advanced threat.  Threat system modifications and capability upgrades rapidly occurring on a global scale have complicated the process of testing against the most recent version of a particular threat.  This reality has underscored the necessity for directly connecting ranges with threat representative models and simulations maintained within the scientific and technical intelligence (S&TI) community.  The concept of establishing a distributed mission testing capability that enables access to S&TI community resources will enhance assessment of U.S. platform effectiveness against current threat system capabilities within a system-of-systems context.   2. Current Threat Representation on Test RangesThe landscape of test and evaluation (T&E) today is characterized by a number of issues surrounding the use of threat representative resources, including models and simulations, to create the most accurate threat environment possible to satisfy test criteria.  These issues include the current use of dissimilar and, in some cases, inaccurate, threat models across the test ranges.  In the area of electronic warfare (EW) testing, variations in miss distance scoring data have been found to occur between ranges using threat models that differ in the recency of the intelligence information they embody.  This variable representation of the threat is a symptom of a suboptimal use of threat resources currently available in the defense intelligence community.3. Confirming EvidenceCurrent problems experienced with the use of threat modeling and simulation resources are often times evident on system acquisition programs that rely on the use of these resources as part of the T&E process.There are several programs in the Department today that currently use threat-modeling resources that have not been validated as representative of the current threat.  For instance, in the area of EW system testing, this issue can directly impact near-term EW T&E requirements.  On one particular EW program, testing has commenced using five command-guided flyout models that do not embody the most recent intelligence data, and on another such program, testing is currently supported with only two suitable threat missile flyout models out of the five models required for test.  Contributing to this problem is the lack of resources required to perform critical maintenance activities on existing flyout models still being used as test resource assets, including software repairs, intelligence upgrades, and validation activities.  This has resulted in the inability to correlate test data derived from the use of these models with a reasonable level of confidence, thus underscoring the issue as crucial to determining test adequacy.4. Concept: Distributed Mission TestingThe ability to interconnect and access multiple and disparate threat resources for test and evaluation can alleviate many of the problems experienced while adhering to the current paradigm of using stand-alone modeling databases.  Creating a distributed mission testing environment that networks the appropriate threat modeling databases resident in the defense intelligence community with current range assets will assist in resolving issues surrounding inter-range data correlation and the use of less-than-current threat models. Additionally, a matrixed test capability will facilitate the evaluation of blue systems within a threat representative system-of-systems context.4.1 Building upon the Joint Advanced Distributed Simulation ConceptThe Joint Advanced Distributed Simulation (JADS) Joint Test and Evaluation (JT&E) conducted an in-depth exploration of the utility of distributed mission testing.  The JADS JT&E sought to determine whether interconnecting virtual, live, and constructive simulations (including interconnecting disparate simulations) would be of value to the test and evaluation process.    The results of the JT&E supported the concept of distributed mission testing, and dispelled the conventional notion that M&S used in T&E applies only to stand-alone constructive simulations used to predict system under test performance [Ref. 1]. Furthermore, the JADS concept demonstrated the interconnection of a real (or partially real) system under test to a synthetic test environment created by linking live, virtual, or constructive players.  These linked players were then used to actually measure the performance of the system under test [Ref. 1]. Application of the JADS concept permits the system under test and the test assets in the synthetic test environment to be geographically separated (the essence of a distributed test).The concept of distributed mission testing was proven to be viable by the JADS JT&E. Establishing direct connectivity with defense intelligence community databases capable of supporting threat models and simulations will leverage the JADS utility described in the JT&E.  Although the final report specifies that the value of distributed testing is case specific, it does maintain that “it provides the only affordable means of conducting adequate system of systems or mission-level testing” [Ref. 1].   In order to realize a “JADS-based” environment that interconnects multiple and geographically distinct S&TI community assets with test range resources, the communications infrastructure and associated business practices must exist to support it.  It has been found that the communications technology in place at many locations is sufficient to support a JADS-based environment, however, the current business practices must continue to evolve to maximize utility of a distributed test capability.4.2 Networked Access to Validated Threat ResourcesThe reliance on realistic and up-to-date threat information and representation by the test community underscores the value of pursuing a vigorous distributed mission testing capability that will build upon the concepts explored by the JADS JT&E and enable a “networked” access to the defense intelligence community and the latest intelligence on a threat system.  The Joint Research Analysis and Assessment Center (JRAAC) located at the Missile and Space Intelligence Center in Huntsville, AL can provide the test community with a verified threat modeling and simulation capability with respect to a limited number of surface-to-air missile systems.  A similar capability for early warning radars exists at the Threat Software Analysis Facility (TSAF) located at the National Air Intelligence Center (NAIC) at Wright Patterson AFB, OH.  The primary focus of the TSAF is to represent the air surveillance radar and ground control intercept components of a threat command and control system.  The JRAAC/TSAF is designed to draw from the most recent all-source intelligence data to create a virtual representation of a threat system and its associated command and control environment.   The primary advantages of connecting the JRAAC/TSAF to test range databases are clear: consistency in the threat data used across the ranges is achieved, the need for the customer to become infinitely knowledgeable about the threat data contained within the model is eliminated, and the overall verification and validation effort is greatly reduced.  Additionally, the JRAAC/TSAF makes it possible for blue system testing to occur within the context of a complete set of components of selected enemy air defense systems, including the interoperability of air surveillance, target tracking/target acquisition radars, and associated command, control, and computer representations.  It is, however, important to note that currently only a limited number of systems are implemented in the JRAAC/TSAF. The JRAAC/TSAF has also proven to be effective in system-of-system testing of blue system effectiveness within a networked environment, as demonstrated during the 2000 Joint Expeditionary Force Experiment (JEFX).  JEFX ‘00 incorporated both the JRAAC and the TSAF into an integrated air defense system environment [Ref. 2] that served remarkably well in providing an increased level of threat simulation fidelity.  Although the JRAAC/TSAF is primarily being used to support S&TI requirements in the near-term, the test and intelligence communities are currently evaluating the future capability of the JRAAC/TSAF to integrate with existing test facilities and assets.  The JRAAC/TSAF uses the High Level Architecture standard to exchange data with other modeling and simulation databases, and can potentially be used as a supplemental test resource to enhance the overall fidelity of the threat environment.The JRAAC/TSAF is a valuable tool that, if networked, would provide the test community with an unprecedented level of fidelity of a complete threat system.  Although a 3-month study is currently underway to investigate various integration issues with existing T&E resources, a clearly defined set of test and evaluation community requirements for JRAAC/TSAF remains to be established.    5. IssuesAlthough evidence exists that networking intelligence community resources to T&E ranges and events is viable, there are a number of issues associated with making this concept a reality.  The ability of the intelligence community to respond to the tester’s demands of representing the most recent threat, along with the available technology, funding strategies, and test range resourcing policies contribute to a large degree of uncertainty surrounding the implementation of a distributed testing concept that directly includes intelligence community resources.   5.1 Rapid Integration of New Intelligence and Analysis Data into Threat Models and SimulationsThe overall value of integrating S&TI digital resources with test ranges is largely dependent upon the ability of the S&TI community to rapidly insert new intelligence and mature analysis data into existing threat representations. As new intelligence on a particular system becomes available through all-source analysis, the corresponding threat models must be modified to reflect any change in the threat’s capability, based upon evidence that the new threat data will directly impact a given test event.  The traditional paradigm of intelligence production has exhibited a great deal of difficulty in supporting this concept.   Under the traditional paradigm, S&TI products have taken the form of parametric data describing threat system characteristics, performance, and vulnerabilities and have been maintained in a text or engineering equation format in large threat databases at the cognizant S&TI center.  This intelligence data is then used by blue system program managers to construct models and simulations that may represent the current threat environment, but will not be well-integrated with a model maintenance process that allows for timely updates based on new intelligence information.  Use of threat models at varying or inadequate levels of intelligence information between the test ranges contributes to a compromise of test result adequacy depending on the test and evaluation criteria of the system being tested.  The defense intelligence community is developing a process to facilitate the insertion of new intelligence data into threat representations created using MATLAB/SIMULINK software (analysis software that integrates a computing language with a set of interactive modeling and simulation tools designed to graphically depict engineering analysis of dynamic systems).  Known as the Threat Modeling and Analysis Program (TMAP), new intelligence information discovered through a variety of sources is rapidly inserted into C++ objects created in MATLAB/SIMULINK and stored in a dynamic, interactive database maintained at the S&TI centers. Depending upon a system’s test and evaluation requirements, these objects can be tailored to operate within the context of a given modeling architecture such as the Joint Modeling and Simulation System.  The continued success of this intelligence integration strategy remains dependent upon the S&TI community’s ability to integrate and respond to the requirements corresponding to the test and evaluation component of the systems acquisition process.  5.2  NetworkingAny future initiative to include the S&TI community as an integral component of a distributed mission testing environment must address a myriad of networking-related issues, both technical and programmatic in nature.  Though it has been demonstrated that the technology exists to achieve the required physical connectivity, other technical issues such as multi-level security, network capacity, and threat asset availability must be addressed.  Using the JRAAC/TSAF as an example, connectivity would be dependent upon access to a secure network backbone such as the Secret Internet Protocol Routing Network (SIPRNET), or a Secure Telephone Unit (STU) III connection.  Although bandwidth cost is marginal (the data transmitted by the JRAAC/TSAF is not bandwidth-intensive), the ability of the facility to support a large number of simultaneous users must be considered.  Another issue related to networking S&TI assets is programmatic in nature.  The value of tying into the S&TI centers versus installing S&TI assets (such as the JRAAC/TSAF) on-site must be considered by the end user.  For instance, the JRAAC/TSAF facility is fairly economical to install on-site, however, the cost of on-site installation must be compared to the increased value of creating a matrixed test environment that will integrate the entire spectrum of verified intelligence resources required to create the most threat representative test environment possible.5.3  Resourcing PolicyAn issue critical to determining the success of networking S&TI assets with existing T&E ranges is that of current resourcing policy and the obstacle it creates to concept implementation.  For example, the JRAAC/TSAF were developed as S&TI facilities for use by the S&TI community for S&TI analysis purposes.  The funding for development and maintenance of these assets came under the auspices of the General Defense Intelligence Program (GDIP), a subcomponent of the National Foreign Intelligence Program.  Current resourcing policy dictates that the GDIP funds activities that provide for [Ref. 3]: •	military intelligence analysis at the Defense Intelligence Agency (DIA), nine Unified Commands, and the military intelligence commands of the Army, Navy, and Air Force; •	infrastructure for DIA and the military service intelligence commands; •	intelligence openly collected by Defense Attaches and other DoD personnel; •	intelligence clandestinely collected by DoD personnel; and •	certain technical collection efforts (e.g. characterizing foreign nuclear testing). Resourcing policy does not allow for GDIP funding of T&E activities [Ref. 3]; program managers or Service test organizations fund all of the costs associated with these activities.  Additionally, there is no precedent for the transference of Service T&E funds to the S&TI community to actually perform test activities.  The root cause of this dilemma is an incongruency of existing resourcing policy with recent advances in technological capability.  The cost associated with the operation and maintenance (O&M) of S&TI assets must also be considered.  Traditionally, if the intelligence community were to deliver a finished intelligence product (a model for instance) to an external customer, the customer would assume the O&M cost of that particular model.  As technology evolves to provide external customers with networked access to S&TI resources that are currently only used to support S&TI analysis, the issue of O&M cost assumption for these resources will become increasingly prominent as the end use of these resources extends beyond the domain of the S&TI community.  Long-term resolution of these resourcing issues would require a major paradigm shift in both the T&E and defense intelligence communities at large.  This shift would require the S&TI centers to be viewed as “threat ranges”, and would require the establishment of a resourcing strategy similar to that of the Major Range and Test Facility Base (MRTFB), a national asset operated and maintained for T&E support missions.  Like the MRTFB, funding of S&TI assets to conduct specific T&E activities would be necessary, and would include the cost of S&TI community labor, material, facilities, minor construction, utilities, equipment, supplies, items damaged or consumed during testing, and any resource or item maintained for a particular user [Ref. 4].  In order to implement this strategy, existing resourcing policy must be reviewed and updated to effect a process by which Service T&E funds could be transferred to S&TI centers to conduct T&E-related activities.   6. SummaryThe future role of the S&TI community in support of test and evaluation will be driven by the requirement of the test community to access the most realistic and up-to-date threat information possible.  There is initial evidence supporting an existing need to integrate S&TI threat assets with the test ranges, adhering to the concept of a distributed mission test environment.  The implementation of such a capability would enhance test realism by providing a common, current, and verified representation of a given threat to support program test criteria.   Furthermore, linking to facilities such as the JRAAC/TSAF would enable the assessment of blue systems within a threat representative system-of-systems context.The challenges to making this matrixed test concept a reality are many.  Issues related to intelligence integration, networking, and resourcing policy remain, for the most part, unresolved.  Despite these challenges, the need for the test community to embrace the concept of connecting the S&TI centers in a distributive manner is becoming increasingly apparent.  The time to begin to formally identify the test and evaluation requirements to support this concept is now.    7.  References[1]  Erick Keck, JADS JT&E: JADS Executive Report on the Utility of Distributed Testing, December, 1999[2]	Capt. Kenneth Kranz, Air Intelligence Agency, Virtual IO Range: Most Significant Advancement of Past Decade, August, 2000[3]	Commission on the Roles and Capabilities of the United States Intelligence Community, Preparing for the 21st Century: An Appraisal of U.S. Intelligence, Ch. 7, March 1996[4] 	DoD Financial Management Regulation: “Major Range and Test Facilities”, Vol. 11A, Ch. 12, May 1998Author BiographyJOSEPH MOROSCO is an intelligence officer at the Defense Intelligence Agency, Missile and Space Intelligence Center supporting the Deputy Director, Resources and Ranges in the Office of the Director, Operational Test & Evaluation on threat modeling and simulation issues.  Mr. Morosco has prior experience supporting the Office of the Undersecretary of Defense for Acquisition, Technology, and Logistics on coordinating the use of modeling and simulation in weapon systems acquisition.  Mr. Morosco holds a bachelor’s degree from James Madison University, and is completing a master’s degree in Telecommunications at George Mason University.