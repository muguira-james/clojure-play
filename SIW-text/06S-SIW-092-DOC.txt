A Comparison of Techniques for Discrimination of Buried Unexploded Ordnance (UXO) Edwin Roger Banks, Edwin Núñez, Paul AgarwalCOLSA Corporation, 6726 Odyssey Drive, Huntsville, AL 35806 HYPERLINK "mailto:rbanks@colsa.com" rbanks@colsa.com,  HYPERLINK "mailto:enunez@colsa.com" enunez@colsa.com,  HYPERLINK "mailto:pagarwal@colsa.com" pagarwal@colsa.com Marshall McBride, Ron LiedelU.S. Army Space & Missile Defense Command (USASMDC)Huntsville, AL 35807 HYPERLINK "mailto:marshall.mcbride@us.army.mil" marshall.mcbride@us.army.mil,  HYPERLINK "mailto:ronald.liedel@us.army.mil" ronald.liedel@us.army.milKeywords:Software tools, UXO, discrimination, genetic programming, genetic algorithms, evolutionary computing, model inference, data mining.ABSTRACT:  Buried unexploded ordnance (UXO) is expensive to remove. Over 10 million acres of land in the United States alone must be cleared of buried UXO. This paper compares a variety of techniques for discriminating buried UXO, including varieties of evolutionary computing (EC) and, in particular, genetic programming (GP). Detection of unexploded ordnance, while a significant problem, is relatively simple compared to discrimination. Mistaken characterization of buried UXO can lead to death or costly digging of benign objects.During a government-sponsored test to discriminate buried UXO at the U.S. Army Jefferson Proving Grounds (JPG), participants attempted to determine if objects deliberately buried underground were UXO or harmless seeded objects. Participants used various technologies, including ground-penetrating radar, magnetic, and electro-magnetic sensors. As part of the JPG study, the sensor readings were published and we took those sensor readings as our input. Predictions were compared with a ground-truth file to determine the predictive capability of the chromosomes (solutions) developed.Although we had no prior expertise in buried UXO discrimination, the GP techniques produced results that were comparable to the best produced by the JPG Phase IV experiment participants. Our paper discusses the specific way these data were used to extract features and the operators used to generate the discrimination formulae. Our recent GP-based results are compared with those of the original Phase IV JPG participants. Results obtained by several very different techniques, namely model inversion, signature matching, and forms of genetic programming are also compared.EC is shown to be a powerful tool for buried UXO discrimination. The warfighter modeling and simulation community will benefit from the broader application of this optimization tool.Distribution A. Approved for public release; distribution unlimited.1. IntroductionThe problem of discrimination based on sensor data is sometimes referred to as model inversion. One can simulate a model to produce the expected sensor readings. However, the inverse, namely inferring model parameters from the sensor data is usually a more difficult task.Many approaches are available for model inversion. Perhaps the simplest is based on signatures. In this case, the problem is to identify that model whose measured response most closely matches an entry in a library of signatures.In another approach, mathematical inversion, one can apply a physics model, then mathematically solve for the model parameters from the sensor data. Unfortunately for real world discrimination problems, mathematical solutions are rare or are excessively computationally intensive.In some approaches discussed in detail herein, genetic programming (GP) is used. While there are several ways to apply GP to the discrimination problem, we chose a regression approach where the GP evolves a solution from the training data sets. In effect, GP discovers the underlying model. In particular, we applied GP to the problem of discriminating buried unexploded ordnance (UXO) from non-UXO. Our result is based on data from the U.S. Army Jefferson Proving Ground Phase IV (JPG-IV) tests. We discovered sensor data files and ground-truth files on the web. We compared our results with those of 10 other vendors’ results.2. Problem DescriptionTen vendors participated in the original JPG-IV experiment. Participants included private companies and government groups, as well as combinations of both. Several participants used sensors of their own design while some used sensors designed by others. Three main types of sensor technologies were available: magnetic (M), electromagnetic (EM), and ground penetrating radar (GPR). From the available data, we chose to re-examine the data obtained by the GeoPhex Limited GEM-3 sensor. This sensor takes data using electromagnetic coils. We chose this data set because it seemed to have enough density of data to allow for the development of adequate discrimination chromosomes, yet enough variety to challenge the technology.In the original JPG-IV experiment, a total of 160 targets were catalogued and deliberately buried underground: 50 ordnance and 110 other assorted non-ordnance (“fragments”). A flag marked the position of all ordnance and fragments. Vendors did not know what kind of object was buried beneath the flags. Targets varied in size, mass, and the depth at which they were buried. Indeed, target weight varied over a scale of 450 to 1 (20 mm to 155 mm ordnance). GeoPhex recorded data measurements at 25 grid-points separated by 9 inches and with the center grid-point directly over the target. Each reading involved 8 different frequencies, ranging from 30 to 23,970 Hz. The in-phase (I) and quadrature (Q) components were measured at each point and frequency. This yielded 400 measurements for each target (25 points x 8 frequencies x 2 components) to use with our genetic software discrimination program. A ground truth file was also available. It provided not only the ordnance type, but also its depth, length, weight, azimuth, declination, and other properties. Figure 1 above provides examples of the types of ordnance buried in the JPG-IV test.3. Chromosome Encoding Our first task in the processing of the available sensor data was to obtain a set of “features” or “operators” that could be used to develop the chromosomes. In a problem of this nature, these are not initially obvious. Creativity is required to determine what might work at extracting information useful for discrimination purposes. For example, the average of the I and Q values over all sensor measurement points was one such feature. Some of these operators were parameterized, taking one or more arguments, typically using the frequency as the parameter. An early attempt to simply use the raw data only and evolve the features did not work as well as the use of such pre-computed features. Some of the features we selected were based on what we deemed to be reasonable physics models, although we are by no means UXO subject matter experts. Other features were capricious, such as one that measures how the spatial gradient of signal intensity rotates with frequency. The idea was to let the selection process weed out poor operators.In addition to the derived operators, we also allow a variety of arithmetic operators such as addition, subtraction, exponentiation, logarithms, as well as some conditionals (if-then-else, greater than, etc.).Figure 2 illustrates the difficulty in discrimination of these buried objects. This figure shows 3 charts of the in-phase (I) and quadrature (Q) sensor readings as a function of frequency for each of the 25 grid-points where measurements were taken. These plots show the entire information available to the discrimination algorithms. (We later found out that the original JPG-IV participating vendors also had extra data not available to us, namely calibration readings taken nearby to the targets. Access to these calibration data values might have enhanced the scores of the study participants.) The bold lines are for the point directly at the flag in the center of the grid. Note that the first chart is for a mortar (ordnance) and the latter two are for fragments although the first two are far more similar!Data for each target could be examined individually using an analysis tool that we developed called the “target explorer”. The target explorer provided some visual insight as to possible features that might be used for discrimination. 4. Genetic ProgrammingIt is not in the scope of this paper to introduce the concept of genetic programming. Many fine articles are available. See References [2, 8-10]. In brief, genetic programming is an optimization technique that starts with a population of potential solutions. Each potential solution is encoded into a chromosome. Selection is used to pick the fitter chromosomes that are then combined in interesting ways to produce new chromosomes so that the members of future generations are fitter; i.e., they achieve better and better solutions to the described problem. Over thousands (sometimes millions) of generations it is often true that the best member of the solution population is quite good, even when starting from a totally random initial population.5. Genetic Programming EncodingIn terms of our discrimination results, the most successful approach was to use classic genetic programming. We mathematically encoded chromosomes as linear strings of operators (genotype) composed of several genes. Initially, chromosome length was 10 genes, with 2 genes each encoding for depth, length, and weight, and 4 genes encoding for discrimination, that is, determination of whether the target represented ordnance or not. Later we simplified the chromosome to evolve these model parameters separately in independent computer runs.For depth, length, and weight, each pair of genes was simply evaluated over the sensor data for a target. This evaluation produced two numbers that were added to yield an estimate for depth, length, and weight. For the ordnance discrimination the last four genes were combined in various ways (arithmetic and logical). The best results turned out to be simply their sum. The sum was compared to a reference number (typically 1.0) and if greater, the target was presumed to be ordnance, otherwise it was classified as non-ordnance.6. Genetic Algorithm EncodingA genetic algorithm (GA) encoding is similar to the GP encoding except that the form (structure) of the evolved expression is fixed and only the numeric parameters are evolved. The GA formulation was also attempted in the form of a single large gene, comprising a constant weight value for each of the available features. The fitness Fpn (see later) was then simply the linear weighted sum of features as compared to a reference value. The result was quite inferior to GP, but due to the nature of the features selected, this was to be expected. We may yet return to GA in the future to combine the features in a less-linear way. At present, we are not using this approach in our UXO discrimination studies.7. Decision Tree EncodingBased on an object discrimination approach described in Freitas [2], we also encoded the UXO chromosome as a decision tree (DT) problem. This approach offered the advantage of much faster evaluation since the result of evaluating the first gene determined which half of the remaining genes in the chromosome should be evaluated. The next gene’s value would then determine which half of the first half needed further evaluation, and likewise for subsequent genes. The balanced binary tree resulted in only logarithmically increasing evaluations when compared with the normal GP approach. Decision tree leaf nodes then answered whether a target was ordnance or not. The DT approach also proved to be inferior to GP and suffered more strongly from overfitting, a problem discussed in the next section.8. Data OverfittingOne of the most troubling issues we had to overcome was the development of chromosomes that would show excessive overfitting to the UXO ground-truth data. In the total of 50 ordnance objects in the data set, we had many different types and sizes. UXO weight ranged from 0.1 kg (20 mm high explosive) to over 43 kg (155 mm high explosive with lifting lug). The data contained only 3 or 4 occurrences of each type of UXO item. Thus it was very easy for the GP to evolve some almost irrelevant expression that just happened to match those very few instances of each UXO type. That chromosome would only fit that data set: the chromosome would be overfit.To avoid the problem of overfitting we divided the whole 160-target data set into three groups: a Training set, a Test set, and a Validation set. Typically these sets included 50%, 40%, and 10% of the data, respectively. Great care was taken to have a similar distribution of all target types in all three data sets. The chromosomes were evolved using the Training data set only. Chromosome fitness was tested against the Test set and the best result selected. Finally, we report the score as this chromosome was applied to the previously unseen validation set. To ensure that we obtained a representative chromosome, each 10% of objects in the Validation set were held back. As a result, each Validation set did not overlap with any other and the entire UXO data set was covered and used in the final evaluation.  (This data validation method is sometimes referred to as a so-called jackknife technique).The UXO classification problem is aggravated by the fact that the classification was binary: ordnance or non-ordnance (O/NO). Both types of classification exhibited very large variations in mass and length, as well as the depth at which the objects were buried. To alleviate this problem, we included a measure of confidence in the result as a magnitude adjustment. When used, this adjustment considered the value of the chromosome as compared to the reference value. Thus, a value of 1.0002 when the chromosome was applied to a particular target would be a determination of ordnance (since it exceeds the reference value of 1.0), but the confidence level is very low, so its effect on the overall fitness was diminished. Similarly we looked at the signal strength as another sort of magnitude adjustment. When the overall signal strength was very weak, we diminished its effect on fitness because it was hardly anything more than noise. We would rather misclassify such ordnance than have an adverse affect on training on targets with stronger signals.In all cases a “dig list” was produced listing UXO digging priority. The items with the most confidence (highest values or scores) almost certainly were ordnance, while the ones with the lowest scores were almost certainly non-ordnance. Intermediate values were more likely to be in error.9. GenotypeWe use a genotype encoding called Karva that follows Ferreira [3, 5-6]. For other problems we also sometimes use other encodings such as Reverse Polish Notation (RPN), but more commonly have found Karva usually superior. In brief, if one views the tree structure for an expression, then reads the operators and variables in a top to bottom, left to right order, the resulting string of symbols is a Karva expression. Thus each gene is simply a linear string of operators and features (variables). These genes are then “compiled” for maximum speed in evaluating the sensor data readings.10. Fitness Function for GPSolution fitness is computed by evaluating the Karva expressions to produce a number which is then in turn compared to a fixed reference value to decide whether the target is ordnance or not. This decision is then compared with the ground truth file. If the decision is incorrect, the result is a false positive (FP) or false negative (FN). Therefore the fitness value to be minimized is described by the following equation: Fpn = FN + R*FP	     (1)In equation (1) above, Fpn indicates the total weighted sum of UXO false positives and false negatives. It is a number we want to minimize. This means that FN and FP represent the number of misclassified buried objects. FN designates the targets classified as non-UXO that in fact were UXO. In contrast, FP corresponds to the number of targets classified as UXO when they really did not belong in that category. R is a coefficient that weighs the relative importance of FN to FP. US Army Corps of Engineers experts in charge of clearing an area of buried UXO want to avoid as much as possible leaving any genuine UXO buried in place. Thus, they give greater importance to discrimination algorithms that reduce FN. The coefficient R is made less than 1 to accomplish this task.11. ARCGPL ParametersThe ARCGPL (Advanced Research Center Genetic Programming Lab) software provides a very large set of adjustable parameters, including several types of mutation, recombination, population manipulation operations, selection pressure, and others. There are approximately 90 ARCGPL adjustable items in total. Through experience we can usually establish a reasonable set of values for starting the solution evolution, and then refine the set by making many runs.We typically used a basic mutation rate of about 3%, (μ, λ) selection, a selection pressure of about 25% (100% is pure rank selection, 0% is pure random selection), a population of a few hundred chromosomes, and computation duration of 6-12 minutes. Ultra-long computation durations of 10 days or so generally were inferior due to overfitting.12. ResultsFigure 3 on this page shows our results, with FN and FP scores. This chart illustrates a single value for most vendors and shows how they fared on the Jefferson Proving Ground Area IV test range. We show three of our results. The three results vary due to the use of a different ratio parameter R that specifies the relative importance of reducing FN and FP. The shaded rectangle in the upper right corner is the “region of desired operational performance” according to [4]. This rectangle corresponds to a maximum of 5% FN (ordnance left in the ground) and 25% FP (non-ordnance unnecessarily to be dug up). The plotted FN and FP scores are fractional due to averaging a large number of separate runs.13. ConclusionEvolutionary Computation, and particularly genetic programming, is shown to be a powerful tool for buried UXO discrimination. The warfighter modeling and simulation community will benefit from the broader application of this optimization tool.Although we have been unable to show an apples-to-apples comparison with the results of Francone [1] due to lack of access to that data set, we have validated their use of EC in addressing this type of classification problem. Furthermore we have expanded thereon by providing additional information such as predicted burial depth, length, and weight as well as a confidence level in our predictions.14. References[1] Frank D. Francone, Larry M. Deschaine, Tom Battenhourse, Jeffery J. Warren, “Discrimination of Unexploded Ordnance from Clutter using Linear Genetic Programming”, GECCO 2004[2] Alex A. Freitas, Data Mining and Knowledge Discovery with Evolutionary Algorithms, Springer, Berlin, 1998[3] Ferreira, C., 2001. Gene Expression Programming: A New Adaptive Algorithm for Solving Problems. Complex Systems, 13 (2): 87-129[4] George Robitaille, Jane Adams, Chris O’Donnell, Pope Burr. “Jefferson Proving Ground Technology Demonstration Program Summary”, 1999[5] Ferreira, C.: Gene Expression Programming in Problem Solving, WSC6 Tutorial, (2001)[6] Ferreira, C., Gene Expression Programming in Problem Solving. In R. Roy, M. Köppen, S. Ovaska, T. Furuhashi, and F. Hoffmann, eds., Soft Computing and Industry – Recent Applications, pages 635-654, Springer-Verlag, 2002[7] George Robitaille, Project Officer. “UXO Technology Demonstration Program at Jefferson Proving Ground, Phase IV”, Report SFIM-AEC-ET-CR-99051. May1999[8] Kalyanmoy Deb et al (Eds), Genetic and Evolutionary Computation – GECCO 2004, Proceedings, Springer[9] Fred Glover, (Ed), Handbook of Metaheuristics, Kluwer International Series, 2003[10] Sadiq M. Sait and Habib Youssef, Iterative Computer Algorithms with Applications in Engineering, IEEE Computer Society, 1999[11] Edwin Roger Banks, Edwin Núñez, Paul Agarwal, Claudette Owens, Marshall McBride, Ron Liedel, “Genetic Programming for Discrimination of Buried Unexploded Ordnance (UXO)”, Genetic and Evolutionary Computing Conference (GECCO) Proceedings, June 2005Author BiographiesDR. EDWIN ROGER BANKS is a Senior Scientist at COLSA Corporation working on applications of genetic programming to a variety of optimization problems. He is a graduate of Vanderbilt University and M. I. T. and is a member of the International Society for Genetic and Evolutionary Computation and American Association for Artificial Intelligence.DR. EDWIN NÚÑEZ is a Senior Scientist at COLSA Corporation where he has managed projects in applying evolutionary computing and genetic programming techniques. He is a graduate of the University of Puerto Rico and Colorado State University. He is also a member of the International Society for Genetic and Evolutionary Computation, American Geophysical Union, American Association for Artificial Intelligence, American Meteorological Society, and the American Physical Society.PAUL AGARWAL of COLSA Corporation is the Software Engineering Manager for the U.S. Army Space and Missile Defense Command USASMDC Advanced Research Center.  He has over 20 years experience in public and private sector computer software and systems analysis, design, development, evaluation, implementation, and program management.RON LIEDEL is a senior engineer with the Future Warfighter Center of the U.S. Army Space and Missile Defense Command (USASMDC) in Huntsville, AL, and has authored numerous SMDC and MDA policy forming software documents.  These documents include the SMDC Software Development Plan, the SMDBL 10 Year Software Plan, as well as the Command Software Mission and Function Statement.  Mr. Liedel founded and chaired the SMDC/SDIO Computer Resource Working Group and has presented several papers nationally on Software Sizing for Mega Systems. He serves as the Technology Products and Services Director for SMDC.MARSHALL McBRIDE is the government technical monitor responsible for the day-to-day operations of the U.S. Army Space and Missile Defense Command (USASMDC) Advanced Research Center, in Huntsville, AL. He has 15 years experience in research & development, modeling & simulation, program management, test & evaluation, and high performance computing center management. He is a graduate of Auburn University with a BS degree in Aerospace EngineeringFragmentFigure 2bFigure 1MortarFigure 2a EMBED Word.Picture.8  FragmentFigure 2c