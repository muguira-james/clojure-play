Computational Models of Team Decision-Making David W. Roberts*, Christine M. Mitchell, David A. Thurman**, and Alan R. ChappellCenter for Human-Machine SystemsSchool of Industrial and Systems EngineeringGeorgia Institute of TechnologyAtlanta, GA 30332404 894-3135, 404 894-4321{droberts, cm, dave, arc}@chmsr.gatech.eduKeywords:Model, Team, Human Behavior, Training, Aviation, Dispatch, Air Traffic ManagementABSTRACT: There are few if any models that adequately represent team decision making. Yet training, aiding, and the infrastructure to support real-time interactive simulation to train or evaluate team decision making require robust computational models of multiple decision makers, potentially distributed in time and space, often, with two or more distinct roles for individuals within the team.  This paper describes one candidate approach: the operator function model and its computational implementation, OFMspert.  The OFM/OFMspert methodology has been successfully used to model and design model-based aids and simulations for individual and small teams, maturing over a twenty-year period.  In this paper, we explore extensions to the OFM/OFMspert methodology to represent team decision making.  As an engineering model, OFM/OFMspert evolution has typically, and successfully, proceeded in an application-driven manner.  This paper describes the use of OFM/OFMspert to model collaborative decision making in air traffic management (ATM).  In particular, the model focuses on the least understood ATM collaborative relationship, that between the company dispatcher and the pilot-in-command of the aircraft for which the dispatcher is responsible.  The paper describes an initial model for this application and summarizes insights derived from the initial modeling exercise. IntroductionMany applications in complex real-world domains require coordination between one or more team members for successful mission completion. Training, aiding, and the infrastructure to support real-time interactive simulation to train or evaluate team decision making depend upon the existence of robust computational models of multiple decision makers, potentially distributed in time and space, often with two or more distinct roles for individuals within the team. To date, research has primarily addressed the development of computational models of individual decision makers or operators. Robust models of groups or collaborating decision makers are few. The models that do exist are typically quite primitive and restricted in domain of application  ADDIN ENRf8 (Pew & Mavor, 1998). Thus, flexible, scalable, computational models of team decision making are urgently needed.This paper proposes the operator function model (OFM) and its computational implementation, OFMspert, for the definition and implementation of a computational model for team decision making. OFM and OFMspert have provided robust representations of operators and other highly skilled decision makers in a variety of real-world, complex, dynamic, often safety-critical, domains. The OFM is an engineering model in the modern sense.  It includes a cognitive representation of the operator, or decision maker, but takes full advantage of the constraints typical of engineering systems and team scenarios. Given overall mission goals and current system state, individual behavior is very predictable. Though developed predominantly to model individual operators and decision makers, the OFM has been used to model and design aids, assistants, and tutors for small teams.  Examples include models of the two-pilot team comprising the flight deck crew of modern aircraft and two-person teams for NASA near-earth satellite control. Moreover, in several of these applications, OFM/OFMspert was used to model teams mixing human and computer agents. Each of these efforts was implemented and empirically evaluated.  In a wide range of OFM/OFMspert-based applications, such as operator aids, tutors, intelligent workstations, and small teams, the systems consistently and significantly enhanced overall system performance as well as individual operator performance. Thus, there is solid empirical evidence of the power of OFM/OFMspert as a computational human behavioral representation and limited, but successful, experience to suggest that OFM/OFMspert can be extended to accommodate the needs of a computational model of team decision making. BackgroundThe National Research Council (NRC) recently concluded a study assessing the state of human and organizational behavior modeling  ADDIN ENRf8 (Pew & Mavor, 1998). The Panel on Modeling Human Behavior and Command Decision Making: Representations for Military Simulations of the National Research Council provided an independent review of the current state and made candid and critical comments about future directions. The panel’s goals and conclusions are summarized below:…to set forth in general terms the theoretical and operating principles of models that are applicable to human behavior representation, to describe specific applications of these theories and principles, and to identify the most promising paths to pursue in each modeling area (p. 17)…The modeling of cognition and action by individuals and groups is quite possibly the most difficult task humans have yet undertaken.  Developments in this area are in their infancy (p. 8)….. Much work remains to be done. There is an enormous gap between the current state of the art in human and organizational modeling technology on the one hand and the military needs on the other (p. 17) (emphasis added).The panel suggests that robust models of team decision making are needed to support 1) training when parts of the team are not present; 2) training and assessment of team performance; and 3) design of team roles and responsibilities. Unfortunately, computational models of team behavior to support these needs largely do not exist. The NRC panel concluded that “…there are very few organizational unit-level models of any sort, and even fewer of the multiagent or network type….(p. 271).” There is no single representation or architecture that is suited to the wide range of individual human and organizational modeling needs. Existing approaches imply their own computational architectures, use different modeling methodologies. Moreover, there is no consensus on any underlying cognitive theory.  Although the panel believes that it is unlikely that a unitary architecture, that is a single architecture, will emerge that addresses all modeling requirements, it recognizes that a common architecture constrains development and thus promotes interoperability.   Thus, it is important to direct research and development to create a small set of team decision making models, which, taken together, address the wide range of needs. Operator Function Model (OFM) and OFMspertThe operator function model is an engineering representation of operator activities in control of complex dynamic systems  ADDIN ENRf8 (Mitchell, 1987).  In modeling the human, the OFM takes full advantage of the constraints on behavior imposed by engineering systems  ADDIN ENRf8 (Sheridan & Ferrell, 1974). Although it is a cognitive engineering model, the OFM is not a psychological model.  The OFM relies on the provocative insight offered by Card, Moran, and Newell  ADDIN ENRf8 (1983) as the rationale for the lack of deep psychology in such models. Complementing the engineering view articulated by Sheridan and Ferrell, the authors of the ubiquitous GOMS model note that investigation of well-trained, well-motivated, expert behavior is hardly psychology at all, but rather a description of the environment. Using the language of finite-state mathematics to represent the discrete role of operators or team members in today’s highly automated systems, the OFM is a cognitive task analysis represented as a hierarchic-heterarchic finite state network. Nodes represent operator activity at various levels of abstraction. Higher level activities represent functions, subfunctions, or phases with related activities. The lowest level activities are actions—physical, cognitive, and perceptual. The OFM network can be visual in form and thus facilitates validation and iterative refinement by domain experts.OFMspert is the computational implementation of the OFM.  As originally conceived, OFMspert was a dynamic or living task analysis.  Over time, it became clear that in conjunction with a dynamic system, OFMspert could anticipate or predict operator activities, and subsequently interpret operator actions. Thus, OFMspert is able to provide the intelligence for a variety of applications. OFM/OFMspert has been used for a range of domains and applications within those domains. The former includes aerospace, manufacturing, space, aviation, and health systems.  The latter, consistently based on an OFM of operator activity within the system, include design and specification of intelligent workstations, assistants, tutors, and, most recently, human-centered, lights-out automation. Mitchell  ADDIN ENRf8 (1999) provides a detailed summary of the OFM and OFMspert, their genesis, and the associated sets of domains and applications.The Operator Function ModelThe operator function model is one of the new set of models whose intent is to describe and/or prescribe the role of the operator in increasingly complex systems.  The goal of the OFM is to create a compact, dynamic description of operator activities based on a visual representation of these activities.  The visual element of this model is essential as it allows operators to easily inspect, validate, and correct it, in ways that outputs from other task-analytic tools typically do not  ADDIN ENRf8 (Kirwan & Ainsworth, 1992).The operator function model (OFM) is an operator, as opposed to a system or work domain, representation  ADDIN ENRf8 (Mitchell, 1987). OFM features include heterarchy (concurrency) and hierarchy (decomposition). The OFM is a system-theoretic representation, a hierarchic/heterarchic network of finite-state systems or nodes. Finite-state systems are similar to finite-state automata, which are defined by a collection of nodes, arcs, and inputs; inputs cause transitions from one node to another. Figure 1 depicts essential OFM properties. Network nodes represent operator activities. The OFM hierarchy decomposes each high-level operator activity into lower level activities defined at multiple levels of aggregation. Each high-level activity is decomposed into successively lower level activities that are used to carry out the higher-level activity. Arcs between nodes depict conditions that can initiate, complete, terminate, or sequence activities.  Two features of the OFM represent flexibility inherent in the operational environment: heterarchy and nondeterminism. The OFM heterarchy represents activities that the operator may perform concurrently, for example multi-tasking, or shifts in the operator’s focus of control from one high-level activity to another. At higher levels, heterarchy represents choices operators have, within some period, to alternate among control activities.  For lower-level activities, nondeterminism represents choices operators have about which activity, from a feasible set of activities, to perform next.  Moreover, high-level activities are not necessarily performed to completion. Activities are interrupted and operators interleave lower level activities and actions to meet dynamically changing high-level requirements. Explicit representation of correct activities via heterarchy and nondeterminism allows the OFM to identify potentially erroneous actions.  If the operator performs an action that does not support any expected activity or if an action is not contained in any feasible set of actions, the action may be an error of commission. An expected action that is never performed may indicate an error of omission.An activity may have initiating conditions  EMBED Visio.Drawing.4   or constraining conditions  EMBED Visio.Drawing.4  .  Initiating conditions typically cause an activity to become active—an activity for which the operator is now responsible.  If an activity has constraints, the operator cannot initiate the activity until all constraints are met. A pilot for example cannot engage an auto flight mode if an autopilot is not currently engaged. An activity may complete naturally, such as a sequence, or it may have explicit completion conditions  EMBED Visio.Drawing.4   that must be meet.  EMBED Visio.Drawing.5  Figure 1. Operator Function Model StructureFinally, an activity may have terminating conditions  EMBED Visio.Drawing.4   that indicate, regardless of current state, the OFM activity is no longer active. Decomposition types include the following: SEQ, AND, XOR, and OR A sequence (SEQ) relationship between two activities at the same level of decomposition is seen frequently. Modelers should be very careful about overusing this specification.  Many activities that appear sequential do not necessarily require sequential execution and thus operators often do not do so. Models that represent non-sequential activities sequentially, a common characteristic, run the risk of being brittle or implicitly incorrect. If used in aiding or training, such models can become an active operator irritant.  The AND relationship is a flexible alternative to the sequential relationship.  An AND decomposition indicates that all the activities in the set must be carried out, but no order is required.  The XOR relationship is often associated with mode choice: two or more alternatives, only one of which may be selected.  The OR relationship depicts alternative ways that an activity can be carried out; an operator may choose to perform one or more of these activities.  Relationships among activities at the same level can also be heterarchical, that is independent or carried out concurrently.OFMspertOFMspert is implemented as a blackboard model of problem solving  ADDIN ENRf8 (Nii, 1994). A blackboard is a natural implementation for a dynamic and computational OFM. The properties of the blackboard data structure and its knowledge sources easily represent essential OFM properties. Real-time blackboard operations include posting hierarchic and heterarchic hypotheses, evolving and updating them as the model interprets real-time input data.  The incoming data strengthen, weaken, or generate new blackboard hypotheses. Blackboard assessment methods periodically examine the blackboard data structure to determine if a new conclusion can be reached or old hypotheses have become obsolete.ACTIN (actions interpreter) is OFMspert’s blackboard data structure.  Blackboard knowledge sources construct expectations about current operator activities (activity trees) and interpret in real time actions that the operator performs. An action is understood if it is expected, that is the action is used to accomplish one or more currently active high-level activities. An unexpected action may be an error of commission.  An expected action, which the operator fails to carry out in a timely manner, may be an error of omission.Figure 2 depicts the OFMspert architecture. ACTIN is the major part of OFMspert’s dynamic operations knowledge (DOK) component. The currently active plan is the other component. For multi-operator representations, the DOK might contain a plan for each agent at an appropriate level of abstraction. The current problem space stores information about the system, including state variables, derived variables, and a semantic description of the operator workstation.  State variables contain sensor-level information about the system. Derived variables represent operator heuristics that aggregate and integrate lower-level data into meaningful information. The workstation description is a description of the information or data currently available to the operator without performing any additional display page or information requests. OFMspert’s operator workstation represents display pages and data that the operator has in view while performing an activity. The final OFMspert component is the domain interface.  This component handles all OFMspert inputs and outputs.  It accepts data from the controlled system and other entities. These data include system state updates and operator actions.  The domain interface also sends commands to the system or queries the controlled system for information not permanently represented in OFMspert’s current problem space. Derived variables are a unique cognitive OFMspert characteristic.  They represent inherently human strategies that operators define and use to assess system state or initiate troubleshooting. For example, a derived variable for a combat application might be potentialThreat.  An expert, given various input data, may use a heuristic to conclude enemy hazards are present. Correspondingly, OFM/OFMspert contains a method to emulate the expert heuristic and, given the appropriate data, sets potentialThreat to true.  Derived variables, typically when true, trigger ACTIN updates.  They can initiate new activity tree construction, blackboard assessments, or activity termination. EMBED Visio.Drawing.5  Figure 2. OFMspert ArchitectureExtension for Modeling Team Decision Making OFM and OFMspert development derives the majority of its face validity and saves extensive time and intellectual effort by allowing domain applications to guide definition of model requirements. Thus, the OFM modeling process uses a bottom-up method.  Although the OFM/OFMspert methodology has been used to model and provide the foundation for simulations and aids for teams, these teams were small, always two-person, possessed a shared, typically identical, vision of the mission, and were tightly coupled in time and space. Given the success of initial team models, the next step is to define formal OFM/OFMspert extensions to model more typical teams. Specifically, a more representative team application was needed. This application must be recognizably characteristic of applications critically dependent on team decision making. Such teams are typically multi-agent, with agents that may be human or computer. Agents often have different roles, and correspondingly, different sets of goals, and different representations of the team as a whole or individual team members.  The initial application chosen for this model development is air traffic management. OFM/OFMspert Application to Distributed Decision Making: Collaborative Decision Making in Air Traffic ManagementAir traffic management is a realistic distributed system, critically dependent on effective team decision making  ADDIN ENRf8 (Orasanu et al., 1997). It is also the focus of widespread attention as the next generation of air traffic control (ATC) emerges to cope with the increase air traffic demands of the 21st century.The National Airspace System (NAS) is a tightly-coupled system comprised of three primary components that collaborate to keep aircraft flowing safely and efficiently through the system: pilots (on the flight deck), dispatchers (in the Airline Operation Center), and air traffic controllers in Enroute and Terminal Area Control  (TRACON) centers.  Figure 3 shows a high-level view of this collaboration. The relationship between aircraft and ATC is widely known. The relationship between dispatchers and pilots-in-command is less well known and often misunderstood.  This relationship, however, is vital to the safety and efficiency of every aircraft flight for major U.S. carriers.The Pilot in Command (PIC) and Aircraft Dispatcher are jointly responsible for the preflight planing, dispatch release, and conduct of the flight…The Aircraft Dispatcher is responsible for monitoring flight progress, issuing necessary safety of flight information including all appropriate weather information relevant to the progress of the flight.  He or she is also responsible for canceling or redispatching a flight if it is determined that the flight cannot operate safely as planned or released…. If the flight is enroute and conditions change such that the flight cannot be conducted in accordance with the release, then the one encountering, or learning of, the changed conditions must contact the other to amend the release.  (FAR 121. 533, Delta Flight Operations Manual, Chapter 6, Flight Planning).This relationship is legally mandated for all large air carriers. By law routing decisions for all Part 121 airlines, major carriers, must be made collaboratively between pilot-in-command and dispatcher.  This collaboration is the focus of the current model-building exercise in which to explore the strengths and limitations of OFM/OFMspert as a computational team model.Figure 3. Collaborative Decision-Making in Air Traffic Management (ATM)Environment DescriptionMany airlines, particularly large commercial carriers such as United, Delta, and FedEx, manage airline operations from a centralized facility, called an airline operations control center (AOC). Airlines have found, from an organizational perspective, that an AOC can enhance both safety and productivity. A modern AOC provides powerful tools—at a reasonable cost. For example, some dispatchers use the FAA's Aircraft Situation Display data as input for flight following tools.  In addition, at state-of-the-art AOCs, dispatchers have at their disposal numerous sophisticated weather prediction tools that provide accurate, dynamic projections of thunderstorm growth and decay.  Lightning strike data affords new levels of thunderstorm detection capability.  Turbulence models track the threat of clear air turbulence and mountain wave activity.  Very high-resolution satellite data provide frequent and detailed representations of atmospheric trends.The evolution of sophisticated AOCs has occurred so quickly that pilots, and even airline management, often fail to utilize fully the capabilities or understand the AOC’s potential. One facet of more effectively using existing AOC capabilities is an increasingly strong link between pilots-in-command and dispatchers. As air traffic management in reconceived for the 21st century, AOCs and the collaboration between dispatchers and pilots-in-command may well add an important factor that enhances safety and efficiency.  Models that represent this collaboration as well as its role in the broader ATM decision making environment are the first step. They can help conceive alternative ATM systems, design training and educational programs to facilitate collaboration, and specify the requirements for computer-based tools to support collaboration that is more effective.Preliminary ATC Collaboration Model Figure 4 depicts the highest level of a preliminary Dispatch-Pilots-in-Command (PIC) OFM/OFMspert model. At this level, OFMspert’s ACTIN blackboard depicts two team members, each with different roles. The first level decomposition for the dispatcher shows that highest level activities include monitoring various sources of available information, flight planning, and flight re-planning when real-time and unanticipated events occur.  The pilot-in-command is modeled with two high-level activities for enroute flight: maintain the current course and deviate from the planned route.  Clearly, the PIC model is only a partial representation of pilot activities. It represents only those activities that relate to collaboration within the ATM in general and dispatch in particular.Figure 4 also shows initiating conditions for the dispatch activity, replan route.  If the derived variable is true, indicating a communication from the PIC that a reroute is being considered, the activity becomes active.  Likewise, derived variables control the initiation and termination of both PIC routing activities.  If the derived variable described above is false, the PIC maintains the current course.  This activity is terminated and the activity, deviate from planned route, is initiated upon receipt of an ATC communication that potentially reroutes the aircraft. Figures 5 and 6 depict successively more model detail and the affects of the dynamically changing flight environment.Figure 4. High-Level OFM/OFMspert Represent-ation of Collaboration between Dispatcher and PICFigure 5 depicts the system in the same state as that shown in figure 4. It includes the decomposition of the monitoring activity to the next level, which defines the sources that dispatchers intermittently monitor. Moreover, it depicts the entire dynamic operations knowledge (DOK) display. The top panel shows a rudimentary plan. In the middle, ACTIN displays expected dispatcher activities.  Upper level activities, rounded rectangles, decompose to expected actions, crisp rectangles. The lowest panel is the place on which OFMspert posts incoming actions from either the dispatcher or PIC. Blackboard knowledge sources try to understand dispatcher or PIC actions by attempting to connect them to expected actions.Figure 6 depicts the DOK display after a state change.  An ATC message initiating a potential reroute and change to the filed flight plan has arrived at the flight deck.Figure 5. Decompositions for Dispatcher and PIC activitiesThe tool tip associated with the now active dispatch activity (figure 6), replan route, indicates that the derived variable, PICMessage, is now true.  The terminating and initiating conditions on the PIC activities, maintain course and deviate from planned route, if inspected, show that an ATC change-of-route-message has arrived.  This message terminates the PIC acitivity, maintain course, and subsequently initiates the PIC activity, deviate from planned route. OFMspert Team ModelThis preliminary model reveals several interesting insights, some were unexpected conceptually, others were challenging to represent computationally.The first, noted above, is that in teams, members that have different roles are likely to require different representations, depending on the collaboration or team decision scenario being modeled.  Existing OFMspert models of pilot navigation look significantly different than the model depicted in figures 4 through 6. Pilot navigation models include much more detail for how to navigate under various state conditions.  ADDIN ENRf8 (Chappell, Thurman, Mitchell, & Gray, 1999).Figure 6. Evolution of Dispatcher-PIC OFMspert ModelThe second issue is that while the pilot role in this model is typically event driven, the dispatcher role includes some activities that are always ongoing, for example, monitor, as well some activities that are event driven.  The current OFM/OFMspert model requires extensions to support more adequately these two different activity types within the same model. ConclusionThe exercise described above provides initial evidence that the OFM/OFMspert methodology holds promise as a foundation for a team decision-making model.  It highlights areas of both strength and weakness.  Strengths included the important demonstrations that the current OFM/OFMspert architecture can be used in a straightforward manner to model multiple agents and reflect the communications among them. Weaknesses manifest themselves by the very nature of team, as opposed to individual, models of behavior. Different roles may require different activity types.  Until now, existing OFM/OFMspert applications represented one or the other type, but never both within the same model.  This exercise shows that modeling and run-time use require extensions to represent the diversity of roles and activities endemic to teams.References ADDIN ENBib Card, S., Moran, T., & Newell, A. (1983). The psychology of human-computer interaction. Hillsdale, NJ: Erlbaum.Chappell, A. R., Thurman, D. A., Mitchell, C. M., & Gray, W. M. (1999). Georgia Tech Case-Based Intelligent Tutoring System (GT-CBITS) for aviation training. Proceedings of the Tenth International Symposium on Aviation Psychology, Columbus, OH, in press.Jones, P. M., Mitchell, C. M., & Rubin, K. S. (1990). Validation of intent inferencing by a model-based operator's associate. International Journal of Man-Machine Studies, 33, 177-202.Kirwan, & Ainsworth (Eds.). (1992). A guide to task analysis. Washington, D.C.: Taylor & Francis.Mitchell, C. M. (1987). GT-MSOCC:  A domain for research on human-computer interaction and decision aiding in supervisory control systems. IEEE Transactions on Systems, Man, and Cybernetics, 17(4), 553-572.Mitchell, C. M. (1996). GT-MSOCC:  Operator models, model-based displays, and intelligent aiding. In W. B. Rouse (Ed.), Human/technology interaction in complex systems (Vol. 8, pp. 67-172). Greenwich, CT: JAI Press Inc.Mitchell, C. M. (1999). Model-based design of human interaction with complex systems. In A. P. Sage & W. B. Rouse (Eds.), Systems engineering & management handbook. New York, NY: John Wiley.Nii, H. P. (1994). Blackboard systems at the architecture level. Expert Systems with Applications, 7, 43-54.Orasanu, J., Davidson, J., Rodvold, M., Smith, P., McCoy, E., Owlsey, T., Bullington, R., & France, L. (1997). Managing irregular operations in a free flight environment. Ninth International Symposium on Aviation Psychology, Dayton, OH, 327-345.Pew, R. W., & Mavor, A. S. (Eds.). (1998). Modeling human and organizational behavior. Washington, D.C.: National Academy Press.Rubin, K. S., Jones, P. M., & Mitchell, C. M. (1988). OFMspert: Inference of operator intentions in supervisory control using a blackboard architecture. IEEE Transactions on Systems, Man, and Cybernetics, 18(4), 618-637.Sheridan, T. B., & Ferrell, W. R. (1974). Man-machine systems: Information, control, and decision models of human performance. Cambridge, MA: MIT Press.AcknowledgementsThe assistance of researchers at NASA Ames, including Dr. Judith Orasanu, and both pilots and dispatchers at Delta Air Lines, including Captain Alan Price and Dispatcher Steve Caisse, is gratefully acknowledged.  Dr. Orasanu’s support and continued involvement in the dispatch and AOC collaboration continue to place this component of the ATM collaborative team squarely on the aviation research agenda.  Without the assistance, intermittent tutoring, and support of Captain Alan Price and Dispatcher Steve Caisse the progress achieved in model development thus far could not have occurred.Author BiographiesDAVID W. ROBERTS is a Research Scientist II with the Distributed Simulation Systems Group in the Information Technology and Telecommunications Laboratory at the Georgia Tech Research Institute (GTRI). He is also a Ph.D. student in the Center for Human-Machine Systems Research in the School of Industrial and Systems Engineering at Georgia Tech.  He received his M.S. from the Johns Hopkins University in Computer Science and his B.S. from Cornell University in Operations Research and Industrial Engineering. He has been involved in modeling and simulation since 1990 in software development and systems engineering roles. He is actively involved in SISO and is past chair of the Testing Forum and past Vice Chair of the Human Decision Making and Behavior Generation Forum. At GTRI, Mr. Roberts leads efforts to design, implement, and use tools to support distributed simulation. Mr. Roberts’ current research addresses the development of models of distributed team decision-making.CHRISTINE M. MITCHELL is a Professor of Industrial and Systems Engineering at Georgia Institute of Technology and an Adjunct Professor in Georgia Tech’s College of Computing. She received her B.A. in English and mathematics from the University of Dayton in Dayton, Ohio; her M.S. in mathematics from John Carroll University in Cleveland, Ohio and her Ph.D. in Industrial and Systems Engineering from The Ohio State University. Her research interests are in the area of the development of models of human behavior in the control of complex dynamic systems and the use of those models to design computer-based artifacts to enhance human interaction with complex dynamic systems. DAVID A. THURMAN is a Senior Research Scientist in the Planning and Operational Effectiveness Group at Pacific Northwest National Laboratory (PNNL).  Mr. Thurman received B.S. degrees in Computer Science and Mathematics from University of Oregon, and his M.S. in Human-Machine Systems Engineering from Georgia Institute of Technology.  He is currently a Ph.D. candidate in the Center for Human-Machine Systems Research at Georgia Tech. His research interests include modeling of human-machine interaction and the design of operator displays, operations automation, and training systems using those models.ALAN R. CHAPPELL is A Ph.D. Candidate and Graduate Research Assistant with the Center for Human-Machine Systems Research in the School of Industrial and Systems Engineering at Georgia Tech. He received the M.S. degree in Operations Research and B.S. in Mechanical Engineering from North Carolina State University. Mr. Chappell is a Professional Engineer. His current research interests include model-based approaches to enhancing automation, practitioner-automation interaction, and design of intelligent tutoring systems for practitioners of complex engineering systems, such as pilots and dispatchers. * Also a Research Scientist II with the Information Technology & Telecommunications Lab at the Georgia Tech Research Institute (GTRI).** Also a Senior Research Scientist with the Planning and Operational Effectiveness Group at Pacific Northwest National Laboratory (PNNL).