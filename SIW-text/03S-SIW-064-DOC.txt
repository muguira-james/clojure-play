Digital Proficiency Feedback for Collective ExercisesLarry L. MelizaU.S. Army Research Institute for the Behavioral and Social SciencesSimulator Systems Research Unit12350 Research ParkwayOrlando, FL 32826407-384-3992Larry_Meliza@peostri.army.milKeywords:Digital Skills, After Action Review (AAR)ABSTRACT:  Effective employment of digitized systems to support command, control, and communications will be a critical component of the Objective Force, but digitization presents significant challenges for trainers.  Digitization adds to the already substantial exercise management and feedback workload of trainers for U.S. Army collective training exercises, and this increase in workload is multiplied further by periodic changes in digital system capabilities and interfaces.   This paper describes efforts to reduce trainer workloads by defining digital system user skills, tailoring feedback activities to match  unit digital proficiency levels, and applying automation.  A top down analytic approach was used to identify twenty-two digital user skills likely to be employed across digital systems and across the careers of leaders and soldiers.   Examples of these skills include “use digital information to maintain an awareness of unit location relative to threats”  and “assess currency of information on the tactical situation.”    Observations, interviews, and literature reviews regarding digital training within the Army’s First Digitized Division (i.e., the 4th Infantry Division) were used in  a bottom-up analysis to envision unit digital proficiency level concepts, develop measures of unit digital proficiency,  and identify targets of opportunity for the application of automation .1. IntroductionThe U.S. Army recognized that transition to the Objective Force will involve substantial changes in the way training is conducted, and it approved  “Methods and Measures of Commander-Centric Training” as a Science and Technology Objective (STO).   The work described by this paper is part of this STO, and it focuses on defining and measuring unit digital skills and proficiency levels.  1.1 Evolution of Digital SystemsDigital command, control, communication, and intelligence (C3I) systems, fielded under the U.S. Army’s Force XXI program, set the stage for improved capabilities to visualize the battlefield, analyze courses of action, and share evolving mission plans.   Platform-based digital systems make it possible for crews to receive and display global  positioning system  (GPS)-enabled  data on the location of instrumented friendly elements as well as making it possible to transmit and receive graphical data and  structured text messages.    Digital systems in the tactical operations center (TOC) provide new ways for the individual battlefield operating systems (BOS), such as fire support and maneuver, to share information with one another and with digitized platforms.  Digitization also provides new analytical tools to support decision making in both the tactical platform and TOC settings. Integration of data from  unmanned aerial vehicles and other improved reconnaissance, surveillance, and target acquisition (RSTA) systems brings an improved knowledge of enemy locations and actions that can be shared with TOCs and platforms.  Digital systems change periodically as new capabilities are added, the human interface is modified, and/or the interface among systems is modified.    At some point these system changes will be fine tuned to complete the transition to the Objective Force.Use of digital C3I systems replaces selected aspects of paper-based, voice radio, and face-to-face person-to-person communications.  As the  Army continues its evolution towards the Objective Force be replacing selected manned elements with robotic sensors and weapons platforms [1], the percentage of communications that are digital in nature will necessarily increase. 1.2  Impacts upon Exercise Management and Feedback for Collective Training Digital command and control capabilities present substantial challenges to trainers for collective exercises [2].  A complete understanding of the performance of a digitized unit requires a trainer to consider information exchanged among digital systems,  interactions between operators and systems,  and interactions among system operators. These observation requirements are in addition to the heavy, existing requirements for pre-digital units.      Exercise management functions also become more complex and labor intensive in the digital situation.   An important part of exercise management is the simulation of roles of higher, adjacent, and supporting units.    Another part of exercise management is keeping track of planned actions to identify potential threats to the safety of units and/or the integrity of the exercise.  Performing these management functions requires accessing  and monitoring the flow of digital communications to find out when units send messages to the units and leaders being role played by exercise staff and to respond to these messages in digital format.  It also requires examining the digital data stream to keep track of changes in uit plans and perceptions of the tactical situation.   To fully appreciate the complexity of exercise management and feedback in a digital environment, one must consider the fact that “planning never stops” for these units [3].  The capability to share planning products electronically makes it possible for digitized units to implement changes in plans throughout a mission.  2. Four Objectives in Reducing Trainer WorkloadsThe first objective in reducing trainer workloads was to define the aspects of digital system employment to be assessed by trainers.   A goal or skill-based approach in defining digital training requirements can help organize what might otherwise be an unwieldy, continually changing list of  digital activities.  Simply put, it is important to focus on  digital system user skills that will retain their relevance as digital systems evolve.The first objective sets the stage for the second,  tailoring observation requirements to fit digital proficiency levels of units.   Rather than applying, for example, one hundred measures to the performance of a digitized unit, a trainer may skip measures that are clearly beyond or below the proficiency level of that unit.  This approach is most useful when there are indicators of  proficiency that can be applied prior to the start of a period of collective training,  but they can also be used in mid exercise to support measurement shortcuts.   More specifically, if a unit fails to set the stage for certain digital activities, little is gained by trying to examine these activities in detail.The third objective  is to apply automation to reduce trainer workloads  [4, 5].   For example, automation can be applied to screen digital message traffic, decide when  define critical events occur, and  document these events for feedback sessions.   Substantial progress has been made in addressing technical challenges in applying automation to reduce workloads for collective training. Ongoing behavioral research is concerned with identifying  specific trainer alerts and feedback displays warranting  production.  The fourth objective is to provide units with feedback during training exercises or actual operations, in time to take corrective actions.  In this version of the application of automation, it is the unit rather than the trainer that employs the automated tool.  Technical challenges in implementing this step include creating a tool that has a small footprint.  The behavioral research focus   is on identifying targets of opportunity for realtime feedback and  assessing the value of the automated tool has a collective training expeditor.      2.1  How Digital User Skills Were Defined The first challenge was to identity capabilities that are separate from tactical skills per se and warrant being classified as user digital skills.    A digital user skill should be an enduring capability as opposed to one that can quickly lose its applicability or be forgotten.    Barnett,  Meliza, and McClusky [6]  defined a digital user skill as a capability that:supports combat operationsapplies across many combat missions/tasksis likely to apply across versions of digital        systems and possibly differing digital       systemsis acquired with difficulty  is likely to be retained over time (i.e., is not highly procedural in nature)is likely to be required over a leader’s careeris applied using digital systemsThe most current version of digital skills fitting this definition is provided in Table 1.  A two-phased approach was used to define these digital user skills.  The first phase was a top down approach [6].  That effort started  with identification of the more frequently occurring problems in the performance of pre-digital units at maneuver combat training centers that are likely to be addressed by the effective application of digitization in visualizing the battlefield and sharing evolving plans. An example of such a problem is  “intelligence requirements are not updated as the situation changes”  This step identified approximately 200 performance problems that fell into one or more of the eight general problem areas shown in Table 2.  This step made extensive use of the U.S. Army Center for Army Lessons Learned (CALL) Table 1.  Digital user skills.Network SkillsPrepare for, and recover from, system crashes or other periods of non-availabilityEstablish and check communications links and network connectionsProtect network from operator error and malfunctionsPerform periodic checks of digital systemsBasic Operator SkillsPrepare, send, and manage digital  messagesControl digital views of the battlespaceExchange data with external databasesBasic User SkillsAssess completeness and accuracy of digital information on the tactical situationAssess currency of digital information on the tactical situationAssess completeness, accuracy, and clarity of digital planning productsCoordinate with others to acquire information in a digital environmentIdentify situations where a physical terrain reconnaissance is requiredMonitor changes in digital planning productsExploitation SkillsUse digital information to maintain awareness of location of own unit relative to threatening situationsUse digital information to compare expected and actual status of friendly unitsUse digital information to maintain awareness of trigger eventsUse digital situational awareness (SA) displays to navigateUse digital SA data and terrain analysis tools to select routes and positionsUse SA data to control unit movement and deconflict routesUse SA data and terrain analysis tools to predict contact variables and support BOS integrationMonitor timing of digital planning activitiesDefine and address digital rehearsal objectivesTable 2.General Problems in the Performance of Analog Units Likely to be Addressed by the Potentials of Digitization   General ProblemDigitization PotentialLack of awareness of some aspect of the tactical (friendly or threat) situationIncreased situation awareness Lack of synchronization (within or across BOSs) in terms of time, space, or activitiesIncreased SA, wargaming tools to enhance situational understanding,  and improved sharing of evolving plans Lack of awareness of some aspect of the plan or lack input to the plan by a BOS or sub-unitImproved sharing of evolving plansDetails missing from plan Improved sharing of evolving plansLack of understanding of the tactical situation (e.g., failure to predict how the situation will evolveIncreased situational awareness and wargaming tools to enhance situational understanding Key elements of the plan produced lateIncreased situational awareness  and improved sharing of evolving plan combine to increase operational tempoInadequate mission preparationIncreased situational awareness and improved sharing of evolving plans combine to increase operational tempoUnit is highly vulnerable or lacks lethalityIncreased situational awareness and  wargaming tools to enhance situational understandingsummaries of  trends in the performance of units at maneuver combat training centers.The next step was to describe the mechanisms whereby digital systems might address the problem  and the skills leaders would need to implement these mechanisms. For example, improved situational awareness should lead to more precise maneuver plans, and more precise maneuver plans should make it easier for other BOSs to envision what must be done to support maneuver.  One of the digital skills required to implement this mechanism is being able to monitor changes in digital planning products. The top down  approach provided a variety of linked measurement targets, as illustrated in Figure 1.  One can measure the occurrence of unit tactical performance problems,  frequency of occurrence of problems falling under a given category,  whether digital mechanisms for addressing problems are in evidence, and whether the digital skills required to apply mechanisms are being employed.  In going from left to  right, the diagnostic value of the measurements increase.  Figure 1.   Linked digital proficiency measurement targets.A bottom up approach was initiated to provide more details regarding skill components, capture examples of low and high proficiency levels, and identify variables influencing proficiency [7].     The sources of information used in the bottom up analysis are described below:Digital task descriptions developed by the U.S. Army Training and Doctrine Command (TRADOC) Warrior-T program. [8, 9, 10, 11, and 12]TRADOC Analysis Center (TRAC) reports concerning the performance of digitized units in exercises at the National Training Center (NTC) and at Fort Hood, TX. [13 , 14, and 15].Various user’s guides oriented towards applying digital systems. [16, 17, and 18]Reports and papers regarding changes in the knowledge, attitudes and behaviors of  4th ID personnel as a function of their experience with digitized systems  [3, 9, 20, 21, and 22]Observations of digital training exercises       Unpublished interviews of  digital unit leaders An ongoing effort in support of the III Corps Battle Command Training Division to develop measures of digital proficiency relevant to the platform-based Force XXI Battle Command Brigade and Below (FBCB2).  Data sources were examined to identify action items appropriate to a specific skill.   Action items under a skill were further analyzed to identify goals supported,   and goals were considered to be skill  components if they were likely to retain their applicability as digital systems evolve   In example, components of the skill “prepare, send, and manage messages” include:send messages that are easy to manageprepare overlays that are easy to employ and updatemanage received digital messagesuse pre-prepared messages to speed up communications and enhance flexibilityenable automated alerts as a sender and receiverTwo of action items for the skill component “prepare overlays that are easy to employ and update” are “keep overlay files small enough to prevent overloading networks” and “ensure version numbers of overlays are clearly indicated to  help identify the most current version.”.  Specific action items may change as digital systems evolve, but most of the goal-oriented skill components are likely to endure.  Variables were identified that have a major impact in terms of influencing which capabilities of digital systems are employed  and how they are employed.  Where a unit stands with respect to these variables might provide a quick indicator of a unit’s overall digital proficiency level.  These variables are illustrated by examples in Table 3.Examples of low and high levels of performance with respect to digital skills were identified through observations of digital training exercises, interviews with leaders from digital units, and  reviews of lessons learned reports and “how to fight” guidance. In addition, cases were identified where effective employment  of one skill was required to set the stage for employment of other skills.   2.2   Tailoring Observation Requirements to MatchDigital Proficiency LevelsExamination of the impacts of major variables on digital system employment (e.g., SOP development), stage-setting relationships among skills, and examples of low and high levels of skill proficiency led to the identification of  fifteen indictors of digital proficiency levels.   Most of these indicators can be applied by asking questions of unit members prior to a period of training, as demonstrated by the fact that most of the variables surfaced in the context of interviews with digital unit leaders.  These indicators are listed at the top of the following page.Table 3.  Major Variables Likely to Influence Unit Digital ProficiencyVariables                                                                               Sample ValuesChanges in digital system capabilitiesThe platform-based digital system allows users to display icons for individual platforms or unit center of mass.  Current options for selecting elements to be displayed as aggregate icons do not match the needs of shooters (e.g., display entity icons for any platform within range of their weapons).  User appreciation of digital capabilitiesMany leaders do not  realize that  a platform based digital system can be used as a mission planning tool .Digital training strategiesUnits must expend a substantial amount of effort to ensure connectivity among digital systems before they can experience the benefits of digitization. Training strategies that allow units to experience of benefits of digitization prior to mastering connectivity skills might enhance acceptance and use of digital systems.Digital SOPsUnit SOPS for naming types and versions of overlay files can make it easier for unit members to manage these files (e.g., identify the most recent version of an overlay)Legacy BehaviorsUnits are struggling with the issue of  what  terrain reconnaissance functions can be shifted from a physical terrain reconnaissance to digital terrain analysis tools. Taking  actions to maintain connectivityDisplaying confidence in the robustness and value of systemsUsing digital systems to ensure timely distribution and review of planning productsAppreciating the value of digital capabilitiesUsing digital systems to apply task triggersEnsuring adequate monitoring of  digital displaysTailoring views of the battlespace to fit visualization objectivesUsing terrain analysis tools to support tactical decisionsIntegrating digital systems into rehearsalsUsing digital displays to monitor/control unit movementActively maintaining awareness of the threat situationUsing digital tactical SOPs to facilitate communication and visualizationUsing effective mixes of reporting modes Delegating digital tasks to ensure adequate employment of digital systemsOrganizing digital data to facilitate communication and understandingFigure 2 illustrates graded proficiency levels for the indicator “organizing digital data to facilitate communication.”  If only the statements toward the bottom of the figure apply to the unit (statements marked with a double asterisk), then it has a low level of proficiency with respect to this indicator. As more of the statements higher up the figure (marked with a single asterisk) become applicable, the higher the proficiency level of the unit.     This indicator becomes an evaluation concern relatively late in terms in the digital progression of a unit, and it useful to consider why. Early in the training of a digitized unit there may be little digital data to organize. Until units progress to the point where they push electronic copies of planning products down to company and platoon level, there may be few planning products to organize and /or little time available to organize these products.  Given the early tendency of units to rely on voice radio traffic, there might be few structured or free text messages to organize. The items selected as indicators of overall unit digital proficiency were selected because they have significant implications for performance measurement activities.   Selected examples of indicators and the implications of a low proficiency level respect to each indicator are provided in Table 4.    It is important to point out that if digital skill levels are low then one should not expect  the relevant mechanisms whereby digital systems can address unit performance problems to be demonstrated.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Higher  ProficiencyLeaders have products supporting alternative courses of actions and can find         these products*Able to quickly find most current versions of overlays and annexes*                                                                                                                   Deletes old messages or out of date planning products from current        mission*     Uses folders to organize messages/overlays*Senders and recipients of planning products apply tactical SOPs for naming files*.Clears queues and logs of old messages after change of mission*Has digital messages but fails to clear queues and logs after change of mission, employ folders, or follow tactical SOPS for naming files **Very few digital messages to filter and organize**Figure 2.    Graded proficiency levels for indicator “organizing digital data to facilitate communications.”Table 4  Sample indicators of a unit’s overall digital proficiency and the feedback implications of a low rating for each indicator. Indicator                                                                           Implications of Low RatingTaking actions to maintain connectivityThe unit is not ready to act as a digital unit unless the training environment plays perfect communicationsDisplaying confidence in the robustness and value of system Users are likely to avoid using many system  Capabilities.Using digital systems to ensure timely distribution and review of planning productsBenefits gained through early sharing of planning products largely disappear.  The unit is unlikely to have time to use wargaming tools and support digital rehearsals.  If companies and platoons receive products very late, it is not meaningful to look at what they do to organize planning products.Appreciating the value of digital capabilitiesA low rating suggests that users will not tailor their view of the battlespace, use terrain analysis tools, or use digital systems to control movement and apply triggers.Using digital systems to apply task triggersIf users do not identify information they will look for in digital displays, then any benefit gained from the system is largely a matter of chance (e.g., the user just happens to look at a display at the right time to observe and understand an important event).   Ensuring adequate monitoring of SA displaysIt may be useful to focus feedback on significant information missed when displays are not observed.Tailoring views of the battlespace to fit visualization objectivesThis may be a digital system problem, if the user has limited options to tailor the view of the battlespace.  If users are not employing these options, then feedback should focus on the utility of improved  views. (here is what you saw versus what you could have seen)2.3  Automation of FeedbackClearly, there are two distinct concepts regarding the functions of after action review (AAR) aids as a feedback tool [23].  Under one of these concepts, the purpose of the aid is to recreate the situation experienced during an exercise (i.e., here is the situation you encountered during the exercise, explain the reasoning behind the order you gave your unit).   Under the other concept, AAR aids provide new perspectives regarding exercise events.  These aids may combine information from a variety of sources to provide information that no single individual had access to during the exercise.  The benefit of this AAR aid concept is that it facilitates the process of deciding what happened, why it happened, and how to improve future performance [24].  To the extent that an AAR aid illustrates root causes of performance problems it can expedite the process of diagnosing strengths and weaknesses in performance and identifying corrective actions.  Often, the decision about how to improve performance involves changing the information flow within a unit so that command and staff will have an improved perspective regarding exercise events during an operation.  It has been suggested that the digitization of unit operations removes the need for an AAR system, because digital displays become the AAR aids.  This line of thinking fits the situation where the function of AAR aids is considered to be recreating  situations experienced during an exercise, but it is not compatible with the concept that AAR aids provide an improved perspective on exercise events.  The need to provide AAR aids as soon as possible after an exercise resulted in efforts to apply automation in generating AAR aids during exercises [23].  This approach worked by tapping into exercise data streams and applying algorithms to guide automated preparation of aids that could be viewed and edited as the exercise progressed [25].    Digital AAR systems have been developed with the capability to provide automated generations of AAR aids based upon the digital data stream. These systems include the Army Battle Command System Integration (ABCSI) [26] and the  Data Collection and Recording System (DCARS) [27].   Both of these systems offer units the flexibility to envision and implement  a wide variety of AAR aids that draw from the digital data stream.   The goal of the current project is not to develop a new digital AAR system.   Instead,  the goal  is  to define the information needs to be addressed by automated AAR aids to support the assessment of digital skill proficiency and overall unit  digital proficiency.   Examples include:What digital radio checks are performed and when are they performed? At what time are digital orders received by various echelons?Are revised versions of overlays created and disseminated? There are at least four electronic data streams that might be used in preparing feedback for digitized units; simulation data, digital message traffic among digital systems, operator interactions with digital systems, and data feeds from RSTA systems such as unmanned aerial vehicles.   If  data are loaded directly to digital systems, rather than being disseminated over a network,  there is a fifth data stream that must be tapped.    One example of such a case is the Master Data Loader supporting the Force XXII Battle Command Brigade and Below (FBCB2) system that can be used to load unit planning products directly to the FBCB2 in individual tactical platforms.  An important goal of the current project is to identify the data sources that most efficiently meet the feedback needs of units.  The  feedback displays can be used to decide whether the use of digital systems have an impact on unit performance problems and categories of problems, and they can be used to decide where digital mechanisms and digital skills proficiency are in evidence. 2.4  Changing Extrinsic Feedback to Intrinsic Feedback Through the Application of Automation Intrinsic feedback is provided in the course of performance, and it serves to to guide and cue performance.  If a  unit calls for artillery on an enemy tank, and then observes  the real or simulated impacts of these fires, the unit receives feedback about the effectiveness of the fires and can take prompt, appropriate corrective actions, if needed.  Extrinsic feedback is provided outside the context of task performance, and it often provides an improved perspective on task performance (e.g., the unit might have employed artillery against a more lucrative target.)  As mentioned in the section immediately above, AAR systems have been developed that produce AAR aids during exercises.   Digitization places unit status data and planning products in an electronic format that enables automated AAR aid production capabilities to be employed during exercises or actual combat operations.  For many situations, the feedback might be employed to take corrective actions.   That is, what used to be extrinsic feedback provided after an exercise can be provided during an exercise to cue and guide performance.  The state of the art automated AAR systems allow units to tailor AAR aid outputs to fit a specific mission or exercise.  In effect, use of these systems to provide feedback in the context of performance makes the AAR system  both a training and operational tool.  The job of  such a “during action” review system is to provide units with an improved perspective regarding the tactical situation.  There is no requirement for the system to provide a recommended course of action, as would be the case with an intelligent tutor application.  This application of the automated “during action review”  concept might provide feedback that would otherwise have to be addressed by a trainer.  The behavioral research issue associated with this type of application of AAR system technology is identifying the information that units might be able to exploit if provided during mission execution and the data sources required to provide this information.   There are also technical issues that need to be addressed in order to support timely generation of digital AAR aids, as will be noted in Section 3.0 of this paper.This approach is merely part of an ongoing trend that is shifting extrinsic feedback to intrinsic feedback.  Certain  digital situational awareness displays provide units with information about the tactical situation (e.g., 1st platoon is moving ahead rather than abreast of 2nd platoon, creating a situation that can lead to fratricide) that pre-digital units usually did not have access to until after an exercise.Units can take corrective actions with respect to this information.  As digitization has evolved, the ability of certain digital systems to provide intrinsic feedback has been enhanced.   For example, users of the platform-based FBCB2 can set their system to sound an alarm if their platform comes within 500 meters of a minefield represented by a geo-referenced icon.  What makes the AAR system application unique is that it cuts across a variety of digital systems and it offers the possibility for units to envision and implement new elements of intrinsic feedback.   3.0   Relevant Data Logging and Integration Issues Addressed by the Simulation Interoperability Workshop CommunityCollecting and analyzing  digital  data and providing AAR or  ‘during action review” aids in a timely manner, without hardware systems creating a massive footprint,  is a serious challenge.    Many of the lessons learned by the Simulation Interoperability Workshop  (SIW) community may prove useful in supporting feedback regarding unit employment of digital systems.Loggers in many networked environments are able to  collect all data from an exercise, but the multicast communications and filtering in the High Level Architecture (HLA) situation eliminated this possibility.  Having a data collection federate subscribe to all of the data defeated one of the major benefits of HLA, reductions in data load  [29].    Various techniques used by HLA to reduce data loads had the effect of undercutting  efforts to generate AAR aids prior to the end of exercises.  This requirement, in turn, triggered efforts to maximize the information available to support feedback by, for example, examining differing methods for implementing distributed data loggers and  integrating data from across loggers  [31].4.0 SummaryDigitization increases the exercise management and feedback workloads of trainers for collective training exercises.  The workload can be reduced by providing a measurement framework that  supports diagnostic functions without being tied too closely to systems features that are continually channging., the application of automated AAR system  technology, and the capability to tailor exercises to fit digital proficiency levelsIn the digital environment, the role of an AAR system may be divided between during-exercise and post-exercise feedback and serve as both an operational tool and training tool.  What contributors to SISO have learned about manipulating data in ways that help reduce network data loads may be crucial to both the training and operations of digitized units. 4. References [1}  Van Fosson, M. H. (2001) “Future combat    systems:       DARPATech2000.”[On-line]. Available:http://www.       darpa.mil/DARPATech2000/Presentations/tto_pdf/       3VanFossonFSB&W.pdf[2]  Brown, B.R., Anderson, L., Begley II, I. J., & Meliza,        L. (1999). Cognitive Requirements for Information       Operations Training (CRIOT). (ARI Study Report        99- 02). Alexandria, VA. U.S. Army Research        Institute for the Behavioral and Social Sciences. [3]  Lynch R. (2001).  Lessons Learned: Commanding a      digital brigade combat team (IDA  Paper P- 3616).      Alexandria, VA: Institute for Defense Analyses.         [4]  Gerlock, D. & Meliza, L. (1999).  “Supporting               exercise control and feedback in the digital domain for                 virtual simulations.”  Presented at the 1999               Interservice/Industry Training Systems and Education               Conference.[5]  Throne, M.H., Holden Jr., W.T., & Lickteig, C.W.      (2000).  Refinement of prototype staff evaluation      methods for future forces:  a focus on automated      measures.  (ARI Research Report 1764). Alexandria,      VA:  U.S. Army Research Institute for the Behavioral      and Social Sciences. [6]  Barnett, J. S., Meliza, L. L., & McCluskey, M. R.       (2001). Defining digital proficiency measurement       targets for US Army units (ARI Technical Report       1117).  Alexandria,  VA:  U.S. Army Research        Institute for the Behavioral and Social Sciences.[7] Meliza, L. (in preparation).  Digital skills and overall      indicators of digital proficiency[8]  Warrior-T (2001a).  Digital battle staff task map        (TRADOC ST 20-101-5, Draft).  Fort Hood, TX   :   Warrior-T Project Office.[9]  Warrior-T (2001b) Army battle command system       (ABCS) smart book overivew version  6.2.x. Fort       Hood, TX; Warrior-T Project Office.[10]  Warrior-T (2002a).  Training the digital brigade        combat team battle staff (16 April 2002 draft).          Fort Hood, TX; Warrior-T Project Office.[11] Warrior-T (2002b).  Army Battle Command System        MCS Workstation Individual Tasks Version 6.2.x  (2        Jul 2002 draft). Fort Hood, TX; Warrior-T Project        Office.[12] Warrior-T (2002c).  Force XXI  battle command         brigade and below (FBCB2) operator, integrator,        and decision maker shared individual tasks        supporting ST20-101-5-ABCS   (3 Jul 2002 draft)    .   Fort Hood, TX; Warrior-T Project Office.[13] Department of the Army (2001).  Division Capstone        Exercise Phase I (DCX I) Initial  Insights        Memorandum (IIM).  [14] TRADOC Analysis Center (2001)   Initial Insights       Memorandum (IIM) for the Division  Capstone       Exercise Phase II (DCXII).  Fort Leavenworth, KS:       Author.[15] TRADOC Analysis Center (2002).  Division        Capstone Exercise (DCX) Final Report. (TRAC-F –        TR-02-006).  Fort Leavenworth, KS: Author.[16] TRW Inc. (1999).  Digital operator’s guide:      Company and platoon level (FBCB2 versio 3.1)   .   Killeen, TX:  Author.[17] TRW Inc. (2000a).  Digital operator’s guide fo r        brigade and battalion staffs (ABCS        version 6.1).  Killeen, TX:  Author. [18] TRW Inc. (2000b).  Digital operator’s guide:       Company and platoon level (FBCB2       version 3.2).  Killeen, TX: Author.[19] BDM Federal, Inc. (1997).  1st BCT, 4ID “Do        Differents” (Annotated Briefing).  Killeen, TX:       Author.[20] Dudley, M. G., Hill, R., Johnston, J.C., Jones, W.S.,        LeGare, M., Leibrecht, B.C.,  Longoria, K.,  &        Meliza, L.L. (2002)  Measuring digital proficiency:        Assessment approaches and echelon considerations        (ARI Research Report 1791). Alexandria, VA:  U.S.        Army Research Institute for the Behavioral and        Social Sciences.  [21] Dudley, M. G., Johnston, J. C., Jones, W. S., Strauss,        C. P., & Meliza, L. L. (2001). Making the transition        from analog to digital warfighting: Changes in unit        behavior and knowledge (ARI Research Report        1785).  Alexandria, VA: U.S. Army Research         Institute for the Behavioral and Social Sciences.[22] Leibrecht, B.C., Johnston, J.C., Black, B.A.,  &       Quinkert, K.A. (2002).  Managing Force XXI       Change:  Insights and Lessons Learned in the Army’s        First Digitized Division   (ARI Study Report 2002        -04). U.S. Army Research Institute for the        Behavioral and Social Sciences.[23] Morrison, J.E. & Meliza, L.L. (1999).  Foundations        of the After Action Review (ARI Special Report 42).        Alexandria, VA:  U.S. Army Research Institute for         the Behavioral and Social Sciences.[24]  Meliza, L.L. (1998) .  A Guide for Standardizing         After Action Review Aids  Alexandria, VA. U.S.         Army Research Institute for the Behavioral and         Social Sciences. [25] Brown, B., Wilkinson, S., Nordyke, J., Riede, D,.        Huyssoon, S., Aguilar, D., Wonsewitz, R., &        Meliza, L. (1997)  Developing an automated training        analysis and feedback system for tank platoons.         (ARI Research Report 1708). Alexandria,  VA:  U.S.        Army Research Institute for the Behavioral and        Social Sciences.[26] Faulkner, L. (2002) “User-centered design and        testing for a digital feedback system. Presented at the        2002 Interservice/Industry Training Systems and        Education Conference.     [27] Electronic Proving Ground  (2002).   Data         Collection, Analysis and Review System (DCARS)         Online: HYPERLINK http://www.epg.army.mil/Instrumentation/DCARS www.epg.army.mil/Instrumentation/                                            DCARS.htm [28]  TRW  (2002)  FBCB2  Version 3.5.3 Embedded         Tutorial ( TM-11-7010-326-10 V.3.5.3). [29] Van Hook, D.J. & Calvin, J. O. (1997). Execution Logging and Replay: Issues and Approaches.”  Spring 1997 Simulation Interoperability Workshop.    [30] Meliza, L. L. & McDonald (1998).  Using HLA to         support performance measurement.  Spring 1998         Simulation Interoperability Workshop .  [31] Magee, G. & Shanks, G. (1999).  Lessons Learned          from an Implementation of a Fully Distributed Data         Collection Too.l. Spring 1999 Simulation         Interoperability Workshop.                  Author Biography LARRY L. MELIZA is a research psychologist with the U.S.   Army Research Institute for the Behavioral and Social Sciences  (ARI) Simulator Systems Research Unit.  Dr. Meliza’s experience in measuring the collective performance of Army units in the live and virtual environments includes   assessing impacts of force modernization on exercise control and feedback requirements and developing procedures and automated tools to support exercise management and feedback. He has served on the Exercise Management and Feedback Forum Planning and Review Panel.PAGE  1Use SA data and terrain analysis tools to to predict contact variables and support BOS integration.Assess completeness and accuracy of planning products.Maintain awareness of trigger events.Supporting Digital SkillsMechanisms   Addressing Problems“smoke plans are rarely made and coordination of the targeting process between fire support and maneuver does not occur.”ProblemPoor SynchronizationProblem CategoryIncreased SA and terrain analysis tools make it easier to see when  and where smoke missions would be useful.   SA displays make it easier to use event-based triggers rather than the less effective time-based triggers for synchronizing smoke and maneuver.  Early review of plans to ensure smoke is addressed.