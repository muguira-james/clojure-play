Lessons Learned From IntegratingSTOW Technology into an Operational Naval EnvironmentRandolph M. JonesPatrick G. KennySoar Technology, Inc.317 North First StreetAnn Arbor, MI 48109734-913-8160rjones@soartech.com, pkenny@soartech.com Keywords:Synthetic Theater of War (STOW), TacAir-Soar, Battle Force Tactical Trainer (BFTT), Air Management Node (AMN), Shipboard Training Simulation ABSTRACT: In 1999-2000 Soar Technology, Inc., has been working with other companies to integrate STOW technology into the newest version of the Air Management Node (AMN) for the US Navy’s Battle Force Tactical Trainer (BFTT). BFTT systems enable naval ships to participate in joint synthetic battlefields. The newest version of the AMN is significant because it is the first application of STOW technology that has been fielded in a fully operational environment.  Our specific role in this project was to build intelligent synthetic pilots for simulated fixed-wing and rotary-wing aircraft, in order to support training of shipboard air traffic controllers.  This paper reports a variety of lessons we learned from incorporating such intelligent synthetic forces into the larger AMN system on board a naval vessel.1. BackgroundIn 1999, Soar Technology, Inc., joined a team of other companies to develop the latest version of the air management node (AMN) for the US Navy’s Battle Force Tactical Trainer (BFTT).  The Navy deploys BFTT systems on ships so they can participate in joint synthetic battlefields.  The newest version of the AMN has been fielded on a multi-purpose amphibious assault ship (LHD6, the Bonhomme Richard) in order to train air controllers performing air traffic and air intercept duties.  Development of the AMN has been a team effort, involving integrated development of human-computer interfaces and HLA simulation systems to support the virtual environment.  Our specific portion of the work focuses on developing intelligent synthetic forces that fly ship departures and approaches with fixed-wing and rotary-wing aircraft.  The primary requirements for these forces are that they must behave appropriately and autonomously without control, but also respond correctly to direction from the controllers.  The entire AMN effort continues to this day, and more sophisticated versions of the system will be deployed in 2000.  In order to support future research and development for BFTT and similar systems, this paper reports on the specific lessons we have learned from integrating intelligent synthetic forces into the larger AMN system, in a ship-board, operational training environment.  Some of these are somewhat general lessons in software engineering and integrated system development, but are worth reiterating in the specific context of intelligent forces and training with distributed simulations.  Other lessons focus more specifically on issues of knowledge engineering and development of intelligent agents.Before proceeding, we want to stress the point that we are presenting these lessons as the results of reviewing our work with a very critical eye.  Because we found there were mistakes to learn from, it may appear that we are dissatisfied with the product we created.  This is not the case at all!  The AMN effort has created a large and robust system that we are extremely proud of.  It is the first instance we know of that deploys artificially intelligent systems and STOW simulation technology in a fully operational environment.  It is also a system that we believe will provide realistic and effective training to Navy personnel.  With that understanding, we proceed to analyze how future efforts can accomplish similar goals more easily, with the benefit of feedback from our experiences.2. User and customer centered designMany authors have argued for the advantages of user-involved design of information systems [1, 2, 3].  In addition, software engineers have long appreciated the need to define system requirements as precisely and as early as possible.  Unfortunately, research also demonstrates that, although everyone thinks these are good ideas, they are too often neglected when it comes down to budgets, resources, and other constraints.  These issues take on their own particular nuances when we throw intelligent systems for military training into the mix.As with many information systems, there is tension between the demands of designing for the customer and designing for the user, and these two groups are often not the same.  Naturally, for training systems, it is important to pay attention to both, because the trainers are experts on how to train and the trainees know best how they carry out the day-to-day activities they need to practice.  Historically, requirements come from the people paying for the system.  However, significant research shows that systems improve when the users are involved in the design and testing process.  Unfortunately, as soon as there are multiple sources of requirements, there is the potential for miscommunication and conflict, sometimes leading to ill-defined or even incorrect requirements.  As an example, we spent significant time early in the project focusing on intelligent behaviors for fixed-wing aircraft.  We then discovered that the initial deployment of the AMN would be aboard ships that do not carry (and cannot launch or land) fixed-wing aircraft.  This led to a quick and intensive shift in priorities toward the synthetic pilots for rotary-wing and VSTOL aircraft.  Such confusion of requirements at best lead to misplaced effort and resources, and at worst lead to wholesale reimplementations of systems or systems that are unusable or ineffective.At times, global requirements would be clear, but details were missing.  This is particularly important for intelligent systems for training because of the premium put on realism.  Training systems must provide as effective and realistic a training experience as possible.  To support that goal, intelligent forces for training simulation must operate in the ways that people expect humans to operate.  This means the system designers must have thorough access to doctrine and standard operating procedures.  For intelligent systems development, the standard solution to this requirement is to use subject-matter experts (SMEs).  We have excellent SMEs who defined many of the requirements, and are invaluable for testing and criticizing the system.  However, for intelligent systems design we must expand the user-centered design tenet, “designers are not users”, to keep in mind that SMEs are also not users.  We were sometimes frustrated that either the system designers or the SMEs would have to guess how to implement certain requirements, simply because we did not have easy access to air-traffic controllers who would actually be using the system.  It would have been extremely useful to involve users throughout the implementation and testing, letting them come into the lab, explore the existing prototype, and inform the design team about what they liked or disliked, or identify missing requirements.  The first deployment of the new AMN occurred in San Diego, while the primary development effort was in Virginia.  The next deployment is scheduled for Norfolk, so we hope that will provide more opportunity for involving real users in the next phases of design, implementation, and testing.None of the above is meant to blame or criticize any portion of the overall development or management team.  Certainly, we are ultimately responsible for gathering and defining requirements for the portions of the system that we build.  We were able to do that for the most part.  The few frustrations we ran into, however, are a reminder that customers and development teams together must be sure to budget time and resources for extensive user involvement, and that this involvement should be taken seriously by designers in all phases of development.  The user-involved approach has proven useful in all types of information system design; the unique requirements of effective training systems simply magnify the necessity of such an approach.  Our specific recommendation is that training-system projects make sure to provide designers with easy access to a community of users so we can design systems the way they actually will be used.  To do otherwise runs a serious risk of building very expensive training systems that will see very little actual use.3. Team implementation and integrationThe AMN effort involves quite a variety of subsystems, including intelligent behaviors to control synthetic flight platforms (our specific focus), the underlying distributed simulation system, visualization systems into the virtual environment, interfaces between subsystems, and human-computer interfaces.  Following good engineering principles and the constraints of reality, the team members developed each of these modules separately, and we worked together to create well-defined interfaces to glue everything together.  Each group ironed out kinks in its subsystems with extensive unit testing.  Naturally, the groups also spent significant time on integration and system testing.  Unsurprisingly, we found that the most productive periods of work occurred when we all got together in one room for a week, putting things together and hammering out bugs.  This suggests that integration trips are extremely beneficial and should occur frequently.  The down side is that such trips have the potential to be quite expensive.  Such trips require significant travel and labor costs.  In addition, critical breakdowns in any of the interfaces or subsystems lead to numbers of highly paid engineers sitting idle while waiting for the critical errors to be fixed.  Such problems tend to decrease as the system becomes more mature and fully developed, but every trip seems to involve at least some amount of expensive, wasted time.  One response to this would be to approach the development of all future systems with tightly integrated engineering teams.  In fact, much of the work on distributed simulations for the military followed that paradigm for quite some time.  However, we argue that such an approach has now become both impractical and undesirable.  It is undesirable because it leads to monolithic systems that sacrifice modularity and become extremely difficult (if not impossible) to debug, maintain, and extend.  It is impractical because computing technology has reached the point where we can create extremely sophisticated subsystems for large applications like distributed simulation.  Designing effective training interfaces, realistic environment simulation, and intelligent synthetic forces each require enormous amounts of specialized expertise and effort.  Although there may be large design teams who believe they can do it all, we believe that is not the path of the future.  Each of these types of subsystems is becoming sophisticated enough that they demand the specialized expertise of separate and small groups.  As we hinted above, we feel this fact is also desirable, because it forces the modular development of the larger systems.  However, if we accept the inevitability of multi-group efforts, we also must make sure to smooth out the interactions between groups as much as possible.  We feel we can improve the tools we used to provide each group with remote access for software version control, as well as for integration of the software systems.  Although none of the components we worked on were classified, the integrated product was maintained in a secured lab, introducing unnecessary barriers for access and cooperation.  This sometimes meant that code versions would get out of synch, and meant that very little integration work could be accomplished without everyone travelling to the central site.Again, these are general lessons for information system design in the twenty-first century; we have not necessarily discovered any new problems or solutions here.  But the demands of the AMN project have highlighted the tradeoffs, rewards, and pitfalls of the team-oriented approach. 4. Integrating intelligent behavior setsWe move now from more general lessons concerning large system engineering to particular lessons about the types of development that Soar Technology focuses on.  To reiterate, our company’s primary expertise lies in developing intelligent synthetic forces for distributed simulations that are used for military training.  Thus, the lessons most important to us focus on the keywords synthetic intelligence, distributed simulation, and training.   The AMN project expanded our concerns into the areas of shipboard training and integration into a larger training system.At this point, we focus on the integration of intelligent behaviors for the AMN training application.  We begin by providing some background.  Most of the members of Soar Technology were involved in the development of TacAir-Soar intelligent agents to fly synthetic fixed-wing aircraft in DARPA’s STOW program [4].  During that time, we worked in collaboration with, but separate from, a team at the University of Southern California’s Information Sciences Institute, who created similar systems for flying synthetic rotary-wing aircraft [5].  Although both systems evolved from a very early version of TacAir-Soar [6], they followed quite separate development paths for a number of years.  The AMN environment requires the realistic simulation of human pilots for both fixed-wing and rotary-wing aircraft.  Thus this project introduced the challenge and opportunity of integrating the heterogeneous behaviors into a more general and flexible system to model human pilots.The ultimate goal of such an integration would be a single architecture for behavior, that includes modules for differences in behavior, but reuses as much code and functionality as possible.  While we succeeded in this integration to some extent, the effort required for a full, ideal integration was beyond the budget of the project.  Much of the code for fixed-wing and rotary-wing pilots is the same, but included large numbers of very minor differences.  These differences are annoying because cleaning them up would greatly increase the elegance and robustness of the system, but since the differences do not actually degrade behavior there were always higher priority tasks to accomplish.Although we did not completely succeed in our integration efforts, the areas in which we did succeed led to immediate payoffs.  The lesson learned here involves recognizing the expanded utility of reusable software to the area of intelligent systems.  It is common software engineering practice to make software modules as reusable as possible.  Taken to the extreme, this approach adopts the attitude “never write the same piece of code twice”.  There are numerous advantages to reusability, mostly involving efficiency in the software engineering effort.  Reusing software modules reduces redundant efforts in the initial design and implementation of the system, and makes debugging and maintaining software much simpler and more efficient.In intelligent systems, knowledge gets encoded into computer software.  This means that the principles of reusable software translate directly into reusable knowledge.  In addition to the normal software engineering benefits of reuse, reusable knowledge provides enormous benefits to the development of systems that generate intelligent, human-like behavior.  The hallmark of intelligent creatures is that they are robust and flexible.  This means that they do not break or freeze up just because they find themselves in unfamiliar or information-poor situations.  Rather, they are very good at adapting what they know to new situations, and making the best of whatever state they find themselves in.  Reusable knowledge directly supports these features of intelligent behavior.When systems store knowledge in a reusable and modular fashion, it enables them to partially match that knowledge to a variety of situations.  This includes situations that the knowledge engineer may not have anticipated.  For example, in the AMN application, synthetic pilots perform a variety of tasks, mostly flying their aircraft and communicating with controllers (and each other).  They maneuver their aircraft in a variety of ways to achieve a variety of goals, such as following launch procedures, proceeding to a point, holding at a point, marshaling, and following approach procedures.  Each of these goals has a great deal in common, as well as some specific differences.  We encode the commonalities in a uniform representation, so the same knowledge can be used for all goals that involve “flying a route to somewhere”.  More specific knowledge patterns apply when appropriate, for example to follow specific procedures for holding in a racetrack or descending onto a ship.  This makes it easy for the system to behave flexibly.  For example, the synthetic pilots for the AMN have behaviors for flying an approach to a TACAN station.  For training purposes, we found it desirable to allow aircraft approaches sometimes to arbitrary waypoints.  The only knowledge engineering effort required was to make sure the range and bearing information from the waypoint computer is represented in the agent in the same way as range and bearing information from the TACAN.  With no further changes, the system flexibly and robustly exhibits proper landing procedures at arbitrary waypoints.The knowledge engineer’s primary job is to create a system that behaves in intelligent and human-like ways.  As we have suggested, a key part of doing this is making sure that the system can respond to similar and unexpected situations in an adaptive way.  Applying the methods of reusable software to the representation of knowledge is an important lesson for any future designers of intelligent synthetic forces.5. Adapting agent architecture to BFTTWe generally describe intelligent agents as consisting of two basic parts: the agent architecture and the agent knowledge for behavior [7, 8].  As we have previously mentioned, the BFTT AMN project introduced new demands on the intelligent synthetic agents, having mostly to do with incorporation into a larger training system on board a naval vessel.  These demands required adaptation of both the TacAir-Soar agent behaviors and the underlying architecture that provides a context and medium for those behaviors.  This section examines lessons we learned from adapting the agent architecture to the AMN application.  TacAir-Soar agents are implemented with the Soar architecture for intelligent agents [7, 8].  For distributed simulation applications, we also include an interface (which we call the SMI) from Soar to the virtual environment simulation.  Finally, the underlying simulation system for AMN is the JSAF system.  The adaptations we had to make focus mostly on the interface between Soar and JSAF.  For example, we added systems particular to the naval air traffic control domain, such as a TACAN model and the ability to track and locate moving ships.  We also devoted particular effort to the issue of dynamic agent creation.  For prior STOW applications, the intelligent agents “lived a full life”, accepting a mission briefing from humans or a digitized air tasking order, taking off, executing their mission, landing, and then reporting the results of the mission.  Although the agents had the knowledge necessary to complete certain types of on-call missions, most missions were specified long before launch, and we could assume that individual agents had a coherent picture of their history and future during the course of an event or mission.  This is a very important assumption for intelligent forces, because intelligent behavior relies heavily on situational awareness, environmental context, and the agent’s personal history.  If you picked up an intelligent synthetic force and dropped it into a new situation without any amplifying context, the agent would become at least as confused as if you did the same thing to a human pilot. In contrast, training with BFTT requires instant, dynamic creation of agents with little initial mission specification.  In fact, the notion of a “mission” is somewhat unimportant for current training applications.  The agents simply need to know how to takeoff, land, and follow controller directions, and mostly bide their time in between.  Also, in addition to launching from a ship or an airstrip, aircraft can be “launched airborne”, completely ignoring normal launch procedures.  Such a launch still requires the intelligent agent to do the “right” thing, in spite of having no personal history or context from which to make decisions.  We created interfaces to JSAF allowing the dynamic creation of aircraft on ships, airfields, or mid-air.  In addition, the agent behaviors now accommodate such rapid-fire launching and landing.  For the most part, this has made the overall intelligent behaviors more robust and flexible, but it has occasionally required making assumptions that may not transfer to other training domains (where situational awareness and mission history are more important).An additional part of the AMN is that it is a distributed simulation, including a number of separate CPUs for simulating aircraft.  The specific number and configuration of CPUs is invisible to the user, but the underlying simulation scheduler must use processing resources in the most efficient ways available.  Thus, an additional part of the dynamic agent scheduler involved new algorithms for determining how many machines were available for creating agents and where they should be created. This design is also invisible to the agents themselves.  They communicate with each other and observe each other only through the mechanisms of the JSAF distributed simulation, and do not care whether they happen to be run on the same CPU as any other agents.  This further highlights the flexibility of the distributed simulation model for training, but it also creates new difficulties for design and implementation.  The AMN involved significant new hardware and software systems, where complications on either side could hinder further develop for the other.  In addition, both the hardware and the software needed to be integrated into the existing systems on board LHD6.  This included creating HLA translations and interfaces between the AMN and existing BFTT simulations, as well as actually interfacing the AMN box to the BFTT computer systems and finding a space on the ship to fit it all [9].  Because of the realities of the US Navy, there was no real way to bring everything together until it was actually on the ship, which in turn couldn’t happen until the ship was in port, on the other side of the country from the main development effort.  These are complicating issues that arise directly from the desired to deploy training systems on board vessels.  There is not necessarily any way to avoid them, but all future similar efforts must anticipate them in their planning and scheduling. 6. Adapting agent behavior to BFTTIn addition to adapting the underlying agent architecture and interfaces to the requirements of BFTT, we naturally had to incorporate specific new types of knowledge into the synthetic force behavior code.  As mentioned previously, we were able to build agents for the AMN from existing, separate knowledge bases for both rotary wing and fixed wing aircraft.  The existing systems were substantial executable knowledge bases designed mostly to generate air intercept and surface attack behavior (for fixed-wing missions) and reconnaissance and tank attack (for rotary wing missions).  To provide a glimpse of the amount of knowledge engineered into these systems, the TacAir-Soar system for fixed wing aircraft included a knowledge base of approximately 5400 rules (it is now up to over 6000 rules).The BFTT air control domain ended up including only a portion of the existing behaviors.  However, we wanted to incorporate all of the different types of knowledge together both to support the general intelligence and flexibility of the system, and to create a new system that is as widely applicable as possible to different training needs and situations.    This was also consistent with our general approach of maximizing the reuse of knowledge within our systems.There were, however, some obstacles to achieving the goal of a unified intelligent agent that encompasses all the different types of behaviors we would ever hope to simulate.  In particular, some of the assumptions in the BFTT domain directly contradict assumptions for the STOW air intercept domain.  As an example, STOW aircraft generally receive a full mission briefing, complete with waypoints and routes to follow, as well as specific (and possibly complex) mission goals.  In addition, STOW applications generally required from the agents a high degree of autonomy.  The intelligent synthetic pilots in STOW were expected to figure out on their own when to refuel, when to commit to targets, how to plan out and fly routes, and when to return to base.For BFTT, the training demands are quite different.  We did not need (or want) the agents to have sophisticated knowledge of waypoints and geographical landmarks, because the controllers will generally not be privy to any of this pre-briefing information.  If the agents started autonomously flying new routes or heading to particular locations, the controllers would likely simply become confused and wonder what the agent is doing.  In the AMN, there is no facility for trainees to query the synthetic pilots about their goals and actions, although that is a facility we are developing for a separate project [10].  These conflicting requirements create a tension within TacAir-Soar’s knowledge base, about when it is appropriate to be proactive and highly autonomous, and when it is important to be somewhat passive and highly dependent on human control.  Naturally, these requirements will vary across training situations.  This suggests that it would be desirable to modularize the intelligent behavior and provide plug-in intelligent capabilities for training domains with varying requirements.  This is not an issue we had considered before running into such a different type of training environment.  It has caused us to alter slightly our vision of intelligent agents in training environments, and to change our conception how we should proceed with the future development intelligent synthetic forces.7. Robust, long-term executionOur final lessons have to do most specifically with the deployment of the AMN system in an operational training environment on board naval vessels.  The Soar architecture has been used to develop a number of demanding applications.  In particular, the TacAir-Soar system had to meet a number of requirements to become an effective part of STOW technology.  In spite of this extensive experience, the BFTT AMN project has pushed even further the limits of intelligent agent development.  One of the primary constraints arising from on-board deployment concerns how long the system has to be up and running.  This is not only a matter of time, but also a matter of the number of significant state changes to the systems (such as creating and deleting agents in the simulation environment).  As most large-system engineers know, the longer a complex application runs, the more chance there is that something bad may happen, causing a system failure.  System failures are never desirable, but in an operational training environment it becomes even more critical to eliminate them.We alluded to part of the solution above.  Intelligent agents must be robust in their interaction with the simulation environment.  Significant reuse of knowledge allows us to have some confidence that the agents will not begin to behave erratically or inappropriately even after they have been in the air for hours at a time.  Aside from the intelligent behaviors, it became imperative to track down potential memory leaks and other possible sources of system failure.  In massive systems such as JSAF, it is effectively impossible to guarantee that the code is bug free.  Thus, it becomes important to incorporate software interlocks and redundant checks to make sure that no temporary glitches in system performance become complete system failures.  Much of this effort simply involves taking an approach to system design that minimizes the assumptions that lead into each action the system performs.Entering the AMN project, we did not appreciate the full extent of the requirements imposed by shipboard deployment. Because the AMN is a novel effort, we did not always know what the total system requirements would end up being. In the end, however, the specific concerns of deploying a shipboard system have caused us to create a new system that is much more robust and solid.  It has also resulted in a high quality product that will improve the effectiveness of shipboard training.8. ConclusionsWe began the BFTT AMN project with a significant amount of experience in developing intelligent synthetic forces for distributed, simulated training environments.  We looked forward to the new project as a way to bring our expertise to a new training area, while also addressing some new challenges.  The particular new challenges from AMN focused mostly on integrating our intelligent agents into a large and quite different training environment, which also happened to be deployed on board real naval vessels.We learned a number of valuable lessons from this experience, and we believe the lessons translate to much improved knowledge about intelligent synthetic forces in general, and their application to operational training environments and simulation in particular.  Many of the lessons are extensions of conventional wisdom in information systems design, as applied to intelligent knowledge-based systems.  Others have more specifically to do with our own approaches to the development of intelligent agents.  We hope this report helps others improve their approaches to information systems design as much as we feel the lessons have improved our approach to building intelligent synthetic forces and related systems.  Future work on the AMN will involve adding and customizing behaviors for training air intercept controllers, integrating the new training requirements into the existing system, and installing the AMN on CVN class carriers9. References[1] J. Greenbaum & M. Kyng: Design at Work: Cooperative Design of Computer Systems, Lawrence Erlbaum, Hillsdale, NJ, 1991.[2] J. Nielsen: Usability Engineering, AP Professional, Boston, 1993.[3] D. A. Norman: The Design of Everyday Things, Doubleday, New York, 1990.[4] R. M. Jones, J. E. Laird, P. E. Nielsen, K. J. Coulter, P. G. Kenny, & F. Koss: “Automated Intelligent Pilots for Combat Flight Simulation”, AI Magazine, Vol. 20, No. 1, pp. 27-41, 1999.[5] R. W. Hill, J. Chen, J. Gratch, P. Rosenbloom, & M. Tambe: “Intelligent Agents for the Synthetic Battlefield: A Company of Rotary Wing Aircraft”, Proceedings of the Ninth Conference on Innovative Applications of Artificial Intelligence, pp. 1006-1012, AAAI Press, Menlo Park, CA, 1997.[6] M. Tambe, W. L. Johnson, R. M. Jones, F. Koss, J. E. Laird, P. S. Rosenbloom, & K B. Schwamb: “Intelligent Agents for Interactive Simulation Environments”, AI Magazine, Vol. 16, No. 1, pp. 15-39, 1995.[7] J. E. Laird, A. Newell, & P. S. Rosenbloom: “Soar: An Architecture for General Intelligence”, Artificial Intelligence, Vol. 47, pp. 289-325, 1991.[8] A. Newell: Unified Theories of Cognition, Harvard University Press, Cambridge, MA, 1990.[9] D. B. Cavitt, M. A. Gibson, B. Dobrydnev, D. S. Bryan, & J. J. Berkeley: “Integrating STOW and the Navy’s Battle Force Tactical Training (BFTT) System”, Proceedings of the Fall 1999 Simulation Interoperability Workshop, 1999.[10] R. M. Jones: “Graphical Visualization of Situational Awareness and Mental State for Intelligent Computer-Generated Forces”, Proceedings of the Eighth Conference on Computer Generated Forces and Behavioral Representation, pp. 219-222, 1999.AcknowledgementsSoar Technology, Inc., worked in close cooperation with BMH Associates, Inc., and Lockheed Martin Tactical Defense Systems on this project.  We are particularly grateful to Lockheed Martin for leading the management of the project.  We would like to than Jim Rosbe and Glenn Taylor for comments on drafts of this paper.Author BiographiesRANDOLPH M. JONES is a Senior Scientist and Vice President at Soar Technology, Inc.  He is also a Visiting Assistant Professor of Computer Science at Colby College.  In 1989, he received his Ph.D. in Information and Computer Science from the University of California, Irvine.  His general areas of research and development include computational models of human learning and problem solving, executable psychological models, and automated intelligent actors for virtual environments. He has worked on the TacAir-Soar project since its inception, and wrote the first implementation of the TacAir-Soar system.PATRICK G. KENNY has ten years of defense industry experience working in the field of artificial intelligence.  He is the Director of Technology and a Senior Systems Engineer at Soar Technology, Inc., as well as the Project Manager for the company’s BFTT efforts. Prior to his current position, he was on the staff of the University of Michigan Artificial Intelligence Laboratory, where he developed Unmanned Ground Vehicles (UGV). He has also held positions at Advanced Decision Systems and Honeywell. He has a B.S. in Computer Science from the University of Minnesota. 