Design and Execution of a Federation for ExperimentationLaura E. FeinermanDavid L. ProchnowDavid W. SeidelJohn A. TufaroloAnnette L. WilsonAnita A. ZabekThe MITRE Corporation1820 Dolley Madison BlvdMcLean, VA 22102703-883-7488, 703-883-6167, 703-883-6828, 703-883-6253, 703-883-5365, 703-883-1389 HYPERLINK mailto:feiner@mitre.org feiner@mitre.org,  HYPERLINK mailto:prochnow@mitre.org prochnow@mitre.org,  HYPERLINK mailto:dseidel@mitre.org dseidel@mitre.org,  HYPERLINK mailto:tufarolo@mitre.org tufarolo@mitre.org,  HYPERLINK mailto:awilson@mitre.org awilson@mitre.org,  HYPERLINK mailto:anita@mitre.org anita@mitre.orgKeywords:FEDEP, ExperimentABSTRACT: The Joint Warfighting Program Trailblazer Federation was created to examine the application of a federation of simulations to experimentation with technologies, doctrine, and organizations in the domain of Information Superiority. Experimentation requires iterative refinement of the hypotheses to ensure that the appropriate federates are selected and can provide the detail required to generate MOEs. This paper reviews the lessons learned as the Federation Execution and Development Process (FEDEP) was applied to the establishment of a federation in support of experimentation.IntroductionThis paper presents lessons learned in the design, development, and execution of a federation of simulations to support experimentation using the Federation Development and Execution Process (FEDEP) as a roadmap [1]. The Trailblazer federation has completed the FEDEP twice as requirements were further refined. At the 1998 Fall Workshop, lessons learned with the Trailblazer federation were presented for the steps of the process that had been completed at that time [2]. This paper continues to examine the federation as it has evolved. In particular, the following topics are discussed: the Federation Implementation Document (FID) as a vehicle for federation design, and verification and validationlessons learned as federates completed compliance testing as a federation; andtime management in individual candidate federates as they affect model accuracy, time management across the federation, and federation performance.1.1 Trailblazer OriginsThe Trailblazer effort has its origins in the congressionally funded, DDR&E-sponsored Joint Warfighting Program. Through a series of experiments, DDR&E aims to examine how changes in doctrine, organization, and technology can enhance our ability to achieve and maintain information superiority in a hostile environment. DDR&E is looking to the Joint Warfighting Program to design and conduct these experiments, and to DMSO to provide technical support to the experiments involving modeling and simulation. In an effort to better understand the requirements of modeling and simulation for experimentation, DMSO has implemented the following strategy: to use the High Level Architecture to take advantage of existing model capabilities, and to prepare a prototype federation in support of experimentation to gain relevant experience. 1.2 Federation Development and Execution ProcessThe Federation Development and Execution Process (FEDEP) was used as a roadmap to form a federation to support experimentation in the area of information superiority. Experiment requirements were extracted  from a 2010 joint suppression of enemy air defense (JSEAD) experiment described in the Joint Staff “JV2010 Information Superiority Implementation and Assessment Plan (U)” [3]. Our goal was to capture lessons learned and evaluate the available federation tools and processes as we executed the FEDEP. The FEDEP is a five step process. The process walks the user from Requirements Definition through Federation Execution and is presented in a simplified form in the box below. Trailblazer FEDEP Use The Trailblazer team has executed the FEDEP twice as of this writing. The first execution culminated in Build 0 executions and the second concluded with Build 1 testing. Build 0 represented the successful application of the FEDEP in the arena of experimentation. It demonstrated that the selected federates could perform distributed simulation and provide data for analysis. The lessons learned from Build 0 were presented previously [2]. Build 1 differed from Build 0 in two important ways. First, J-6 expressed interest in the Trailblazer federation as a way to complement live experiments and worked closely with the federation development team, and secondly, the team had executed the FEDEP once and was eager to put lessons learned into practice. The Trailblazer federation consists of three core federates: the Extended Air Defense Simulation (EADSIM), Eagle, and the Naval Simulation System (NSS). These simulations provide a joint battlespace foundation of friendly and threat air, ground, and naval forces. Other federates may be added if indicated by experiment requirements. The fourth federate, the Federation Management Tool (FMT) provides federation monitoring capabilities during execution.The Trailblazer team consists of the following government and contractor members:DMSO and the MITRE Corporation (Washington) as lead and systems engineer;USA Training and Doctrine Command Analysis Center (TRAC) and SAIC for Eagle;USAF Electronic Systems Command (ESC), Teledyne Brown Engineering, and the MITRE Corporation (Bedford) for EADSIM; and USN Space and Warfare Command (SPAWAR), and Metron for NSS. EMBED Word.Picture.8  One of the overriding lessons learned from the Build 0 experience was that it is important to capture the user’s objectives for the experiment. Ideally, the user will work closely with the development team. The challenge is to extract as much information as possible from the user in an efficient manner, and to document it in a format that is unambiguous to both the user and the developer. To this end the Federation Implementation Document (FID) was created. The FID serves as a reference document for the user, the systems engineer, and the federate developers. The FID also supports the accreditation of the federation for the experiment. As such the FID is useful through all Federation Development and Execution Process steps. Federation Implementation DocumentThe Federation Implementation Document (FID) identifies the key events of the experiments and the objects and activities that comprise each event. The Trailblazer FID was created during the Requirements Definition step of the FEDEP and evolved through the Conceptual Model and Federation Design steps. The box below outlines the contents of the FID for one of the events that occurs during the experiment. This section of the paper identifies how the FID was used during the Trailblazer experiment.The Trailblazer FID served as a blueprint for the experiment. It originated as the team began its second iteration of the FEDEP, this time with the J-6 user. Based upon the original JV2010 report and conversations with the user, the systems engineer constructed the FID to identify the events, and key objects and activities important to each event. As the FEDEP progressed to the Conceptual Model Development step, the systems engineer interviewed the user to identify the factors that affect each event as they relate to the objects and activities for that event. Key factors were those that could influence the experimental outcomes and therefore were important for inclusion in the federation design. Examples of key factors vary by event but might include: operational characteristics of the objects (such as processing times and communications delays), doctrinal characteristics (such as rules of employment), and natural factors (such as terrain masking, earth curvature, and weather). The user then reviewed the systems engineer’s interpretation and depiction of the factors and prioritized them to focus development efforts.The subject of the experiment was the joint suppression of enemy air defense (JSEAD) mission. This mission was simplified into the following key events: Target emits, Target detection occurs and is reported, Strike assets are tasked, Engagement occurs. Each event is composed of one or more objects executing one or more activities that may be influenced by different factors. As an example, consider the third event, Strike assets are tasked. The objects that participate in this event include the joint air operations center (JAOC) and the different strike assets. The activity that occurs during this event is the assignment of the target to a strike asset. The assignment is governed by the location of the target, the location of the strike assets, the vulnerability of the strike assets, and doctrinal guidance for selecting a strike asset. To varying degrees, this event (tasking strike asset) may be influenced by the following factors: the geography of the event, the speed of available assets, the range of the strike asset weapon, and current competing activities of the strike assets. As the Trailblazer effort continued toward the third step of the FEDEP, Federation Design, the role of the FID was expanded to include algorithms, and the requirement for and use of data. The allocation of objects and activities to federates was assessed against the requirements of the user’s experiment, level of detail required, and federation performance considerations. Federate developers then provided information about the specific algorithms that would be executed for the key events. This provided visibility into the black boxes of the simulations. The user could assess the appropriateness of the algorithms for the experiment and the federate developers could assess the consistency of the information exchanged between models. The federate developers annotated the FID to highlight data requirements and usage for the key event algorithms and objects. This served several purposes. Identified data requirements for modeling future systemsIdentified vetted data sources for modeling current systemsIdentified the usage of critical data allowing the analyst to anticipate when “data in equals data out”As an example of this last point, a user asked to specify the communications delays between two objects may reasonably expect that output reflecting the communications delay between those objects will closely reflect the data input. Throughout the Federation Design step, the FID provided information about the objects and interactions that the Federation Object Model (FOM) should support. These mapped easily into the FOM constructed for Build 0. Some modifications occurred as the federates took on larger roles and new or additional information requirements surfaced. The FID also served as the basis for the Data Collection Plan. Measures of effectiveness (MOEs) were noted in the FID. The Data Collection Plan ensured that data necessary to calculate the measures could be collected. Additionally, the Data Collection Plan annotated data elements that were reflections of data inputs. Since some of these inputs were varied for different experiment cases, it was important to include the data in the collection effort for completeness.As the Integration and Test step began, the FID was instrumental in constructing the test plan. Not only were key events tested, but factors identified as having an impact were examined for desired effect during this step. The development of the FID was an iterative process and served to coordinate the efforts of all participants. It evolved with contributions and revisions by all participants. The FEDEP is a sequential description of a process that may have multiple backward and forward loops between the different steps. Similarly, changes to the FID helped capture information as it came to light and the ramifications of new information was understood. The FID can also serve as an information source for the purposes of a VV&A agent. The agent can assess the appropriateness of algorithms and data sources for conducting the experiment and analysis. In the Trailblazer experience, the user also served as the VV&A agent. As such the user could direct modifications so that the federation would better serve the experiment. Compliance TestingAs Build 1 was in development, and federate compliance dates stipulated in the Kaminski memo were approaching, the federates considered different approaches to obtain High Level Architecture (HLA) Compliance Certificates. Since compliance certification is specific to a particular version of the HLA Specification and not a particular federation, the federates had two options for completing compliance testing. One option was to be tested as individual federates, the other option was to test the individual federates as part of the Trailblazer federation. The latter approach was chosen by the federate sponsors and developers for the following reasons: Dual purpose testing (federate compliance and federation integration testing) would save time, travel, and moneyExistence of other federates in a federation execution lessens or removes the requirement for federate stimulation using the test federate or other test harnesses Additionally, a new release of the RTI software was in beta testing and use of this software version by the federation would further the beta testing goals of the RTI development team and allow the compliance testers to debug their tools with the new RTI software. A potentially complicating factor was that the federation was using classified data, prohibiting conducting compliance testing over the internet. Discussions with the compliance testers revealed that they had encountered this situation before and had experience bringing their hardware and software tools into and out of classified computing facilities. Having resolved these issues, compliance testing was scheduled to occur during an integration event, using RTI 1.3 beta version 5 in the JWP facility while executing Trailblazer test runs.The Trailblazer Federation as described earlier consists of four federates: EADSIM, Eagle, NSS, and the FMT. Two federates, Eagle and NSS, had experience with the HLA Compliance Testing process as they had completed the procedure for version 1.0 of the HLA Specification. All four federates required compliance testing with the 1.3 version of the HLA Specification. Several difficulties were encountered and solved. The host computer for one federate was not functioning for some of the scheduled test time. This prohibited the use of the federation as stimulus for the individual federate being tested, testing the computer-less federate, and integration testing. Additionally, the beta release of the RTI software for the Irix platform was imminent but not yet available. A combination of test strategies were used: Both RTI 1.3 version 3 and beta version 5 were employed for testing two federates (the FMT and NSS)The FMT was tested using a subset of the federation, as well as using a test federate to provide stimulus for services not exercised by the Trailblazer federationNSS compliance testing was accomplished using a subset of the federation and a second instantiation of NSS to provide the required stimulusResolving the hardware problem permitted the creation of the beta release for Irix, and permitted the federate hosted on the Irix machine (EADSIM) to be tested and provide stimuli for Eagle. For two of the federates compliance testing occurred as a federation using RTI 1.3 beta version 5. Two lessons are offered for federates that are actively part of a federation and preparing for compliance testing:A federate’s SOM may include more or different objects and interactions than are exercised in the federation used for compliance testing. When this occurs, test mechanisms are needed to supplement the federation as the federate stimulus.Conformance Statements need to reflect only those services the federate is prepared to demonstrateHaving completed compliance testing as a federation the following observations about this method of compliance testing are offered: Errors in federate submissions necessitated manual changes to the test tool. This was time-consuming for all. The ability to receive new submissions and cause automated changes to the test tools on-site would speed the test process.When testing individual federates, errors in SOMs and Conformance Statements probably occur as well, but they occur in the privacy of the federate’s lab. When conducting compliance testing at a federation testing event, the risk of wasting a larger number of people’s time at a single event is greater. The practiced route of federate compliance testing is as an individual federate (not as a federation). Understandably, the tools are built to log the information for the specific federate being tested. As a federation (had we not had the hardware and other challenges), it would have been more efficient to log all the federates during a single execution rather than executing the federation for each federate. In summary, compliance testing at a federation event should be and was more efficient than individual federate testing for the Trailblazer federation. Even given the difficulties that the Trailblazer federation encountered, the testing of four federates occurred over the course of three mornings. The compliance testers were resourceful and accommodating. While hardware and software issues were worked, the testers were able to test the federates that could test independently. Additionally, the testers reviewed the test logs on-site to ensure that everything needed had been captured. Although a manual check, it was well worth the time. If compliance testing at a federation event is to be encouraged in the future, the following suggestions are offered: Involve the integration agent. The integration agent knows the FOM, and more importantly, the federate responsibilities relative to the FOM. Use the Federation Execution Planners Workbook (if available) as an input to the testing. The workbook contains federate publication and subscription information as well as the Conformance Statement information required for testing.Allow the federates to amplify the conformance statement if demonstrating additional capabilities is desired by the federate.Discuss where and when the additional capabilities should be tested. Although the integration event may be appealing, it may not be the only time available to test these capabilities. Provide feedback to the integration agent on the status and requirements of the federates. Time Management IssuesOne area of federation development that is not well codified revolves around time management issues. As the Trailblazer federation was created, certain aspects of time management were considered. For example, as the federation was being created for analysis purposes, it was desired that the federation run faster than real time and facilitate multiple, controlled iterations. This requirement moved simulation selection away from simulations that rely on a human in the loop or execute in real-time. Other issues that require further examination are discussed below. These issues are federation dependent. How does each federate manage time? Do these schemes allow the federates to exchange data in a way that is meaningful in the context of the federation? As an example, NSS is event-stepped and pre-computes the flight of an aircraft, scheduling internal events for interesting points along the flight path. In contrast, EADSIM is a time-stepped simulation and computes the current location of the aircraft each time-step. The application of these different time-flow mechanisms is a trade-off of efficiency and can reflect the nature of the systems being modeled. While the two may work efficiently by themselves, when they are mixed (as in this federation), the sum can introduce inefficiencies.A larger lookahead permits greater concurrency, but sacrifices accuracy of the information by increasing the interval by which a federate’s state changes are viewed. For each federate, what lookahead permits the most computation in parallel without compromising the validity of the model? If a federate is time-stepped, what is the time-step? Does this provide the accuracy required for analysis? What happens to model validity as the size of the time step is varied?When should object attributes be updated? Are they updated at some fixed interval or when an attribute value has changed by some threshold? To achieve maximum performance, an attribute should only be updated as often as required by other federates to maintain the fidelity of their model.Is there a performance improvement to be gained by having the federation employ dead-reckoning to reduce the number of updates generated at the cost of computational overhead for each of the federates? If dead-reckoning algorithms are implemented, all federates must implement the algorithms properly to avoid reducing the correctness of federation results.The Trailblazer federation has looked into some of these issues with respect to federation performance. Results from these endeavors are presented in another SIW paper. [4]SummaryThe Trailblazer Federation was created to gain experience with the High Level Architecture in general and specifically the use of distributed simulation in the domain of experimentation. The federation team has executed the FEDEP twice. In doing so, lessons have been learned about the FEDEP, compliance testing, and time management issues. The use of the Federation Implementation Document is offered as a vehicle for capturing user requirements and concepts, providing the user visibility into the models, and participation in design decisions. References“Department of Defense High Level Architecture Federation Development and Execution Process (FEDEP) Model”, Version 1.3, DRAFT, Dec 9 1998 Zabek, A, L Feinerman, D Seidel: “Joint Warfighting Program Information Superiority Experiment Trailblazer” Proceedings of the Fall 1998 Simulation Interoperability Workshop, paper 98F-SIW-228, Orlando FL, September 1998.“JV2010: Information Superiority Implementation and Assessment Plan (U)”, Joint Staff (J-6), 30 September 1997 (SECRET) Seidel, D, A Wilson: “Enhancing Performance in Analytic Federations”, MITRE Corporation, McLean VA, DRAFT, December 1998. Author BiographiesLAURA FEINERMAN is a lead Modeling and Simulation Systems Engineer in the Information Systems and Technology Division at The MITRE Corporation. She is currently working on the Trailblazer Project for DMSO. She has previously led and participated in subcommittees of the Interface Working Groups for the Joint Training Confederation, designed and developed training courses for the Aggregate Level Simulation Protocol users and participated at confederation events. She was project leader for the Japanese American Redress Verification Information System (JARVIS) at the SYSCON Corp. Ms. Feinerman has a B.A. in Economics and an M.S. in Applied Mathematics from the State University of New York at Stony Brook.DAVID PROCHNOW is a lead engineer in the Information Systems and Technology Division of the MITRE Corporation. He is currently the technical lead for the development of the Federation Management Tool (FMT) for the Joint Training Confederation, and he also works on the Trailblazer systems engineering team. Mr. Prochnow chairs the Logistics Form at the semi-annual Simulation Interoperability Workshop. Previously, he developed computer simulations for BDM International and Control Data Systems. He has a BS in Computer Science from the University of Virginia. DAVID W. SEIDEL is an associate manager for the Software and Information Architecture Technical Area in the Information Systems and Technology Division at the MITRE Corporation. For DMSO, Mr. Seidel supports the Joint Warfighting Program and the Cadre program, primarily working with the T&E community. Mr. Seidel has been active in the refinement of the Management Object Model, the Federation Execution Developer’s Workbook, and the Object Model Template. Previously, Mr. Seidel supported the JSIMS Program Office, the STOW program, and the ALSP project. He has developed Navy, Army, Air Force, and Joint wargames and Navy command and control systems. Mr. Seidel has a BS from Illinois Institute of Technology and an MBA from Bryant College.JOHN A. TUFAROLO is a lead Simulation Systems Engineer for the MITRE Corporation in Reston, Virginia, where he is currently involved in High Level Architecture (HLA) testing and HLA federation development activities. He has over 12 years experience in modeling and simulation, supporting development, testing, and application of military training and analysis simulations. Mr. Tufarolo is the Information Director for the Association of Computing Machinery (ACM) Special Interest Group on Simulation (SIGSIM), and a member of the ACM, IEEE CS, and SIGSIM.  His professional interests include discrete event simulation, simulation systems development, and military modeling and simulation. Mr. Tufarolo has a B.S. in Electrical Engineering from Drexel University and an M.S. in Systems Engineering from George Mason University.ANNETTE L. WILSON is a lead Modeling and Simulation Engineer in the Information Systems and Technology Division at the MITRE Corporation. She is currently project leader for the RTI Verifier, is a member of the RTI 1.3 development team, and supports the CADRE program by providing RTI expertise for the participating federations. Ms. Wilson was also one of the developers of the ALSP Infrastructure Software (AIS) and chaired the AIS Subgroup of the ALSP Interface Working Group (IWG). Previously, Ms. Wilson worked as a systems analyst supporting the TACWAR model for J-8. Ms. Wilson has a B.S. in Computer Science from Texas A&M University and is currently pursuing an M.S. in Computer Science at George Mason University.ANITA ADAMS ZABEK is a Program Area Manager in the Information Systems and Technology Division at The MITRE Corporation. She is the task leader for the Joint Warfighting Program Trailblazer Project for DMSO. She has previously supported the JSIMS Program Office and was the task leader for MITRE systems engineering support for the ALSP-based Joint Training Confederation. She was project leader for Corps Battle Simulation ALSP integration at the Jet Propulsion Laboratory and has been an Operations Research analyst at the Institute For Defense Analyses. Ms Zabek has a B.S. and an M.E. in Systems Engineering from the University of Virginia.  The J-6 is the Command, Control, Communications, Computers, and Intelligence Directorate of the Joint Staff.  EADSIM is owned by USA Space and Missile Defense Command but ESC has an arrangement with SMDC for use and modification of EADSIM in their Modeling and Analysis Simulation Center (MASC)  On 10 September 1996, Paul G. Kaminski, then Secretary of Defense, promulgated a memorandum designating the High Level Architecture as the standard technical architecture for all DOD simulations. This memo identified a date for demonstrating intent to achieve HLA compliance.Step 1:  The federation sponsor and development team define and agree on objectives, and document what must be accomplished to achieve objectives.Step 2:  A representation of the real world domain of interest is developed, and described in terms of required objects and interactions.Step 3:  Federation participants are determined (if not previously identified), and a FOM is developed to explicitly document information exchange requirements and responsibilities.Step 4:  All necessary federation implementation activities are performed, and testing is conducted.Step 5:  The federation is executed, outputs analyzed, and feedback provided to the federation sponsor. Federation Implementation DocumentEvent:  Task Strike AssetObjects	Outputs	JAOC		Tasking	Air Assets	MOE	Ground Assets		Time to weapon release	Sea Assets		Time to weapon impactActivities	Factors	Task C2 Aircraft		Geography	Task CTOC		Weapon range	Task NSW Cdr	AlgorithmsInputs		Pseudocode	Intel		Data Requirements			Data Sources