Web-based Distributed Simulation using HyperActive( and Nimble(Joshua E. SmithKaon Interactive Company, LLC125 Cambridgepark DriveCambridge, MA(617) 876-KAON  (corporate)(978) 355-6148  (direct)jesmith@kaon.comKeywords: Non-HLA; WWW; Distributed Simulation; Entertainment; Programming Languages; SEDRIS; FOMKaon Interactive has developed technology that allows the embedding of 3D multi-user audio-visual applications (simulations, virtual worlds, games, etc.) into web pages.  The technology is deployed as a free browser plugin called HyperActive(.  The applications are defined in an XML-conformant object language called Nimble(.  The Nimble language allows definition of virtual environments (as would be described by SEDRIS), interoperability protocols (as would be described in a FOM), and the simulation rules and behavior all in a common environment.  In this way, a Nimble program is similar to a "Scenario" used by classical constructive simulations.  The Nimble language and its underlying object model encapsulate the fundamental techniques used in Distributed Simulation, analogous to the HLA's RTI.  Although this technology is primarily aimed at the deployment of lightweight, homogeneous, client-server applications, the differences between this technology and that of the HLA are instructive.  Further, there may be uses for this technology in ancillary applications like data analysis, after action review, FOM and SEDRIS repositories, and scenario development.Note: All acronyms used in this paper are explained in a section at the end.Architectural OverviewAlthough the infrastructure of the global Internet creates the illusion of a shared experience, the reality of the “Web Page” model is that everyone is left exploring cyberspace alone.  The irony of this situation should be particularly clear to the defense simulation community, which has been using internetworking protocols to create shared virtual experiences for years. The primary obstacle preventing the application of distributed simulation technologies in the web space is the dominance of the web browser as the Internet platform.  While the game industry has managed to exploit the Internet infrastructure for deploying multi-player environments, it has not managed to do this within the context of the web browser platform.  Thus, “Internet games” and similar multi-user applications have been completely separate from “the Web.”1.1	The HyperActive PluginThe HyperActive browser plugin was created to allow the deployment of distributed simulation techniques in the context of the web browser platform, opening up the world of this technology to the mass Internet audience.  The plugin has three major components:A high performance multimedia rendering engine, which can display compelling 2D and 3D graphics, and 3D spatialized sound in a web browser.  This is similar to the role filled by a VRML plugin, although HyperActive’s performance is much better, and its data formats are far smaller and more flexible.An interpreter which reads programs written in the XML-conformant language Nimble.  The language reflects an object model that encapsulates all the primary technologies of distributed simulation (synthetic environments described by scene graphs, dead reckoning, simple physics models, etc.), as well as the enabling technologies of the web (data compression, data streaming, standard image formats, etc.).A “glue” layer which binds the interpreter to the services provided by the browser platform, including HTTP data retrieval, caching, integration with the Java virtual machine, and the ECMAScript (JavaScript) programming environment.The plugin is deployed in two forms: as a Netscape Navigator Plugin, and as an ActiveX Control for Internet Explorer, both for the Win32 platform (Windows 95, 98, NT).  It relies on enabling technologies in the operating system, such as DirectX (to access 3D video and audio hardware and to perform emulation when none is available), and ACM (to access the TrueSpeech( CODEC for streaming user-to-user audio).Deployment on other operating system platforms in the future will probably also be tied to native capabilities of those operating systems.  Sun Microsystems has recently introduced the Java 3D API which is a 3D rendering engine accessible directly from Java (unlike the Java VM, this is not widely available in web browsers).  Eventually we may port the Nimble interpreter to Java, and rely on this API may provide a run-anywhere solution.  However, the Java VM is just too slow for this application on today’s computer hardware.1.2	The HyperServerThere are two reasons to use client/server system architectures in the Internet space:Multicast doesn’t work yetSometimes you just need a serverThe former reason is something the defense simulation community has been able to ignore because infrastructures like the Defense Simulation Internet (DSI) have been designed from the ground up to support multicast (each exercise took place in a separate multicast space).  While the public Internet uses the same protocols as the DSI and could provide multicast capabilities using those protocols (IGMP, RSVP, IPv6), nobody has yet figured out economic models in which it makes sense for ISPs to actually turn those capabilities on.  As it stands, you have to “bounce” messages off a server to emulate multicast, and the owners of those servers pay for the high bandwidth of the redundant outgoing data streams.  If, instead, individual “surfers” could multicast, an individual could produce huge bandwidth demands, and her ISP would have to pay.  For this reason alone, client/server will have to be the dominant model until bandwidth is nearly free.The other reason to use servers is more nebulous.  There are many cases in the defense simulation community (dynamic terrain [DT], semi-automated forces [SAF], etc.) where servers have been used to provide dynamic parts of the “environment” in which the simulation takes place.  Although, architecturally, the defense simulation community usually treats these components as just another heterogeneous peer, recognizing their role as a server allows certain architectural efficiencies to be achieved.  In particular, the role of “packet bouncer” explained above could be performed by the same component providing this environmental simulation.In our prototyping experiments, we have thus far been able to avoid the use of very smart servers.  We have mostly just used an “EchoServer” which echoes messages to each connected client (emulating multicast).  However, just as DARPA’s SIMNET system evolved from being a suite of manned modules with server entities (DT, SAF) playing a minor role, into a system where the focus of the simulation was the DT and SAF, it is likely that the HyperServer component will become more critical as well.  As the server demands grow, so will the need to add functionality to servers in a modular fashion.  Our plan is to allow the Nimble language to be used to program the behavior of server entities, just as it is used to program the behavior of client entities in the plugin context.  The benefits of this approach will become clear later when we discuss our Distributed Simulation Design Pattern.1.3	The WebThe final architectural component of a HyperActive system deployment is the web itself (the browser, HTTP servers, and other web infrastructure components).  The web provides the context in which the HyperActive applications are experienced by the user, and standard web elements provide the means to get the media content from the provider to the user.  Further, the web can act as a part of the user interface.  For example, a whiteboard conferencing application we wrote in Nimble used HTML radio buttons to select pen color.  While user interface elements like checkboxes can certainly be implemented using Nimble’s 2D graphics classes (and should be in a “game” context where the checkbox represents a physical “thing” like an eject button), putting those controls on the web page can be more intuitive in some cases.Similarly, a virtual world application might provide “hot links” which can be touched in three-space, and trigger information display in another web page frame, or in a popup browser.  Leveraging the existing web, with all its tools and techniques just makes sense in these cases.Finally, the web provides access to a full-functioning system programming environment, in the Java Virtual Machine embedded in most browsers.  Allowing a seamless interface between this programming environment and the Nimble interpreter provides unlimited extensibility without cluttering the Nimble language with system programming constructs.The Nimble LanguageThe objects in a HyperActive application program are selected from a fixed object model with over 60 classes.  These classes range from “Frustrum” which defines the viewer’s field of view, near clipping plane, etc; to “Ballistics” which is a basic physics model useful for basketballs, pool balls, and cannonballs.  Nimble is a declarative programming language used to specify what objects should exist in an application, what classes those objects are drawn from, and what values to use for attributes of those objects.2.1	Nimble is XMLNimble conforms to the W3C’s XML specification [1].  There exists a Document Type Definition (DTD) for the Nimble language, and every Nimble program can be represented as a “valid” XML document according to this DTD.  The advantage of using XML syntax for this language is that it allows the use of dozens of XML tools to edit, validate, and analyze Nimble programs.  For example, the following is a section of the Nimble DTD that defines the Message class: <!ELEMENT Message ( P* )><!ATTLIST Message  name ID #IMPLIED ><!ELEMENT P ( #PCDATA )><!ATTLIST P  a NMTOKEN #REQUIRED>Each Message contains zero or more attribute/value Pairs (the “P” element).  The Message can have a name, which must conform to the XML “ID” production.  Each Pair identifies an attribute (“a”) and gives a value as character data.  For example:<Message name="turn_and_stop">  <P a="turn">90</P>  <P a="speed">0</P></Message>Sometime within the next year, the W3C should produce a specification for XML-Schema, which will eventually replace the use of the DTD (it will allow specification of attribute data types, for example, which is not possible in a DTD).  As soon as this draft is finalized, the Nimble DTD will be recast as an XML-Schema definition to allow continued interoperability with the evolving XML tools marketplace.2.2	Nimble is not JavaNimble programs look nothing like programs written in Java, C, Basic, or Fortran.  There are no functions, no “if-then” statements, no “for” or “while” loops.  Instead, objects that respond to events and “watch” for messages control program flow.  Iteration (which is almost never needed in a Nimble program) can be achieved using something like Scheme’s tail recursion.The following example shows a portion of a Nimble program which implements a shared “laser pointer” (all visitors to a web page see the same object, and each person can click on different parts of that object to “point” at things).<!-- Laser pointer--><Stamp3D name="spot" smooth="0.2" emissive="1.0" xlow="-0.5" xhigh="0.5" ylow="-0.5" yhigh="0.5" width="0.2" height="0.2" blend="true" facing="VIEWER" show="false" zbuffer="false" >   <Image url="spot.jpg" /></Stamp3D><Color name="red" red="255" /><Color name="dark" blue="51" /><Object3D name="pointer" x="-1.5" y="2.5" z="2.0" facing="spot" >   <Mesh url='pointer_4_0.msh'>	  <Material diffuse="dark" />	  <Material emissive="red" />   </Mesh></Object3D><Event event="Pick" echo="echo" >   <Adapter target="spot" >      <Msg a="show">true</Msg>   </Adapter></Event>First, there is a Stamp3D (a 2D image projected into three-space; like the trees in most military simulations) named “spot” which moves smoothly (parameterized by the ( of the familiar stepwise exponential smoothing algorithm xt = (1-()x' + (xt-1 , generalized to variable frame rates).  The stamp emits light, is centered around its location in three-space, blends its color with the object behind it, faces the viewer, starts off not showing, and does not test the z-buffer (several other attributes are using default values, and thus are not listed).  The stamp uses an image found at the relative URL “spot.jpg”.Next a couple of colors are defined, and an object is placed in the scene.  The object is told to always face the object “spot” so that it will appear the spot is coming from the object.  The object includes a polygon mesh, which uses two materials (one for the dark blue body of the pointer, and another for the red tip).An event handler is defined to catch “Pick” events (generated when the user clicks on an object in three-space), and adapts the message by appending “show=true” to it.  The Pick message already contains the coordinates of the pick location (among other things). The adapter targets this composite message to go to the stamp “spot” which will start showing and move smoothly to the coordinates of the pick.  The pointer object will remain oriented toward the spot.  The pick message is sent to an EchoServer (not shown) named “echo” which reflects the message to all the other users at the web site, so they, too, see the spot move to the new location.  (Specifically, the message goes to an Adapter object in each client, which performs the append function and sends the message on to that client’s local version of the “spot” object.)Distributed Simulation Design PatternThe above example demonstrates one variation on the Distributed Simulation Design Pattern used in HyperActive programs.  This Design Pattern [2] comes into play in any case where the same object will be represented simultaneously in several different client applications.  Familiar cases include shared virtual whiteboards in conferencing applications, shared objects in a 3D virtual world application (for example, tanks on a virtual battlefield), and the game pieces on a shared virtual chessboard in a multi-player game application.In each of these cases, there is one notional object, and an arbitrary number of proxies, which represent that object.  The Design Pattern addresses the problem of how to ensure that every proxy accurately reflects the actual state of the object without using unreasonable amounts of network bandwidth.3.1	The Static ObjectThe simplest case is the one where the object does not change.  These objects are usually considered part of “the environment” and their characteristics are duplicated in every client.  In most military simulations, the sky is one of these objects.  In many, so are the trees, soil, water, and even the buildings.In HyperActive, these objects would be instanced directly through declaration in the Nimble program.  Since each user is guaranteed to have the same program, each copy of the object is guaranteed to have the same state.  (In cases like fractal terrain or vegetation generation, the random number seeds are specified explicitly in the Nimble program to ensure consistency.)Formally, each client is showing a proxy of the object, which is not really “simulated” anywhere, and thus doesn’t “exist” in the usual sense.3.2	The Deterministically Dynamic ObjectA simple extension of the Static Object is one where the changes that occur in that object are deterministic (for example, a rotating radar antenna).  Often, the exact state of these objects is not terribly important (we might not care that everyone sees the antenna pointing north at the same time, for example), but sometimes it is.  When it is important, we need a way to ensure that the object’s state remains reasonably synchronized.One way to do this is to establish a single client as the authoritative source of that object’s state (classically, the object would therefore “exist” in that client).  Another method is to let any client issue updates to that object’s state (in which case, the object has a nebulous simulation locus).  In either case, all clients must have an internal representation of the behavior of the object, to fill in the gaps between authoritative state updates.  In most distributed simulations, this representation is not the actual behavior of the object.  Rather, it approximates that behavior (using a technique called “Dead Reckoning” in which low-order derivatives predict future motion).  Because of this, the issuer of the state messages must be concerned with deviation between the actual state of the object, and the expected evolution of this simpler model (using an algorithm called “DR Thresholding”).  In particular, this makes it almost mandatory that a single client be the authoritative source of the object’s state (otherwise, any previous modifier of the object would be prone to issue redundant or conflicting updates ad infinitum).Our Design Pattern is fundamentally different in this regard.  Instead of using an approximation of the object’s behavior algorithms, we use the actual behavior algorithms to extrapolate the behavior of the object.  This is possible because every client, by definition, has a copy of the entire Nimble program available to it.  (HyperActive applications are “homogeneous simulations.”)  While deviations between the authoritative source and the proxies can still happen, they would only occur due to the introduction of external factors.  Thus, updates need only be sent when one of these external factors is introduced.Thus, by using this Design Pattern, we eliminate the need to do Dead Reckoning at all (in the traditional sense).  In addition, obviously, we needn’t do any DR Thresholding.The “laser pointer” sample given above is a very simple example of this variation of our Distributed Simulation Design Pattern.  In that case, the external factor is the “Pick” event, and any client can generate the resulting control input.  Naturally, the client on the computer where the pick happened will generate these inputs and send them along to all the other clients via the EchoServer.  The behavior of the stamp (the exponential smoothing algorithm) is known to, and executed by, every client.  The behavior of the pointer object (facing the stamp) is similarly known and executed.Where are these objects being “simulated?”  Everywhere?  Nowhere?  It really doesn’t matter.  All the proxies will accurately reflect the state of the object, although the object isn’t really being simulated at all, in the usual sense (there is no defined “owner” of the object – no defined “locus of simulation”).  Put another way, the “Dead Reckoning” algorithms being used are so accurate, no simulation is needed.Another example is a tank driving across the terrain.  In the Nimble program, a Kinematics object (behavior), and a hierarchy of Object3D objects (appearance) represent the tank.  The driver of that tank sends the kinematics object a message specifying direction and throttle settings, and the kinematics object applies internal and external constraints to produce motion over time.  Every client has a copy of the tank’s exact kinematics model, and can thus produce exactly the same behavior. (The kinematics model automatically modifies every control message to include initial conditions prior to the message being sent to an EchoServer, to avoid “butterfly effects.”)†Notice how this example used a highly dynamic, user-controlled vehicle as an application of the “Deterministically Dynamic Object” variation of the Design Pattern.  This is because all simulations are, at their roots, deterministic (or they should be, at any rate).  By synchronizing the deterministic behavioral simulations, and exactly replicating all the derived behaviors, complex behavior will remain synchronized as well.  There are always oddball cases, of course (two near-simultaneous collisions, for example, where each client might determine a different order of events), but an occasional synchronization message and a little exponential smoothing can do wonders to paper over those faults.Other examples of this Design Pattern variation previously used in military simulations include animated explosions, moving limbs on simulated humans, and spinning helicopter blades.  However, in each case, the object being “co-simulated” was ultimately “owned” by a single client, so the pattern was not exactly followed.3.3	The Ownship/Othership DichotomyIn the tank example, above, every client has a Kinematics object representing that tank, and every version of that Kinematics object would have the same name. For one client, this tank is “ownship” (the camera follows the kinematics), while for the rest of the clients, this tank is an “othership” (an Object3D in the scene follows the kinematics).  The Nimble program might read:<Class name="OwnTank" stuff omitted… >   <Kinematics name="OwnTank.kin"    max_accel="2.0" min_accel="-20.0"    max_speed="60.0" min_speed="-40.0"    max_turn="120.0" min_turn="-120.0"    gears="4" />   <Ownship kinematics="OwnTank.kin" … />   …</Class><Class name="OtherTank" stuff omitted >   <Kinematics name="OtherTank.kin"    max_accel="2.0" min_accel="-20.0"    max_speed="60.0" min_speed="-40.0"    max_turn="120.0" min_turn="-120.0"    gears="4" />   <Othership kinematics="OtherTank.kin"    model="OtherTank.obj" />   <Object3D name="OtherTank.obj" …   …</Class>A client joining the simulation would instance an OwnTank with a globally unique name (say, “Bob”) and tell every other client (by sending messages directly to their language interpreter, which is an object named “System”) to instance an OtherTank with that same name.  User inputs would go to “Bob.kin” which would influence ownship locally, and an othership on other clients.  This is how a completely homogeneous client environment allows mixing heterogeneous objects (every player is, after all, in a different tank).3.4	Implications of the Design PatternOur Distributed Simulation Design Pattern has some significant benefits.  Foremost among these is the reduction of communication bandwidth.  Almost all the messaging in traditional simulations is concerned with fixing deviations between actual behavior models, and the low-order dead-reckoning models being used by peer simulators.  In one dramatic example of this dating back nearly a decade now, about half of the bandwidth in a SIMNET exercise was found to be due to SAF tanks slewing their turrets back and forth.  By putting a copy of the slewing behavior model into every receiver, just about all of this messaging would be eliminated.  (One of the early Synthetic Theater of War demonstrations included something close to this technique.)Another benefit of the elimination of the quirky Dead Reckoning / DR Thresholding algorithms from the system has to do with software engineering.  Many times in the past, teams have attempted to create reusable distributed simulation “APIs” to encapsulate the complexity of the technology.  The most recent attempt is the HLA RTI.  In every case, the ugly fact that the dead reckoning algorithms are actually just not-very-good behavior models muddied the APIs with unclear division of labor.  It would seem natural for the stuff under the API to do Dead Reckoning and DR Thresholding†, but since these are really behavior algorithms, that implies a mother-of-all-simulations under the hood of the networking API.  In some cases, just selected DR (like the DR of entity motion) was put into the network API, and other DR (like turret slewing) was left to the application.  Another approach was to use Object Frameworks to make the idea of DR a network API responsibility, but leave the implementation to the applications.In the case of Nimble, the interpreter (which is serving as the networking API) just sends messages to objects elsewhere on the network.  Since there are no behavior algorithms disguised as network protocols, the division of labor is straightforward.  As new behaviors are added to higher software layers, there is no need to change the communications infrastructure to accommodate dead reckoning those behaviors.Defense ApplicationsThe HyperActive system architecture has little in common with the Department of Defense High Level Architecture.  In particular, it uses a different design pattern for distributed simulation:Any client may change any object, without regard for issues of “ownership.”  In most applications, such as the laser pointer example, explicitly managing ownership is a real trauma, which gives no added value.  All the complexity of the Persistent Object protocol in ModSAF, for example, was attributable to the problem of hiding ownership management under the API.  The cases where ownership must be managed tend to be driven more by application design issues (for example, only the driver of a vehicle should be giving control inputs to that vehicle).  High-level application specific protocols should be used for this kind of management.  The fact that the architecture allows any client to give control inputs is not a problem if they are not using that capability.Every client is presumed to have the capability of duplicating the simulation performed on any other client.No provision has been made for client-side interest declaration (instead, this kind of scalability would be achieved through smarter servers, directing messages only where they are needed).As such, using HyperActive for defense simulation would be taboo under current military policy that mandates the use of HLA.  However, there are certainly related areas where the technology could be applicable.The following is a list of “good ideas” we’ve come up with for the use of the technology in the defense domain.4.1	Repository BrowsingOne of the essential facets of defense simulation policy is to encourage the reuse of simulation components (SEDRIS environments, FOMs, combat models, etc.).  It has already been recognized that the web provides an excellent means to provide indexes and catalogues of these repositories as they are built.  HyperActive could be a useful tool for presenting these indexes and catalogues.The most obvious example is SEDRIS.  Imagine a virtual world in which each object in a SEDRIS transmittal is represented by a floating cube, with a label and connections to other cubes.  If that cube represented a fractional scene graph (for example, a visual model of a combat vehicle), touching the cube could retrieve a Nimble representation of that object and display it in another browser frame.  Converting a SEDRIS database into one of these applications could be a completely automated process (and would be a far easier thing to do than to convert the world to a similar VRML representation).  With such a tool, an exercise designer could use her existing web browser to examine the available environments and determine suitability to task for each.Another target of opportunity would be the combat models produced by military battle labs.  Many of these models are accompanied by reams of technical documentation explaining their methodologies.  Interactive animations demonstrating the basic operation of these models could be tremendously useful to engineers selecting models for use.4.2	Architectural PrototypingOur experience with the Nimble language is that you can create surprisingly rich distributed simulation systems with very small quantities of code.  Thus, it might be suitable for use as a system architecture prototyping language.  While there are many languages which are suitable for building system mockups and simulating information flow, there is a distinct advantage in using one where your program manager can go to a web page and “be” one of the elements of the system.Each federate in an HLA federation, for example, could be “played” by a visitor to the web site.  Rather than investing heavily in building a simulation of the behavior of each federate, the “player” would perform actions in keeping with the expected behavior of that federate.  This is analogous to the Semi-Automated Forces paradigm, in which humans play an active role in the simulation to compensate for insufficiently “smart” models.4.3	Scenario PrototypingA considerable amount of effort goes into the planning of scenarios to be executed by HLA federations.  Typically, a weeklong exercise is preceded by a year of planning.  Much of this planning involves “gaming” out the ways that the scenario might evolve.  HyperActive could be used to create the “virtual sand table” on which this gaming takes place.  Particularly for joint exercises, the ability of planners to do this “gaming” from their home bases, using the web infrastructure they already own, could be a significant cost saver.4.4	After Action ReviewAfter action review is one of the most important parts of many man-in-the-loop simulation exercises.  Often, this review takes the form of a hurried “highlights video” at the end of the day to a battalion of exhausted troops.  One reason for this is that there is no equipment available to provide these troops with visual feedback outside the training facility.  If the after action review material were instead turned into a HyperActive application, the troops and their commanders could spend more time and effort on the learning process from the privacy of their own web browsers, after they have left the expensive training facility.Similarly, HyperActive could be used to present important analytic simulation results to program managers at their desks (or homes), using the browsers they already have.4.5	ObservationAlthough it would certainly be a nontrivial task, an HLA federate could be built to act as both an exercise observer and a HyperServer.  Such a device would allow viewers outside the exercise facility to view ongoing exercises from a web page.  In principle, full 3D audio-visual renderings should be possible (although the lack of insight into the behavior models of other federates would require falling back to SIMNET’s “Dead Reckoning” Design Pattern, with it’s concomitant high bandwidth requirements).HyperActive CapabilitiesThe rendering engine encapsulated in the HyperActive plugin is the next generation of the engine used in Kaon’s game, “Terra: Battle for the Outland.”  Thus, all the crucial game features are present.  In addition, we have added many features that seem useful in non-game settings.5.1	Current CapabilitiesThe following is a non-exhaustive list of things the engine knows how to do:3D scene rendering using hardware acceleration, when available, and software emulation when necessary.  This is a game engine, designed to do high-quality rendering at high frame rates.Fog, linear texture filtering, ambient light, direct light, and dynamic point lights.Lens flare, sky, water, and terrain surface effects.Stamps (also called Decals, these are 2D images which face the viewer) which can remain vertical on the screen, vertical in the world, be manifold surface-clamped, or be aligned with an object frame.  The stamps may display a fixed image, multi-image animation, or select an image based upon the direction the stamp is moving relative to the viewer (“South Park” animation).Alpha blending (for effects like dust), color blending (for effects like fire or smoke).3D scene graphs (object frame attachment hierarchies).  Each object in the graph can be controlled by fixed first order derivatives in position and angle, by ballistics or kinematics controllers, or though key frame animation.  Per-object exponential smoothing may be enabled anywhere in the hierarchy.Key frame animation of any object, including 3D objects, stamps, or the viewport (for “tour” animations).Optional fractal terrain surface generation (with infinitely variable seeds, or explicit seed patterns), and randomized clutter generation (for vegetation, rocks, etc.).  The clutter is dynamic – trees can be knocked down, for example.  Generating terrain and vegetation algorithmically allows significant development cost savings and eliminates huge downloads which would not be tolerable in the Internet space.Infinite worlds and wrapping worlds.Elevation support provided by either a fractal terrain surface, or an arbitrary polygon mesh.  The mesh needn’t be a two-manifold (multiple elevation structures are fully supported).Collision detection and guaranteed object separation based on spheres, planes, and arbitrary polygon meshes.  A small amount of preprocessing is done on the meshes to allow this collision detection to be a very low overhead operation.Fully parameterized second-order kinematics model suitable for emulating vehicle and human motion.  The model supports gravity, collision behavior like pushing, elastic collisions, and velocity and spin components resulting from collisions.  All these effects are parametrically controlled.Ballistic model with capabilities similar to the kinematics model.Scene export from Kinetix 3D Studio Max(, and conversion of various file formats.Ambient sound, directional sound using pan and fade heuristics, and full Head Relative Transfer Function (HRTF) 3D spatialized audio (accelerated by 3D audio hardware, when available) capable of driving 5 channel speaker systems.  Volume and pitch can also be adjusted on the fly.Streaming user-to-user speech.  Streaming compressed user-to-user graphic primitives drawn on overlays (for shared whiteboards, for example).JPG, BMP, and PNG image formats, 3 bit CCITT ADPCM audio, and a lean 3D polygon mesh format which allows arbitrary bit-resolutions (for example, 9 bits of accuracy in XYZ and 3 bits of accuracy in UV).2D game interface paradigm that allows construction of dynamic interfaces using user graphics, rather than built-in checkboxes and the like.  Primitives include Toggles (select between two images), Sliders (blend two images), Overlays (fold different images onto a background), Maps (represent selected 3D objects with symbols in a 2D map), Card decks, Text and Counters.Partially transparent overlays floating over the 3D scene (for heads up displays, custom cursors, etc.) containing images or text.Prompts, passwords, control of browser status line, and full two-way integration with ECMAScript (JavaScript) on the web pages hosting the plugin in both Netscape and Explorer.  This include the ability for the plugin to invoke arbitrary script functions on the page, for script functions to send messages into the plugin, for the plugin to target frames to different URLs, and for the plugin to transition from one program to another.Keyboard and mouse event handling.User-defined classes supporting inheritance (including DAG resolution)†, delegation, containership, polymorphism, the “Singleton” design pattern, and globally unique name generation.  Classes for containers, selection, and other object management.  Classes for event handling, message manipulation, and basic math operators.5.2	Planned CapabilitiesAt the time of this writing, the following capabilities are planned for the plugin.  Some of these may be done by the time this paper is presented, and other ideas will doubtless have come up.Programmable HyperServerThe idea is to define the objects to be executed by the server in the Nimble program along with all the client objects.  The server would be a “special peer” in the simulation, which gets its program when the first client using that program connects. This simplifies writing simulations where authoritative state must be maintained in a single computer (for example, on-line polls, multi-player game lobbies, or multi-user simulations with lots of autonomous actors).A single HyperServer is able to support many simultaneous client worlds, and this capability will be maintained in the programmable servers.High Performance Java VM ConnectionCurrently, JavaScript can be used to connect an arbitrary Java application to the running HyperActive plugin.  This allows a program to be written in Java, and use HyperActive as a very smart rendering engine (the role Java3D may someday fill).  However, the connection through JavaScript is clumsy at best, and certainly inefficient.  We will define a suitable high-bandwidth channel to allow full control of the plugin from Java, including frame synchronization and master/slave operation of the rendering loop.  We haven’t found a way of using the Java Native Interface (JNI) to make the connection through API calls, which is portable across browsers (this “just works” in Netscape, and “just doesn’t” in Explorer).  Meanwhile, we are exploring other options like using peer socket connections hidden under lean Java interface classes.Port to Other PlatformsOur first port will certainly be to the Mac.  After that, we will explore porting to a run-anywhere Java/Java3D implementation, and native ports of a subset of the interpreter to emerging “Internet Appliances.”Vertex Animation and MorphingVertex animation and morphing are poorly supported in DirectX, so enabling them in HyperActive will be a challenge.  However, we expect that they will be required for some cutting-edge entertainment applications, so we’ll find a way to make them work.Plugin PluginsEach native class in the Nimble language is part of the HyperActive plugin (which is less than ½ Meg to download).  It would be nice to be able to add “Native” classes to the language by defining a signed Java applet, and including it on the same page as the plugin.  This would certainly require JNI integration, so finding a portable way to support it will be difficult.Tools, Tools, ToolsExporters, converters, and plugins for development environments like 3D Studio Max, and Macromedia Director( will be developed as required.  Converting from SEDRIS and VRML 97 are two high-value, high-difficulty converters we anticipate writing.ConclusionHyperActive and Nimble are enabling technologies, which bring the power of Distributed Simulation into the world of the Web.  They use a Distributed Simulation Design Pattern that differs significantly from that typically used in military simulations.  As such, they may be instructive to future military simulation architects.  Presently, the technologies may be useful in a wide range of ancillary applications related to, but not part of, military simulations.AcronymsACM	Audio Compression Manager.  This is a Windows API for accessing audio CODECs.ActiveX	ActiveX is a version of Microsoft’s Common Object Model (COM) API, which allows software modules to be easily distributed over the Internet.  ActiveX is the technology that is used to add Plugin functionality to Microsoft Internet Explorer.API	Application Programming Interface.  A standardized set of function calls (or object methods) used to access a set of insulated functionality.BMP	A simple image format commonly used in the Windows programming environment.ADPCM	Adaptive Differential Pulse Coded Modulation.  This is a standard way to compress digital audio.  The CCITT standard encoding used by HyperActive is used in many digital cell phones.CODEC	Coder/Decoder.  This is the generic name for software that compresses and decompresses audio or video data.DARPA	Defense Advanced Research Projects Agency (the “D” is sometimes silent, depending on the latest polls).  This is the arm of the Defense Department which pays for the really cool stuff.DirectX	An API provided by Windows to facilitate writing video games.  It serves the same functions as OpenGL and Intel’s RSX 3D.  It is used in HyperActive for 3D graphics and sound.DR	Dead Reckoning.  Although this literally refers to using first-order derivatives to predict the position of a moving entity, the term is used loosely to refer to any predictive algorithm.  A more general term for the same thing is “Predictive Contracts.”DT	Dynamic Terrain.  Modeling changes to soil and structures due to external influences such as explosives or combat engineering.  Often other dynamic modeling of the environment, such as weather, is lumped into this term as well.DTD	Document Type Definition.  A formal specification defining the tags used in a given XML document, the attributes to be used with those tags, and rules about what tags may appear “inside” other tags.ECMAScript	This is the international standard version of the programming language JavaScript.FOM	Federated Object Model.  This is a formal specification of the classes of objects that appear in a simulation and the ways those objects are allowed to interact.HLA	High Level Architecture.  The US government mandated way that military simulations are to be built.HTML	Hypertext Markup Language.  The document format used by web browsers.HTTP	Hypertext Transfer Protocol.  The protocol (layer atop TCP/IP) used to transfer data between web servers and web browsers.JavaScriptA programming language developed by Netscape, which is often used on web pages to provide limited interactivity.  The easiest way to provide interactions between the web page content and a plugin is by using JavaScript.JNI	Java Native Interface.  This is the method by which a Java program is extended to make calls to functions written in other languages.JPG	This is a “lossy” image format which works very well for photographs, and is generally acceptable for storing textures used in 3D graphics.  The current standard uses discrete cosine transforms (DCT) to convert the colors in an image to the frequency domain where they can be filtered to improve compression.  The next version of the standard will use wavelet compression.Plugin	(Sometimes Plug-in or Plug In) This is a general term for a software module written by a third party, which extends the functionality of a major software product.PNG	This is an open standard (free of patent problems) image compression format similar to GIF.  It does not compress quite as well as GIF, or support animation, but it does support true color images, and images with small palettes (features GIF lacks).SAF	Semi-Automated Forces (also CGF, Computer Generated Forces).  This is a general term for agents in a virtual environment, which take high-level direction from a human operator, and perform rote functions autonomously.SEDRIS	Synthetic Environment Data Representation Interchange Specification.  This is a standard for exchanging large data sets of terrain, atmospheric, and cultural entities for use in virtual worlds.  Unlike visual-only formats like VRML, it supports the exchange of topological information useful for SAF and high level combat planning applications.SIMNET	This was the first major distributed simulation program, which provided the technological base for the HLA.VM	Virtual Machine.  The interpreter built into most web browsers which allows them to run software written in Java and compiled to a platform-neutral “P-code.”VRML	This is a standard exchange format for scene graphs (visual parts of virtual worlds).  The format is quite inefficient, and has support for so many advanced rendering features that the plugins that support it are huge and tend not to perform very well in the absence of high performance 3D rendering hardware.W3C	World Wide Web Consortium.  This is a pay-to-play industry consortium, which defines the data formats used by web browsers and related Internet applications.XML	Extensible Markup Language.  This is a language similar to HTML, except that it allows the use of arbitrary tags, instead of predefined ones.  It is rapidly becoming the standard interchange mechanism for business-to-business communications over the Internet, and will eventually replace HTML as the language of the web.References[1]	I. Graham, L. Quinn: XML Specification Guide, Wiley Computer Publishing, New York, 1999.[2]	E. Gamma, R. Helm, R. Johnson, J. Vlissides: Design Patterns, Addison-Wesley, Reading, MA, 1994.Author BiographyJOSHUA E. SMITH is Chief Technologist for Kaon Interactive Company, LLC, where he directs development of “Terra: Battle for the Outland,” HyperActive, and other projects.  He was the software architect of ModSAF, and authored enabling technologies including libCTDB, libPO, libPDUAPI, libReader, and a few hundred other “libs.”  He was recently granted patent number 5,899,810 for an unusual Distributed Simulation technique deployed in “Terra,” in which the server distributes dynamic scripts to clients, and clients send scripts to one another.† This is a reference to the observation from Chaos Theory that very small differences in initial conditions can make a very big difference in the outcomes of dynamic simulations.  In this case, the very specific starting state of one Kinematics model is chosen as the state with which every other Kinematics model should start applying the control inputs.  Every other model will have to discretely change to exactly this state prior to applying the control inputs.  In the Dead Reckoning Design Pattern, this would mean sending both the position and the velocity.  The visual display of this model must be “smoothed” so that it does not appear to jump to the new state.† The protocols which rely on DR invariably require that a message be sent when the accumulated error between the actual behavior and the expected dead reckoned behavior in a peer simulator exceeds a threshold.  Thus, the exact predictive algorithm being used by other parties is rightly considered part of the protocol.  Since the API is supposed to be encapsulating the protocol, it should encapsulate this remote dead reckoning.† The class hierarchy in an object oriented program using inheritance can be viewed as a Directed Acyclic Graph (DAG) of classes.  Often, a class deep in this graph can be reached in more than one way from an instanced class.  For example: Clown is a Person, Politician is a Person, President is a Clown and a Politician.  When President is instanced, the Person stuff should only be created once, not twice.