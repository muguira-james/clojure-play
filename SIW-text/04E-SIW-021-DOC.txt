Where Next for the Composability of Models and Simulations?Paul K. DavisRobert B. AndersonThe RAND Corporation1700 Main St. Santa Monica, CA 90407-2137310-451- 6912, 310-393-0411 HYPERLINK "mailto:pdavis@rand.org" pdavis@rand.org,  HYPERLINK "mailto:Robert_Anderson@rand.org" Robert_Anderson@rand.orgKeywords: models, simulations, composition, modularity, abstraction, systems of systems, distributed simulation, interoperabilityABSTRACT: This paper summarizes a recent RAND study done at the request of the U.S. Defense Modeling and Simulation Office (DMSO).  Commissioned in recognition that the last decade's efforts by DoD to achieve model "composability" have had only limited success (e.g., HLA-mediated exercises), and that fundamental problems remain, the study surveyed the underlying problems that make composability difficult.  It then went on to recommend a series of improvement measures for DMSO and other DoD offices to consider.  One strong recommendation was that DoD back away from an earlier tendency toward overselling composability, moving instead to a more particularized approach in which composability is sought within domains where it makes most sense substantively.  Another recommendation was that DoD needs to recognize the shortcomings of standard software-engineering paradigms when dealing with "models" rather than pure software.  Beyond this, the study had concrete recommendations dealing with science and technology, the base of human capital, management, and infrastructure.  Many recommendations involved the need to align more closely with cutting edge technology and emerging standards  in the private sector.1. IntroductionComposability is the capability to select and assemble components of a model or simulation in various combinations to satisfy specific user requirements meaningfully.  It has sometimes been seen as the elusive holy grail of modeling and simulation (M&S); past Department of Defense (DoD) efforts to achieve it have had distinctly mixed success despite the many technological developments that have occurred over the past 5 to 10 years.  This paper summarizes a monograph [1] that reviewed the situation in 2003 and identified key elements in a path toward greater success in the future.  A journal-length article is forthcoming.[2]  Both contain extensive references to the literature.  2. DiagnosisThere are many reasons for seeking composability when dealing with complex systems, but the basic question addressed here is, What are the factors that determine what can be ‘composed’ when, and with how much expense and risk? In the aggregate, those factors includeThe complexity of the system being modeled.The difficulty of the objective for the context in which the composite M&S will be used.The strength of underlying science and technology, including standards.Human considerations, such as the quality of management, having a common community of interest, and the skill and knowledge of the work force.Figure 2.1 shows a richer breakdown of these factors.  Unfortunately, there is no single Gordian knot—many factors currently limit success.Notionally, if these factors could be roughly quantified, they could be used to characterize the probability of success of a particular proposed composition effort.  A parametric plot of risk might look something like Figure 2.2, which is purely speculative but qualitatively reasonable.  Risk rises with some measure of “effective” size and complexity, but it rises faster if the composite M&S will be used in rigorous work (i.e., work requiring that well-controlled and reproducible results be used for matters of choice), and it rises extremely fast if any of several danger factors are present.  These include poor management; the crossing of many military or cultural boundaries in attempting the composition; and a poor understanding of what is being modeled, worsened by a weak treatment of uncertainty.  In these cases, the risk of failure is high even if expenditures are increased; these shortcomings cannot be overcome by simply throwing money at the problem.Figure 2.1—Factors Affecting the Difficulty of M&S CompositionFigure 2.2—Notional Curve of Risk versus Attributes of the Composite M&S Being Attempted With this image in mind for assessing risk as a function of factors, we consider all of the factors in Figure 2.1.  Doing so increases humility, which has sometimes been notably absent in the thinking of composability advocates.  Customers—those who pay for and hope to use the fruits of composability-driven efforts for practical purposes such as weapon acquisition, training, or warfighting—need realistic expectations and assistance in establishing those expectations and related requirements.  The appealing imagery of arbitrary plug-and-play is fatally flawed for complex models, even with adherence to the standards of DoD’s high-level architecture.  The viewgraph-level metaphor of jigsaw-puzzle pieces snapping together is not appropriate either, except, for example, when the components have been carefully designed with the intention of fitting together neatly in a known context, or when the components happen to deal with stable, well-defined, and usually low-level matters such as a simple physics calculation.The basic reason for this is that composing models is not as simple as composing software components that provide straightforward and readily compartmented services.  That is, while the engineering of pure software composition is notoriously difficult, model composition is much more difficult, something often not appreciated even by good software engineers: Models are different.   The more-complex model components have typically been developed for particular purposes and depend on context-sensitive assumptions, some of which are tacit.   When composing such component models, “successful” composition efforts often require days, weeks, or even months, most of which go into understanding and modifying would-be components and interfaces so that the resulting composed model will be reasonably valid for its intended use.  This process is not likely to change drastically, i.e., to a matter of minutes to days, except for relatively simple atomic components, because so many of the problems are substantive, rather than being mere issues of syntax or superficial semantics.  This said, there are important opportunities for technological progress, as in reuse of at least a significant number of components, the use of metadata for search and ranking of plausible components, and rapid evaluation in new contexts.  The opportunities are quite different, depending on whether the function intended is simple or, as is the case in many exercises, fairly loose, even if complicated, or both complex and rigorous, as in some analyses.  Generally, we see the opportunities for progress as being greatest for enhanced man-machine efficiency and effectiveness, not for automated model composition.As a measure of how serious the disconnect between hype and reality has been on composability, some experts in a recent workshop, experts who understand composability issues and might be expected to favor composability per se, said candidly that they often find themselves arguing vociferously against composition efforts because the people proposing them do not understand how ill-served end-users would be by connecting modules developed in different places and times and for different purposes, or how hard it is to understand the substantive consequences of connecting such modules.  We agree with this assessment and believe that DoD should focus its composability efforts on those domains and circumstances in which they actually make most sense—not for their own sake, but in a “business-case” sense.  A related vision for DoD is the potentially great advantage of having first-rate virtual environments for assessing alternative weapons or doctrinal concepts, environments that could be used for some years with many changes of individual modules but with most aspects of the environments being well controlled, and with the underlying models being open to scrutiny by all concerned so as to permit fair competition.  Such a vision would have immediate implications for commercial companies, which would discover business cases for modular M&S efforts accordingly.  There are parallels in simulation-based acquisition (SBA) and integrated manufacturing. Significantly, tangible examples of composability-oriented analysis work groups have existed for some years, as illustrated in the text of this monograph with examples from the RAND Corporation and Lockheed-Martin (Sunnyvale).  DoD’s OneSAF program is seeking a high degree of flexibility based on modularity.  3. Synthesis and PrescriptionGiven a diagnosis of the issues, what can be done to improve the situation?  Here, a “systems approach” is needed, because there is no single stumbling block, but rather a set of them.  There are many ways to characterize systems, but we chose to focus on “targets,” that is, on objective system elements for which we can see specific measures to be taken.  We suggest the following targets for a broad approach, as indicated in Figure 3.1: Science (of the subjects being modeled and of the M&S activities themselves), and technology, including standards for composability.Understanding (e.g., of pitfalls, best practices, relevant metrics, and of what can reasonably be achieved).Quality of management in substantial composability efforts (including goal setting, team building, metrics setting, and collaborative methods).Quality of the workforce (e.g., education, talent, experience).Health and vitality of the communitywide M&S environment, including a motivated industrial base with a mix of stable centers of excellence and more-dynamic competition, and with sensible motivations for industrial cooperation among players in particular subject areas (e.g., developers of a major next-generation suite of weapons and doctrine, such as the Army’s Future Combat System or its successor).Figure 3.1—A System View of Suggested TargetsOur conclusions on how to achieve these are outlined below.3.1 Science and Technology, Including Standards3.1.1 Military Science and TechnologyIn many instances, deep knowledge of the phenomena being modeled limits what can be accomplished.  This is not a “software problem,” but rather something demanding in-depth inquiry about the science of appropriate subject areas—military science, in the case of DoD models.  Although DoD pursues many subjects in various studies and experiments, it typically does so unsystematically and leaves behind no settled understanding of those subjects.  DoD should instead mount military-science programs to assure a strong base of knowledge in key domains.  The Defense Modeling and Simulation Office (DMSO) should advocate for and cooperate with such programs where they exist.  The efforts of DoD’s Command and Control Research Program (CCRP) might be seen here as an exemplar in some respects: It has pulled together a community of people who have scientific conferences, publish thoughtful papers and books, and even generate suggested best-practices guides.  Some examples of subject areas for study include effects-based operations, network-centric operations, and jointness at the tactical level (others are given in the main text).  The study of each would benefit greatly from an increased ratio of science to art.In this connection, we believe that the M&S and command, control, communications, computers, intelligence, surveillance, and reconnaissance (C4ISR) worlds need to be pursuing some fundamental issues together, because their efforts should logically supplement each other.  Although the scope of M&S is much broader than that of C4ISR, pursuing this suggestion where it makes sense would have major implications for everything from system modeling (e.g., identifying and naming the entities) to the adoption of standards.  The NATO C4ISR community is moving toward commercial standards.3.1.2 Science and Technology of M&SThe science of modeling and simulation is substantial and growing.  It involves, for example, understanding languages and notations—e.g., unified modeling language (UML) and discrete-event system specification (DEVS)—for expressing models, alternative ways to structure them—e.g., agent-based and object-oriented methods—and interoperability frameworks, such as the high-level architecture (HLA).  DoD should encourage and support M&S education and training programs that reflect this science well.  Success in composability also depends critically on science-and-engineering advances in a number of methodologies, notably:Model abstraction and the related issues of aggregation and disaggregation.  These relate to the problem of “vertical integration” and cannot be solved without working the substantive problems of the subject area.  Understanding how to achieve acceptable degrees of context-specific consistency or even integration across levels is a problem of methodological theory.  A key element in progress is multiresolution, multiperspective families of models and games.  It should be possible to extend and translate recent advances into practical guidelines.Validation.  Methods and tools are needed to facilitate assessing whether a given composition would make sense in the envisioned context.  For example, how do the components’ features interact?  And how do risks, uncertainties, and errors propagate as components are combined?  There are opportunities for near-term successes here in theory, technology, and practice. Heterogeneous M&S.  Methods and tools are needed to facilitate using components described in very different representations, formalisms, and styles, including those for both discrete and continuous systems.Communication: documentation and new methods of transferring models.  Better documentation is needed, as discussed below.  However, new methods and tools are also needed for communicating and transferring key concepts and other essentials of components and systems.  The new methods should recognize that people, even “analytical people,” typically learn well by doing, e.g., when learning new commercial games, participating in war games, or being appropriately tutored.Explanation mechanisms. Whether built-in or retrofitted, explanation mechanisms, including those for agent-based models, are badly needed.  Ways to express “requirements” meaningfully are also needed. Intimate man-machine interactions. These interactions and the tools facilitating them are needed at most stages of development and application. In the main text, we suggest tentatively related initiatives for investment and management.3.1.3 Standards and ProtocolsStandards should be an outgrowth of progress in science and technology and an enabler of efforts.  Much success has been achieved with the DoD’s high-level architecture (HLA) and related instruments such as the run-time infrastructure (RTI) and development tools.  It appears to us, however, that a critical point has been reached on protocol-oriented standards, one at which the existing set of standards should be substantially extended or even replaced. The time is ripe for DoD to revisit the standards, much as it did in the pre-HLA days of 1994.  There have been many successes in the years since then, but it is now time to review, revise, exploit commercial momentum, and fill in where necessary.Fierce disagreements exist on the matter of next-generation DoD standards, even after one discounts for “theology” and enthusiasm.  The language of the debate revolves, for example, around the degree to which a next-generation set of DoD standards should incorporate or be replaced by the de facto standards emerging in the broader marketplace, including model-driven architecture (MDA), extended markup language (XML), unified modeling language (UML), and common object request broker architecture (CORBA).  As for the successor to today’s high-level architecture (HLA) and run-time infrastructure (RTI), there is clear need for various functional extensions, such as allowing for dynamic composability within simulations and tighter specification of models related to time management, but we believe that DoD should hurry to realign its direction better with that of the commercial marketplace, rather than merely patching the HLA/RTI on the margin.  The principles of the HLA will probably stand up well, but the current implementation will not, because commercial developments such as web services are often faster, better, and in more rapid development.  In creating an improved approach, DoD needs to deemphasize rigid adherence to detailed implementation standards, which has been a problem (as in developments that were part of the Millennium Challenge 2002 experiment).  Engineers with a real and tangible product to deliver should be permitted to use what is sensible in their context.  In particular, some analysis applications require precise management and control of simulation events over time, while others, such as training applications, can often be very forgiving in that respect but are quite demanding in terms of scale and the ability to combine components not designed specifically for composability.  Given the diversity of applications, different implementation methods are necessary.  3.1.4 Model Representation, Specification, and DocumentationThe time is also ripe for convergence on a related matter, higher-level representations that would simplify characterization of components, communication among individuals and groups about components and possible compositions, and evaluation of alternatives.  Although there will be no permanently “right” representation, and although we do not wish to prejudge the results of a review, we note that much of the relevant community is adopting evolving features of UML, XML, and variants.  These, however, are not yet sufficient, even where object orientation is appropriate.For many purposes, particularly when one is concerned about the substantive aspects of a composed simulation, rather than just on whether it will “run,” more-detailed specifications are needed in a systems framework.  Some of these relate to component-level behaviors and internal logic, to sound and comprehensible ways of dealing with hierarchical coupling of modules, and to anticipation of event sequences so that time management can be specified.  Another fundamental need here is to build into agreed methods of representation the requirement that model, execution engine (simulator), and the context of use (sometimes called “experimental frame”) be distinguished and specified separately.  Often, the validity of compositions simply cannot be assessed without such a framework.  In short, supporting mechanisms are needed for evaluating the “”goodness of fit” when items are composed.  We believe that a community consensus on methods for accomplishing these goals could now be achieved.Documentation would be greatly facilitated by these developments.  We also suspect that retro documentation would prove very worthwhile in some projects, since legacy simulations will be with us for many years, and it is currently very difficult to know the implications of using such components as part of a larger system.  Retro documentation has seldom been proposed in the past, because it could be very expensive if done in the detail needed for full specification.  What is needed most is higher-level documentation (at a “meta” level), rather than the extremely burdensome documentation of line-by-line programs.  There is as yet no agreement on precisely what such higher-level documentation would look like, but we believe—based on the considerable experience of workers in the field in actually composing systems—that much consensus could be reached on what is most valuable.  This would probably be a higher-level or perhaps simplified version of the documentation described above. 3. 2 UnderstandingGiven the experiences of the last decade, both successful and unsuccessful, it should now be feasible to develop primers and best-practices descriptions that would greatly assist clients and developers in understanding both particular needs and what can be accomplished as a function of ambitiousness and cost, and with varying degrees of risk.  This understanding seems currently to be absent in the community, perhaps a reflection of earlier naïveté. As an example, managers or agencies may demand plug-and-play because it sounds attractive, when they should instead be asking for adaptiveness (via mechanisms such as wrappers, perhaps) that would allow compositions to be achieved in minutes, days, or weeks, depending on their real needs, the need for new components, and their willingness to pay.  We suggest that DoD invest in research to turn the speculative and qualitative ideas about composability risk suggested in Figure 2.2 into something more solid and empirically grounded.Obviously, the discussion above about next steps on standards is closely related to the ability to “understand” the state of the art of model specification and the specification of simulation experiments.As one tangible recommendation related to management, we urge DoD to commission independent and objective lessons-learned studies on past composability-related efforts, such as those of JSIMS (joint simulation system), JWARS (joint warfare system), and OneSAF (entity-level battalion and below constructive simulation with semi-automated forces).  It is ironic that major lessons-learned studies have been or are being conducted by the services and the joint staff on warfighting, but DoD has done nothing comparable to learn from its previous modeling and simulation composability efforts.  Prompt action is needed because the information will be lost as people retire and existing records disappear.3.3 ManagementEven with the best science, technology, and concept, composing large M&S systems can be doomed to failure by inadequate management.  A systematic effort is needed to define requirements and methods for developing first-rate managers, educated at the appropriate time in their careers about the special needs of complex M&S projects.  This must include acquainting managers with the special problems of model composition.  The suggested recommendations address actions relating to credentialing, at-the-time education, primers, partnerships, and changes of military rotation cycles.  The content of primers for managers would include realistic goal setting, assessing talent and team building, collaborative-management tools, and establishment of sensible metrics that do not have perverse side effects.Many of the measures needed here are much more general than those of concern to DMSO.  Preparing people for system engineering, for example, is a broad challenge.  However, if DMSO wishes composability efforts to be successful, it cannot merely assume that “someone else” will take care of these issues.  It should team with other government and industry groups, such as the Defense Systems Management College, to promote appropriate initiatives.  One aspect of management is that of having the right tools.  As discussed under environment (below), we would envision centralized configuration management and virtual repositories of candidate components.3.4 The WorkforceIn the past, those building even large-scale M&S systems of systems have seldom been trained for this demanding activity.  As with management, there is need for related systematic education, selection, and training.  And, as with management initiatives, much could be done while teaming with other agencies and industry groups.3.5 The General Environment for DoD M&SUltimately, the future of composability depends on having a favorable environment, one that includes a strong industrial base, incentives that promote sensible developments, and mechanisms that support technically sound and fair competitions among ideas and proposals.  Standards, addressed above, are a key element here, but many other elements apply as well.  These relate to issues such as existence of a marketplace of ideas and suppliers, mechanisms for configuration management and virtual repositories, incentives at the individual and organizational level, and a balance between maintaining long-term relationships with centers of excellence and assuring vitality with a constant inflow of ideas and challenges.  In addition, it will be important to create a sense of community in appropriate segments of industry where close cooperation is sensible.  This will also require incentives.  One way for DoD to create incentives is to conduct evaluations of competitive weapon-system concepts in virtual environments that are as open as possible to all concerned, and that allow for component substitution if it can be demonstrated that one is better than another for a particular purpose.Large-scale DoD M&S efforts would be well served by a much greater degree of commonality with the activities of the commercial sector.  This would increase both options and dynamism, in part because it would enable good commercial-sector ideas, methods, and tools to be adapted quickly to defense applications.  One possible element of “other infrastructure” would be technology and standards allowing rapid searches for potentially relevant components, and allowing reasonably efficient zooming.   These might include running candidates against standard datasets to see whether, at least superficially, the components do what the researcher imagines they will do.  Evaluating possible compositions in the contexts of intended use automatically requires more cutting-edge developments, but movement in that direction is possible.4. Bottom LineIn summary, to improve prospects for composability in its M&S, DOD must recognize that models are different from general software components and that model composability needs to be based on the science of modeling and simulation, not just on software engineering with its core paradigm of connecting black boxes.  DoD should develop and communicate a set of realistic images and expectations, back away from excessive promises, and approach improvement measures as a system problem involving actions and investments in multiple areas ranging from science and technology to education and training.  Most of the investments could have high leverage if commercial developments are exploited; some will be more focused on DoD’s particular needs.AcknowledgementsThe work from which this paper is drawn owes much to the many suggestions we received in a workshop held in RAND’s Arlington VA office on July 28, 2003.  See [1] for participants in that workshop and follow-up efforts.  See appendix G of [1] for particular comments received at the workshop.References[1] P.K. Davis and R. B. Anderson, Improving the Composability of DoD Models and Simulations, RAND, Santa Monica, CA, 2003. [2] P.K. Davis and R. B. Anderson, “Improving the Composability of DoD Models and Simlations,” Journal of Defense Modeling and Simulation, Vol. 1, no. 1, forthcoming.Author BiographiesPAUL K. DAVIS (B.S., U. of Michigan, Ph.D., Massachusetts Institute of Technology) is a senior scientist at RAND and a professor of policy analysis in the Pardee RAND Graduate School.  His research involves defense planning, high level decision support, and advanced modeling and simulation.  He is the author of recent monographs on capabilities-based planning and the “influence component” of counter-terrorism.  As a member of the Naval Studies Board under the National Research Council, he has led or contributed to studies on modeling and simulation, network centric operations, and military experimentation.  Dr. Davis has published pioneering papers on the theory and practice of exploratory analysis and multi-resolution modeling.  In the 1980s he was the architect of the RAND Strategy Assessment System (RSAS), a large analytic war gaming system that included political- and military-level artificial intelligence agents, as well as combat models.  Robert B. Anderson (B.S., U. of California, Berkeley, Ph.D., Harvard) is a senior information scientist at RAND and head of the information sciences group.  Recent research has involved the safety and security of U.S. infrastructure from “cyberspace” attacks, and of the impact of the information revolution on organizations, countries, regions, and cultures in the world.  Dr. Anderson is also a professor in the Pardee RAND Graduate School, teaching courses in CyberAssurance.  In earlier years, Dr. Anderson ran his own consulting company and served as executive vice president of Interactive Systems Corporation.