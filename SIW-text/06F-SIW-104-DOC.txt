Challenges in Integration of Simulation and Automated Planning and SchedulingJeremy Frank, Peter A. Jarvis1, Ali Farhang Mehr1, Philip Wysocki2NASA Ames Research CenterMoffett Field, CA{frank, pjarvis, amehr, pwysocki}@mail.arc.nasa.gov AbstractAutomated planners and simulation technologies have been used widely within NASA. Simulators offer planners a high fidelity world model in which to evaluate plans. Planners offer simulators a new deliberative capability that enable them to include intelligent decision-making capabilities within simulations, and planning technology can speed up simulation. In this paper we argue that there is significant value to integrating planning and simulation. We describe current work in this area, present a range of integration architectures, and discuss the benefits and limitations of each together with the outstanding research issues. The central contribution of this paper is a snap shot of the state of the art in integrating these technologies and a motivated roadmap of essential research issues that must be addressed.Introduction Automated planning and scheduling has been applied to a wide variety of endeavors across NASA, including the scheduling of ground-based, aircraft-based and space-based telescopes; on-board scheduling of deep space craft; and ground-based planning of deep space missions such as the Mars Exploration Rovers Spirit and Opportunity. Plans and schedules are generated in the face of constraints on activity time and resource needs. These constraints are provided as inputs to the automated planning system. The goal of the planner can be to produce short plans, plans that minimize resource use, or plans that maximize an objective, e.g. collect the maximum number of science targets. Simulation has also been widely applied to NASA endeavors, including air traffic control, spacecraft ground processing, robot performance, and space mission simulation. We focus on the simulation of controllers that must choose how to act, as opposed to simulations of highly complex but “uncontrolled” processes. In this context, controllers act in simulated worlds were actions succeed and fail and extraneous events occur all with predefined probability distributions. Part of the purpose of such simulations is to evaluate the quality of the controllers. Automated planners are integral parts of such controllers. A wide variety of general-purpose technologies have been devised across academia, industry, and government agencies to address the need for both automated planning and simulation of controllers in high-fidelity environments. Automated planner technologies include (but are not limited to) HSTS (Jonsson et al. 2000), ASPEN (Chien et al. 2000), EUROPA (Frank & Jonsson 2003), MOPPS/AMPS (Morris et al. 2004). Since this paper is mainly focused on controlled processes that relate to maintenance and operation of an aerospace vehicle, we will limit our discussion to a class of simulations known as process simulations. Examples of such simulation methodologies include Discrete Event Simulations (DES), Testability Analysis, and Reliability models (e.g., Fault Trees.) A variety of software packages have been developed both within NASA and commercially based on these simulation methodologies. Commercial examples include: Arena, Extend, CORE, Satellite Toolkit (StK); government lab (including NASA) developed simulators include Sapphire 7, Mission Simulation Facility (Pisanich et al. 2004), and ROver Analysis Modeling and Simulation (ROAMS) (Yen et al. 1999).To date, many of these technologies have evolved independently. As a result, while controllers employing automated planning must be validated in high-fidelity simulations, planners often cannot directly employ such simulations during the search for plans. Similarly, simulators have only limited ability to call planners, and often cannot exploit technology developed for automated planning to improve the speed of simulation. In this paper we propose that integrating these technologies will offer significant benefits and we survey previous approaches and identify the outstanding research questions that must be addressed. An integrated architecture will allow planners to take guidance from the higher fidelity model supported by simulators and for simulators to take advantage of the deliberative capability of planners to more effectively simulate decision-making processes. Figure  SEQ Figure \* ARABIC 1: Extend Simulation Model of Spacecraft Ground ProcessingFigure  SEQ Figure \* ARABIC 2: Europa (partial) Plan of Spacecraft Ground ProcessingFigure  SEQ Figure \* ARABIC 3: Europa Subgoal tree and OperatorWe structure this paper as follows. We first provide a high level summary of the respective capabilities of planning and discrete event simulation technologies. We then introduce a number of integration architectures and discuss the benefits, limitations, and open research questions.A Running ExampleWe motivate our discussion with a running example involving the design of a spacecraft ground-processing infrastructure. Ground processing encompasses everything from the receipt of spacecraft subsystems either new from their manufactures or returned to earth from a previous mission through the vehicle’s launch. The design decisions include determining the layout of the physical space (number of bays etc.), the type and amount of test equipment available, and the number and skill mix of the servicing staff. We base our example on NASA’s new Crew Exploration and Crew Launch Vehicle (CEV/CLV) that is in the design phase at the time of writing (July 2006). The CLV is derived from Space Shuttle lift components (main engines and solid rocket boosters) but the CEV uses a new capsule design for housing the crew. The vehicles will replace the Space Shuttle early in the next decade and will be the backbone of the Agency’s manned lunar and Martian exploration missions REF _Ref14265738 \h Figure 1Figure 1 shows the top level view of a Discrete Event Simulation (DES) of the ground processing of the new vehicle developed in the Extend simulation package (Staton 2006). Each box in the simulation contains considerably more information organized in multiple hierarchal levels. This is an extensive model of ground processing of a specific vehicle design that is used to provide estimates of vehicle turn around time and to identify bottlenecks. Working left to right within the figure, you first see the spacecraft components arriving. The Solid Rocket Boosters (SRB) are returned by rail (either new or refurbished) from the Thiokol contractor in Utah. The central (orange) fuel external tank (ET) and main engines arrive by barge while the parachute (PRF) and SRB aft skirts (ARF) are delivered by the surface ships that recover them from the ocean. The components are assembled in the Vehicle Assembly Building (VAB) before being moved to the launch pad for launch. After launch, the SRBs are jettisoned from the ET and dropped into the ocean and recovered, disassembled and returned to Thikol in Utah. The remainder of the launch vehicle is discarded and is burned up in the earth’s atmosphere as it falls out of orbit. In this simulation the payload (typically the crew vehicle) return is not modeled as the author’s focus is on the launch vehicle.Significant work is carried out within the VAB. Integrating the vehicle involves the assembly, testing and integration of spacecraft components. These steps involve processing different components, including transporting parts, testing parts, replacing faulty parts, loading fuel and other hazardous fluids, and connecting interfaces The simulation element involves details that ultimately influence the time taken to perform each processing step. The planning element involves deciding how to allocate resources (trucks, test stands, power, people), task timing and task ordering when such options are available.Spacecraft ground processing has a rich set of constraints and preferences. For example, some steps take a long time to complete and therefore cannot be started late in the day (e.g. the long rollout to a launch pad). Some tasks are better performed during specific periods of the day (e.g. transporting spacecraft overland is best done at night where cooling costs can be reduced). It is also difficult to predict the time a task will take. A failing part may require data to be retrieved from its original manufacture which could take several days. Tasks are also heavily interdependent so the outcome of a task could affect the ordering or need for future tasks. For example, a failed test will introduce corrective tasks that will compete for resources.Automated Planning and SchedulingAutomated planning and scheduling is a heavily researched area of computer science focused on providing computational intelligence. The general problem is to take a description of the activities in an application together with definitions of the current state of the world and the intended or goal states and generate the sequence of actions required to reach a goal state. Planning can also be posed as an optimization problem, where the goal is to optimize quantities such as makespan, number of achieved tasks, and so on. Ghallab et al. (2004) provides an excellent introduction to the technology.The computational intelligence perspective on planning is to provide a general computer program that will solve problems in any application domain. This allows the same software to work on many classes of a problem (e.g. rovers, deep spacecraft, and ground processing). This perspective holds whether planning is performed by a completely automated system, as was done for the Remote Agent Experiment (Jonsson et al. 2000) and the Autonomous Sciencecraft Experiment (Chien et al. 2005), or whether a human operator uses some finer-grained functionality to search for plans as is done for the Mars Exploration Rovers (Bresina et al. 2005).A planning problem is described by three elements. The initial state of the world is specified as a set of logical statements. E.g. state(avionics_computer, requires_serving), flight_hours(main_engine, 200). The goal state of the world that the planner is to bring about is also specified as a set of logical statements. E.g. state(avionics_computer, flight_ready). The set of actions available to the planner are described in three fields:The signature of the actions. E.g. service(?avionics_computer). Note that the “?” denotes a variable that can be bound to any specific avionics computer.The preconditions of the action as the set of logical sentences that must hold before an action can be executed. E.g state(?avionics_computer, requires_servicing).The effects of the action again as a set of logical sentences. E.g (not(state(?avionics_computer, requires_servicing)), state(avionics_computer, flight_ready).The task of the planning algorithm is to take a planning problem described in terms of these three elements and find a set of ordered actions (actions can occur in parallel) that leads from the initial state to the goal state that ensures the preconditions of each action are always satisfied. REF _Ref13728066 \h Figure 2Figure 2 shows a portion of a ground-processing plan produced by the Extensible Universal Remote Operations Planning Architecture (EUROPA) planner for processing a particular spacecraft. The three vertical lines each correspond to a component of the spacecraft. The first represents the overall vehicles physical state, the second the power status of the vehicle, and the third the status of the primary avionics computer. As the plan proceeds, you can follow the servicing of the primary avionics computer. The vehicle is powered down to permit the computer to be removed and is powered back up again to support its integration testing.  REF _Ref14246476 \h Figure 3Figure 3 gives insights into the planner’s reasoning process. The top level of the tree notes that a particular avionics computer is not ready flight (all computers are marked in this state on returning from a mission). The planner’s goal is to get this computer ready for flight. It reasons backward from the goal realizing that the computer must be tested. To be tested it must be uninstalled, etc. In this figure, we can see the “uninstall” action has been generated from the flight computer’s “not ready” state. The uninstall goal, in turn, spawns new subgoals that include the vehicle’s being off, its being orientated horizontally, and that a technician of “Type C” be available. The problem with this application independent approach is that planning problems are fundamentally difficult to solve due to their computational complexity. The planner has to search over all the actions available to the agent it is planning for and all the objects every action could be applied to. The problem is complicated further if actions have uncertain outcomes, as the planner must search through all possible action outcomes. Planning problems generally require exponential time or worse in the number of tasks to schedule, or the number of activities to plan. While specialized algorithms can be found for some problems, this limits the application of automated planning to relatively small problems (e.g. tens to hundreds of activities). SimulationSimulations help us examine the behavior of a complex system (e.g. physical, chemical, biological, etc.) by modeling the system itself as well as its interactions with the world surrounding it. Since the process of designing aerospace systems is multidisciplinary by nature, engineers often have to develop and run several different models (usually in different simulation environments) to analyze different aspects of performance for a given spacecraft. Each simulation is used to measure certain performance metrics, often referred to Figures of Merit (or FOMs.) A network of such simulations is then used to adequately understand the overall performance of a complex system by observing the tradeoff among these various FOMs. To further demonstrate this point, we return to the example of CEV/CLV design process introduced earlier in this paper. The following is a typical shortlist of high-level FOMs that used to analyze the overall system from cost/risk/performance standpoints.Probability of Loss Of Mission (LOM)Probability of Loss Of Vehicle (LOV)Probability of Loss Of Crew (LOC)Launch AvailabilityDevelopment CostProduction CostAnnual Operational Cost$/lb (Mission Price/lb)Mean Time To Repair (MTTR)Mean Time Between Failure (MTBF)Cost of SparesWeightPayload CapacityNet Present Value and IRR of the ProgramSeveral models have to be developed and integrated to measure this set of FOMs. Sometimes engineers have to re-arrange these FOMs in a hierarchical fashion to allow a methodical analysis of the overall system. Such hierarchical decomposition of FOMs (and other local sub-problem decompositions) enables a systems engineer to optimize a given complex system as a multidisciplinary system-of-systems. For the purpose of this example, however, we investigate a flat integration of the simulation models. Each simulation model provides an abstraction of the real-world system and is useful to understand certain aspects of performance. Therefore, as demonstrated in this section, engineers often have to develop multiple simulation models and link them together to create a more comprehensive view of the system. In the following, we briefly describe some of the models used in this example to calculate various FOMs. Later in the paper, we will address the integration issues.  Discrete Event Simulation ModelThe DES Model is used in this example to predict the launch availability and turn around time. The model includes all activities that transpire after vehicle elements have been recovered, undergone safety inspections and returned to the maintenance facilities. Turnaround activities conclude when all subsystems contained within each of the vehicle elements have successfully passed integrated system tests.Probabilistic Risk Assessment ModelProbabilistic Risk Assessment (PRA) identifies and assesses risks in complex technological systems. The Loss of Mission model assesses the likelihood that a failure will result in the inability to complete a mission. To evaluate the reliability of the vehicle subsystems, NASA widely uses the Saphire 7 PRA tool developed by the Idaho National Engineering and Environmental Laboratory. The fault tree is used as part of the overall simulation to evaluate figures of merit such as LOM under different assumptions. Figure 4 illustrates the fault tree of the X-34 Main Propulsion Feed system for a Loss of Mission scenario.Testability AnalysisTestability Analysis is the primary technique used in determining fault detection coverage, ambiguity groups, fault isolation and reliability. Testability Analysis generates a testing strategy in the form of a diagnostic decision tree. To do testability analysis, a functional model is created to keep track of the inputs and outputs from each component and the relations between components. The model also captures the association between components and failure modes with respect to the state of the components. Figure 5 depicts a snapshot of a testability analysis model developed for a spacecraft propulsion subsystem. False Alarm ModelThe False Alarm Rate (FAR) model accounts for possible false alarms that can impact system performance. False Alarm Rate is defined as the ratio of false alarms to the total number of alarms. The False Alarm Rate for a general system is determined by decomposing the system into independent subsystems. The Expected Values for false alarms (FA’s) for the subsystems are then combined into an overall Expected False Alarm Value. This is a recursive process as the subsystems, in turn, are decomposed into simpler, independent subsystems whose expected FA values are directly determined.Maintenance ModelsThree maintenance models are used to provide maintenance related input on a subsystem-by-subsystem basis, as described below.Scheduled Maintenance Model: The Scheduled Maintenance Model generates an expected turn around time based on predictable maintenance and work schedules.Probability of Unscheduled Maintenance Model: The Probability of Unscheduled Maintenance Model computes a probability that corrective maintenance is required. Corrective maintenance is all actions performed (a) as a result of a failure to an item in prior mission, (b) to restore an item to a specified condition (condition based maintenance), or (c) because of a false alarm.Unscheduled Maintenance Duration Model: The Unscheduled Maintenance Duration is made up of ‘fault detection time’ and ‘Fault correction time’. Any additional time to verify the faulty item(s) is also a portion of this maintenance model. Unscheduled maintenance includes any or all of the following steps: Localization, Isolation, Disassembly, Interchange, Reassembly, Alignment, and Checkout.Figure  SEQ Figure \* ARABIC 4: Probabilistic Risk Assessment ModelIntegration ArchitecturesIf we consider the design of the CEV/CLV, it is apparent that there are numerous places where planning and simulation interact.  The DES and Maintenance models must capture the planning of logistics and refurbishment operations to accurately analyze both availability and maintenance figures of merit.  Planning and other forms of intelligent control (particularly Intelligent Systems Health Management) can lead to reduced risk, but must be captured in the testability, false alarm and PRA models to accurately assess the impact.We now examine several integration approaches and identify the benefits, drawbacks, and research issues of each. We first look at how planners can call upon simulators before considering the reverse. EMBED Word.Picture.8  Figure  SEQ Figure \* ARABIC 5: Testability analysis model of a feed systemPlanners Use of SimulationAutomated planners work with a course symbolic model of the world. Simulators offer a rich resource in which a planner can evaluate as it plans; work in this area extends (at least) back to Miller (1987). Here we consider some possible integration architectures that will make these rich model outputs available to automated planners.The Plan Critic ArchitectureIn this approach the planner passes a completed plan to a simulator for its execution to be simulated. The simulator reports on the result of that execution to indicate if the plan succeeded or failed and reports on properties of the plans performance. Cohen et al. (1996) have investigated this approach in the military air campaign-planning domain. The authors take a range of plans produced by an automated planner and run each through a simulation. The simulator reports on the success or failure of the plan in terms of the number of enemy targets hit, the degree of the damage caused, and the number of friendly aircraft damaged or lost. The annotated plans are then passed to a human to aid in selection.The benefit of this approach is that it is relatively easy to engineer. The challenge is chiefly in converting to output format of the planner into the input format of the simulator. The user is provided with useful information on the expected performance of a plan when it is executed under a number of assumptions. The central limitation is that the simulator is not providing feedback to the planner during plan generation. The planner cannot make use of the richer simulation model to make better choices while planning. For example, if the planner makes a bad choice early in its decision-making process, later designs will typically depend upon it. The poor score resulting from the simulation will have no explanation that the planner can make use of. The planner will have to reconsider each of its decisions in turn.Real World SurrogateClosely related to the plan critic architecture is the use of a simulator as a surrogate for the real world. In this approach a plan is executed in a simulation and action success or failure is feed back to the planner. This allows the planner to re-plan for actions that fail to achieve their expected outcomes or take advantage of unexpected fortunate effects. Freed et al. (2005) use a similar architecture to evaluate their earth observation planner. Several projects within NASA have explored similar approaches. Jain et al. (2004) describe the Rover Analysis and Modeling System (ROAMS) which is designed explicitly to support interaction with an autonomy system for evaluating planetary rovers. The simulator enables rover plans to be executed and to test the ability of the planner to respond to unexpected outcomes. Pisanich et al. (2005) describe the Mission Simulation Facility (MSF), which provides a more generic interface for autonomous systems to operate in simulated worlds. Kortenkamp and Bell (2003) have developed a tool called BioSim to evaluate different life support system designs in simulation. A range of life support designs are simulated and a deliberative planner is used to control each.The strength of this approach is that it allows the rapid testing of a planner’s ability to control a range of different physical environments without the cost of having to setup read-world situations to control. The limitation is that the planner cannot take advantage of the simulation model during the plan generation process. Mixed-Initiative Planner and Simulator ArchitectureIn this approach the planner and simulator work together during the generation of the plan. The planner has decisions to make between alternative actions for achieving a goal (e.g. visual inspection vs remove and test of rig), alterative objects for filling roles (use equipment type one or equipment type two), and orderings (perform test A then B or the reverse). In a mixed initiative integration the planner can ask the simulator to evaluate range of choices and report back on the trade-offs to inform the planner’s decision.Dyke et al. (2000) have explored this approach in the context of evaluating noncombatant military evacuation operations such as rescuing refugees from a war zone. The authors simulate several alternatives to key decision such as routes in and out of the area and the types of transport vehicles. The simulator identifies routes that are likely to fail due to weather of enemy activity or vehicles unsuitable for the terrain or not offer sufficient protection from enemy activity. This information is the feedback during the planning process to make informed planning decisions. Dyke et al. report a number of problems with this approach. First, simulators cannot be started mid simulation and with partial information. They typically need to know the values of all variables and be started from the beginning. This is a problem, as planners typically do not plan actions in the order they will be executed. Even if the planner is to plan in order it may require the simulation of an action that has tasks in parallel that have not been planned yet. The authors constrained their planner to plan strictly in the order actions will be executed and blocked calls to the simulator until all actions that could occur in parallel and before the simulation point where planned. The second major problem was that simulators by their very nature have a finer grained model of the world and do not report problems in a plan at the level needed for the planner to digest. Dyke et al. found it difficult to translate the reasons for a plans failure (e.g. lack or armor on vehicles) and found that this seriously limited the utility of the simulator.Drabble’s (1993) Excalibur system demonstrates the type of benefits a mixed-initiative integration could produce. Drabble uses a simulation based on Qualitative Reasoning (QR) techniques to evaluate the effects actions during planning. While the simulation is not a fine-grained as the discrete event simulators we discuss in this paper, QR’s course grained nature simplifies the simulation summarization problem as the entities in each system have a one to one correspondence. This tight coupling enables the integrated system to make smart decisions during the planning process based on the QR simulator’s results.Simulation Use of PlanningSimulations can be invoked repeatedly to analyze different configurations of a system to either select an optimal configuration or define a trade-space. When evaluating controllers, the simulation may either evaluate a single plan that the controller follows, or evaluate a policy the controller uses to generate plans.  In this section we discuss how these approaches to simulation differ.Simulating Deliberation via Dispatch RulesExisting simulators such as Extend and Arena have relatively advanced capabilities to influence the course of simulations. For example, complex queue structures allow items to be assigned priorities and to renege after a specified time period. Using these capabilities, users can simulate dispatch rules and evaluate different task priority policies. However, dispatch cannot effectively simulate detailed planning. For example, consider the spacecraft ground-processing problem where Reaction Control Engines (small engines for maneuvering in orbit) are removed and sent to one of two bays for processing. A priority and renege scheme can handle small perturbations in the execution of the schedule at a tactical level, such as moving all engines into a queue for a single bay if one bay becomes unavailable. What this scheme cannot do is step back and examine the global effects of failures and perform the necessary replanning. In our bay scheduling example, the global effect may be that we can no longer service all engines in the remaining bay, for example, due to personnel constraints.  As a consequence, we may now have to reconfigure the ground processing facility to accommodate all of these constraints, possibly shifting tasks that have looser deadlines tasks to ensure all essential processing is completed in a timely manner.  Dispatching may lead to further replanning down the road, leading to suboptimal plans according to the figures of merit.  Detailed planning during the simulations is needed to ensure that the simulations are not overly pessimistic.Integration and AutomationPhoenix Integration’s Model Center v6.0.3 is used to automate the passing of parameters between models and to initiate execution of the models when input parameters change. Output parameters are generated from each model in a deterministic fashion, some being parsed and passed from output reports, others being directly passed via scripting to the receiving models.  Desired parameters are then passed onto the next models. The current integrated process at NASA Ames Research Center is automated to enable an ad-hoc optimization of the overall system.   This technology be used to support the plan critic architecture, real-world surrogate architecture, and (in limited circumstances) the mixed-initiative architecture. Figure  SEQ Figure \* ARABIC 6: Integrated ProcessThe general flow of information is top-down and left-to-right. Arcs below the diagonal represent the environmental parameters. The arcs above the diagonal represent the inter-model dependencies, with the top left representing the input variables from the ISHM design.A Roadmap for IntegrationThe following roadmap of research challenges has emerged from our survey of planner and scheduler integration efforts within and outside of NASA. Using Surrogate Models to Reduce Computational Complexity of Integrating Simulation and PlanningOne main issue that limits the integration of automated planning techniques and real-world simulation models is that automated planning usually requires many evaluations of the simulation models. Due to the high computational complexity of such simulation models, however, a direct integration is often computationally infeasible. One possible solution is to approximate the computationally expensive simulations by less expensive surrogate models (similar to Drabble’s work described above.) There are many different surrogate-modeling techniques in the literature (see, for instance, Myers and Montgomery 1995; Sacks et al. 1989; Farhang Mehr et al. 2004). Among these techniques, the most common approach is to choose a sample of design points via a classical Design Of Experiment (DOE) technique and fit a polynomial to the response values. These techniques, however, are mostly appropriate for physical experiments that have inherent randomness, and thus, are not capable of providing sufficiently accurate surrogate models for deterministic computer simulations. This raises a need for more advanced approaches that can act as a medium between deterministic computer simulations and automated planning to reduce the computational complexity of the overall integrated framework. Incremental Simulation ArchitectureTo support planners during the planning process, simulators need to provide the capability of running partial simulations of fine granularity.  An incremental simulation capability of this nature can be invoked by a planner after a smaller number of commitments (search steps).  This architecture can provide rapid feedback to planners that can be used during the planning process.  Such an architecture has an advantage over approaches that abstract the simulation, in that the most precise model is used to evaluate the plan; however, it may generally be slower than the surrogate model approach.  The naturally hierarchical nature of many simulations lends itself to such an approach.  Planners that append actions to the end of a plan (called “progression planners”) can make direct use of such simulations; however, the “feed-forward” nature of simulations may make it difficult to integrate with planners that plan from goals to initial states (called “regression planners”), or planners that generate plans with possible conflicts (e.g. “partial order planners”).Simulating plannersArchitectural support for planners that can be called directly from simulations will enable a much finer-grained degree of simulation of processes with deliberative agents.  The loosely coupled model used by many NASA applications is suitable for simulation of a single deliberative agent such as a spacecraft or rover at a high level of abstraction.  However, it is not well suited to situations in which large numbers of deliberation tasks must be performed under widely different conditions.  Examples of this include highly concurrent, detailed simulations of single entities, or simulations involving coordinated control of many distinct entities. The generic “foreign function” interface provided by many simulators does not provide enough abstractions that support planning.  A well-thought out integration architecture that permits the description of scheduling problems in the simulation itself, referencing simulation objects, and calling upon simple, standard scheduling algorithms would greatly enhance the capabilities of simulation systems.SummaryWe have described relative capabilities of automated planning and simulation software systems and motivated their integration. We have presented several integration architectures form the viewpoint of each systems and identified strengths and limitations of each. We hope that the research roadmap presented in this paper motivates work on solving these exciting problems to produce a new and truly useful capability across a broad range of applications both in and outside of NASA. ReferencesBell, S., Rodriguez, L, and Kortenkamp, D., 2005. Using dynamic simulations and automated decision tools to design lunar habitats. In proceedings of the International Conference on Evolvable Systems. Spain.Bresina, J., Jonsson, A., Morris, P., and Rajan, K., 2005, Activity Planning for the Mars Exploration Rovers. In proceedings of the International Conference on Automated Planning and Scheduling Systems (ICAPS-05), Monterey, CA. Chien, S., Rabideau, G., Knight, R., Sherwood, R., Englehardt, B., Mutz, D., Estlin, T., Smith, B, Fisher, F., Barrett, T., Stebbins, G., and Tran, D., 2000. ASPEN - Automating Space Mission Operations using Automated Planning and Scheduling. In proceedings of International Conference on Space Operations (SpaceOps 2000). Toulouse, France. June 2000Chien, S., Sherwood, R., Tran, D., Cichy, B., Rabideau, G., Castano, R., Davies, A, Mandl, D., Frye, S., Trout, B., D’Agostino, J., Shulman, S., Doyer, D., Hayden, S., Sweet, A., Christa., A. 2005. Lessons Learned from Autonomous Sciencecraft Experiment. In proceedings of Autonomous Agents and Multi-Agent Systems Conference (AAMAS 2005). Utrecht, Netherlands. July 2005Cohen, P. Anderson. S., and Westbrook, D., 1996. Simulation for ARPI and the Air Campaign Simulator. In A. Tate, editor, Advanced Planning Technology: Technological Achievements of the ARPA/Rome Laboratory Planning Initiative, pages 113--118, AAAI Press, Menlo Park, CA, 1996. Drabble, B., 1993. Excalibur: A program for planning and reasoning with processes. Artificial Intelligence, 62:140, 1993. Dyke, D., Salt, M., Jarvis, P., and Desimone, R., 2000. Experimental Results from Integrating Planning Systems and Simulation Models. In Proceedings of the 2000 Command and Control Research Technology Symposium, Vienna, VA.Farhang Mehr, A., Li, G., Azarm, S., Diaz, A., “Meta-Modeling of Multi-Response Engineering Simulations”, Proceedings of the 10th AIAA/ISSMO Multidisciplinary Analysis and Optimization Conference, Albany, NY, 2004Frank, J., and Jonsson, A., 2003. Constraint-Based Attribute and Interval Planning. Journal of Constraints Special Issue on Constraints and Planning, vol 8 no. 4.Freed, M., P. Bonasso, K.M. Dalal, W. Fitzgerald and R. Harris. 2005. TITLE MISSING. Proceedings of American Institute of Aeronautics and Astronautics "Infotech@Aerospace" Technical Conference, September 26-28, Arlington, Virginia.Ghallab, M, Nau, D and. Traverso, P. Automated Planning: Theory and Practice. Morgan Kaufmann, 2004.Jain, A., Balaram, J., Cameron, J., Guineau, J., Lim, C., Pomerantz, M, Sohl, G., 2004. Recent Developments in the ROAMS Planetary Rover Simulation Environment. In Aerospace Conference, IEEE.Jonsson, A., Morris, P., Muscettola, N., Rajan, K., and Smith, B., Planning in Interplanetary Space: Theory and Practice. In proceedings of Fifth International Conference on Artificial Intelligence Planning and Scheduling (AIPS-00), Breckenridge, CO, USA. Kortenkamp, D., and Bell, S., 2003. BioSim: An integrated Simulation of an Advanced Life Support System for Intelligent Control Research. In proceedings of the 7th International Symposium on Artificial Intelligence, Robotics, and Automation in Space (i-SAIRAS-03)Miller, D. P. The Role of Simulation in Task Planning, in Proceedings of the 1987 Winter Simulation Conference, pp. 530-533, December 1987.Morris, R., Dungan, J., Khatib, L., Gasch, J., Hempel, P., Williams, J., and Wood, T., 2004 Coordinated Science Campaign Planning for Earth Observing Missions. In proceedings of NASA’s Earth Science Technology Conference, Palo Alto, CA. Myers, R. H., and Montgomery, D. C., 1995, Response Surface Methodology: Process and Product Optimization Using Designed Experiments, John Wiley & Sons, New York.Pisanich, G., Plice, L,, Neukom, C., Fluckiger, L, and Wagner, M. 2005. Mission Simulation Facility: Simulation Support for Autonomy Development. 42nd AIAA Aerospace Sciences Conference, Reno, NV, January 2004.Sacks, J., Welch, W. J., Mitchell, T. J., and Wynn, H. P., 1989, “Design and Analysis of Computer Experiments,” Statistical Science, 4, pp. 409-435. Staton, E., 2006. CLV Operational Availability Model version 1.0, Sverdup Technologies, Inc, Marshall Space Flight Center, Al, USA.Yen, J., Jain, A., and Balaram., J., 1999. ROAMS: Rover Analysis, Modeling and Simulation. In proceedings of Artificial Intelligence, Robotics, and Automation in Space ISAIRAS, Noordwijk, Netherlands..  Reaction Control Engines use hypergolic fuel, which is hazardous and requires special handling which imposes significant scheduling constraints.  EMBED Word.Picture.8  1QSS Group Inc.2ASRC Aerospace Inc. EMBED Word.Picture.8  