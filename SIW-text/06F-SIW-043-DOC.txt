Intelligence, Surveillance, and Reconnaissance (ISR) Behavior ModelingMr. Timothy G. DiVecchiaProgram Manager, M&S Research and DevelopmentGeneral Dynamics Advanced Information Systems10560 Arrowhead DriveFairfax, VA 22030Voice (703) 277-1824 HYPERLINK "mailto:timothy.divecchia@gd-ais.com" timothy.divecchia@gd-ais.comMr. Wilfredo V.  PerezChief EngineerDefense Training, Analysis & AcquisitionGeneral Dynamics Advanced Information Systems12001 Research Parkway, Suite 300Orlando, FL 32826Voice (407)514-2323 HYPERLINK "mailto:Wilfredo.Perez@gd-ais.com" Wilfredo.Perez@gd-ais.comKeywords:ISR, Behaviors, M&S, MLSABSTRACT:  One of the challenges over the past several years is trying to model the evolving Intelligence, Surveillance, and Reconnaissance (ISR) architectures used by our military commanders.  While the basic types of ISR behaviors [task, sense, collect, process, exploit, analyze] are typically performed; the way they are performed, and by which organization, often differ from conflict to conflict. Under IR&D, General Dynamics has continued to advance an ISR simulation they developed for Army and Joint training.   The enhanced simulation decouples the ISR behaviors from the platform that hosts them and allows the user to “configure” the behavior-host structure for each exercise.   This decoupling allows for higher fidelity (and higher classified) ISR behavior models to be used with platform models running at lower classification levels.  This paper will describe overall architecture, usage and benefits of this ISR behavior-host approach.1. IntroductionIntelligence, Surveillance, and Reconnaissance (ISR) capabilities provide critical information to today’s tactical and strategic decision makers.   ISR simulations face challenges representing the necessary fidelity while maintaining causality within the simulated battlespace.  This paper will discuss recent developments of ISR models that address these challenges.2. BackgroundIn the mid 1990s, the Joint Simulation System (JSIMS) was developed to provide a training and mission rehearsal tool for the Joint Warfighter and the individual service commands.   General Dynamics was responsible to develop the next generation tactical intelligence models to replace legacy service simulations such as the Army’s Tactical Simulation (TACSIM). As participants of the JSIMS architecture team, General Dynamics also led the creation of the JSIMS Battlespace Abstract Model (BAM) for ISR. The BAM provided guidance for all JSIMS intelligence components (tactical and national).When the JSIMS program ended in 2002, General Dynamics received government approval to enhance and develop the ISR framework and models for its internal research and development (IR&D).   The IR&D initiative was named the Reconfigurable Asymmetric ISR Development (RAID).This paper will discuss the ISR modeling component of RAID.   These models use the same architecture and design used for the Army’s Warfighter’s Simulation Intelligence Module (WIM) and the Joint Tactical Intelligence Module (JTIM) being considered for use at JFCOM. The RAID ISR component uses generic, data-driven models to simulate the following multi-INT sensor systems:IMINT –EO, IR, SAR, MTI, FTIELINTCOMINT MASINT Thermal, Acoustic, Seismic, Magnetic, Doppler RadarHUMINTLRS, DOCEX, IPW, NCS, CFSOThese sensor systems were designed for with two primary goals in mind:  Support Military training exercises for commanders and their intelligence staffs in a constructive simulation HLA Federation mode. Support concept development and analysis of ISR architectures and performance in a course-of-action (COA) standalone mode.These two goals drove the overall architecture to embrace flexible composition, and exposure to internal data to support metric measurements.3. ISR RepresentationMost ISR simulations are very good at modeling the physics of sensor systems.  Line-of-sight calculations, frequency link-closure algorithms and radar-cross-section computations can all be found in a host of textbooks.  The challenge with modeling ISR systems is more than just the sensor.  There are operational elements responsible to ensure the sensor is configured and operating.  There are processors to correlate sensor feeds.  There are intelligence personnel processing and exploiting the sensor feeds.  All of these non-sensing components of an ISR system are typically in the simulation and susceptible effects from the simulation environment.Data links and environmental effects play a large part in the effectiveness of an ISR system.    Weather and temperature can affect equipment performance.  There are also aspects of human efficiency that need to be modeled.   An operator with several months in-theater experience may be more efficient than two reservists who just arrived.   Also the platforms that host, and the personnel that perform the operations, processing and exploitation activities may be damaged or unable to support the necessary functions.This level of representation also provides benefits when modeling ISR capabilities of a threat. To disrupt and/or disable a threat’s information infrastructure, military operations are often planned against critical data links and processing centers, rather than a threat’s entire suite of sensor platforms.   Discretely modeling the ISR information flow also support the construction of asymmetric threats and their atypical work flows.  In the early years of the JSIMS effort, General Dynamics led the development of an ISR battlespace abstract model that described the intelligence functions and the data/information work flow.  It was important to capture the various data types and when and where that data “moved” around the battlespace. This architecture helped define the data and interactions between the various tactical and national ISR model developers.Figure 1. Intelligence Modeling Architecture4. ISR AnalysisISR systems and their products enable decision making processes.  In order to determine the success and “worth” of an ISR system, one must understand how the systems are configured, employed, and ultimately how their products are used.   A system can collect exactly what it was tasked, and yet provide no valuable input into specific decision process.  Was the ISR system successful?  A common question arises in ISR training and analysis simulations.  What was not collected and why? It’s easy to inspect the final intelligence products and trace the reported detections back to the sensor and specific mission tasking.  But what about the critical threat aspect that was not collected; that weapon or specific radar signal?  In order to meet training and analysis objectives, the ISR simulations need to be able to store not only intermediate data, but algorithm outputs (i.e. when objects are not sensed due to lack of line-of-sight, the simulations need to be able to log that data for analysis).The RAID ISR models, their data products and algorithm outputs are all available for capture and storage into a repository for further analysis.To extend the value of the ISR models, the intermediate data was also included in the overall data model exposed via the HLA FOM.  This allowed other analysis tools to use the ISR data to support their needs.5. ISR ImplementationUpon implementing the ISR abstract model, including the intermediate data, it was determined that certain portions would not need to be automated at this time.   After examining the intended training and analysis exercises, most of the collection management and analysis tasks were to be performed by live users (either role-players and/or training audience members).   Therefore, the implementation focused on the sensor system operations, execution and initial exploitation.  The initial set of intelligence behaviors include Tasking, Operations, Sensing, Processing, Exploitation, and Analysis SHAPE  \* MERGEFORMAT Figure 2. Implementation Models5.1 Tasking and AnalysisTasking and Analysis behaviors were not automated since, as we mentioned earlier, those functions were performed by live personnel. However, there was still an important function that each behavior needed to model.  The tasking and analysis organizations (units) were often “represented” in the simulation battlespace and were susceptible to “simulated” damage, weather and terrain effects.  The ISR tasking and analysis behaviors ensure the simulation representations were healthy enough (i.e. operational) to exchange tasking and intelligence products.  If not, no ISR information would not be accepted and/or sent from the other simulated ISR behaviors.5.2 Operations Operations behaviors modeled those organizational elements that are required to control the operations of the sensor.   If the sensors do not require continuous operator support, this behavior is often not used.5.3 Sensing Sensing behaviors simply apply the physics of the sensor to the simulated battlespace and generate a set of detection data.  There is no attempt to filter or correlate data at this level.5.4 Processing Processing behaviors simulate equipment-based processing of sensor data.  These processors that correlate and filter detection data can be co-located with the sensor or resided in remote facilities.5.5 ExploitationExploitation behaviors simulate the initial human-based processing of sensor and/or processor output.   These behaviors typically result in single-source intelligence reports (i.e. IPIRs, TACREPs, SALUTEs, TACELINTs)5.6 Intermediate DataEach of the behaviors ingests a specific type of intelligence data, and generates another.  All of the data formats and content are defined in the HLA FOM and are accessible by analysis applications SHAPE  \* MERGEFORMAT Figure 3. Data Products6. ISR Behavior-Host ApproachWhen General Dynamics began developing an ISR abstract model, we found that while the subject matter experts (SMEs) agreed on the types of ISR behaviors (“task”, “operate”, “collect”, “process”, “exploit” and “analyze”),  they differed on who and where the functions were performed .   It was determined that the ISR behaviors would be completely decoupled from the platform and organization models that host them.  This allows the sensor system to be quickly composed to meet current ISR architecture and work-flow processes.   This also provides flexibility to rapidly construct new concepts for future ISR systems and architectures.   SHAPE  \* MERGEFORMAT Figure 4. Hosted BehaviorsSensor systems are composed by first selecting and configuring the set of behaviors needed to model it.  Next, the data inputs and outputs to each behavior are assigned, thus creating a data work flow among the behaviors.  Finally, each behavior is “attached” to a host simulation object in the battlespace.  Multiple behaviors can be attached to a single host as needed.The behavior-host approach also proved successful in hosting on platforms from other simulations.  As an example, we have hosted ISR behaviors on platforms being modeled externally in a DIS simulation.7.  Multiple Levels of Classification Another design factor driving the behavior-host approach was classification.  Some of the ISR behaviors operated at a higher classification than the host platform carrying it.  By separating the two as distinct simulation objects, we were able to run both, in separate simulation environments. A one-way guard allowed the state of the “host” to be reflected into the “higher” simulation running the ISR behavior.  SHAPE  \* MERGEFORMAT Figure 5. Security Guard ApproachOne of the security-related challenges involved handling the information flow of systems where the various behaviors operated at different classifications.  We were able to mitigate this by imbedding the work flow routing information (i.e. who this behavior communicates with) as an attribute of the behaviors.   We also leveraged the HLA event mechanism to allow behaviors to pass information via HLA events.  These events could pass through a security guard in one federation and be “inserted” into another federation, where other ISR behaviors would receive them based on their interest expressions.There are some obvious issues where behaviors in a higher classified environment needed to communicate to a behavior in a lower environment.  While our ISR simulation does not automate that ability, by exposing our information in an HLA FOM, we more easily enable security guards approved for downgrading, to handle this exchange.8.	ISR Simulation Challenges - ConsistencyEven a robust composable and extensible ISR simulation must address consistency with the battlespace.  Most legacy ISR simulations are developed as closed “black-box” systems.  Tasking is sent in and intelligence products come out.  This is primarily due to classification concerns that include issues like “the fact of” certain intelligence capabilities, and “processes associated with” certain intelligence systems.  Even if the ISR simulations expose some capabilities, often the representation of the threat environment is not sufficient to meet the collection and reporting needs of the sensor systems.  As ISR simulations enhance their perception of the battlespace” and add realism to intelligence reports, they introduce discrepancies.  The enhanced ISR reports, with robust content, do not correlate with the “simulation battlespace” therefore; often resulting in negative training and erroneous analysis.A good example of this is the positioning of equipment/platforms belonging to a threat unit.  Large scale simulations often use templates of preset offsets to position equipment from a center location of a unit.  If the ISR models reported the simulated location of the equipment, training audiences, using C4ISR devices with real-world maps, display the equipment in lakes, atop mountains, off bridges or even stacked atop terrain features like tree lines.  When the ISR simulations adjust the reported locations, the C4ISR displays look “plausible”.  When they tried to use the C4ISR tools to target the threat equipment, however, they missed.  The locations of the threats in the simulated battlespace (i.e. the combat simulations) did not correlate to the locations reported in the intelligence reports. In the end, what we discovered was the most important lesson learned for ISR modeling for training and analysis:It is more important to be consistent with the simulation than to have better sensor/product resolution.For this reason, the RAID ISR simulation limits the amount of enhancements and relies on threat data attributes and events defined in the HLA Data Model. Author BiographiesTIMOTHY DIVECCHIA is a Senior Systems Architect at General Dynamics Advanced Information Systems.  Mr DiVecchia has spent over 20 years developing ISR simulations for tactical and national systems.  He worked on NWARS and TACSIM, as they supported training exercises with ALSP and HLA.  He was the chief architect for the WARSIM Intelligence Module (WIM) and member of the JSIMS Architecture Group. Mr. DiVecchia authored the intelligence section of the JSIMS Battlespace Abstract Model (BAM) and was a member of the group that defined JSIMS Abstract Model (JAM), currently used as the basis for the OneSAF Objective System (OOS).  Mr. DiVecchia has a Bachelor of Science degree in Computer Science and Mathematics from James Madison University.WILFREDO V. PEREZ is a Chief Engineer at General Dynamics Advanced Information Systems.  Mr. Perez has spent over 25 years developing simulations for naval combat, radar, and ISR systems.  He was the software manager for the WARSIM Intelligence Module (WIM). He is the chief engineer and program manager for the RAID system. Mr. Perez has a Bachelor of Science degree in Physics from the University of Puerto Rico and a Masters of Science in Electrical Engineering from the University of Maryland. 