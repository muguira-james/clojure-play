Joint Modeling and Simulation System (JMASS)What it does,… and What it doesn't!Robert J. MeyerASC/AAJ (JMASS JPO)2145 Monahan Way, Building 28Wright Patterson AFB, OH 45433-7017937-255-3969, ext 3818Bob.Meyer@wpafb.af.milKeywords:Object-Oriented, Modeling, Simulation, Architecture, Interface Standards, ToolsABSTRACT:  For the past 10 years, JMASS has been something of a "third rail" in the Department of Defense (DoD) Modeling and Simulation (M&S) arena.  In this paper, the author dares to touch this "third rail," peeling back the layers of myth and misunderstanding by laying out how this engagement/engineering level M&S system breaks new ground in the realm of Object-Oriented (OO) digital constructive simulation.  While other M&S systems deliver a complete, integrated simulation as their end product, JMASS instead provides an architecture, interface standards and a set of GUI-based tools, which can be used to build models to those standards and integrate these models with the architecture components to in turn build simulations.  While other M&S systems have their evaluation mechanisms embedded and for the most part pre-determined, JMASS forces applications to define those mechanisms in re-usable, re-configurable components.  This challenges potential users to thoroughly understand and decompose their problems and at the same time offers them extraordinary flexibility in implementing solutions to those problems.  While other M&S systems leave interfaces as an "exercise for the reader," JMASS uses powerful code-generation techniques to lock-in those interfaces, virtually assuring code reliability and stability.  This paper expands on these and other differences between JMASS and other M&S systems, illustrates convincingly how the JMASS approach constitutes a new paradigm in DoD M&S, and gives crucial insight into the product and process changes commensurate therewith.1.  A Brief Introduction and BackgroundPerhaps more so than any other DoD M&S endeavor, JMASS has evoked visceral reactions from just about everyone who has crossed its path during its decade-long evolution.  While exploring the various viscera involved in these reactions may make for an interesting study, it is not the purpose of this paper to so do.  Suffice it to say that aspects of the JMASS approach have been both enchanting and unsettling to the M&S community – quite characteristic of the type of changes in the way we do business that are often lumped together under the moniker of "paradigm shift."Rather, this paper's purpose is to show how "truths" about the JMASS architecture, interface standards and Graphical User Interface (GUI)-based tools force practitioners in the engagement/engineering level M&S arena to look at their problem domains just a bit closer and to implement solutions just a bit differently.1.1  What JMASS is.For the purposes of this paper, JMASS consists of the parts contained within the triangle labeled "Tri-Service Program" in Figure 1.1.  This specifically includes:the architecture, consisting primarily of a simulation engine and associated servicesinterface standards between this architecture and the various system and phenomena models which might make up a JMASS simulation a variety of GUI-based tools to assist in this process, all the way from building a model to analyzing results of a simulation run.An in(tro)spective look at Figure 1.1 raises perhaps as many questions as it answers, the first of which could easily be, "If the triangle represents JMASS, then what about those items outside the triangle?"  This question leads directly to our first "truth" of JMASS.Figure 1.12.  JMASS is not a simulation.What gets delivered on the JMASS CD is an architecture and associated tool set, which supports the building of models, the combination of models into a simulation, the execution of simulations, and the post-processing (i.e., examination) of the results (i.e., output data) of executions of simulations.  No models or simulations, other than very simple tutorial examples, are delivered on the distribution CD, i.e., you cannot usefully "run" anything on the CD.  No analysis of any sort is possible using just the JMASS software as it comes on the delivery CD.This apparent lack of utility differs considerably from what one normally gets when taking delivery of any other DoD M&S system, whether it be a legacy tool such as Enhanced Surface-to-Air Missile Simulation (ESAMS), or a more current development such as Joint Warfare Simulation (JWARS).  At worst, the analyst may be called upon to provide certain configuration data for specific system or phenomena representations when using these other tools, but with JMASS the analyst must provide not only configuration data but the software representations of the specific systems and phenomena themselves.In the current vernacular, this could perhaps be described as something akin to that dreaded phrase often associated with holiday gift-giving – "Some user assembly required!"  An alternative, perhaps better analogy might be to that other dreaded phrase from the same time of year, "Batteries not included," or more accurately in the case of a JMASS software delivery, the reverse of this phrase.In perhaps a somewhat tortured convolution of these two analogies, getting the JMASS CD is something like having only the batteries (simulation engine) and the assembly tools (toolset), and then having to go shop for the body, wheels and remote control unit (models) in order to build your child's new toy truck (simulation).By way of further illustration and also introduction of an application example, consider the analytical problem of assessing the survivability of an aircraft with onboard Radio Frequency (RF) Electronic Counter-Measures (ECM) as it penetrates the launch envelope of an RF surface-to-air missile (SAM) system (or conversely, the lethality of such a SAM system against that aircraft).Both a JMASS-based simulation and any one of several legacy simulations could be used to address this problem, but as Figure 2.1 depicts, the two simulations are quite different "underneath the hood."  Typically, the legacy simulation possesses, to some degree, the aspects therein listed (i.e., monolithic code, etc.) while the JMASS approach generally exhibits quite different characteristics (i.e., modular code, etc.)  While many of these aspects could be argued by advocates from both the legacy and JMASS camps, that is not the point of this paper, nor is it the point of this explanation of the first "truth."The key notion to take away from Figure 2.1 is that the structure of a JMASS-based simulation is considerably different than a functionally similar/equivalent legacy simulation.  Moreover, this figure provides a visual reinforcement of the first "truth" – that JMASS is not a simulation.  The figure parts in purple (the text box containing "Simulation Engine," the left adjacent vertical dashed line, and the horizontal dashed lines between "Acq Radar" and "Track Radar," "Track Radar" and "Missile," etc.) visually represent what is embodied on the JMASS CD – a simulation engine and interface standards which allow models to plug individually into it.1In summary, the "truth" that JMASS is not a simulation derives from the fact that not all the piece parts needed to form a simulation are present on the distribution CD.  While this incompleteness may seem to be a weakness, it is really a strength in disguise, as subsequent "truths" and their associated explanations will illustrate.Figure 2.11 To be more precise, the current CD also includes the previously-mentioned GUI-based toolset, as well as a model of the RF Env(ironment).  This RF environment model may be maintained and distributed separately in the future.3.  All JMASS action is player-basedNothing happens in a JMASS-based simulation without the intent to make something happen by at least one model (or player) in that simulation.  For example, the calculation of miss distance at the point of closest approach for a missile intercept of a target must be done by some model (player) in the simulation - the JMASS architecture "knows" nothing about such things and "cares" even less.  This simulation approach is sometimes known as "free-play" - the models are "free" to "play," but they (or other models) must also capture and report important event data if the results of this "free play" are to be studied and analyzed further.Said another way, nothing in the JMASS software (i.e., the simulation engine, services, tools, etc.) as delivered on the CD causes any action to take place in a simulation built using this software, except for starting and stopping the simulation.  Thus, if any useful activity is to take place between "start" and "stop," it must be initiated by one or more of the models (players) in the simulation.It might be useful as an aside to discuss the somewhat clumsy construct, "JMASS-based simulation."  The word usage is actually quite precise in this term, since one uses JMASS software to build a (JMASS-based) simulation, and since JMASS itself is not a simulation, as the previous discussion highlighted.  Alternately, the term "JMASS simulation" could be used as well, as long as it is understood to mean "JMASS-based simulation."Continued reference to the previously introduced example depicted by Figure 2.1 may prove useful in elaborating this "truth" about action in a JMASS simulation.  In this case, typically the Acq(uisition) Radar model (or player), the RF Env(ironment) player and the Aircraft player would interact to simulate the process of detection (or acquisition) of the aircraft by that radar.One way this could be done is for these three players to agree on a digital (or data-based) representation of RF signals, and then exchange these signals in a logical order.  The Acq Radar player could "transmit" (send) a set of data representing its signal to the RF Env player, who in turn could account for propagation losses and other effects between the Acq Radar and the Aircraft and then send the signal data on to the Aircraft to be "reflected" back again "through" the RF Env, eventually arriving back at the Acq Radar to be "received" and processed.As this process (which mimics closely the real world of radar processing) continues, eventually the Acq Radar may or may not "detect" or acquire the Aircraft.  In fact, this approach has been used in current applications of JMASS to the arena of RF SAM engagement simulation.What is key to remember in this "truth" discussion is that all of this activity must be initiated, performed and saved by the models/players in this JMASS simulation, and thus must be designed into the behavior and structure of those models/players.  Said another way, what happens in any JMASS simulation is a product only of the models/players in that simulation.  In terms of the earlier holiday toy analogy, what sort of toy (truck, robot, doll, game, etc.) you build is not influenced whatsoever by the batteries (simulation engine) or the assembly tools (toolset), but is solely determined by the piece parts you bring to the assembly process.  That having been said, JMASS does assist in this process, as the next "truth" reveals.4.  JMASS is interface-ignorantThe JMASS architecture (i.e., simulation engine and interface standards) is blissfully unaware of the content, intent or extent of model-to-model communication before, during or after simulation execution.  The architecture, through its control of the "port" mechanism, ensures that appropriately-formatted conduits are present to support data exchange among models in a JMASS simulation, but is not "cognizant" of the values, volume or validity of the data flowing among models during execution.Thus, continuing the example of Figure 2.1, the signal data sets that the Acq Radar, RF Env and Aircraft players send between each other would be implemented as a port in the JMASS simulation.  Once the developers of those players agree on a form(at) for the signal data, JMASS (simulation engine and toolset) supports the construction of the "port" mechanism which facilitates the transfer of that data between the thereby "associated" models.Using the toy building analogy further, one could think of the JMASS port mechanism support as follows.  First, one might decide that the piece parts (models) of the toy will be held together with screws of certain types and sizes (ports).  Given this form(at) of interface, the appropriate drill, tap and die tools (toolset) would be used to "prepare" the piece parts (models) for assembly.  Lastly, a (set of) screwdriver(s) (toolset) would be used to put the piece parts (models) together with the batteries (simulation engine) into the finished toy (simulation).Another analogy which might be useful is with the High Level Architecture (HLA) standards and services.  Attributes (data) can be passed among simulations (note the distinction – simulations, vice models) via the data distribution (and other) service(s) in an HLA federation (JMASS simulation).  The ability to do this is supported by the RTI (simulation engine) and various tools (toolset).  One primary, already-noted distinction is that the HLA yields interoperability among simulations, while JMASS supports interfacing between models.Another look at Figure 2.1 shows that the portion colored  blue (the text box containing "Model Interfaces" and the vertical dashed line to its right) visually represent the port mechanism which JMASS provides to support inter-model communication.  While it could be argued that this is really part of the JMASS architecture, it is more instructive to show it separately, since the form(at) of these ports at run time is wholly determined by the models which have collaboratively defined this form(at).Once again, the key point to take away from this "truth" discussion is that JMASS (simulation engine and toolset) is not "cognizant" of any semantic or syntactical aspects of model-to-model data exchange in a JMASS simulation.  The next "truth" will draw an important distinction with respect to one implication of this current "truth."5.  Compliant is NOT interoperableA model which is found to be JMASS-compliant (e.g., passes compliance testing) is not guaranteed to be (meaningfully) interoperable with other compliant models when combined in a JMASS simulation.  While true that compliance more or less guarantees executability (i.e., a simulation made up of JMASS-compliant models will run, or execute), interpretation of model-to-model interfaces is outside the purview of JMASS compliance and must be consistent among models in a simulation for them to be considered "interoperable."Consider the RF SAM engagement analysis example from Figure 2.1.  Even though the developers of the Acq Radar, RF Env and Aircraft players agree on a form(at) for the signal data, and the JMASS software has provided a compliant "port" through which this data can be exchanged, meaningful exchange of this signal data may or may not actually occur.  For meaningful interfacing among models sharing a JMASS "port," these models must agree on the content (semantics) of the signal data as well as the form(at).The key point to realize in this "truth" is that JMASS (simulation engine and toolset) has no control over the meaning of model-to-model interfaces, thus it is not too surprising that successful JMASS compliance testing does not prove interoperability in its truest sense.  This could raise a question about what the purpose and efficacy of JMASS compliance testing are, or for that matter what the benefit of JMASS compliance as a concept is.While the discussion of JMASS compliance is a topic better suited for another paper, one example of what the compliance concept embodies could be useful.  This example concerns model-to-model communication – to be JMASS-compliant a model must use the JMASS-provided "port" mechanism for all such communication.  Said another way, no "backdoor" exchange of information between models is allowed.  While this may seem at first blush to be arbitrary and unnecessarily restrictive, this compliance criterion actually promotes the greater good, as the final "truth" of JMASS will illustrate.6.  JMASS is NOT "plug and play"All executable software in a JMASS simulation, i.e., players and their components as well as the simulation engine and associated services, must be run through the code generation process to effect the JMASS interface standard.  Once built in this fashion, JMASS players and their components can be combined into simulations as if they were truly "plug and play," but a more accurate description of the overall process is "plug and build," or perhaps "plug and build and play."The JMASS code generation process enforces not only the interface standards between the models and the simulation engine and services, but also the port-based communication between/among the models.  By so doing, JMASS further enforces compliance to the criterion of no model-to-model communication other than the port mechanism.  This criterion ensures that models can be reused in other JMASS simulations, since the inter-model communication mechanism is highly visible as part of the code generation process.One last use of the toy assembly analogy might be useful.  If one of the piece parts (model) had an alternative, non-standard way of connecting or interfacing with the other parts (models), it is quite likely (at least for most home-grown toy assemblers) that the toy as built (simulation) may not match or meet the original expectations!  It is even quite likely that this non-standard interface (JMASS non-compliant inter-model interface) may not be able to be built with the assembly tools (toolset).Thus the "plug and build and play" nature of JMASS, rather than restricting reuse as it may appear to do, actually promotes reusability through the enforcement of the inter-model communication compliance criterion, as well as many other aspects of the JMASS interface and compliance standards.  This "truth," in conjunction with the previous ones, raises some implications of the very different way that JMASS approaches the whole business of modeling and simulation.7.  Implications of these JMASS "truths"The "toy assembly" nature of JMASS simulations raises the question of who builds the piece parts (and how) that must ultimately come together to form a simulation.  It is fairly apparent that this situation naturally leads to the distributed development paradigm, which in turn has its own further implications, such as coordination difficulty, dedication of resources, etc.The interface-based nature of JMASS is at once extremely flexible and challenging.  The fact that one can define virtually any simulation-based problem in a JMASS way carries with it the stigma of having to define that problem sufficiently to assemble and configure the appropriate piece parts to build that JMASS-based simulation.  In the toy analogy, one can build almost any toy, but one has to approach building any specific toy very carefully in terms of the choices of piece parts and their interfaces.Another implication is that reuse of models, components, and other piece parts can occur at all levels, but will not necessarily occur unless promoted by some process or infrastructure.  One aspect of this process/infrastructure will be that requirements for model and component capability should be documented and coordinated with as many potential users of those models and components as possible to ensure the maximum reuse possible.These and other implications of the JMASS paradigm are worthy of more expanded and studied treatment in a separate paper and/or forum.  Suffice it to say that the JMASS approach really does reflect a new way of doing business in the modeling and simulation world, one whose promise is limited only by the imagination and determination of those who would use it.Author BiographyROBERT J. MEYER is the Navy Senior Engineer at the JMASS Joint Program Office (JPO), located at Wright Patterson AFB, OH.  He is on long term loan from his home office at the Naval Air Warfare Center, Weapons Division (NAWCWD), China Lake, CA.  His decade-long association with JMASS has mostly been as a member of the Joint Technical Coordinating Group on Aircraft Survivability (JTCG/AS) engagement-level analysis community, looking for ways to ensure that JMASS meets their needs.  His current role at the JMASS JPO includes representation of this same community, with the same goal of a JMASS-based simulation capability for engagement-level analysis. EMBED Word.Picture.8   EMBED Word.Picture.8  