Bandwidth Utilization/Fidelity Tradeoffs in Predictive FilteringBernard P. Zeigler George BallHyup ChoJ.S. LeeHessam Sarjoughian AI and Simulation Group Department of Electrical and Computer EngineeringUniversity of Arizona,Tucson, Arizonazeigler@ece.arizona.edu Keywords:Predictive filtering, predictive contracts, discrete event, fidelity/performance tradeoffABSTRACT: In confirmation of earlier developed theory,  this paper presents some very promising empirical results obtained for tradeoff between message bandwidth utilization versus error incurred in a predictive filtering method called predictive quantization.  The results relate bandwidth utilization and error against quantum size for the same federation executing on DEVS/HLA (an HLA compliant distributed simulation environment) in Unix and NT networking platforms.  The theoretical and empirical results so far indicate that predictive quantization can be very scaleable due to reduced local computation demands as well as having extremely favorable bandwidth requirement reduction/simulation fidelity tradeoffs.  Since the DEVS formalism was employed to formally characterize predictive contract mechanisms.in a generic manner, application in distributed simulation environments, whether HLA-compliant or not, is facilitated.  QuantizationIn recent  work we have developed a theory of predictive filtering which takes into account the global error due to error propagation  ADDIN ENRfu [1, 2]. Previous analyses  ADDIN ENRfu [3] of predictive contracts’ accuracy/performance tradeoffs have assumed that open loop analysis carries over to the closed loop case.  Unfortunately, experience in numerical analysis suggests that the dynamics of feedback interaction may cause errors generated to grow without bound. The theory of quantized systems we developed provides conditions, based on a formulation of input sensitivity, under which homomorphic (error-free) quantization-based predictive filtering is possible. It shows how error can be generated if the conditions are violated and formulates a suitable concept of approximate homomorphism. We have verified the theory when applied to predictive quantization of  arbitrary ordinary differential equation models.    On this paper, we will present some very promising empirical results that we obtained for tradeoff between message bandwidth utilization (number of bits transmitted) versus error incurred.  The results plot bandwidth utilization and error against quantum size for the same federation executing on DEVS/HLA (an HLA compliant distributed simulation environment) in three networking platforms: PC LAN, Unix Ethernet, and Unix WAN.  The theoretical and empirical results so far indicate that predictive quantization can be very scalable due to reduced local computation demands as well as having extremely favorable bandwidth requirement reduction/simulation fidelity tradeoffs.  The paper also shows how the DEVS formalism is employed to formally characterize predictive contract mechanisms.in a generic manner. This allows application in distributed simulation environments, whether DEVS-based or not, whether HLA-compliant or not.The basic concept in quantization is illustrated in  REF _Ref439385901 Figure 1. Rather than represent a continuous curve by points sampled at regular time intervals, the curve is represented by the crossings of an equal spaced set of boundaries, separated by a quantum size. In classical Dead Reckoning, quantization is applied to the error between a reduced order  model and a high fidelity model of a federate ADDIN ENRf8 [9]. However, a more fundamental approach is to allow any desired object attribute to be quantized. This has two advantages  ADDIN ENRf8 [5]. First, a wider space of possible algorithms is opened up for investigation, including more direct approaches that do not require federates to keep local models of other federates. Second, it enables us to clearly distinguish the global error incurred as a result of predictive filtering from the local error that may be used to, as in Dead Reckoning, to effect a change in local models exported to others.  We’ll return to this point in a moment.EMBED PowerPoint.Slide.8Figure  SEQ Figure \* ARABIC 1 QuantizationThe baseline mechanism for quantization, called non-predictive quantization,  is illustrated in  REF _Ref439385937 Figure 2. We assume a sender federate is updating a receiver federate on a numerical, real-valued,  state variable  (dynamically changing attribute), V. In the non-predictive  approach, a quantizer demon is applied to the sender’s output which checks for threshold (boundary) crossings whenever a change in V occurs.  Only when such a crossing occurs, is a new value of V sent across to the receiver. We note that in this change-based filtering operation, the frequency of message updates may be substantially reduced, thereby reducing network traffic but potentially incurring error. The cost/benefit analysis between reduced traffic and increased error can be framed in terms of  tradeoff  curves as we shall soon discuss.  Note, for future reference,  that while message traffic is reduced,  the size of messages sent is unaffected in this approach.  The quantizer demon incurs some computation at the sender federate but this is relatively inexpensive. Such additional computation, does raise another issue – scalability, how fast does the additional computation required by a predictive filtering method grow with increasing  simulation size. Also, the receiver must be prepared to handle updates arriving asynchronously.  If synchronous updating was assumed in its design, this may require redesign – depending on the flexibility of the underlying simulation code, this may, or may not, be easy to achieve.  In object oriented designs, with flexible time management, this would not be a major issue.  To summarize, the characteristics of non-predictive quantized filtering are:Sender federate generates fixed (or variable) time step outputs.Quantizer demon is applied to sender output.This reduces the  number of messages sent (although not their size).The quantizer incurs some computation at the sender’s federate.The sender’s  model computation is unaffected.In sum, this approach is relatively easy to apply and requires minimal restructuring of the federates’ state computation processes.   However, it can incur loss of accuracy due to the receiver’s diminished state updates and this may propagate in a global error due to feedback between sender and receiver as we will discuss. The DEVS/HLA environment supports this approach through its development of quantizer objects and their automatic interfacing to the HLA subscribe/publish data distribution service. However, the concept is generic and can be employed in any distributed simulation environment.EMBED PowerPoint.Slide.8Figure  SEQ Figure \* ARABIC 2 Non-Predictive QuantizationA more efficient form of quantization is predictive quantization, as illustrated in  REF _Ref439386029 Figure 3. Here the sender employs a model to predict the next boundary crossing and time it will occur given its current state. As we will show, such computation can be quite inexpensive depending on the model used. This approach is inherently discrete-event based since the sender waits until the predicted next event (boundary crossing) time before sending its output and effecting its state change. Note that the federate need not be computing state changes during this waiting period, thus gaining computational advantage over non-predictive quantization.  Since the next boundary crossing is either one above or one below the last recorded boundary,  the sender need not send the full floating point (double word) value to the receiver. Indeed, assume that the receiver keeps track of the last boundary  and knows the quantum size. Then only one bit of information is required – for example, a +1 indicates adding   the quantum to the last boundary, while –1 indicates a similar subtraction.  Thus, not only the number of messages but also the message size – in other words, total number of bits transmitted  – can be significantly reduced in this approach.   As shown in  REF _Ref439386029 Figure 3, the stream emitted by the sender must somehow convey the boundary crossing times. Whether this incurs additional network bandwidth depends on the context.  In discrete event logical time simulations, messages can be easily time stamped. This usually involves no additional cost, as all messages are time stamped to enable strong synchronization in the accepted distributed simulation protocols. In real time simulations, preservation of the order and time spacing between messages may provide the required information without time stamping. This form of  messaging is often assumed in classical DIS (Distributed Interactive Simulation) training exercises. HLA provides the flexibility to choose among logical and real-time time management schemes. To summarize the characteristics of predictive quantized filtering are:The sender employs a model to predict  successive boundary crossings.It sends a one-bit message at crossings ( whether the next higher or next lower boundary has been reached.The main advantage over non-predictive quantization  is that both number of messages and their size can be reducedA second advantage, is that if simple predictive models are used,  discrete event prediction can also greatly reduce the sender’s state transition computation execution time and frequency. The messages must convey the time of boundary crossing. In discrete event logical time simulations, messages can be time stamped with usually, no additional cost, as this is the background approach. In real time, preservation of the order and spacing between messages may provide the required information without time stamping. EMBED PowerPoint.Slide.8Figure  SEQ Figure \* ARABIC 3 Predictive QuantizationA detailed theoretical and empirical study of the advantages of predictive quantization over non-predictive quantization is provided in  ADDIN ENRfu [1, 4].  Here we will briefly review some salient elements of this study.Generic Predictive Quantization MethodsFirst,  we note that the model employed for predictive quantization can be very simple. An approach that is fully generic for differential equation systems is illustrated in  REF _Ref439386139 Figure 4. An ordinary differential equation system (ODE) consists of a finite number of integrators connected by instantaneous derivative  functions to each other and to the external interface.  A straightforward mapping of such a network on to a distributed equivalent is as follows: EMBED PowerPoint.Slide.7  Figure  SEQ Figure \* ARABIC 4 Mapping Differential Equation Systems directly to Distributed Discrete Event FormEach derivative function is mapped to a persistent function element and each integrator is mapped to a predictive quantization equivalent while preserving the interconnection topology.  Basically, a persistent function element receives event inputs produces the output of a derivative function after any one of the inputs changes.  The predictive quantization integrator (PCI) is basically linear extrapolation as illustrated in  REF _Ref439386169 Figure 5. The time to next boundary crossing is basically the quantum size divided by the input (derivative). The boundary is predicted either to be one up or one down according to the sign of the derivative. We note that when an input event is received, the state is updated using the old input before recalculating the predicted crossing. This provides an important correction for error reduction. EMBED PowerPoint.Slide.8Figure  SEQ Figure \* ARABIC 5 Predictive Quantization IntegratorApplication to Dead ReckoningA second application of interest is to dead reckoning employed in vehicle training simulation exercises. Recall that the conventional approach is employ a reduced order model at each federate which represents the motion of its high fidelity vehicle model and is exported to other federates.  Typically, the reduced order  model is a  2nd order extrapolator that works on position, velocity and acceleration (p,v,a) updates. These updates are sampled and sent to other federates only when the error, as determined by a federate’s comparison with its high fidelity model, exceeds a given threshold.  Two  alternatives to the conventional approach that employ predictive quantization can be formulated:Direct application to the models involvedDistance-based predictive quantization.In the direct application,  the predictive quantization approach can be applied to the reduced order model, the high fidelity model and the error comparator ( REF _Ref439432112 Figure 6).  For  the 2nd order extrapolator, the time to next crossing and the next boundary can be simultaneously  determined by the smallest positive  root of an easily formulated algebraic solution  with parameters, quantum size, position, velocity, and acceleration. Application to the high fidelity model would employ the generic ODE mapping discussed above. With the quantum size set as the error tolerance, the error comparator would need to determine only whether the +1,-1 inputs from the models are different to trigger a sampling of the (p,v,a) vector and its transmission to other federates. While this implementation does not affect the number of state updates needing to be exchanged among federates, it can significantly reduce the internal computation within a federate by capitalizing on the discrete event efficiency of the predictive quantization approach as discussed above. A less attractive alternative – available when the high fidelity model cannot be easily restructured into predictive quantization form -- is to employ non-predictive quantization for  the latter. EMBED Word.Picture.8  Figure  SEQ Figure \* ARABIC 6 Predictive Quantization formulation of 2nd order extrapolator for Dead ReckoningWe are also developing a concept of dynamic, and in particular, distance-based quantization as a second possible alternative to conventional dead reckoning.  As illustrated in  REF _Ref439386270 Figure 7, in this approach a quantum size manager would allocate quantum sizes for communication between pairs of federates as a function of their distance in “routing” space.  Indeed, this scheme can be viewed as a refinement of the routing space mechanism implemented in HLA which control data exchange among federates in all-or-non fashion. The proposed scheme employs variable quantum size to reduce message traffic in more finely-tunable fashion.This approach has the advantage that each federate need no longer maintain a compliment of  reduced order models of other federates, thus greatly reducing the local computation. However, a potential area of concern for scalability is the of the quadratic list scanning required for quantum management. Thus an efficient scheme must be designed to properly test this alternative.  EMBED PowerPoint.Slide.8Figure  SEQ Figure \* ARABIC 7 Distance-based Quantization Scheme Scalability issuesAs already indicated, the computational cost incurred by a predictive contract method must be taken into account in considering its scalability to large simulations. A view of this issue is presented in  REF _Ref439386320 Figure 8 which summarizes results obtained so far  for the number of messages, total number of bits sent, and number of computations incurred by a sender in the quantization-based methods discussed above. The scalability of the  predictive quantization method versus its non-predictive counterpart is apparent. While both have the same message reduction curves as a function of quantum size (a), the predictive mechanism enjoys the same reduction curve in number of computations due to its discrete event nature. Also, shown is reduction in total  number of bits sent due to the predictive mechanisms reduced message size. EMBED Word.Picture.8  Figure  SEQ Figure \* ARABIC 8 Scalability of Predictive QuantizationTo summarize, quantization, especially in predictive form,  appears to have excellent scalability properties. For the latter, the incurred computation cost can actually be reduced with increasing quantum size. Computational complexity enters the picture again when we go on to consider quantum size management with the distance-based alternative to conventional dead reckoning.   The DEVS/HLA environment will provide the platform for investigating this issue.Error/Message Reduction TradeoffAs mentioned earlier, with regard to error, we make the distinction between local and global error.  In the Dead Reckoning paradigm, local error is the federate-measured difference between its high fidelity and its reduced order model. However, maintaining this error below threshold cannot guarantee control on global error. The latter is the deviation from true global state that would prevail in the absence of predictive filtering. This is so since remote federates are making judgments based on the their local reduced order representations before they are updated at error threshold crossings. During such periods, errors may be introduced in their responses, propagated globally and fed back for further accumulation. EMBED Word.Picture.8  Figure  SEQ Figure \* ARABIC 9 Bandwidth Utilization/Error TradeoffThe theory we have developed takes into account the global error due to predictive filtering. We have formulated and verified the theory behind this predictive quantization realization of arbitrary ordinary differential equations.   REF _Ref439386406 Figure 9 portrays  a  view  of  the tradeoff between performance and error. When plotted against increasing quantum size, bandwidth utilization can be expected to decrease, while (global) error is expected to increase.  Given an error tolerance there is a maximum quantum size that will result in errors below or equal to the threshold. At this quantum size, there is a corresponding bandwidth utilization that is incurred representing the best that can be achieved within the given error tolerance.  The tradeoff curves are favorable if the error curve rises slowly while the performance curve drops sharply.  The most fundamental pair of curves that exemplify this issue has the error increasing proportionately to the quantum size while the bandwidth utilization falls inversely proportional to the quantum size.   Indeed, we have obtained very promising empirical  results for tradeoff between  message bandwidth utilization (number of bits transmitted) versus error incurred.Pursuer-Evader Case Study REF _Ref439347158 Figure 10 depicts a Pursuer-Evader example to illustrate the use of predictive quantization. The Pursuer and Evader are coupled models of vehicles and  drivers with simple rules for pursuit and evasion. . It has a component called PursWQuant, which in turn contains a RedTank model whose states will be reflected to the Evader federate. To enable experimental study of quantization in a distirbuted simulation setting we developed a DESV/HLA model with two federates each capable of holding an arbitrary number of matched pursuer-evader pairs.  A stochastic formulation enables independent sampling for initial states and boundary crossings based on quantum size. The stochastic model is consistent with a deterministic predictive quantization model perturbed by small uniform noise.  An experiment consisted of a number of randomly initialized  identical pairs simulated for the same simulation time with the same quantum size. In successive experiments, he number of pairs was increased so as to approach network saturation conditions.EMBED PowerPoint.Slide.8Figure  SEQ Figure \* ARABIC 10. Pursuer-Evader Model and PairsThe results of  the study, as presented in  REF _Ref439347200 Figure 11, confirm the relationships presented earlier.  REF _Ref439347200 Figure 11a) shows that the number of messages generated for the same simulation run decreases sharply as the quantum size is increased, while the error grows linearly ( REF _Ref424532060  \* MERGEFORMAT b).  The increase in execution time with  decreasing quantum size is non-linear demonstrating the expected approach to saturation ( REF _Ref439347200 Figure 11c).  Finally, the message rate increases linearly with numbers of pairs as expected ( REF _Ref439347200 Figure 11d), setting the stage for the results in the next figure.EMBED PowerPoint.Slide.8Figure  SEQ Figure \* ARABIC 11. Experimental Results REF _Ref439386596 Figure 12 illustrates the utility of the quantization approach to executing large simulations with many entities.  As the number of pairs (or message rate) imcreases the execution increases non-linearly for each quantum size. Given a bound on the execution time available, the number of pairs that can be accommodated within that time, increases more than linearly as the quantum size is increased.  This is especially true for the increase from 1 to  5 when operating at network saturation levels. EMBED PowerPoint.Slide.8  Figure  SEQ Figure \* ARABIC 12  Execution Time vs Number Pursuer/Evader PairsConclusions and Further ResearchThe theory of predictive filtering we   developed takes into account the global effects of error propagation. We have verified the theory when applied to predictive quantization realization of arbitrary ordinary differential equations. We have obtained very promising results for tradeoff between  message bandwidth utilization (number of bits transmitted) versus error incurred.  A variety of studies with different  types of models including non-linear and chaotic ordinary differential equation systems have indicated the robustness of the approach.  The theoretical and empirical results so far indicate that predictive quantization can be very scaleable due to reduced local computation demands as well as having extremely favorable message reduction/error tradeoffs.We are planning to demonstrate the utility of alternatives to conventional dead reckoning including event-based versions using predictive quantization and distance-based quantization. Our hypotheses are that the event-based and distance-based quantization mechanisms will afford distinct advantages in regard to scalability, error propagation, and their tradeoff with message traffic reduction. The platform to support such demonstration studies is the DEVS/HLA distributed simulation environment. Once validated in this way, the mechanisms will be usable in other  distributed simulation environments, whether DEVS-based or not, whether HLA-compliant or not. Indeed, their formal characterization within DEVS facilitates such a formulation and guarantees that they are not constrained by environment dependent features.References ADDIN ENBbu 1.	Zeigler, B.P., DEVS Theory of Quantization, . 1998, DARPA Contract N6133997K-0007: ECE Dept., UA, Tucson, AZ.2.	Zeigler, B.P., et al., The DEVS/HLA Distributed Simulation Environment And Its Support for Predictive Filtering, . 1998, DARPA Contract N6133997K-0007: ECE Dept., UA, Tucson, AZ.3.	Bassiouni, M.A., et al., Performance and Reliability Analysis of Relevance Filtering for Scalable Distributed Interactive Simulation. ACM Trans. on Model. and Comp. Sim. (TOMACS), 1997. 7(3): p. 293-331.4.	Zeigler, B.P. and J.S. Lee. Theory of Quantized Systems: Formal Basis for DEVS/HLA Distributed Simulation Environment. in Enabling Technology for Simulation Science(II), SPIE AeoroSense 98. 1998. Orlando, FL.BERNARD P. ZEIGLER is Professor or Electrical and Computer Engineering at the University of Arizona, Tucson. He has written several foundational books on modeling and simulation theory and methodology. He is currently leading a DARPA sponsored project on DEVS framework for HLA and predictive contracts. He is a Fellow of the IEEE. This work was supported by Advance Simulation Technology Thrust (ASTT)DARPA Contract N6133997K-0007 Several possible variations on this theme, concerning for example, whether we send the actual value of V, or a modification depending on the boundary crossing. Such details are beyond the scope of this report. Again, there are variations on this theme. Physical space is standard for many applications such as training but can be generalized to other spaces. with the same well-posed conditions required for standard numerical integration methods. Although with hind sight this should have been obvious. However, our data led us to this conclusion.