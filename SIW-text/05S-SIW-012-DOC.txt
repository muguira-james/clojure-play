The Impact of RTI Performance on HLA Federation Performance - Workshop ResultsRandy SaundersJohns Hopkins University Applied Physics Laboratory11100 Johns Hopkins RoadLaurel, MD  20723-6099240-228-3861Randy.Saunders@jhuapl.eduKeywords:  RTI, Performance TestingABSTRACT: In early 2005 DMSO sponsored a workshop on the impact of RTI performance on HLA federation performance. The goal was to provide federation developers and RTI developers a forum to discuss performance issues. Both perspectives will be examined to identify possible measures that might accurately predict federation performance. In the future, it may be possible to evaluate these measures as part of RTI Verification. It is not expected that a single measure will completely characterize the RTI contribution to performance, but predictions might be made with a combination of measures in areas such as: • Network performance and bandwidth • Sensitivity to the federation design (such as publication and subscription patterns, ownership transfer patterns, number of joined federates, number of object instances, number and size of attributes, number and size of interactions, and update rates)• RTI throughput and latency • Coordination overhead (such as time advance grant, save/restore, synch points, DDM)This paper will present the workshop process, participant perspectives and results. Understanding performance implications and driving factors is important to enabling employment of M&S within network centric warfare environments.Problem DescriptionThe Federation Development and Execution Process (FEDEP) [1] defines Activity 3.2, “Prepare Federation Design”.  This activity considers the conceptual model, scenarios, and available federates to produce a design statement which describes how all the pieces will fit together.  One aspect of the Federation Design is the “Federation architecture (including supporting infrastructure design)”.  This design activity has often proven difficult to accomplish without significant trial and error.FEDEP Activity 3.1 “Select Federates” used a static concept of federate interfaces to determine which federates might be appropriate.  The SOM provides this representation.  Subsequent work in FEDEP Step 4 will build the FOM, a corresponding static representation of HLA objects within the federation.The Federation Design effort must consider more than static relationships among federates.  Many aspects of architecture and infrastructure require a richer description than “Federate A publishes attributes for Object B which are subscribed to by Federate C”.  The FOM only elaborates these attributes in static terms, like their numeric format.The HLA community lacks a common understanding of the dynamic relationships between federates.  This workshop was developed to begin the process of developing this understanding.  New measures of federate and/or RTI performance might make the Federation Design process less difficult, once the issues of these dynamics are understood.Workshop ApproachThe workshop examined Federation Design through a series of invited presentations.  Federation experiences were presented from a number of programs which have used HLA.  In addition to federation specific concerns, the presentations addressed general rules for design of federates to ease Federation Design.  During each presentation, comments were collected to categorize the performance requirements of the federation.  The results of this requirements collection are in Section 3 of this paper.Each of the RTI vendors presented the performance considerations they examined in the design of their products.  They also gave their perspective in the federation requirements previously collected.A bibliography of prior RTI test publications was distributed and presentations were made by some members of the test community.  Comments were collected during these test discussions to try and identify metrics applicable to the previously identified requirements.  The results of this metrics collection are in Section 4 of this paper.To compare these metrics and results the participants developed a cross-correlation matrix.  The effectiveness and utility of each proposed metric was evaluated.  To summarize, the metrics were prioritized based on their utility in informing future Federation Design efforts.  The results of the prioritization are in Section 5 of this paper.The final workshop agenda and speaker identification is shown in Figure 2.1Table 2.1 Final Workshop List of Speakers TopicSpeakerJoint National Training Capability Warren BizubAPL Integrated Mission Simulation Joe KovalchikNetwork Based Defense Björn LöfstrandMATREX Federation Keith SnivelyUSAF Distributed Mission Operations Jerry SzulinskiJSIMS Performance Jeff SteinmanHLA Performance; JDEP Federation Perspective Alan RiefferFOM Agile Federates Annette WilsonHigh Performance Computing and HLA Jeff SteinmanMäK RTI Doug WoodPitch RTI Björn MöllerRTI-NG Pro Annette WilsonBoeing Testing Bill TuckerPerformance Issues in HLA Time Management Richard FujimotoHigh Latency and HLA Mark HazenDMSO and the Role of Policy Chris TurrellHLA Evolved - The Role of StandardsRoy ScrudderPerformance RequirementsAbout 15 Use Cases were suggested. including alternatives, to identify the performance requirements.Six cases were synthesized to generalize the analysis:Use Case A = Real-time platform federation with some slow network links.Use Case B1 = Analysis federation with unexpected serialization of processing.Use Case 99 = Federation where federate code changes are not acceptable and adjustment/mapping must take place in a bridge/gateway.Use Case F = Systems engineer in early FEDEP steps trying to understand performance drivers BEFORE picking federates or RTIs.Use Case 120 = Federation containing HLA 1.3 federates, DIS gateway to sims, and TENA gateway to live range converts to HLA 1516.Use Case TS = Tuned federation is relocated to different computers and added link latency. Use Case AThe Federation Manager gets a message that a new remote location needs to be connected to the Federation for a training event next month.  Unfortunately for the FM, this remote location is pretty remote, so the usual T1 link solution isn't going to be available.  The remote location has a satellite broadband link with 500KB/s of usable throughput and a 80ms each way link latency. The FM calls up a model of the current Federation configuration, and adds the new node for the remote location.  When the model is run, as a check, it flags the new link as oversaturated.  The FM can click on the link and see the traffic characterization for the link and the estimate that it is 150% of what the link can handle.  As a potential fix, the FM adds a box (called hierarchical interconnect, or DIS filter, or whatever) on the federation side of the link in the model.  The FM calls up the characteristics for the New Box, and sets it to discard every other location update, figuring that anybody with 160ms of round trip delay is going to see plenty of jerkiness anyway.  When the model is run again, the prediction is that the link will work, albeit with some artifacts.  The FM then heads off to the storeroom to get a New Box and start plugging things in.  The next week the FM will compare his test results with the actual link performance to do a finer tuning of the link interface box. Use Case B1The Federation Manager gets a complaint from the head of the Analysis team that when they added the three new high-fidelity missile models to the air defense federation it takes forever to get the runs completed.  The FM points out that the new models only take 30% longer than the models they replaced, and adding 30% to the 7 hour run time to complete 500 Monte-Carlo runs hardly seems like forever.  The head of Analysis claims that the last 500 iteration run started 14 hours ago and it isn't done yet.  The FM heads over to the lab and finds that the federation is in iteration 423 after 15.2 hours.  The FM checks the three new computers, and finds that they are less than 15% CPU utilized.  Then the FM opens up the (RID file | RTI console | whatever) and turns on performance logging.  Of course, nothing happens until iteration 423 completes.  When the RTI initializes for iteration 424, it starts logging the performance parameters needed by the performance model.  Iteration 424 takes a little longer, the performance records cause the RTI to consume more resources.  The FM turns the performance logging control off and reads the performance parameters into the model.  The model predicts that 500 iterations will take 19.2 hours.  The large change in run time is a result of the new missile models simulation of the air defense radar steering commands to the missile.  The missile models subscribe to every radar pulse, and delay the whole federation computing the radar path loss and their course correction.  The FM can now sit down with the Analysis team to discuss model changes that might improve run time: 1) Can the analysis be accepted with every other pulse being ignored for course corrections? 2) Can an approximation be used to reduce the path loss calculation time? 3) Can the time management constrain be loosened to permit the model to run with less accurate radar pulse data?  The performance problem has now been translated into tradeoffs that the users can appreciate.  Following reduction of calculation time, it is still found that it takes 14 hours to conduct the runs, which is determined to be too long by analysts.  Returning to the performance software the FM turns on RTI message tracking (or whatever) and finds that the addition of the new models added interactions that have serialized the federation execution in the missile countermeasures federates.  The FM will now need to re-examine the federation design to determine if there are changes to the design (in TM or DDM) that can be used to re-establish parallel execution.  Use Case 99The "solutions" to RTI performance questions expressed so far all require modifications to the Federate. Many times this is not possible (because of configuration management or verification, validation, and accreditation restrictions) or too expensive (because of simulation developer lock-in or exotic development environment).  Is this simply the cost of good performance? Use Case FThe Federation Planner is planning a federation. She surfs to SISO's Use Case Repository where she finds examples of prototype federations along with performance figures for various RTIs. Selecting the prototype most closely matching the intended federation takes her to a download page where she can get source code for the complete prototype federation, and also download performance results.  Her lesson learned is that performance requirements should be identified earlier in the FEDEP process to prevent cases like the other examples.  Before more cash is spent and man-hours committed to fixing the immediate problems, the FM should make sure that the performance requirements are clearly defined. Use Case 120The conversion of 20-25 DIS federates, currently linked via a gateway with 2 HLA 1.3 federates.  There are large numbers of entities, with significant portions of them active at any time.  The federation in planning to convert in some sequence, although they must not have down time due to their schedule, and each scheduled event may or may not use all the federates.  Not all federate sites (distributed across the US and potentially overseas) have equivalent communications capacities.  There are some recently captured network statistics, but they seem to be growing with each event, and the need to add new federates is obvious.  Special function servers have been added to the federation to ensure adjudication of effects, etc., but federates crash, data is corrupted, and restart is time-consuming.  Accuracy of results is sometimes in question.  What DIS filters, adaptors, RTI performance parameters would help in the planning of and testing the best migration path for the federation?  The federation will probably remain as a hybrid, with the added complication of having to interface with TENA and multiple HLA standards.  Some things must be real-time in the future, but not all.  Communications are not currently overloaded.  FOM/SOM flexibility is desired.  Crash recovery and restart are very important and accuracy of data for analysis.    Data distribution is very important. Use Case TSThe Federation Manager has been asked if a large, geographically distributed LVC environment used for immersing C2 personnel and fighter pilots in time sensitive targeting environments can be replicated in a TS environment (different, somewhat less capable networks and computers) to examine a pressing sponsor need.  For the federation to run in its current Secret environment, extensive tuning/balancing and scenario/federation design compromise was required using an ad-hoc set of processes and tools.  The Federation Manager has a week to report to his management whether or not the federation can be replicated adequately in the TS environment-- and if not, what upgrades/investments will be necessary.Performance MeasuresMoE Alternatives were evaluated in three groups:  a) Prediction Inputs, which some RTI monitor   can measure, but serve to define the user configuration;  b) Prediction Outputs, which need corresponding validation checks, but provide results to the federation manager; and c) Additional Recommendations.4.1.  Prediction InputsComputer Loading = % of CPU time not idleNetwork Loading = % of available bandwidth not usedFOM Character = any parameter, like # of object classes, that can be computed from the FOM/FEPWReal-time = Yes or No, is federation constrained to track GPS time.Time Managed = Yes or no, do federation repeatability needs mandate time management be used.Callback Latency = time for the federate to respond to a callbackTick Efficiency = does the federate calling tick enough (ratio timely tick calls / total tick calls)DDM Efficiency = is the region/dimension/overlap scheme computationally affordable.4.2.  Prediction OutputsRTI support cost = $ needed to buy an RTI, integrate, and tune the federation.LBTS calcs = # of LBTS calculations (involving global messaging) per unit time.OoT Alarms = specific alarms indicating a performance factor is outside the safe operating range.Federation Startup Time = how long it will take to start up the federation.Federation Game Ratio = logical federation run time / elapsed timeCritical Path = the sequence of data flows that constrains federation run time.4.3.  Additional RecommendationsSISO PDG to produce HLA Federation Performance Recommended Practices Guide/FAQ/FEDEP Overlay.Fault tolerance needs will drive performance / a fault tolerant RTI may solve some performance issues.Conclusions and Recommendations Top 5 ActionsModel Critical Path dependencies in a federation, based on some RTI logging.Define RTI-specific “Out of Tolerance” measures and define alarms to flag operation outside the proven performance envelop.Work with SISO to develop HLA Federation Performance Recommended Practices Guide/FAQ/FEDEP Overlay.RTIs should produce a measure of network bandwidth utilization.RTIs (or some test tool) should measure the callback latency of a federate to measure it’s contribution to performance.References [1] IEEE Std 1516.3™-2003, IEEE Recommended Practice for High Level Architecture (HLA) Federation Development and Execution Process (FEDEP), April 2003.[2]Author BiographyRANDY SAUNDERS is a Senior Staff Engineer at the Johns Hopkins University Applied Physics Laboratory.  He has over 20 years of experience in the design, implementation, and integration of high-fidelity simulations for military and business customers.  He received his M.S. degrees in Engineering from Harvey Mudd College in 1980 and in Computer Science from the University of Southern California in 1985.  Mr. Saunders has been involved in distributed simulation standardization since the first DIS Workshop, both DIS and HLA standards committees, and as a member of the SISO Standards Activities Committee.  He is presently a vice-chair of the HLA Evolved Product Development Group.  He joined APL in 2001.