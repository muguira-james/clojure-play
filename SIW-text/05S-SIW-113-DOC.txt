Process Control and VV&A of Distributed Simulations at Runtime for Network Centric ImplementationsMonte PorterMichelle HermanFred SeverinComputer Sciences Corporation4090 South Memorial ParkwayM/S 4-2-06Huntsville AL 35802mporter@csc.commherman@csc.comfseverin@csc.com800-477-1140Key Words: C4I, Modeling and Simulation Software, Intelligent Monitoring, Net-Centric Warfare, VV&AAbstract:  “Net-Centricity” is a term we associate with future command and control.  Many see it as an enabler key battle command functions but there are wide diversity of explanations of how “the network will know”. To think through the process, practitioners have turned to simulation to represent future force concepts and provide stimulation to command and control prototypes.  In a well run experiment, model and C2 prototype developers have successfully navigated through the issues of validation and verification during development, at acceptance testing, and during integration. This paper will discuss Verification, Validation, and Accreditation (VV&A) issues at run time with large distributed simulations and address considerations for real time process control, specifically how to obtain and measure data for analysis. Germane to this is the ability to measure functionality for networked fires (NWF) in a network centric environment.1. IntroductionSimulating future Network Centric warfare provides a challenge for Modeling and Simulation (M&S) professionals specifically in the area of Verification, Validation, and Accreditation (VV&A).    This paper will discuss VV&A issues at run time with large distributed simulations and address considerations for real time process control.  Having defined some of the issues, the balance of the paper will describe enablers for monitoring and then show some examples.2.  Problem Statement   As we conduct experimentation to wrestle with network centric concepts, one constant is the need for a credible experiment product.  The tactics need to represent the current thinking and the simulation tools must have the right data and algorithms to support the concept. Conceptual C3 Complexity.  The war fighter battle labs routinely conduct large distributed exercises to “think through” some extremely complex issues. Distributed Interactive Simulation (DIS) and/or High Level Architecture (HLA) based simulations enable the battle labs to connect prototypes and emulations of future Command, Control, and Communications (C3) concepts and examine these concepts and their requirements before key decisions are made.  Unfortunately, in many cases our conceptual thinking is outpacing our simulation capability and we are forced to use “work-arounds” or find simulations that represent the component parts of what is needed and tie them together in some meaningful way.   The upshot is that there are more moving parts and interconnected / various simulations than ever before.  In the midst of this new complexity, simulations participating must interface with the C3 participants in a way that is first, appropriate and second, “in control”. Rapid Pace of Experimentation.   In the early days of digitization (mid 90’s), large simulation exercises such as the Rapid Force Projection Initiative were developed over a few years and experimentation schedule included one major event each calendar year[1]. RFPI had a single force structure; a single set of messages and one prototype Command and Control (C2) system (Applique’ – precursor to FBCB2).  Experiments today involve changing equipment specifications, an evolving force, and many prototype C2 functions.  To complicate the problem, the pace of experimentation has drastically increased to support the warfighters need to experiment.  The result is that there is frequently untested or untried software during the experiment because very little time is available for integration and testing.  This means that anomalies must be found early and controlled to allow the C3 concept under test to be exercised.  People – Part of the Problem.  One problem with experimenting with and simulating network centric operations is the players themselves. They do not have the same level of discipline, leadership, training, and familiarity with the system as a real unit would have [3]. Appropriate system train-up helps to eliminate many inappropriate actions but as with all man-in-the-loop experiments, the decisions and actions of the role players can have a huge impact on the outcome.  Player interactions must be monitored in real time to ensure that they are appropriate and valid to support the goals of the experiment.3.  Real Time Monitoring –Requirements for SuccessKey considerations for monitoring computers and people to ensure the process is in control include simulation independence, interaction or message trace-ability, and policy compliance monitoring.  a.   Simulation Independence.   One of the most dangerous pitfalls in command and control experimentation is to provide C2 information to the role player based on what the simulation knows.  Target Location Error (TLE) and Battle Damage Assessment (BDA) are two areas for concern.  If ground truth is provided then the problems of fusion and target location error cannot be appropriately dealt with.  If target disposition is provided (e.g. dead vehicles are shown as dead when the simulation knows it) then the whole problem of retasking sensors to accomplish BDA is ignored.  The ability/ inability of sensors to determine BDA also requires attention.To support network centric C2 analysis, simulation messaging algorithms must be separate from the physics based functionality in the model.  Simulations must develop the target cues along tactical reasoning lines:Is there more than one target in my sensor FOV?What size unit do I see?What is the target doing?What is the target’s disposition?In the open, defilade, moving, on/off roadDead, damaged?In order to allow C3 surrogates to manage the battlefield, simulations need to pass data based on tactical policy or need, not on simulation cycle.  They must be flexible on update rate and must accept external update rate policies.  They should not send updates as often on targets that are not moving. They should not send updates on individual dismounts unless special situation requires it.b.  Traceability.  Traceability is probably the single most important factor in C3 run-time VV&A.  Every message/interaction must have a “thumb print” from every workstation or node that has input to the message and every node that receives it.  Platforms are the easiest to label using a “Bumper Number”.  In both RFPI and RDECOM’s 1st Application [2,4] we used a 10 digit alpha-numeric marking that easily relayed the task-organization, reporting links and chain of succession.  As network centric services are provided, the need for a “thumb print” is more pronounced.  An indication of which machine provided the service is required to determine if the processes of that machine were in control.  In RDECOM’s 1st Application exercise, we used missile servers and unmanned aerial vehicles (UAV) out the window servers to provide capabilities to the force.  The missile services were too transparent – we could not tell which machine was participating.  This made it difficult to measure the appropriateness of the server’s responses. c.   Policy Compliance.  In order to provide measurable goodness of tactics, techniques and procedures used in an experiment, measures of both machines and decision-maker inputs must be compliant with standard operating procedures and network policies.  Bandwidth constraints must be placed on the simulation to evaluate the effects of the network policy, latencies, and decision points.  Real time monitoring must be done to ensure compliance, provide feedback to the role players on the effects of their policies and goodness of their tactics.4. Specific applications of run-time monitoring.a.   Process Control.  The use of time sequence charts provides a valuable monitoring tool to determine if a process is in control.  Figure 1 is a plot of Spot Reports sent from a several different simulations to the surrogate C2 system plotted in 4 sec increments.   SHAPE  \* MERGEFORMAT Figure 1.  Spot ReportsThis pattern shows a process that is in control but not optimized.  The pulses every 30 seconds show a dependency on simulation time.  If this simulation sent reports that were truly independent, then spot reports would probably not pulse on a regular basis.  This pulsing poses a concern for C2 systems that must reason about the proffered information if the pulses get too large.In runs the next morning, the same set of simulation participants generated the plot in Figure 2.  Spikes of over 50 spot reports in 4 seconds began to slow the processing of the surrogate C2 system. SHAPE  \* MERGEFORMAT Figure 2. Process not in control.Examination of the message sets at the indicated time showed that a single simulation was producing duplicate data and sending twice as many reports as it had the previous run.  Because we had a good “thumb print” on the messages, we were able to pinpoint the problem simulation, correct it, and restart the run.b.  Human Decision Making.  Figure 3 shows a time sequence chart that plots a cumulative number of calls for fires against each target. The Y axis is the number of calls for fire and the x axis is each call for fire event.  SHAPE  \* MERGEFORMAT Figure 3. Calls for fire on current targetWe canvassed the role players in the After Action Review (AAR) to ask why the number of multiple calls for fire.  The problem was a lack of BDA.  The operator did not know the result of his call for fire so he re-engaged.   The Tactics, Techniques, and Procedures (TTP) was changed to add a request for BDA and the C2 surrogate software was changed to lock the user out for a period of time between the first and subsequent calls for fire on the same target.c.  Human Role Player TTP compliance. Figure 4 shows a comparison of mission managers collected in real time.  The boxes on the right show the number of fire events for each of two missiles.  The boxes on the left show the detonate events.Figure 4 Real-time TTP DataThe operator of CAB MMA 2 had a significantly larger number of PAM engagements.  The operator of UA MMA 2 had a larger number of LAM in the air. This alerted us to differences in TTP and we were able to canvas the operators in the AAR, determine the better TTP and bring the human participation in the simulation back into control.d.   Battlefield Loading.  We used run-time monitoring in the Extended Area Protection and Survivability (EAPS) [6] program simulations.  The CMCB radar events in an exercise were driven by the number of volleys fired.  Figure 5 shows a time history of volleys in flight.  Using color coding we were able to determine what types of munitions were fired and when they were fired. SHAPE  \* MERGEFORMAT Figure 5.  Monitoring BarragesWe noted as we were monitoring that we need more granular detail on each barrage.  So we began monitoring using a 2 hour time sequence chart and a 5 minute time sequence chart.  This allowed us to see the aggregate effect but at the same time watch the details of each engagement.Another plot (Figure 6) showed the same data calculated as a total number of rounds in the air.   SHAPE  \* MERGEFORMAT Figure 6.  Monitoring Rounds in Aire.  Visual Analysis.  Finally, we needed to understand visually what was going on in the battle as shown in Figure 7. SHAPE  \* MERGEFORMAT Figure 7.  Real time visual analysisIn a JANUS analysis [5] we needed to know the geometry of engagements and which barrages were fired from where (shown in red).  Also we needed to know which volleys the radars were unable to pick up due to overload (shown in blue).  This analysis showed us contextually where the engagements happened and gave us a better understanding of the functioning of the process.  We were able to identify input parameters that were hindering radar performance and were able to correct the problem prior to two record runs.5.  Benefits of Real Time MonitoringThe addition of a real-time monitoring provided a critical element of VV&A at run-time.  Time sequence charts, visual analysis and monitoring of human decision making allowed us to add value to the experiment and determine when our simulation was or was not in control.  Many times we were able to detect and correct anomalies before they were able to impact the simulation run.  As we go forward in net-centric experimentation, real-time monitoring will be critical to measure the network functioning as well as the human in the loop contribution to the process.  6.  Future Work.CSC’s Modeling and Simulation Center of Excellence has incorporated run-time analysis and monitoring in all their Modeling and Simulation (M&S) C4I experimentation efforts to include Networked Fires emulation and A2C2 efforts at AMRDEC’s Advanced Prototyping, Engineering, and eXperimentation  (APEX) Lab.  8.  References[1] 	AMRDEC: “Forensic Analysis of Rapid Force Projection Initiative Field Experiment”, May 1999[2] AMRDEC: “Final Report, RDE Command First Application (1stApp)”, July 2003.[3] AMRDEC: “Final Report, NLOS-LS C3 STO Simulation”,   December 2003.[4] 	Weber, Ralph; Tackett, Greg; Larsen, Karin; and Roose, Kathryn: “The Many Lessons from the RDE Command 1st Application – But Did We Learn Anything?”. SIW Paper 03F-SIW-005, September 2003.[5] Porter, Monte; Herman Michelle et.al.: “Janus / ProtoCommand Integration in Support of Extended Area Protection and Survivability (EAPS) STO”, SIW Paper 04F-SIW-071, September 2004.[6] AMRDEC: “EAPS Study Year 04 Initial Insights Report”, September 2004.Authors BiographiesMonte Porter has over 12 years experience in integration simulations to support C4I experimentation and is the primary developer of the Intelligent Exercise Monitor at CSC’s Modeling and Simulation Center of Excellence.Michelle Herman is a certified M&S professional and lead simulation engineer at CSC’s Modeling and Simulation Center of Excellence.Fred Severin is the scenario lead for JANUS simulation at CSC’s Modeling and Simulation Center of Excellence.PAGE  