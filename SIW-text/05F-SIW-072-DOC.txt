A Conceptual Approach to Meaning ComposabilityJames R. McCrackenThe Design Knowledge Company2661 Commons Blvd., Ste. 242Dayton, OH  45431-3704937-427-4276, 937-427-4283jim@tdkc.comRobert G. EgglestonUSAFRL/HECBldg. 190WPAFB, OH  45433937-255-8764robert.eggleston@wpafb.af.milKeywords:Composability, human modeling, conceptual spaces, modeling and simulation.ABSTRACT: The paper will present the theoretical basis for and preliminary results of research and development of a concept space-based approach to meaning composability, based in part on the conceptual spaces approach of Gardenfors.  The goal is to support composability of knowledge for intelligent agents and provide other support for insertion into simulations.  Two examples illustrate what it means to implement composability using conceptual spaces.  Preliminary methods for and approaches to composability using XTM technology are discussed and the methods and tools used are briefly described.1. IntroductionThe practice of modeling and simulation is moving to a system-of-systems approach where models developed by multiple, independent vendors will be linked into a shared simulation space.  Within that context, we are developing an approach to meaning composition.  Meaning composition is important in this heterogeneous simulation space because intelligent, adaptive, and complex agent work cannot emerge unless there is consistency in the flow at the meaning level across the various models providing aspects of object and agent behavior in the simulation.What has been done previously in terms of modeling and simulation composability?  Standards such as Distributed Interactive Simulation and the High Level Architecture were developed to govern the assembly of federations of models.  These standards define interaction syntax and provide interface control via a common data dictionary.The semantic web is working toward machine-machine communication via a markup language to ensure syntactic composability, and semantic composability is being attacked by using commonly held ontologies.  Topic mapping is an emerging W3C and ISO/IEC 13250 standard, aiming at capturing semantics by providing a terminology and link to resources. Merging is a fundamental process in the topic mapping paradigm.The merge process enables distributed and modular creation of topic map “knowledge-bases.”  There are three ways that two topic maps can be merged (see  HYPERLINK "http://www.techquila.com/pi_topicmapmerging.html" http://www.techquila.com/pi_topicmapmerging.html):Under explicit application control. A topic map application may provide the user with the ability to selectively merge topic maps. There is no restriction in the XTM specification to prevent an application from merging topic maps at runtime as needed or as directed by the application user.Processing a <mergeMap> element. The <mergeMap> element allows an author to explicitly request the merge of another topic map with the map that he or she creates. The mark-up for the <mergeMap> element also allows the author to define a set of topics to be added to the scope of every characteristic in the external map. This additional, externally defined, scope can be useful for preventing unwanted topic merges from occurring, or else to indicate the source of a characteristic in the final merged map.Processing a <topicRef> element. A <topicRef> element is not limited to referring only to topics contained within the same topic map document. A reference can be made to a topic in another topic map document. If a reference is made to a topic in an external topic map, then a topic map processor is required to retrieve the entire topic map containing that topic and to merge it with the topic map containing the reference.The DIS/HLA and semantic web approaches support composability at the “plug and play” level.  Both these approaches fall short in capturing the experiential dimension of meaning, that is, the effect that context has on the interpretation of linguistic tokens to create meaning.  DIS/HLA and semantic web view composability at either a logico-mathematical level (AND/OR, concatenate) or a functional level (such as a programming join).  The term “merging” has been applied to documents to facilitate comparisons of versions of documents.  None of these types of composition describes what we are doing here.  Our approach to merging is nearer to Falconnier’s [1] blend.  A blend inherits structure from its input concepts and has emergent structure of its own.In cognitive semantics, meaning construction is equated with conceptualization, a dynamic process whereby linguistic units serve as prompts for an array of conceptual operations and the recruitment of background knowledge, used to construct meaning from those linguistic tokens, taken in the context of present experience.  We  ground our basic strategy with the conceptual-space theory work of Gardenfors [2], (conceptualization) built on the human ability to make similarity judgments and describe a single process (merging) to meaning composition.  We provide a simple illustration of the concept-space modeling approach.  Finally, we briefly discuss the methods and tools used to develop conceptual space models.2. Assumptions and FoundationsConceptual structure differences originate in the requirement of the efficient sharing of knowledge [3].  Conceptual structure can be based on experience, the function of artifacts [4], on social roles/cultures, or can be introduced by science.  This linking of conceptual structure and experience is the basis of what we refer to as meaning composability.Composability at the meaning-level is achieved by modeling based on similarity and isomorphic underlying dimensions that comprise conceptual spaces.  The conceptual space of color, for example, includes the dimensions of hue, chromaticity and brightness.  The conceptual space of sound is formed from loudness and pitch dimensions.  In general, two concepts can be made to be isomorphic in meaning to the extent that they share underlying dimensions. Such concepts must share at least one dimension to have any degree of isomorphism.In modeling and simulation, it is common practice to pick and choose what aspects of a problem to include and what to exclude, based on the question to be answered by the exercise.  This section describes our assumptions regarding what we are choosing to model and our reasoning behind those choices.  Our choice of levels on which to model centers on a conceptual space approach to cognitive systems development as compared with a neural net or symbolic rule-based expert system approach.  We chose to model at the conceptual space level because we contend that it is appropriate for representing experiential and linguistic (symbolic) meaning.  Philosophical support for this position is provided by Jackendoff.There must be levels of mental representation at which information conveyed by language is compatible with information from other peripheral systems such as vision, nonverbal audition, smell, kinesthesia, and so forth [5].There is a single level of mental representation, conceptual structure, at which linguistic, sensory and motor information are compatible [6].The conceptual space approach provides us with an architecture for knowledge representation that supports composability.  While our emphasis here is on the concept-based approach to modeling, we believe that the method is complementary to, not a replacement for, neural net or symbolic modeling approaches.  See, for example, the discussion of the rule versus similarity based processes by Hahn & Chater [7].We next present three reasons for choosing the conceptual space level for modeling.  The first two, similarity judgments and structural coupling, are biologically based.  The third, concept mapping, is a visual/linguistic token construct.2.1 Similarity judgmentsWe begin our discussion of biological foundations by posing the question, “What does the brain do?”  The brain certainly responds to perceptual stimulation and correlates that stimulation with internal states.  The brain also performs comparison or difference functions on the incoming perceptual stream.  “All perceptions are of difference” [8].  These perceptual differences support the human’s ability to perform judgments of similarity.The brain stores perceptual experience in long-term memory, allowing us to make these similarity comparisons.  In everyday life, we routinely perform comparisons of memories of previous experience with experience as it is currently perceived.  For adults, some experiences are completely new; most contain variations of some previous experience.  Comparing previous to present experience results in judgments of similarity.  Hearing a tone of a particular frequency can easily be judged to be higher or lower than a preceding or subsequent tone.  These judgments of similarity on quality dimensions support the notion of distances along the dimensions.  The smaller the distance along a given quality dimension of a given set of objects, the more similar they are.  Using our tone example, the closer the frequency, the more similar the tone.  Similarity is thus defined as the distance between the representing points along a quality dimension.  We elaborate further on dimensions in our discussion of conceptual space in Section 3.  There is extensive literature on similarity-based conceptual constructs; a starting point is Sloman & Rips [9].  The second chunk of foundation for conceptual space modeling is structural coupling.2.2 Structural couplingStructural coupling was introduced by Maturana and Varela [10] to describe the mutual changes effected via the interaction of organisms with their environment.  Structural coupling consists of reciprocal perturbations in which an entity’s interaction with the structure of the environment triggers structural change in the entity.  The result is a record of mutually congruent change.  To illuminate further, consider the following.  An organism can modify the physical environment by changing the adaptive pressures on itself (e.g., by moving to find water or building nests).  Changes in the environment can affect the organism (e.g., weather changes) leading to adaptation or changes in behavior such as migrating seasonally.  The environment “remembers” the structure/action of its inhabitants (consider elephant vs. mouse footprints) and (the brains of) the inhabitants remember the structure/actions of the environment.  These memories form the basis for similarity judgments.Living beings carry knowledge of their environment as action-induced structural change.  Maturana and Varela [10] define knowledge as follows:  “We admit knowledge whenever we observe an effective (or adequate) behavior in a given context, i.e., in a realm or domain which we define by a question (explicit or implicit).”Thus, one can say a cognitive agent has knowledge of, say, a hammer, based on observed effective use of the tool.  Structural coupling creates and augments knowledge when the recurrent use of the tool first creates and leads to improved structural congruence between the use and the tool.  Using the hammer as an example, the proper weighting of the head, balance of the whole tool, and the shape of the handle all are structural properties that interact harmoniously with structural properties of an action agent (e.g., hand size and shape, arm strength) to contribute to the efficiency and effectiveness of the tool in use.Words can be viewed as tools for communication, as can hand gestures, signs, and other signals.  Vocabularies have been engineered (consider the phonetic alphabet) for maximal discriminability.  Acquiring words, the attaching of symbol to experiential state, is a first step in externalizing cognition.  In normal, fully sighted and hearing humans, this is ordinarily first accomplished as a spoken word, voiced appropriately.  However, other perceptual modalities can support the coupling of experiential state and symbol; consider the experience of Helen Keller.When modeling the use of a tool such as a hammer, the modeler has decisions to make.  The same is true when modeling human cognition.  “The tendency is nearly always to simulate too much detail rather than too little.  Thus, one should always design the model around the questions to be answered rather than imitate the real system exactly” [11].  Our approach to model composability is based on meaning.  “Meaning is a conceptual structure in a cognitive system” [2].  The emphasis given to questions in this paper is not accidental.  Questions were employed by the first author as a critical focal point of research for understanding human problem-solving and conceptual structure in design problem-solving [12].Maturana and Varela’s definition of knowledge as existing when effective action is observed in a given context inextricably links knowledge and action; we embody the definition of knowledge as an understand/action process where understanding is taken to have components of perception and cognition.Maturana and Varela discuss at length the proverbial chicken-and-egg problem that leads to a circular causal cycle of understanding.  “Effective action leads to effective action: It is the cognitive circle that characterizes our becoming” [10].The notions of structural coupling and conceptual spaces have interesting implications for modeling individual and cultural differences; different experience creates different structure in brain, thus the differences we see in knowledge and behavior of individuals and the similarities among individuals of the same or similar cultures.Culturally derived quality dimensions have geometric structure.  In western culture, time has a linear structure; it is isomorphic to the line of real numbers in science.  Phenomenally, we can make judgments of how recent or how imminent events are/might be.  In Hopi culture, time is circular.  Thus, Hopi time might be measured in terms of polar coordinates or repeated events.  These cultural differences reflect shared conceptual structure that exists to support meaningful communication.  Given these cultural differences when modeled in conceptual space, we may be able to create transforms to compare cultural differences (such as linear vs. circular notions of time) in the same way we can transform frames of reference in physics from Cartesian to polar coordinates.Similarity judgments and structural coupling provide the experiential/biological basis for our conceptual space approach.  The next foundation piece lies in a further externalization of experience and translation into linguistic tokens, which is concept mapping.2.3  Concept MappingThe ability to externalize our perceptions as the foundation of communication is based on the notion that conceptual structure differences originate in the requirement of the efficient sharing of knowledge [7].  We argue that this progressive externalization leads to oral and written languages, computers, books, and other artifacts – the “Things That Make Us Smart” [13].Our experience with Subject Matter Experts (SMEs) has taught us that experts differ in their ability to express their expertise.  Thus, experts who have previous experience in expressing their expertise (via teaching experience or writing an authoritative subject area text) are far more able to externalize their knowledge than others with similar domain expertise who are lacking in practice in externalizing knowledge [14].SME knowledge acquisition (KA) has long been a bottleneck in the development of cognitive systems.  In the halcyon days of artificial intelligence, knowledge engineers were referred to as mediators between SMEs and computer programmers.  An important goal of thre present work has been to enable SMEs to directly generate knowledge models using concept mapping.  The concept mapping approach, which we discuss next, is the basis for our Application of XTM and XFML to Individual and Organizational Modeling (AXIOM) Phase II SBIR for AFRL/HEC.In order to alleviate the bottleneck in transfer of knowledge from SME to cognitive systems, we turn to the technique of concept mapping.  Concept maps were first developed by Joe Novak [15] of Cornell to facilitate science teachers’ troubleshooting of students’ conceptual knowledge of science.  The concept mapping approach utilizes the epistemological Vee of Gowin [16], which is constructivist in nature, i.e., new knowledge is constructed on top of, or using the base of, existing knowledge.  Concept mapping is easily learned by elementary and secondary students; it is extremely flexible – so flexible, in fact, that more structure is needed to support computability.  We implement concept maps as XML topic maps (XTMs) to provide syntactic structure; concept mapping provides semantic content, and conceptual space dimensions support merging and other operations on XTMs to provide meaning-level composition.We have discussed the progressive externalization of meaning using the language of similarity, structural coupling, and concept mapping.  Next, we present the theory of conceptual spaces that binds these three together.3. Conceptual SpacesWe build on concept mapping as an approach to shared knowledge structures by using a concept space-based representation of knowledge.  The theory of conceptual spaces is discussed extensively by Gardenfors [2],  We briefly discussion dimensions in relation to the construction of conceptual space.The conceptual space approach is aimed at the problem of merging (composability) and other operations on conceptual models (pruning, grafting, conceptual combination).  We are exploring these and other notions of manipulating conceptual mapping such as various blends [1].Conceptual space computing is a tool for modeling the relations among our perceptual, cognitive, and motor experiences as supported by Jackendoff [5].  These experiences can be either current or remembered, real or imagined.  The concepts generated by experience can be phenomenal, scientific, or abstract.  We next turn to a review of various aspects of the dimensions underlying or composing conceptual space.3.1 DimensionsPerception of size in visual space induces relative size judgments of objects that introduce differences when compared to independent (objective) 3-D Euclidean measurements of the same objects.  Perception of color induces relative judgments that do not correspond directly to measures of a physical property such as wavelength.  We mention these examples to illustrate that judgments of similarity can be dimensionalized in both perceptual/cognitive as well as agent-independent terms.The structure of dimensions enables a conceptual space model in which distance in conceptual space is tightly coupled to judgments of similarity.  These judgments of similarity are also tightly coupled to the quality structure of objects in/composing the environment.  The estimation of place along these dimensions leads to the development of multi-dimensional concepts that have a spatial structure.From  HYPERLINK "http://www.topicmaps.org/xtm/index.html#def-topic" http://www.topicmaps.org/xtm/index.html#def-topic, we note, “A topic is a resource that acts as a proxy for some  HYPERLINK "http://www.topicmaps.org/xtm/index.html" \l "desc-subject" subject; it is the topic map system’s representation of that subject. … A subject is anything that can be spoken about or conceived of by a human being.”We use a conceptual space representation at each node of a topic map, thus linking dimensional analysis and judgments of similarity along dimensions to the W3C XTM 1.0 standard, which, by definition, includes “…anything that can be spoken about or conceived of by a human being.”  Figure 1 illustrates the notion of  the topic “sound,” composed of pitch and loudness dimensions.Figure 1.  Sound topic as a conceptual (meaning-level) space.The term vector space, which refers to the space defined by a system of coordinates, has a surprisingly literal interpretation in the nervous system.  The functional architecture of many structures that process higher-level sensory inputs is such that anatomical dimensions of the structure correspond to descriptive dimensions of the stimulus. There is reason to think that this correspondence is not fortuitous; rather, it is a foundation for the nervous system’s capacity to adapt its output to the structure of the world that generates its inputs [17].A reminder from introductory statistics: data can have nominal, ordinal, interval, and ratio structure.  Interval and ratio data are more straightforward as supporting measurable dimensions.  Quality dimensions may have only a discrete (nominal) structure.  Examples include Linnaean classification of biological species and kinship relations in humans.  Even though they are nominal data, it still makes sense to say chimpanzees are more closely related (more similar) to orangutans than to horses.Many complex phenomena may be represented by a set of qualitative dimensions.  Judgments of similarity or difference generate at least an ordinal relation along the dimension (low vs. high pitch, cold vs. hot temperature).  Dimensions create the framework to assign properties to objects and specify relations among them.  A property corresponds to a region of a domain of a space.  These spaces form the nodes of concept or topic maps.3.2 Isomorphism and dimensional structureQuality dimension structure supports measures of isomorphism at multiple levels.  Isomorphism comparisons can be made at the object (AXIOM XTM node) level, XTM (object/relation) level, and at the conceptual process (AXIOM model) (object/relation/control) level.  We currently are developing methods to quantify conceptual distance and node structure, and have used the principles described in this paper to successfully achieve conceptual-level merges, thus providing a proof of concept of our technique.  We next plan to test scalability and robustness of the approach.We have chosen to utilize the notion of isomorphism to maintain structurally congruent concepts.  What we mean by isomorphism is that for a given conceptual construct, the underlying dimensions will be the same.  For similar, but not identical conceptual constructs, there will be one or more shared dimensions.  This approach supports dimensional analysis, also known as factor label math, as a method for conceptual simplification.3.3 Integral vs. separable dimensionsIntegral dimensions are those for which one cannot assign a conceptual object a value on one dimension without assigning a value on another dimension (hue and brightness, pitch and loudness).  Separable dimensions are those for which one can assign a conceptual object a value on one dimension without assigning a value on another dimension (size and hue, size and taste).  Relations among dimensions can vary, that is, dimensions can be treated as either integral or separable, depending on the context of use.Consider, for comparison, the varying treatment of space and time in Newtonian physics (in which space and time are separable dimensions) vs. relativistic, as represented by Minkowski metric physics, in which space and time are inextricably welded (integral dimensions).4.  Model CompositionHow does model composition for incorporation into a modeling and simulation environment work using the AXIOM conceptual space approach?  First, we assume that simulations are conducted to answer questions.  The question to be answered must be analyzed to uncover its underlying conceptual structure using linguistic tokens specified in an ontology.  These tokens are used by an SME to build a concept map that reflects the structure and content of the question, and the concept map is structured according to W3C topic map syntax.  See Figure 2.  The question content and structure are then used to search using a query language for pre-existing AXIOM models or components that have the same (or at least similar) underlying conceptual space dimensions and are used to populate the knowledge base for the simulation.  If the structures are not exact matches, but share one or more dimensions in their conceptual space, the shared dimensions are used to merge the maps, creating a new concept that fits the space.Figure 2.  AXIOM Composition Architecture.4.1 Composition of Knowledge StructuresThe underlying concept dimensions and the XTM merge of existing AXIOM models enable the composition of new knowledge and a structural matching of models in response to novel question elements.  What this means is that we can generate new knowledge structures from pre-existing knowledge in order to most closely match the structure of the question to be answered.As AXIOM knowledge is used to participate in the simulation, it receives feedback and modifies the conceptual space representations.  These modified structures are stored along with the question that formed the context of the simulation.If the knowledge required to answer the simulation question matches exactly a knowledge structure in the AXIOM historical model library, it is simply inserted into the simulation knowledge base.  But to illustrate how knowledge embodied in topic maps can be used to support action for which previous knowledge did not explicitly exist, we present two examples.  In our first example, we present a method of knowledge construction using the underlying dimensions of the concept space.  In the second, we construct new knowledge by merging at the concept level.4.1.1  Dimension-based generation of knowledgeIn the domain of air traffic control, aircraft traffic is conceptualized in terms of traffic flow and “slots.”  Slot sizes and slot times are assigned to aircraft to maximize the efficiency of the flow; thus a separation envelope around the aircraft is created, which is intended to maintain safety while making the use of airspace as efficient as possible.  A complication arises in that slots are not all the same size.  Wake turbulence from heavy aircraft can have a large impact on smaller aircraft.Let us suppose that we have a knowledge base that includes structures describing the slot size (or horizontal separation) between aircraft.  The knowledge base currently contains the slot size between a Boeing 757 and a Cessna Citation (Figure 3); and the same knowledge for a 757 and B-1 (Figure 4).  The knowledge of each of these aircraft is modeled to contain the dimensions of weight and landing speed (Vref).  The single dimensions could be extended to be tables of weight and airspeed if additional sensitivity or resolution were required.  We use the simple dimensions for the purpose of our illustration.Figure 3.  Slot size – 757 and Citation.Figure 4.  Slot size 757 and B-1.Suppose that for an upcoming simulation, we need to model an air traffic controller that knows the slot size for a G200 (we need to create the map depicted in Figure 5) following a 757, but our knowledge base does not contain that information.  So, the simulation question (see Figure 2), is “What is the slot size for a G200 following a 757?”Figure 5.  Slot size – 757 and G200.Our question-asking “goodness checker” ensures that the question is phrased in terms that are included in the AXIOM air traffic control ontology and that the map is well formed.  Further, we know the appropriate structure for such a map (referencing Figure 3) and the underlying dimensions.  When we query the AXIOM historical model library, we discover that no slot size chunk exists for a G200.  We will assume there is no match in the library of legacy models using Soar, ACT-R, or other techniques.  The modeler for the upcoming simulation does have the airspeed and weight specifications for the G200, so he can search for aircraft that have similar dimensions.  He can specify how similar those aircraft need to be.  For example, a search can be conducted on weight +/- 10% and airspeed +/- 15%, or other degrees of similarity, using either tighter or looser specifications.In this case, a search for aircraft weight AND airspeed yields a match with a Cessna Citation XLS, for which we do have a slot size when paired with a 757.  We then build a new map that utilizes the slot size for the Citation, but labels the aircraft as a G200, with its weight and airspeed specifications replacing those of the Citation.  The result is Figure 5.  When the simulation is run, feedback will be generated regarding the goodness of the model by measuring the level of wake turbulence experienced and the slot size modified accordingly.4.1.2  Concept-based generation of knowledgeNext, consider what would happen if the modeler were faced with the simulation question, “What is the slot size for a Citation following a B-1?”  This time, our search shows we have knowledge of the B-1 and of the Citation in the AXIOM knowledge base and the structure fits that of the simulation question, but no map exists in which the Citation is the aircraft with which the B-1 is paired.  In this case, we need to generate a knowledge structure that has the form of Figure 6.Figure 6.  Citation/B-1 slot size.We are able to find maps that contain the B-1 and Citation that have the 757 as the other member of the pair.  Using the 757 as a common concept between maps, we do a topic map merge at the concept level and generate an estimate of the slot size, represented by the map in Figure 6.In this set of examples we have not specified the order of the landing.  It is an easy extension to create pairs of maps that provide knowledge with changing slot size dependent on order.These examples illustrate the first two methods we have devised for combining knowledge fragments to generate new knowledge.  We are testing additional methods of combining pieces of knowledge to create specified structures.5. Methods and ToolsIn order to generate the dimensions and metrics for conceptual spaces, we are exploring several approaches.  These include back-of-the-envelope, SME-generated dimensions and levels of similarity such as self-generated Likert scales, multidimensional scaling techniques, proximity analyses, and direct dissimilarity scaling (pair-wise comparisons of all possible pairs, one at a time).  Selection of the method for scaling the space depends on the need for precision and/or generality of the application.Our preliminary tool suite has been composed of:  Protégé, an ontology development tool freely available from Stanford  HYPERLINK "http://protege.stanford.edu/" http://protege.stanford.edu/; Topic Mapping for Java (TM4J), available at  HYPERLINK "http://www.techquila.com/tm4j.html" http://www.techquila.com/tm4j.html; and various Java tools and components.  We are evaluating XTM visualization tools and exploring tools to import concept maps into XTM.  Our topic maps adhere to the W3C topic map standard.We have completed a proof-of-combination-of-concepts based on the principles of conceptual spaces, utilizing the dimensionality of the concept space to derive a merged (composed) concept.  We next anticipate scaling the approach to more complex models and testing the robustness of the approach.  Future work will explore mixed methods of modeling, combining neural net, conceptual space, and rule-based symbolic approaches.6. SummaryWe began by outlining our assumptions and the foundations of our approach.  We described our approach to composability using judgments of similarity and the principle of structural coupling, and discussed concept mapping as a method of externalizing knowledge for creation of behavioral models.  We added structure, using a theory of conceptual spaces, and presented an outline of the modeling approach.  Finally, we briefly discussed the methods and tools used to develop conceptual space models.The AXIOM approach to composability links experiential and linguistic meaning in a biologically grounded, progressively externalized method of modeling human cognition, embodied in standards-based, platform-independent technology.7. References[1]	G. Falconnier:  Mappings in Thought and Language, Cambridge University Press, New York 1997.[2]	P. Gardenfors:  Conceptual Spaces:  The Geometry of Thought, MIT Press, New York 2000.[3]	J. Freyd:  “Shareablity:  the social psychology of epistemology” Cognitive Science, Vol. 7, pp. 191-210, 1983.[4]	D. Marr & L. Vaina:  “Representation and recognition of the movements of shapes” Proceedings of the Royal Society in London, Vol. B214, pp. 501-524,1982.[5]	R. Jackendoff:  Semantics and Cognition, MIT Press, Cambridge, MA 1983.[6]	R. Jackendoff:  Foundations of Language, Oxford University Press, New York 2002.[7]	A. U. Hahn & N. Chater:  “Similarity and rules: empirically distinguishable?” In Similarity and Symbols in Human Thinking, MIT Press, Cambridge, MA 1998.[8]	G. Bateson:  Mind and Nature:  A Necessary Unity, Bantam Books, New York 1979.[9]	S. Sloman & L. Rips:  Similarity and Symbols in Human Thinking, MIT Press, Cambridge, MA 1998.[10]	H. Maturana & F. Varela:  The Tree of Knowledge:  The Biological Roots of Human Understanding, New Science Library, Boston 1988.[11]	R. Shannon:  Systems Simulation:  The Art and Science, Prentice-Hall, 1975.[12]	J. R. McCracken:  Questions:  Assessing the Structure of Knowledge and the Use of Information in Design Problem Solving. Published Doctoral Dissertation, The Ohio State University, Columbus, OH 1990.[13]	D. Norman:  Things That Make Us Smart. Addison-Wesley, Reading, MA 1993.[14]	R. G. Eggleston & J. R. McCracken:  CAST:  A constraint analysis and structuring knowledge elicitation tool (Internal Laboratory Report), Aero Medical Research Laboratory, Wright-Patterson AFB, OH 1987.[15]	J. D. Novak:  A Theory of Education, Cornell University Press, Ithaca, NY 1977.[16]	J. D. Novak & D. B. Gowin:  Learning How to Learn, Cambridge University Press, New York and Cambridge, UK 1984.[17]	C. Gallistel:  The Organization of Learning, MIT Press, Cambridge, MA 1990.Author BiographiesDR. JAMES MCCRACKEN has been the Chief Scientist of The Design Knowledge Company in Dayton, Ohio since 2002.  At TDKC, he is conducting research to define tools and work-centered environments to aid intelligence analysts and satellite operations, developing knowledge-based methods of cognitive modeling to create synthetic human-in-the-loop capability for large-scale simulations and in support of deployed operations, applying semantic web technologies to next-generation network-centric warfare tools, and building tools based on temporal, spatial, and other data to support reasoning and anticipate activity.  He is a member of HFES, IEEE, and SISO.DR. ROBERT G. EGGLESTON is a principal scientist in the Human Effectiveness directorate of the Air Force Research Laboratory.  His recent research has focused on understanding how experts “make sense” of complex and conflicting information in the context of work, studies of how experiential-based and symbolic-based knowledge and reasoning may blend to provide efficient in-context understanding, and studies of work modeling and the design of the graphical user interface as a work-centered support system.