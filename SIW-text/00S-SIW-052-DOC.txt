Conceptual Modeling Lessons Learned from WARSIM 2000Daniel P. SaganDaniel E. KerseyDynamics Research Corporation3505 Lake Lynda Drive, Suite 100Orlando, FL  32817407-380-1200 x113, 407-306-1564 HYPERLINK mailto:dsagan@drc.com dsagan@drc.com,  HYPERLINK mailto:ekersey@drc.com ekersey@drc.comLTC Phillip MayU.S Army Training and Doctrine CommandOrlando, Florida  32825407-384-3621 HYPERLINK mailto:phillip_may@stricom.army.mil phillip_may@stricom.army.milKeywords:Conceptual model, WARSIM, Knowledge acquisition, Knowledge engineering, Lessons learned, FDBABSTRACT: This paper describes the lessons learned from an ambitious military simulation knowledge acquisition and knowledge engineering effort for development of the Warfighters’ Simulation (WARSIM) 2000 constructive simulation.  The resulting models were used to simultaneously populate the U.S. Army’s conceptual model repository, the Functional Description of the Battlespace (FDB). The charter of the conceptual modeling effort was to produce, document and archive accurate, validated and traceable standard descriptions of the components and characteristics of Army battlespace functions, which could then be used to produce credible simulations of these same functions.  Additionally, there was the concurrent need to meet the requirements of a specific simulation under development, WARSIM 2000.  The models were also intended to support simulation interoperability by describing cross-domain interactions with other JSIMS models.A comprehensive process was developed and documented to guide the effort.  During the conduct of the various phases of the FDB effort, countless challenges were encountered and solved with appropriate adjustments to the plan and process.  Valuable lessons were learned in the areas of requirements analysis, knowledge acquisition, knowledge engineering, repository storage and validation to include such things as contractual obligations, software development and system requirement support, simulation modeling and fidelity decisions, use of automated tools, traceability as well as several others.Since the intent of the FDB was to serve as a basis not only for WARSIM 2000, but also for development of subsequent simulations such as OneSAF, it is imperative that these lessons be noted, heeded and applied in future simulation development. IntroductionThe value of a warfare simulation is directly related to the credibility of its representation of real-world military operations, equipment and systems, and environmental factors.[1] Simulation designers must have a clear understanding of the domain to be simulated The domain description must be multi-dimensional and must include a depiction of the entities, actions, tasks, and interactions that must be represented. [2]The most important aspect of a successful, integrated simulation development process is producing models of the real world domain that are valid and sufficient for the intended purpose or use.  The simulation development process involves a transfer of knowledge about the real world to simulation designers and developers. As a part of this process, simulation developers begin by analyzing how civilian and military organizations and entities perform missions and tasks. They then select the parts of the real world to represent as well as the required level of resolution. Historically, this analysis has been performed by software developers without the continuous, active participation of authoritative, domain knowledgeable personnel.  Once a project has completed development, the carefully collected and organized real world knowledge is usually contained in software development documentation or buried deep within the computer code of the simulation. [2]In the case of WARSIM 2000, this carefully collected and organized real world knowledge was stored, as it was developed, in a repository called the Functional Description of the Battlespace or FDB.  This repository was then made available to the simulation developers to support their domain knowledge requirements, and to validators as part of the overall conceptual model validation process.[3]The following sections describe the history, organization, planning, processes, and knowledge repository used in the WARSIM conceptual modeling effort; but more importantly, they address the lessons learned in each of those areas and how future simulation development might benefit from these lessons.BackgroundWARSIM 2000 researched previously completed simulation programs to identify what already existed in the areas of conceptual model development (plans, knowledge acquisition and representation documentation, repository, etc.).  What was learned was enlightening.In the past, many simulations were developed without active participation by knowledgeable and authoritative military domain experts. This led to inaccuracies in the results of the simulations and required costly modifications to correct the deficiencies. When WARSIM researched what was available for re-use in their conceptual modeling effort, it found very little in the way of documentation that would help in their effort.  There was no previously established, defined and documented process or plan from any previously developed simulation found. Some limited conceptual models were located, but most were not at the level of detail required by WARSIM.  This is not to say they were not useful. The WARSIM 2000 program leveraged prior efforts to the maximum extent possible, but very little was useful.  Programs such as the US Army’s Close Combat Tactical Trainer (CCTT) program provided Combat Instruction Sets (CISs) which were of some value.  The Defense Advanced Research Projects Agency's (DARPA) Synthetic Theater of War (STOW) program also provided a certain amount of assistance.  And finally, the Command Forces (CFOR) project, an integral part of the STOW program provided much needed input to the initial phases of WARSIM KA.  All of these efforts were useful during the early stages of the WARSIM knowledge acquisition effort.  However, an established process to guide the WARSIM effort was still lacking, as was a repository of existing information.OrganizationIn order to execute the task of knowledge acquisition for a program as immense as the Warfighters’ Simulation 2000, a rather extensive organization had to be created in a relatively short period.  A knowledge acquisition hierarchy had to be emplaced and subject matter experts from across the spectrum of software development requirements brought on board, trained and put to work rather quickly.  To accomplish this goal, the WARSIM 2000 concept of using an Integrated Development Team (IDT) was extended to include the knowledge acquisition effort.  Representatives of the user community (Training and Doctrine Command (TRADOC) & National Simulation Center (NSC)), the materiel developer (Simulation, Training and Instrumentation Command (STRICOM)), the WARSIM contractors (Lockheed Martin Information Systems (LMIS), Dynamics Research Corporation (DRC), Sterling, Logicon and Science Applications International Corporation (SAIC)), and the WARSIM Intelligence Module (WIM) contractors (MRJ) were brought together under the umbrella of the Functional Description of the Battlespace (FDB) Working Group and the Knowledge Acquisition Working Group to form the aforementioned hierarchy.  The charters of these working groups were: 1) to manage FDB requirements and monitor the FDB to ensure requirement compliance, and 2) to guide, coordinate and produce the information required to meet the FDB requirements and populate the FDB.The actual knowledge acquisition team consisted of military domain subject matter experts in a wide variety of specialties, working knowledge acquisition activities for several Concurrent Engineering Teams (CETs), responsible for developing a number of Computer Software Configuration Items (CSCIs).  At its peak, the KA team consisted of some 60+ members working at locations across the country, but primarily located in Orlando, Florida and Fort Leavenworth, Kansas. Planning and Process The development of a conceptual model for constructive simulation requires the creation of a focused context, the acquisition of data, the representation of knowledge, and the conveyance of that knowledge to the software engineers in understandable terms. [3] Likewise, all of these require a detailed plan and established processes in order for them to succeed.The PlanThe process for developing the WARSIM knowledge representations is documented in a Knowledge Development Plan (KDP).  The KDP is similar to a Software Development Plan, and is based on MIL-STD-498.  The Knowledge Development Plan defines the activities and tools used to generate knowledge development products.  By documenting, maintaining, and following the Knowledge Development Plan, a mature process can evolve. [3]This Knowledge Development Plan (KDP) describes the development approach, methodologies, tools, procedures, and policies to be used for knowledge acquisition and engineering activities in support of populating the FDB for use by the WARSIM 2000 program.The Knowledge Acquisition (KA) ProcessThe knowledge development process had to be clearly specified from the perspective of the knowledge developers (See  REF _Ref471205412 \h  \* MERGEFORMAT Figure 1).Figure  SEQ Figure \* ARABIC 1.  The Knowledge Development ProcessThe FDB WG specified FDB requirements based on the CETs’ requirements.  The FDB requirements specified both content and functionality expected from the FDB.  Content requirements drove the production of the knowledge representations.  Functionality requirements were used by the FDB contractor to define the FDB repository’s features through the FDB’s system specification and software requirements specifications. The activities described in the plan are associated with representing knowledge for use in populating the FDB. The resulting representations were provided to the FDB contractor for incorporation into the FDB, where they underwent the validation process.  The FDB is then used by the WARSIM CETs in the development of WARSIM.The primary activities associated with the overall process include coordinating KA activities, acquiring data, managing the WARSIM library, representing information and translating those representations into usable, understandable products for use by software engineers (Knowledge Engineering (KE)). The associations between these activities are represented in  REF _Ref471205548 \h Figure 2, below.Most of the knowledge development management is associated with coordinating KA activities (activity 1 from  REF _Ref471205548 \h  \* MERGEFORMAT Figure 2).  These coordination activities include coordinating the working group, development of Data Acquisition Plans (DAPs), and the development of Information Representation Plans (IRPs).Data Acquisition Plans (DAPs) describe the resources and activities to be performed to collect data.  The development of the contents is specific to the subject area.  The KAWG ensured the DAPs were compared to all related DAPs in order to ensure coordination across CSCIs. Information Representation Plans (IRPs) describe the activities that a team will conduct to represent the data they have collected.  Just as with DAPs, the content will differ greatly between CSCIs.  As with the DAPs, the KAWG ensured the IRPs were compared to all related IRPs in order to ensure coordination across CSCIs.  Pivotal to the whole KA effort was an internal review and preliminary approval process prior to the placement of any product on the FDB repository.  This process included inspection of the DAPs and IRPs as well as a final internal review of all products. EMBED Word.Picture.6  Figure  SEQ Figure \* ARABIC 2.  Production of FDB ContentsPart of the DAP inspection included insuring that the KA teams used only approved authoritative data sources (ADS).  Inspections of the IRP included making sure that the critical types of information were extracted from the acquired data and included in the information representations. Upon completion of each model, a final internal review was held.  This review was less formal than the inspection process described above for DAPs and IRPs. Models to be reviewed were provided to key KAWG members in order to identify any obvious inconsistencies or misrepresentations.  Following any updates resulting from review comments, the models were then provided to the WARSIM library and to the FDB contractor for inclusion into the FDB.  They were considered preliminarily approved for use and marked accordingly, while awaiting proponent validation.The Knowledge Engineering (KE) ProcessBecause there were severe time constraints in the WARSIM program, a spiral build concept was used.  The knowledge acquisition process began months ahead of software design, resulting in incomplete definition of specifically what information was necessary for collection and inclusion in the early KA products.  In fact, the first software design phase was completed concurrently with the second KA phase.  Design decisions made during software development resulted in identification of additional data, which had not been included in the early KA products.  Unfortunately, there were no resources available to re-write/update the existing KA products.  Additionally, it was discovered that there were very few software engineers available that had sufficient military experience to understand the KA products adequately to move directly into writing code.  It quickly became apparent that an interim step needed to be performed; the existing KA products (representations of Army doctrinal behaviors) had to be dissected for missing or incomplete data, and translated into specific steps, or functionality, that the software engineers could understand and model.  Decisions had to be made concerning which steps within behaviors were to be explicitly modeled, and which could be handled implicitly.  Decisions were required from the government concerning the level of detail required within the simulation, levels of control demanded by the unit controllers (role players), and whether certain data should be “hard coded” or represented in data.  The process by which these issues were identified and resolved became known as the Knowledge Engineering (KE) process.The KE process began with the teaming of a contractor SME (KA Author) with 3 to 5 software engineers.  Each software engineer was assigned one or more KA products covering related military behaviors, and was required to read the KA products.  This inevitably generated a series of discussions with the contractor SME as the software engineer sought to completely understand doctrinal processes to be modeled.  Between the contractor SME and the software engineer a series of “interim” documents were developed (see section 2.4.2) and reviewed at weekly meetings.  Attendees at the meetings varied, but generally included senior software engineers, additional contractor military SMEs, equipment and training contractor SMEs, and government representatives from STRICOM and NSC.  Having the right people in attendance allowed a thorough review of modeling concepts being developed, and allowed the software engineer to validate his/her design concepts, get guidance, and get decisions on important design questions.  While this process was manpower intensive, the result was a common understanding between the government representatives and the various CETs as to what would be represented within the simulation, and how it was to be represented; before the actual lines of code were written for the behaviorsProducts The purpose of developing a conceptual model is to bridge the authoritative knowledge gap between warfighters and simulation developers by providing descriptions of the real world.  Military subject matter experts use their experience with the subject domain to communicate with software engineers/modelers who represent the information in knowledge representation formats.  The resulting products are entered in a repository and used by the simulation developers to support the requirements analysis, design, and implementation of their simulation.[3] This section addresses the knowledge acquisition and knowledge engineering products developed for the WARSIM 2000 program and the repository developed and used to store them.KA ProductsBehavioral representations are the most complex and numerous representations in a constructive simulation.  They are used by the simulation developers to model the behaviors of the computer-generated forces (CGF). [3]Army behaviors, as developed for WARSIM and stored in the FDB, are described using a variety of representations including:Unit Models (Organizational Descriptions)Mission Models (Process Descriptions)Task Models (Process Descriptions)Equipment ModelsUnit Models describe the organization and purpose of a specific unit. The unit model provides a unique identifier for each unit type, a reference matrix, a general description of the unit type, organization of the unit (Table of Organization & Equipment (TO&E): subunits, personnel, and equipment to platform level) to include typical or representative non-organic “slice,” task organization information, an equipment list in accordance with the TO&E, a list of missions the unit is capable of performing, a list of tasks that the unit is capable of performing in the execution of the previously listed missions, unit basic load information and any default procedures which define standard operating procedures for the unit.Mission Models describe the missions that a unit can perform.  The mission model provides a unique identifier for each mission, a reference matrix, a general description of the mission, the specific purpose of the mission (which distinguishes a mission from an operation or task), a temporal view of the mission’s task sequences, to include a template and discussion, a list of the tasks which make up the mission, planning considerations and execution considerations and course of action options and analyses.Task Models provide detailed descriptions of tasks, which are performed as part of a mission.  Task descriptions contain the bulk of the information required to simulate behaviors and include: a unique identifier for each task, a reference matrix, an introduction and background, a general description of the task, a planning section containing triggering conditions, resources, step details (to include inputs, methods, and outputs), and a temporal view, and an execution section containing triggering conditions, resources, step details (to include inputs, methods, and outputs), situational interrupts, terminating conditions, and a temporal view.  The format of the task models is primarily textual with appropriate modeling diagrams used to support the text.	In addition to Army behaviors, each type of equipment to be simulated in WARSIM also had to be described.  Although constructive wargames are often considered to be modeling at an aggregate level, equipment-level descriptions are still needed.  Some simulations, such as WARSIM, are built “bottom-up”; that is, small units (such as platoons) are formed from a collection of equipment “entities”.  These small units are then combined with other small units to form larger units (such as companies).  Also, some constructive wargames, such as WARSIM, include a viewer.  Visual representations and other attributes are required to present a reasonable representation of the battlefield situation.  Many of the simulation’s requirements may result in equipment-level representations. [3]Equipment Models in WARSIM initially took the form of individual, static, parametric data spreadsheets.   It soon became apparent that this was not a manageable method to store parametric data and attributes for over 400 individual pieces of equipment.  Existing spreadsheets were therefore merged into an Oracle relational database and the remaining equipment descriptions were entered directly into this database using an automated tool developed specifically for that purpose, but re-usable for future simulation database development.Finally, algorithms were needed by a variety of WARSIM CSCIs, primarily Unit and Equipment. Physical models were required, in the form of algorithms, which described low-level interactions with the simulated environment including ballistic trajectory, line of sight, and damage assessment calculations.  Similarly, Human Characteristics Models were required which described the quantitative impacts key characteristics have on selected task performance measures for certain tasks and unit types.  Examples of information that was represented in algorithms include Sensing, Human Characteristics, Damage Assessment and RepairKA activities were also performed in other areas including military communications.  System details were documented in a variety of formats to include interface representations, message set formats and high-level descriptions of systems in white papers.  KE ProductsDuring the KE process up to four separate types of documents were developed for each behavior; an Operational Domain Outline, a Behavior Definition Frame, Fundamental Behaviors, and Predicates.An Operational Domain Outline organizes and presents doctrinal topics presented in multiple KA documents and summarizes how each topic is modeled.  An Operational Domain Outline provides traceability to requirements and to source KA documents.  Operational Domain Outlines were typically prepared by the contractor SME, in collaboration with the software engineer, at the beginning of the process, while the software engineer was reviewing the KA documents and becoming familiar with the doctrinal functions to be modeled.  Once the Operational Domain Outline had been reviewed, refined, and accepted by the government, the software engineer began the behavior definition process.Behavior definition is principally a process of composition; that is, organizing fundamental and non-fundamental behaviors in planning (i.e., how to plan the mission or task) and execution (i.e., the steps in executing the mission or task) timelines. Defining planning and execution functions are closely entwined.  Fundamental behaviors are atomic behavioral building blocks from which non-fundamental behaviors are built.  Fundamental behaviors are implemented directly in the simulation. Non-fundamental behaviors, on the other hand, are represented as data structures read from Source Database CSCI and interpreted for execution by Unit CSCI software.  Non-fundamental behaviors represent military missions and tasks as well as aggregates of fundamental behaviors from which military missions and tasks are composed.  Non-fundamental behaviors are defined in Behavior Definition Frames (BDFs).  Each BDF is composed of slots containing information for planning and execution.  Planning plots define the sequence of behaviors for planning non-fundamental behaviors. Execution plots define the sequence of behaviors for executing non-fundamental behaviors.  The Unit CSCI architecture reflects the division between planning and execution by including planning and executor agents.  Planning agents use BDFs to create plans while executor agents follow plans to coordinate subordinates’ actions on the battlefield.Predicates are Boolean functions written in prefix notation using natural language-like words.  The software engineer develops the semantics for new predicates, that is, establishing the criteria to be used to determine whether the value will be set to True or False.The KE process, and the resulting products, is the source of realism for the simulation.  That which is not modeled by KE will not appear in the simulation.  RepositoryThe FDB process began with lessons learned from the development of the Close Combat Tactical Trainer (CCTT) as part of the Combined Arms Tactical Trainer (CATT) program.  CCTT used a series of combat instruction sets (CIS) to describe the operational processes that would be simulated.  The CCTT program started with a focused effort to collect only existing relevant data, which evolved into the development of the CIS.  The CIS were developed by military subject matter experts hired by the CCTT contractor but not explicitly validated by the Army before being written into computer code. The FDB leveraged this data collection and information development process with the development of WARSIM and began to focus on a long-term solution to retain this information for future use.  The idea of an on-line repository to hold functional descriptions of the Army battlespace evolved from the WARSIM requirement to portray doctrinally valid behaviors.The method that the WARSIM combat developers chose to provide doctrinally valid behaviors was to have government military subject matter experts review the conceptual models written by contractor personnel and declare the conceptual models to be valid representations of doctrine.  The government subject matter experts consisted of doctrinal experts from the various TRADOC schools and organizations and were recognized experts in the areas that they reviewed.  The contracted subject matter experts who researched and wrote the actual conceptual models became known as KA authors.  By reviewing and validating the conceptual models, the Army ensured that the behaviors to be simulated were traceable to current doctrine.  And while the KA authors were recognized as subject matter experts, the government subject matter experts (SME) gave the Army's stamp of approval on the conceptual models.Physically, the FDB is a web based, distributed data repository system that can be accessed via commercial internet browser software to support the development of future simulations.  This data repository is a password protected web site that consists of a validation utility, a document repository, an equipment database and a change request utility.  The validation utility allows the KA authors to post their draft conceptual model on the web site.  An email is generated automatically to the appropriate government subject matter expert who is given 30 days to review the document and post comments in the comment section of the validation utility.  This generates another automatic email to the author who will review the comments and either incorporate the comments into the document or contact the government SME for clarification.  The validation utility allows an open exchange of ideas and anyone with access to the FDB can review the documents and subsequent comments.  Upon a meeting of the minds between the SME and the KA author, the SME will validate the document online using a simple button.  Once the document is validated, it moves to the document repository.  The document repository consists of a series of hyperlinked documents grouped logically by battlefield function.  A user can call up a document by clicking on the hyper link or by using an embedded search engine.  The document is retrieved in Adobe “.pdf ” format to facilitate configuration management of the documents.  The equipment that is to be simulated in WARSIM represented a different challenge to the KA authors and the FDB developers.  As described in paragraph 2.3.2, conceptual models of equipment were more accurately represented in a relational database, rather than in text format.  The entire database was stored on the FDB.  A user can pull up a report on a specific piece of equipment by selecting the equipment from a provided list.  The report is generated on the specific piece of equipment using plug-in software.Users can also provide comments or report on errors within the FDB itself using the change request utility.  Submitting a change request generates a message to the FDB system engineer who will review the request, establish priorities, and seek approval from the FDB Program Manager, through the configuration management process.Lessons LearnedAs part of its continuous process improvement, the WARSIM IDT made several discoveries and captured several lessons learned during the course of its conceptual modeling effort. Those lessons are divided into three general categories:  process, products, and repository.  Furthermore, the process and products sections are subdivided into two additional sub-categories:  knowledge acquisition and knowledge engineering.  Since the WARSIM conceptual modeling process and resulting products were actually divided into the two separate and distinct phases, the lessons learned are addressed separately as well.  The initial phase, as described in section 2.2.2 The Knowledge Acquisition (KA) Process, consisted of planning, focusing the scope of the knowledge/data to be gathered, researching authoritative data sources (ADSs), acquiring information and data, and recasting it into textual and databased descriptions.  The second phase, as described in section 2.2.3  The Knowledge Engineering (KE) Process, is taking the previously developed textual descriptions and translating them into understandable and usable representations for the simulation developer (software engineer).Process Lessons The development of conceptual models requires a knowledge development process, similar to the process employed for developing the simulation’s software.  The execution of this process results in knowledge representation products.  An objective of the process is to produce models that are complete, accurate, and traceable [3], however, “The best laid plans of mice and men oft go astray.”From the poem “To a Mouse (On Turning Up Her Nest With a Plough)”, by Robert BurnsKnowledge Acquisition Process LessonsDuring the course of the WARSIM conceptual modeling effort, several lessons dealing with the overall conceptual modeling process were learned.  The major ones include:A Prior, Well Defined Process.  During the conceptual modeling effort, numerous changes to the process were made to accommodate the evolution of simulation design. Even with these required changes, it has become apparent that a prior, well-defined process is still essential to success.  This process must be well defined prior to the start otherwise you end up with a haphazard effort at best, which most likely will not meet the needs of the simulation developers.Supplemental Plans.  In addition to the initial plan, it quickly became apparent that a number of supplemental or incremental work plans would be required.  These incremental plans, together with continual updating of the basic plan and process serve to focus the effort, adapting the process to “ground truth”.Coordination. Coordinating and crosschecking with system & software engineers was found to be crucial.  On more than one occasion, a work plan called for KA in an area that had been moved to another build, deleted as a requirement or significantly changed.  It was only through close coordination with software development personnel that the conceptual modeling effort successfully met system requirements.Synchronization. Synchronization of KA with software development is also a critical element of success in addition to the aforementioned coordination.  KA must be an integral part of the overall development process.  In WARSIM, even though the KA authors worked directly for the CET/CSCI leads KA and SW development sometimes still got out of synch.  Working groups helped in this area, but only if the SW developers were participating members.  Secondly, because KA significantly preceded SW development, validation of the conceptual models sometimes lagged. This was not a significant problem because of the very reason that caused the problem in the first place.  With KA preceding SW development by such a lengthy period, it allowed more than normal, adequate time for validation.  However, this will not always be the case, nor should it.  And finally, since there was no overlap between the Knowledge Acquisition and the Knowledge Engineering activities, much of the expertise used to develop the conceptual models was no longer present during the KE phase.  The effect of this is discussed in further detail in sections 3.1.2 and 3.2.2.Working Groups.  As mentioned previously, face-to-face coordination in Working Groups is an absolute necessity.  As is well known to all, requirements often change.  WARSIM was no exception.  As a result, frequent “in-person” meetings were required to iron out differences and ensure requirements matched products.  Forming sub-groups to study particularly difficult or controversial issues was also extremely useful.  It is clear from the WARSIM experience that this work can not be done in any other forum, other than face-to-face meetings of all parties involved to include the customer, software developers, KA personnel, etc. One Effort vs Many.  KA should be done as an integrated whole.  It cannot be piecemealed by build, version or modularly conducted without significant additional expenditure of resources and a corresponding decrease in quality.  It must provide a continuous flow of effort from inception to Final Operating Capability (FOC).  It is readily apparent that it is more costly and less efficient to constantly have to release KA and KE personnel and then re-staff at a later date with new, untrained individuals. It is difficult enough to find true Knowledge Engineers and discontinuous KA operations will make it impossible.Additional, Unplanned Work.  The spiral build process creates additional KA requirements.  New behaviors identified during the KE process required additional KA to be performed in order to satisfy the requirement. (See section 3.1.2. below).  Developmental and technical approach decisions and changes often-required additional KA work that had not originally been planned.  When this additional KA was required to be performed after the formal KA period had already closed, there was no longer any process for Army validation of the new information.  This unvalidated information could have more impact on the simulation than the doctrine in the original KA conceptual models.  For WARSIM, while it was “officially” unvalidated, that is, not a product of the formal FDB review/comment/revise/review/validate procedure, it was approved for use by the user representative.Physical Location.  KA is best accomplished co-located with the software development team.  WARSIM KA was accomplished at multiple locations.  This approach worked, but the level of KA, KE and SW interaction required, makes it much more efficient to co-locate assets.  A significant savings (approximately 15%) in average conceptual model production time was realized by the co-located KA authors.Metrics Collection.  KA metrics collection was hindered by changes and lack of automation.  Metrics were collected to provide accurate, experience-based estimates for KA work.  KA metrics are unlike SW development metrics, as there is no pre-defined process or metric requirements.  As a result, significant effort must be placed on deciding up front what statistical information you wish to collect and for what purpose.  Additionally, as witnessed in WARSIM, when requirements and formats change, metrics collection becomes more difficult.  The manual method of collection used in WARSIM 2000 was not optimal and did not support rapid compilation and analysis.  Use of an automated tool such as the Knowledge Development Tool (KAT) developed for DMSO by DRC will provide significantly more accurate and timely metrics.Knowledge Engineering Process LessonsThe use of a spiral build concept, and the beginning of KA work prior to specific KA requirements being known, caused early KA products to lack some information ultimately deemed necessary for software design.  As a result, additional KA work had to be done during the KE process.  The majority of this additional KA work centered around collection of data to populate data tables that were not identified until certain design decisions were made.In addition to requiring additional KA work during KE, a clearer picture of the KA requirements, and the level of detail required in KA products, prior to beginning the KA effort would have reduced the amount of time required to produce the KA products.  A format much closer to the Operational Domain Outline could have been used, greatly reducing both the KA and KE effort.  Essentially, the KA products that were developed had too much detail in some areas, and not enough in others.  However, given the time constraints that are often imposed on M&S programs, up front software design and KE process planning would be useful in mitigating this problem.Bona fide Knowledge Engineers (software engineers with advanced military subject matter expertise) are not abundant, nor easily hired.  As a result, a great deal of time was spent educating the software engineers on the doctrinal processes and functionality required in the many behaviors being modeled.  The teaming of contractor (military) SMEs with software engineers had not been originally planned, but evolved as a very effective technique to overcome the lack of military expertise among software engineers.  In the absence of large numbers of bona fide KEs for any program, planners must provide SMEs to collaborate with the software engineers.  Having access to a SME can save software engineers many hours of work researching information (or rewriting code) for things known well to the SME.  A few minutes spent on a blackboard often saved hours of wasted effort.Because the need for a KE process was not clearly recognized early, the process evolved from necessity, through trial and error.  The learning process was costly in terms of resources expended.  Even given the constraints imposed by a spiral build and lack of clear KA requirements, early recognition of the need to team SMEs with software engineers would have resulted in increased productivity in the early stages of software design.Product Lessons As with the conceptual modeling process discussed above, several lessons were learned during the research, development, review, revision and validation of the knowledge acquisition products.  Knowledge Acquisition Product LessonsScope.  Both the number of models to be produced and the content of the individual models need to be carefully delineated prior to conceptual model development.  In WARSIM, the initial number of models was estimated at approximately 14,000.  It soon became apparent that this was neither fiscally feasible nor could it be accomplished within schedule.  As in WARSIM, budget often becomes the driving force behind a program’s conceptual modeling.  Rather than developing separate unit, mission, task and equipment models for all 14,000 items, a “functionality and representative” approach had to be used to reduce the total number of models and still provide sufficient data to support developer needs.  Significant time and effort was spent “re-scoping” the WARSIM KA effort.  The lesson of scope also pertains to the content of individual models.  With WARSIM, the KA effort was performed well in advance of the software development spiral, to include requirements analysis.  Since the simulation developers were not yet exactly sure what information they would need and in what detail they would need it, the result was KA models that were written to a much greater level of detail than was actually needed to support simulation development.Multiple Views.  There is no “silver bullet” explanation of or model for how an activity or organization performs.  Multiple “views” or models are often necessary depending on who is using the information.  The proverb “One man’s junk is another man’s treasure” accurately depicts the challenges in developing representations that are understandable to all those who read them.  It helps significantly to craft the model formats and content requirements with the user (customer) in mind, i.e. the software engineer, but even this is not always 100% effective.  Additional views, models, or information augmentation will undoubtedly be necessary at some level.  The key is to try to minimize this requirement by actively involving the software developer in this crafting process.Changes to Requirements and Formats.  All changes, whether they are to requirements or formats, have an adverse impact on schedule and cost.  In order to minimize these impacts, formats should be finalized prior to the start of the knowledge acquisition effort.  As mentioned above, this finalization should be done in close concert with the end-user.  But this is extremely difficult, given that oftentimes the end-user in not yet sure what information will be needed and what format is best suited for their ultimate use.  Additional impacts on format are Quality Assurance (QA) and Configuration Management (CM) requirements that may be imposed.  These QA/CM processes and requirements must also be established prior to start of KA, otherwise numerous mid-stream format changes may be necessary.  In the WARSIM KA effort, numerous conceptual model format changes were necessitated by several factors such as changes in the needs of the SW developers, lack of an initial QA Document Style Guide and CM process, and numerous JSIMS-driven Formalized Data Product (FDP) format requirements and changes.  An automated tool, such as the DRC developed DMSO Knowledge Acquisition Tool (KAT), would appreciably reduce the number of formatting issues and the amount of effort necessary to make resulting changes.Authoritative Data Sources (ADS).  ADSs that describe the domain being simulated are critical to any conceptual modeling effort.  Overall, the ADS process used by the FDB and WARSIM worked exceptionally well.  The ultimate customer – the simulation end user provided an initial list of ADSs.  The Knowledge Acquisition Working Group then established a standard procedure for the use and approval of any sources not on the initial list.  While there were some “glitches,” such as certain domain area proponents wishing to use “draft” doctrine, these were minor in the overall scheme of things and easily resolved.  The only real noteworthy problem was difficulty in obtaining contractor access to certain “restricted” reference sites and further access to even more restricted documents on those sites.  This did somewhat hamper KA efforts and often delayed model production.  The optimal solution is to obtain all the necessary access authorizations prior to beginning the KA work; however, this is not always possible, as you never know to which source a KA research effort will lead.  Bottom line; obtain access to as many as possible as soon as possible for as many of the KA authors as possible.Validation.  While the overall validation process worked extremely well, a few minor problems arose with the validation of WARSIM products. Significant time and effort was wasted reviewing, responding to, and correcting validator comments that ultimately would have no impact on the simulation, such as:  proverbial “happy to glad” changes, grammatical suggestions, title changes not affecting behavior or organization, and other similar reviewer comments.  While the validation authority tried valiantly to establish and enforce validation review standards, it was near impossible to do when the reviewers are scattered across the US. Additional discussion of validation lessons, in the area of the document repository and its validation utility are discussed in section 3.3 below.Knowledge Engineering Product LessonsDuring the initial software development phases, the software engineers were assigned to read the textural KA documents and prepare the Operational Domain Outlines.  Most were less than satisfactory, and required a great deal of time to prepare, be reviewed by SMEs, and be rewritten by the software engineers.  While useful in the education of the software engineer it consumed far too many resources.  The software engineers were not able to extract the most important steps within the individual behaviors, nor were they able to determine which steps were acceptable for implicit representation, and which needed to be explicitly represented.  Eventually KA authors were assigned to synthesize the KA documents into the Operational Domain Outlines, in collaboration with the software engineers.  Once the software engineers had read the KA document, discussed the behaviors with the contractor and government SMEs, and assisted in the preparation of the Operational Domain Outlines, they understood the behavior well enough to prepare the BDFs, Fundamental Behaviors, and Predicates that were required.  The key to success was the teaming of the contractor SME and the software engineer to translate the textural KA product into something useful and understandable by the software engineer.The jury is still out on the final lesson learned concerning KE Products.  Unlike the formal process defined for KA products, the KE products were handled much more informally.  As documents were prepared in various drafts, they were transmitted by e-mail to the personnel responsible for reviews.  As noted previously, these reviews were conducted weekly, often via teleconferencing, and issues were captured in meeting minutes.  The documents themselves were never posted to the FDB for “world-wide” review and comment, nor is there a repository of all comments made, and linked to a “validated” document.  This “less formal” process was much less resource intensive to manage, and avoided the considerable delays involved with posting, and re-posting, documents to the FDB.  On the negative side, however, we do not have the same level of traceability of comments, discussions, and approved resolutions of issues that we have for FDB documents (KA products).  While there was some risk assumed with this approach, it has proven to be cost effective, generally attributable to the professionalism and close working relationship between the contractors and various government representatives.Repository LessonsThe web-based validation utility worked exceptionally well for reviewing, commenting, tracking progress and validating the conceptual models.  The process by which the subject matter experts, scattered throughout the world, could review the documents and comment online worked very well and provided the kind of immediate feedback that is normally lacking in the Army's staffing process, which usually involves shipping hard copies of documents via mail.  The downside on the web- based system is the variety of computer networks in use by the Army worldwide.  Local bases often did not have the network infrastructure in place to handle the downloading of large text and graphics files.  The users often perceived this as a problem with the FDB hardware, when in fact; it was usually a local problem.The FDB would also benefit by becoming more intuitive to the users and more user friendly.  The organization of the conceptual models is in need of improvement and is not intuitive.  Software developers often had difficulty in locating the conceptual model in which they were interested.  Key word and title searches often resulted in displaying a large number of documents due to the similarity of document titles.  Documents are identified by unique numbers, consisting of thirteen characters, so searching on document numbers is difficult.  Software developers found it easier to approach the KA author or military SMEs and have the author point him to the applicable product in the local copy of the repository, rather than use the tools available on the FDB to locate the conceptual model.  The documents themselves, once displayed, were not in a user-friendly format.  The same Adobe “.pdf “ format that made the configuration management of the documents simpler, also made the documents harder to work with, which was a common observation by the software developers.SummaryThis paper has discussed the lessons learned from an extremely ambitious military simulation knowledge acquisition and knowledge engineering effort for development of the Warfighters’ Simulation (WARSIM) 2000 constructive simulation.  The charter of the conceptual modeling effort was to produce, document and archive accurate, validated and traceable standard descriptions of the components and characteristics of Army battlespace functions that could then be used to produce credible simulations of these same functions.  Additionally, there was the concurrent need to meet the requirements of a specific simulation under development, WARSIM 2000.  The models were also intended to support simulation interoperability by describing cross-domain interactions with other JSIMS models and the resulting models were used to simultaneously populate the U.S. Army’s conceptual model repository, the Functional Description of the Battlespace (FDB).Significant lessons were learned in several areas. A comprehensive process was developed and documented to guide the effort.  During the conduct of the various phases of the FDB effort, countless challenges were encountered and solved with appropriate adjustments to the plan and process made.  Valuable lessons were learned in the areas of knowledge acquisition, knowledge engineering, and repository storage and validation.Since the intent of the FDB was to serve as a basis not only for WARSIM 2000, but also for development of subsequent simulations such as OneSAF, it is imperative that these lessons be noted, heeded and applied in future simulation development.  In the words of George Santayana, American philosopher, educator, poet, and novelist,“Those who do not remember the past are doomed to repeat it.”References[1]	Sheehan, Jack; et al: “CMMS: Basic Concepts, Advanced Techniques, and Pragmatic Examples”, (Paper 98S-SIW-127), Proceedings of the Simulation Interoperability Workshop, March 9-13, 1998.[2] 	Risner, Steve, et al: “Conceptual Modeling in the Joint Simulation System (JSIMS)”, (Paper 98F-SIW-147), Proceedings of the Simulation Interoperability Workshop, March 9-13, 1998.[3] Lacy, Lee and Dr. Larry O'Brien, "Conceptual Modeling for WARSIM 2000", Proceedings of the Interservice/Industry Training Systems and Education Conference, (I/ITSEC '97), Orlando, Florida, December 1-4, 1997.Author BiographiesDAN SAGAN is a Senior Staff Systems Analyst with Dynamics Research Corporation and has been working on the WARSIM 2000 program since 1997; most recently as the DRC sub-contract Program Manager.  Dan is a 1974 graduate of The Citadel and has an MS in Mathematics from the University of South Carolina.  He is a retired Army Lieutenant Colonel, having most recently served in an Operations Research/Systems Analysis position in charge of training simulations at Fort Benning, GA.DANIEL E (ED) KERSEY is a Staff Systems Analyst with Dynamics Research Corporation and has been working on the WARSIM 2000 program since May 1997.  Ed is a 1969 graduate of the United States Military Academy, and has an MA from Central Michigan University.  He served as a Platoon Leader and Company Commander in Vietnam, commanded an Infantry Battalion in the 82d Airborne Division, and retired as a Colonel.  Ed is also a graduate of the Command and General Staff College, and the National War College. LTC PHIL MAY is the Project Director for the Functional Description of the Battlespace and is assigned to the National Simulation Center.  He is a 1980 graduate of the United States Military Academy and has an MS in Operations Research from Texas A&M.  Previous assignments include Deputy Director for Technical Support at the Warrior Preparation Center and battalion operations officer and assistant division engineer for the 2nd Armored Division.