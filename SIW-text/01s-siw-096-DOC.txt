Bandwidth, Latency, Jitter, and Synchronization: A High Fidelity Simulation PerspectiveRonald G. BertinThe Boeing CompanySt Louis, MOWilliam C. BeavinThe Boeing CompanySt Louis, MOAbstractIn order for high fidelity, real-time simulations, which require realistic scenarios, to interoperate in a distributed fashion, it is critical to understand the requirements for network bandwidth, latency, and jitter, as well as computer synchronization.  This is especially important in planning future networking capabilities, and so is important to share with the simulation community.  This study will use a well-controlled emulation of a 3-site wide area network (WAN), in addition to several test points obtained from actual WAN configurations, to determine baseline network characteristics, establish a DIS based reference data set, and an effectively equivalent HLA RPR FOM data set.  Network loading will include basic state information, emissions, and communications such as JTIDS.  Conclusions will include overall bandwidth, latency, jitter, and synchronization requirements, which were identified from the tests.  Data reduction techniques, such as data distribution management (DDM), will not be directly addressed in this paper, other than indicating the network requirements if such methods are not utilized. AUTONUMLGL  Introduction“Theater Simulation” is a Boeing program extending through the year 2004.  A goal of the virtual simulation component is to connect 4-7 sites across the enterprise (via a secure network) in real-time simulated HLA exercises featuring up to 2000 “virtual” and “constructive” entities.  Meeting this objective will require significant and in-depth analysis of network requirements.Given the need by 2004 for the ability to simulate a realistic theater-level environment, such as 5-lanes over Korea, with potentially thousands of bodies, it is imperative that we gain a comprehensive understanding of network requirements from the perspective of bandwidth, latency, jitter, and synchronization.  The simulated bodies (“virtual” and “constructive”) will be distributed and observed over multiple sites initially including but ultimately not limited to the Interactive Technologies Development Lab (ITDL) in Seattle, the Virtual Warfare Center (VWC) in Saint Louis and, the Systems Assessment Lab (SAL) in Seal Beach.  Sites will be added incrementally each year.  State of networking technology, availability of resources, and affordability need to be factored into the equation and subsequent tradeoffs identified.This intermediate paper presents the results of a well-controlled emulation of a 3-site wide area network (using Shunra “Cloud( WAN Emulator” software) to study the impact of variations in network properties.  Additionally, the results of an in-depth bandwidth analysis for small, medium, and large scenarios utilizing entity and transient (event-driven) data shall be presented.  The DIS and HLA-based analysis will include Entity State, Electromagnetic Emissions, JTIDS (via Signal PDU), and Radio (Transmitter, Signal, Receiver PDUs) data.  Other data, such as simulation management, fire, and detonate, will be assumed to be relatively small.  Designate data will not be included in the initial study.  While inclusion of designation data could have a noticeable impact on overall bandwidth, we don’t believe the impact would be of sufficient magnitude to change the indicated trends.  Also included in the analysis will be information to drive display repeaters and send digital video streams.  It will be assumed for initial analysis purposes that all information will be broadcast, as is standard for DIS operations.The basic scenarios used for the off-line bandwidth analysis will be “small”, “medium”, and “large” in terms of the number of entities.  The following paragraphs describe the ultimate simulations – the bandwidth analysis merely quantifies (mathematically) the potential demands on the network for scenarios of such sizes.  Ultimately, for our testing and subsequent analysis these scenarios will be emulated using local machines and the aforementioned “Cloud(” software package to introduce WAN typical latencies and “jitter” into the local area networks (once these “typical” values have been quantified).“Small” scenario:	This scenario will include 1 AWACS, 11 fighter (5 blue, 6 red) entities, and 5 cruise missiles.  Each fighter will be capable of firing up to 4 radar-guided missiles.  Four of the blue fighters will be piloted in cockpits - a MIL/AASPEM station will control the fifth.  There will be two operator stations; one in Saint Louis (VWC), the other in Seattle (ITDL).“Medium” scenario:	This scenario will include 2 AWACS, 98 fighter/mover (34 blue, 68 red) entities, and 50 cruise missiles.  Each fighter will be capable of firing up to 4 radar-guided missiles.  Four of the blue fighters will be piloted in cockpits - two MIL/AASPEM stations will control two others.  There will be three operator stations; two in Saint Louis (VWC, VIC), the other in Seattle (ITDL).“Large” scenario:	This scenario will include 2 AWACS, 998 fighter/mover (340 blue, 658 red) entities, and 500 cruise missiles.  Each fighter will be capable of firing up to 4 radar-guided missiles.  Eight of the blue fighters will be piloted in cockpits - two MIL/AASPEM stations will control two others.  There will be four operator stations; two in Saint Louis (VWC, VIC), the other two in Seattle (ITDL). AUTONUMLGL  ApproachBoth analysis and measurements are performed using a systematic approach in order to determine bandwidth, latency, jitter, and synchronization requirements.  Initially, we will examine projected bandwidth requirements for the three previously defined scenarios.  This will be accomplished by looking at current requirements for DIS simulations initially assuming HLA (using the RPR FOM) will have similar results.  If, after robust implementation of routing-space filters, optimal use of multicasting, and thorough system and network analysis, HLA proves to perform significantly worse than DIS, it is assumed that improvements to the HLA implementation will be required to make the HLA-based scenario performance at least equivalent to the DIS-based performance.The results presented in this paper have been generated using KISS (“Keep It Simple …”) testing.  The KISS test simply sends packets from one machine to another, keeping track of time increment parameters along the way.  These parameters are as follows: 1) DIS Timestamp, 2) Transmit Time, and 3) Receive Time.  It also generates a waveform to include as data in order to help determine if packets are being dropped.  From these parameters, representative numbers for packet generation time (Transmit minus Timestamp), Transmit Latency (Receive Time minus Transmit Time), and Latency Jitter (minimum, maximum, and average latency) may be calculated. AUTONUMLGL  KISS Testing – Local Area NetworkIn order to determine benchmark characteristics for LAN performance, the KISS test will be run on machines configured as a local network, including WAN emulating PCs running the “Cloud(” software –in order to add latency and jitter to the packet times, thus emulating the effects of a long haul connection.  An Ethernet Analyzer will be used to measure “Wire Time” in order to assess the stability of the packets sent from the packet generator.  The configuration used to test the LAN is illustrated below in Figure 1. EMBED PowerPoint.Slide.8  Figure 1: KISS Testing - Saint Louis LAN ComponentsThe methods used to perform the test are shown in  REF _Ref500824868 \h  \* MERGEFORMAT Table 1: KISS LAN Testing Methods.TestMethodDataPurpose3.3.1.1 Use Ethernet Analyzer to measure packet timesDirectly measure network timingDIS Timestamp, Transmit Time, Wire TimeHow stable do packets come out of the generator machine?3.3.1.2 LAN-OnlyMeasure KISS data with 2 computers on same LANDIS Timestamp, Transmit Time, Wire Time, Receive TimeComplete 1-way timing statistics for benchmark characteristics3.3.1.3 LAN-with-WAN Emulation PC set to No Delay & No JitterMeasure KISS data between 2 computers with Emulated WAN between themDIS Timestamp, Transmit Time, Wire Time, Receive TimeBenchmark performance including PC-Induced characteristics3.3.1.4 LAN-with-WAN Emulation PC with Range of Delays and Jitter SettingsMeasure KISS data between 2 computers with Emulated WAN between themDIS Timestamp, Transmit Time, Wire Time, Receive TimePredicted WAN performanceTable 1: KISS LAN Testing Methods AUTONUMLGL  Preliminary Bandwidth Analysis ResultsFrom our calculations, it can be seen that the bandwidth requirements tend to increase logarithmically from a small scenario requiring rates in terms of megabits per second, to a medium sized scenario requiring tens of megabits, to a large scenario requiring in the hundreds of megabits per second range.The logarithmic linearity can be seen in  REF _Ref501185661 \h  \* MERGEFORMAT Figure 2: Preliminary Bandwidth Analysis Results (Log Scale).  Superimposed on the chart are lines indicating T1, DS3, OC3, and OC12 performance.  The limitations imposed by these line capabilities are indicated in the following 4 diagrams.Figure 2: Preliminary Bandwidth Analysis Results (Log Scale)As shown in  REF _Ref501186248 \h  \* MERGEFORMAT Figure 3: Preliminary Bandwidth Analysis Results (Linear Scale), a small scenario will function in the range of T1 lines, a medium in the range of DS3 lines, and large scenarios in the range of OC3 lines.  This chart gives only a rough idea of the “average” loads, however, and doesn’t show the possible ranges which may be expected.  It also doesn’t factor in the improved results from using routing spaces, filtering, or other intelligent means of reducing bandwidth requirements.Figure 3: Preliminary Bandwidth Analysis Results (Linear Scale)A closer look at the range of data requirements for a large scenario is shown in  REF _Ref501186569 \h  \* MERGEFORMAT Figure 4: Preliminary Bandwidth Analysis Results - Large Scale Scenario Data Range.  This indicates that, excluding digitized display streaming data, an OC3 line would be able to handle the average load.  However, in the potential case where more than an average number of entities are maneuvering and emitting, the requirements go up sharply – potentially increasing from about 100 Mbps to about 300 Mbps.  Such a case would require 2 OC3 lines (budget risk) or significant software data reduction (technical risk).This figure also shows that digitized video data could require a steady 100 Mbps.  This could clearly ramp up or down, depending upon computational ability to generate digital video data and bandwidth to transport it.  Experience would indicate that some imagery is best suited for digital transmission (sensor imagery) while other imagery is best regenerated at a remote site and driven from a few parameters (a cockpit’s HUD display).  So, a compromise solution will probably work best.Figure 4: Preliminary Bandwidth Analysis Results - Large Scale Scenario Data RangeFigure 5: Preliminary Bandwidth Analysis Results - Medium Scale Scenario Data RangeThe previous figure,  REF _Ref501187413 \h  \* MERGEFORMAT Figure 5: Preliminary Bandwidth Analysis Results - Medium Scale Scenario Data Range, indicates that a DS3 line should be capable of handling the case of the medium sized scenario – excluding digitized video.The indication in  REF _Ref501187531 \h  \* MERGEFORMAT Figure 6: Preliminary Bandwidth Analysis Results - Small Scale Scenario Data Range is that even without any digitized video, 2 T1 lines would have trouble handling the load of a small scale scenario, given that the bandwidth required will occasionally approach the maximum load.  By giving up display repeat data, using radios only during “data lulls”, and using software filtering techniques, it should be possible to execute a small scale simulation over 2 T1 lines with reasonably stable results.  This result should hold so long as the communications perform at least as good as, if not better than, DIS.Figure 6: Preliminary Bandwidth Analysis Results - Small Scale Scenario Data RangeThe next 6 figures present a breakdown of the data analysis of information grouped by DIS PDUs.  The small, medium, and large scenario expectations are the data points while the vertical lines represent the minimum and maximum potential values for each point.It can be seen that in the case of entity state, emissions, and JTIDS, the bandwidth required increases nearly logarithmically with scenario size.  The radio is fairly constant assuming the number of voices speaking at once is limited - increasing perhaps with the addition of voice channels.  Display repeats are more limited by the number of observation displays in use, which are expected to increase somewhat as the scenario becomes more complex and distributed.  It is also assumed that digitized data streams will not be used for the small scenario, since it would totally overwhelm the relatively small bandwidth required.Figure 7: Preliminary Bandwidth Analysis Results - Entity State Data RangeFigure 8: Preliminary Bandwidth Analysis Results - Electromagnetic Emission Data RangeFigure 9: Preliminary Bandwidth Analysis Results - JTIDS Information Data RangeFigure 10: Preliminary Bandwidth Analysis Results - Radio Data RangeFigure 11: Preliminary Bandwidth Analysis Results - Display Repeat Data RangeFigure 12 Preliminary Bandwidth Analysis Results - Digitized Display Stream Data Range AUTONUMLGL  Local Area Network KISS Test Results AUTONUMLGL  Follow-On StudyAs a “next stage” in this effort, we will undertake a study of bandwidth, latency, “jitter” and, synchronization using both single simulated aircraft and a wide range of multiple-entity scenarios utilizing DIS and alternately, HLA.  All of these tests will be performed using local assets and simulating the subject WAN via the “Cloud(” software and the parameters developed in this paper and subsequent testing. AUTONUMLGL  Bandwidth TestingBoth single aircraft and wide range of entity scenarios will be tested for bandwidth requirements.  The same scenarios will be tested with both DIS and HLA with comparison data collected.  In the case of HLA, it is important to have at least 3 sites emulated in order to accurately compare DIS broadcast method versus HLA receiver-requested method.  Figures 13 and 14 below illustrate our proposed “setup” for the single and multiple entity bandwidth tests respectively. EMBED PowerPoint.Slide.8  Figure 13: Bandwidth Test - Single DIS/HLA Aircraft EMBED PowerPoint.Slide.8  Figure 14: Bandwidth Test - Many DIS/HLA Entities AUTONUMLGL  Latency Impact TestingLatency impact testing will be targeted to specifically watch for effects of increasing/decreasing latency, especially to the point of inducing errors on the DIS Test Suite (DTS) and Federation Test Suite (FTS) programs.  These test suites will be run on both sides of the WAN (latency) emulator to indicate the magnitude of the errors due to the added latency.  Only 2 sites need to be emulated in this case. AUTONUMLGL  Latency-Jitter TestingLatency-jitter testing will be targeted to specifically watch for effects of increasing/decreasing latency-jitter, especially to the point of inducing errors on the DIS Test Suite (DTS) and Federation Test Suite (FTS) programs.  These test suites will be run on both sides of the WAN (latency-jitter) emulator to indicate the magnitude of the errors due to the added latency-jitter.  Only 2 sites need to be emulated in this case.  Figures 15 and 16 below illustrate our proposed “setup” for the DIS and HLA latency/latency-jitter tests respectively. EMBED PowerPoint.Slide.8  Figure 15: Latency and Latency-Jitter Impact Test - DIS EMBED PowerPoint.Slide.8  Figure 16: Latency and Latency-Jitter Impact Test - HLA AUTONUMLGL  Synchronization TestingComputer synchronization sensitivity testing will be targeted to specifically watch for effects of increasing/decreasing discrepancies in computer synchronization, especially to the point of inducing errors on the DIS Test Suite (DTS) and Federation Test Suite (FTS) programs.  The synchronization signal fed to the computers will be controlled and incremented so as to increase the synchronization discrepancy between the computers.  Figure 17 below illustrates our proposed “setup” for the DIS and HLA synchronization tests. EMBED PowerPoint.Slide.8  Figure 17: Computer Synchronization Impact Test – DIS/HLA AUTONUMLGL  References AUTONUMLGL  Author BiographiesPAGE  12