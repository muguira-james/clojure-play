C2IEDM Data Mediation ServiceBo Sun, Andreas Tolk, Ph.D.Virginia Modeling Analysis & Simulation Center Old Dominion University.Norfolk, VA, 23529(757) 686-6205 (757) 686-6203bsun@odu.edu, atolk@odu.edu ABSTRACT: To support unambiguous definition of data element for information exchange, designing and implementing model-based data management (MBDM) is becoming more and more important.  Data mediation service of command and control information exchange data modeling (C2IEDM) is an example for MBDM system.  The C2IEDM was developed by NATO to enable interoperation among operational Command and Control (C2) systems of coalition forces and is applied within the Multilateral Interoperability Program (MIP).  C2IEDM data mediation service borrows the idea of web service, which provides the most convenient methods to meet all kinds of clients’ need.  The representation of this paper focuses on the implementation technology of data mediation approach, including architecture, data translation, and tools.  The implementation ideas are generally applied to all kinds of data translation system. IntroductionThe Command and Control Information Exchange Data Model (C2IEDM) becomes more and more a “lingua franca” in the international military domain.  Having been developed by data modeling experts from more than 20 nations over a period of more than 15 years, the technological maturity of this model is already outstanding.  However, what makes this model really unique is that the information exchange requirements captured by the technical experts represent the operational consensus on what needs to be exchanged on the battlefield based on the expertise of all participating nations.  It is therefore not astonishing that in particular the new NATO nations are choosing the C2IEDM as their data model for new Command and Control (C2) developments.Today, lots of alternative data models have been developed concerning battle space data.  These data models deal with various data structures and data formats.  The questions arises what should be done with these data models.  If C2IEDM becomes a general standard, these data models must migrate towards C2IEDM capable solutions.  Therefore, the design for an automatic data population/translation system is becoming an issue.For this reason, we designed C2IEDM Data Mediation Services between C2IEDM and other military data models and conducted a feasibility study using the Multiple Base Data Model (MBDM), which extends the Joint Common Data Base (JCDB), one of the recent development efforts with the US Army. The primary objective of C2IEDM is to provide an information exchange model for C2 Systems.  Additionally, many NATO nations use it as reference data model/data storage for their C2 data management and administration.  In both cases, the concerned data is related to the battle space, such as orders, missions, tasks, situational awareness data, etc.  C2IEDM explicitly copes with four different aspects of the battle space, and these areObjects of interest and their inherent properties,Past, present, or future situations as represented by facts about the objects,Past, present, or future activities that involve the objects, and Containers for grouping data into information packages.These four aspects of the battle space are described with associations of propertied concepts.Generally, mediation services will navigate between individual service interpretations of data, i.e., they translate data from one interpretation into another.  If a common reference model is used, mediation services can utilize the data modeling results, which map individual data interpretations to the standardized data elements of the reference model.  Thus, mediation services can be applied using mediation schemas to navigate from the individual service interpretation to the standard and vice versa.  This idea of data mediation is captured in figure 1.1.  While every service can use its native data model, data mediation services are going to translate both dialects into each other when information is exchanged without having to change the applications themselves.             Figure 1.1 Data Mediation ServiceThis service family can therefore be used to migrate applications into the loosely coupled environment of services.  Furthermore, the approach is generally applicable to every application domain with a common reference model describing the information exchange needs as defined by the C2IEDM for military operations.This paper captures our lessons learned when evaluating and implementing feasibility prototypes.  Section 2 will introduce the general way to build data relationship; section 3 is going to go through how data mediation service is designed and implemented for MBDM in term of data engineering; section 4 will detail the implementation technology and section 5 concludes and points out the future research direction of data mediation service.  Data Mapping The current main function of the C2IEDM data mediation service is data translation.  Therefore, the focus of our research was concentrating on finding an efficient technology that can handle this functionality.  Briefly, the translation procedure for C2IEDM data mediation service comprises four phases:A Preparation Phase;A Documentation Phase;A Data Validation and Verification (V&V) Phase; andAn Implementation Phase. As figure 2.1 shows, preparation phase, documentation phase, and implementation phase are processed one by one in order, while the data V&V phase is involved in the end of Documentation Phase and goes through the Implementation Phase.  It is possible to add loops into this process, as in every phase shortcomings of earlier phases may be detect and this may require updates. EMBED Word.Picture.8                                               Figure 2.1 Data Mapping PhasesThe individual steps of each phase are the topic of the following paragraphs and subsections.  Preparation Phase The first step is to apply a common method to describe the data models on the source as well as on the target side to avoid heterogeneous conflicts resulting from different ways of documentation (such as IDEF1X and Oracle TM methods).  The data translations/populations among different data models are based on preceding conceptual database mappings.  The level of mapping complicity depends on the record construction of both source and target database.  The more tables make up the databases, the more difficult will be the conceptual mapping.  The preparation phase contains two steps:Conceptual learning Conceptual learning of source and target database is the start point of database mapping for data translation developers.  It directly effects the correction of data mapping if she/he can grasp the exact concept of database.  For the large varieties of data subject areas, subject matter experts (SMEs), in particular the data producers themselves are frequently called upon to assist in the conceptual learning.  The learning process is involved with data V&V and is continuing with each further implementation until data mapping relationship is built.Identify foreign key relationshipsDrawing foreign key relationship as a graphic is a good way to clarify the internal relationship of database.  The graphic is going to be very applicable to the Documentation Phase.In summary, this phase ensures that the data modeler and data mapper is familiar with the content, context, structure, and application of the data models.  Support by SMEs is crucial to ensure quality of the final results.Documentation PhaseThe documentation phase identifies the translation relationships between source and target data elements and captures assumptions and constraints in a way that other experts can understand the result.  This relation setup is based on conceptual knowledge we got from the preparation phase, and the accomplished mapping relationship will be documented for the implementation phase.  Generally, building translation relationship uses two sub-phases:Mapping is based on table of source database.  Get attributes of one table from the source database and find corresponding attributes one by one from potentially different tables in the target database, then repeat this step table by table;The basic idea is captured by figure 2.2.  However, the translation relationships are not limited to same type of attributes and one to one mapping as figure 2 described.  Different type of data conversions are included, such as attribute aggregation /disaggregation and attribute format conversion (see samples in section 4). Figure 2.2 Table Attributes Mapping based on Source DatabaseInside the target database, find the primary key translation for the tables having the mapping relationship with the source database;This procedure avoids duplication of records in the process of translation.  The primary key of the target table may not directly relate to the primary key of the source table, but most of times, their relation is reachable by foreign key relationship graphic.  However, it is not necessary to apply this procedure all the time.  For example, the target table may have a non-meaningful index as primary key.  Following is a general way to find primary key mapping:Check if they are one to one direct mapping;If not, check if target table has non-meaningful index as primary key; If not, check if they have indirect relation trough foreign key relationship graphic;If not, back to concept of table and find a way of meaning primary key translation.This step is closely related to the definition or in case of re-engineering identification of business objects or associated concepts reflecting information that normally is exchanged as a group to reflect business rules of the application area.  In the military domain, this can be an order, a task, or a report.2.3 Data V&VBefore applying the results of the data mapping in the implementation phase, data verification and validation is crucial.  They can be defined as:Verification: Is the data is mapped correctly?  This work is assigned to the mapping developer to check if the mapping relationships are correctly built between source and target data elements.  Usually, this part starts in the documentation phase and is continued in the implementing phase, which is guided by the mapping relationship documentation from documentation phase.Validation: Is the data is correctly mapped?  Because of the special nature of data V&V, particularly because of the large varieties of data subject areas, subject matter experts (SMEs) – including but not limited to the data producers themselves – are often called to assist in the data V&V process [1].  The purpose of validation is to see if the right meaningful data is in right field of target database.  This step usually is applied at the end of implementation phase.Data V&V in term of data mapping is involved in documentation phase to help data mapped correctly, and goes through the whole process of implementation until the validation (data correctly mapped) is done.2.4 Implementation PhaseThe implementation phase focuses on applying the right technology to implement data translation efficiently and effectively.  Today, software technology has been developed very quickly.  Implementation based on software technique is no doubt the way of development.  Particularly, a lot of software is designed for data mapping.  So our work is based on current research to find further potentials.  In section 4, we will detail how we use software to accomplish the implementation phase.Model-Based Data ManagementTolk first introduced model Based Data Engineering (MBDM) in 2003 to extend the general ideas of data engineering by the application of common reference models in the data management phase [2]. Data engineering includes four parts, named as data administration, data management, data alignment, and data transformation.  Following, it will be shown how C2IEDM data mediation service is developing in term of data engineering.Data administration is the process of managing the information exchange, including the documentation of the source, format, and context of validity, fidelity, and credibility of data.  In our prototype, the C2IEDM data mediation service family was originally designed and implemented with the purpose of supporting the information exchange between the multiple source database (MSDB) used in earlier US Army Battle Management Language (BML) prototypes, and the C2IEDM database.  The insights led to much broader concepts resulting in XML based mediation services. In our initial example, the validity of data, which is translated from the MSDB, needs to be identified first, such as if a non-null field has null data.  Next, data fidelity, i.e., whether the valid data is translated correctly, is checked based on internal relationship of each database and mapping documentation having been developed together with our partner ACS.  For example, when a non-primary data in MSDB is mapped to another non-primary field in C2IEDM, necessary primary key mapping must be issued for pursuing a non-duplicate record.  Finally, data credibility, whether the data has been correctly mapped to C2IEDM, is executed, which is measured by the basic definition of C2IEDM to have the right meaningful data in the right field of C2IEDM.Data management is planning, organizing and managing of data by defining and using rules, methods and tools.  In our initial C2IEDM data mediation service, we used MSDB and C2IEDM database implementations based on MySQL.  The mapping that needed to be supported by data management was twofold.  First, we needed to map the Joint Command Database (JCDB) elements plus its BML extensions used within the MSDB to the C2IEDM in order to be able to populate the C2IEDM implementation using the original BML data for validation purposes.  Second, we needed to map the XML tag sets as used in the BML Web Service Definition Language (WSDL) to the C2IEDM data base in order to allow dynamic update and insert of data during runtime.  The data elements of the initial BML WSDL were aligned with the C2IEDM, but the prototype used its own syntax and semantics based on the needs of the US Army prototype.Data alignment ensures that the data to be exchanged exist in the participating system as an information entity and aggregation/disaggregating of information entities are applied so that they match the information exchange requirements, including the adjustment of data formats.  This is part of the data V&V phase.  In the C2IEDM data mediation service, a mapping tool called MapForce makes the whole data engineering process easier.  In the section four, we are going to detail how this tool is applicable for data alignment.MBDM is the idea of using a common reference data model for data management, capturing the meaning of data and their relations.  If such a common reference model is used, data alignment becomes a simple mapping result comparison: We have to compare the mapping of the source model to the common reference model with the mapping of the target model to the common reference model.  If every piece of information needed by the target model (which means a data element of the common reference data model is in the mapping results of the target model) is delivered by the source model (which means a data element of the common reference data model is in the mapping results of the source model), the source and target model are aligned.  This leaves Data Management as the dominant challenge within the topics of Data Engineering.  Based on this comparison, the reference model is enhanced and extended to define standardized data elements in case of need.  Reference [3] gives details of cases that can be observed, and references [4] and [5] give additional detail and describe the underlying             methodology of property values, properties, propertied concepts, and associated concepts for different levels of resolution.As stated before, C2IEDM was created as a common reference model of C2 systems and is used by many NATO nations.  Our data mediation service is designed as a data translation system to translate data from other military model to C2IEDM and vice versa, if the content of the source data model is aligned with the C2IEDM content.  Combining these two functions, it is obvious that C2IEDM and its data mediation service can be in charge of data management of other military models, which are conceptually related to C2IEDM, as a common reference model.  Figure 3.1 shows data translations between data model A and B managed through the C2IEDM data mediation service.  This idea is applicable to more than two data models.                       Figure 3.1 MBDMImplementation We implemented the C2IEDM database and the data mediation service as a web service based translation system.  Two software components are involved to make the whole implementation process flexible, effective, and efficient.  The first software is called MapForce used for data transition; the second tool is Web Method Glue used as web service container. The implementation architecture of data mediation service is captured as figure 4.1.  The core part of it is mapping function, which is implemented in software language either java or XSLT.  MapForce automatically generates this part of codes.  Mapping codes are embedded into web service codes, so that user can access this translation function in term of service.  Furthermore, web service is coded by java.  Figure 4.1 Architecture of Data Mediation ServiceIn the evaluation phase, MapForce [6] has been identified as our first choice of data mapping for advanced integration projects.  This visual data mapper can automatically generate custom mapping code in XSLT 1.0/2.0, XQuery, Java, C++, and C#.  With the power to map any combination of XML, databases, flat files, and EDI to XML, databases, and/or flat files, MapForce is an appropriate tool for data alignment in information exchange.One of the main challenges in the data mapping phase is to define the functional connection between the target and the source data elements.  Only in trivial cases, data elements are identical and therefore simply have to be tagged with the tag sets of the target data model.  Very often, at least simple transformation functions are needed.  The general case is that several attributes of the source side have to be functionally transformed into a set of attributes in the target side.  Aggregation and disaggregation, transformation, and conditions are among the necessary operations.  Simple mappings as promoted by XSLT solutions are not sufficient if target and source data models are not very similar in scope and resolution.MapForce is able to deal with different types of data translation, which is provided by its functional library.  Each function can be dragged to the main interface to build relationship between source and target data source.  For example, data aggregation / disaggregation can be handled by functions “concat”, “left” and “right”; functions “char-from-code” and “code-from-char” are able to deal with data format conversion (see figure 4.2).Figure 4.2 Function of Data Alignment in MapForce Removing duplicated data can be accomplished at the target database, as figure 4.3 shows, every table could be set to “update if” one of attributes gets an existed data (where “equal” is set).     Figure 4.3 Duplicated data setting in MapForceBesides various functions of data alignment that MapForce is provided, the other most intelligent advantage of this tool is the visual mapping interface that figure 4.4 describes.  As section 2.1 mentions, the conceptual learning process is guided by database and application experts (people that really know database from the technical and the operational view) and is continuing with each further implementation until data mapping V&V is done.Generally, database experts verify the mapping relations and mapping developers implement the mapping process.  A visual interface in term of the mapping relations will bring much more efficient V&V. Furthermore, comparing with plain SQL language, MapForce has less software language knowledgeable requirements for both database experts and mapping developers.  This will give more effective human resource.              Figure 4.4 Visual Mapping InterfaceData mediation services use glue [7] as its web container, which is an easy-to-use, fast, comprehensive platform for creating and developing application with web service.  After the detail functions of data mediation service are defined in term of interface of java, glue automatically generates WSDL.  WSDL of data mediation service contains 5 methods, namely, who, when, where, what and why, which are the construction of target database, C2IEDM.  For using this service, user simply needs to call these methods to realize data translation from BML to C2IEDM.Having these two software components involved, the whole implementation technology brings a lot of advantages:Efficient: MapForce is able to automatically generate codes based on developer’s manually mapping graphic (Figure 4.4); Web method Glue has its own defined web service framework.  Developer simply needs to fill the specific methods that are supported by web service.  Having these two software components working together for data mediation service, implementation time reduces more than a half.Effective: Comparing with software and database languages, these two software components require less programming knowledge.  They are easy to use through their nice human interfaces.  Furthermore, they can generate the same results that senior programmer can give. Flexible:  Because two software components are able to efficiently and effectively build data mediation service.  So, no matter what kinds of data you want to translate to each other, with them, it is always a piece of cake.The prototype showed us very clear that only a rigorous process based on common standards for mapping, documentation, V&&, and management based implementation supported by SMEs can be successful.  Automatic translation for XML interfaces of complex M&S applications is hardly possible.5. Conclusions and Future ResearchBriefly, the technique for building C2IEDM data mediation service contains two parts: (1) Setting up conceptual mapping relationship between source and target databases and (2) applying right software to implement it.  It is effective, efficient, and generally applicable to all kind of data translation system.  It also reduces the potential sources of ambiguities by eliminating the interpretation of mapping results by implementers, as the results are directly used to configure software layers of the data mediation service.The future research of data mediation service has two points.  First, there is more theory research needed for the documentation phase of data mapping.  The best-developed theory would fit various databases without human being involved.  Second, once the best documentation theory is generated, setting up conceptual mapping relationship between source and target databases will be implemented as software to automatically get the mapping relationship documentation done.  In this way, SMEs will only take care of data V&V.  SISO can lead the way to identify applicable standards.References[1]   Data V&V for New Simulations, last accessed in June 2005 at  HYPERLINK "http://www.msiac.dmso.mil/vva/ special_topics/datavv-new/" http://www.msiac.dmso.mil/vva/ special_topics/datavv-new/[2]  Andreas Tolk: "Common Data Administration, Data Management, and Data Alignment as a Necessary Requirement for Coupling C4ISR Systems and M&S Systems," Information & Security: An International Journal, vol. 12, no. 2 (2003): 164-174[3]   Andreas Tolk, Saikou Diallo, Kevin Dupigny, Bo Sun, Chuck Turnitsa:  HYPERLINK "http://www.vmasc.odu.edu/publications/Tolk/05E-SIW-034.pdf" “A Layered Web Services Architecture to Adapt Legacy Systems to the Command & Control Information Exchange Data Model (C2IEDM),” European Simulation Interoperability Workshop 2005, Paper 05E-SIW-034, Toulouse, France, June 2005[4]	Andreas Tolk: “Moving towards a Lingua Franca for M&S and C3I – Developments concerning the C2IEDM,” European Simulation Interoperability Workshop 2004, 04E-SIW-016, Edinburgh, Scotland, June 2004[5]	Andreas Tolk: “XML Mediation Services utilizing Model Based Data Management,” Proceedings of the 2004 Winter Simulation Conference, IEEE Catalog Number 04CH37614C, pp. 1476-1484, Washington, DC, December 2004[6] MapForce website, last accessed in May 2005, online available at http://www.altova.com/ products _ mapforce.html[7] WebMethod Glue, last accessed at May 2005, http://www.webmethods.com/meta/default/folder/0000007014.Author BiographiesBO SUN is M&S Ph.D. Student at Virginia Modeling Analysis and Simulation Center (VMASC) of Old Dominion University (ODU) of Norfolk, Virginia.  She holds a Master in Computer Science from Lamar University, Beaumont, TX.  Her research interests include Data Model, Biomedical Model, and 3D Graphics.  She worked as a General Research Assistant for Dr. Tolk.  She implemented the Data Mediation Service.ANDREAS TOLK is Senior Research Scientist at the Virginia Modeling Analysis and Simulation Center (VMASC) of the Old Dominion University (ODU) of Norfolk, Virginia.  He has over 15 years of international experience in the field of Applied Military Operations Research and Modeling and Simulation of and for Command and Control Systems.  His domain of expertise is the integration of M&S functionality into related application domains, such as C4ISR or web-based services, in particular based on open standards.