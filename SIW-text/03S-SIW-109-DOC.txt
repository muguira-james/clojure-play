Demonstration of a Systems Architecture for Live, Virtual, and Constructive InteroperationDr. Peter DrewesDr. Robert FranceschiniSAIC12901 Science DriveOrlando, Fl 32826407-243-3348 HYPERLINK "mailto:Peter.J.Drewes@saic.com" Peter.J.Drewes@saic.com       HYPERLINK "mailto:Robert.W.Franceschini@saic.com" Robert.W.Franceschini@saic.comKeywords:Semi-Autonomous Forces, Live, Virtual, ConstructiveAbstract: Interoperation of live, virtual, and constructive simulations requires solutions to several difficult correlation issues.  For example, position location of participants in the live simulation must be determined and correlated to positions in the virtual and constructive simulation.  The level of detail portrayed in the synthetic environment of a virtual or constructive simulation must be reconciled with the tremendous detail available in the live environment.  Point solutions attacking pieces of the overall interoperation problem continue to be developed.  What is missing, however, is a unified vision for how the entire system should operate.  This paper presents SAIC-Orlando’s work on a fully-implemented live, virtual, and constructive interoperation system, one goal of which is to develop a systems architecture for live, virtual, and constructive interoperation.  The live component of the simulation is portrayed by indoor/outdoor robots, with position, orientation, and obstacle sensors, and the capability to portray direct and indirect fire effects.  The virtual component of the simulation is portrayed by the Multi-Modal Semi-Automated Forces (M2SAF) system, which is a reconfigurable vehicle simulator.  The constructive component of the simulation is the One Semi-Automated Forces Testbed Baseline (OTB).  The paper will discuss the design of the system architecture, including its evolution over a two year period.  The paper will describe the efforts that have been undertaken to monitor trends in technologies, plan for including emerging technologies, and implementation of the plans.  Specific solutions to position location, orientation determination, providing live sensed data to the virtual and constructive simulations, and providing control information to the robots from the constructive simulations will be described.  The role of a standards-based interface such as the High Level Architecture in this interoperation will be described.IntroductionThe Robotics Internal Research and Development (IR&D) program was a 24 month research effort focused on the commonality between the Computer Generated Force (CGF) environment and unmanned systems. This effort was expanded to include interfacing the robotic units to multiple CGF systems as well as interface other tools to robotic units. COTS robots were selected to prototype existing and next generation unmanned vehicles. The OneSAF Testbed Baseline (OTB) was utilized as the CGF system. The OTB was selected because its high level capabilities and its transition to the OneSAF Objective system for the Army. This report is a summary of the activities of the IR&D along with some of the lesson’s learned from the research.1.1 Commonality in behaviors between OTB and unmanned vehiclesThe initial view is the capabilities of the OTB and the needs of the unmanned vehicles are very similar. The OTB was designed to model and replicate the actions of both manned and unmanned vehicles in the constructive environment. This includes both physical modeling of the individual vehicle, as well as the interactions between vehicles and soldiers to create complex multi-vehicle environments. The OTB does model some unmanned vehicles within the constructive environments. Many of the existing unmanned vehicle test units are based on similar manned vehicles, such as the HMMV. One of the obvious issues between the constructive environment and the live environment is that the live environment will change. Another is the ability to physically model the live environment, so that the constructive environment will be able to reason on similar or the same information that is available in the live environment. Some of these issues have been addressed in various ModSAF and OTB versions to include microterrain, and additional weather/environmental modeling. With lower cost data collection centers, and research capabilities such as, the ability to collect high fidelity large scale areas is becoming more cost effective. This still leaves the issue of constructive and the live environment not being the same after the beginning of the scenario. This will be addressed later in this research.1.2 Live robot interactions with the constructive environmentIn working with Dr. Robin Murphy of the University of South Florida (USF) the discussions of utilization of urban search and rescue units in combination with the simulation environment became part of the discussions for the IR&D.  Based on the previous research done by Dr. Murphy, it was decided to prototype the DIS interface to/from the OTB and the use of their urban robotic units. To test the capabilities, the Seventeenth International Joint Conference on Artificial Intelligence offered the urban search and rescue scenario to test the robots and provide feedback to the simulation system. The three robots ran through the NIST test course, and were able to identify injured victims faster than any of the competition teams there. The OTB was displayed on the overview screen as the robots moved through the NIST test course. The USF robot is shown in  REF _Ref28680956 \h  \* MERGEFORMAT Figure 1.Figure  SEQ Figure \* ARABIC 1- Initial Robotic Test Units The local building parking lot was modeled within the OTB system so that the OTB could be utilized to assist with obstacle avoidance. The parking lot database is shown in  REF _Ref28681739 \h  \* MERGEFORMAT Error! Reference source not found.. This allows the CGF control of the robots to avoid the outer boundaries of the parking lot, as well as the center drain. In the middle of the parking lot is a metal drain. Without assistance, the robots will become stuck in the drain area (if heading north<->south). By utilizing the OTB, not only can high level commands, such as move to a point in a certain formation be utilized, but also avoidance of known obstacles, such as the center drain, and the curbs that are along most of the sides of the parking lot.Figure  SEQ Figure \* ARABIC 2– OTB with parking lot database2.0 Unmanned System Issues2.1 Mobility issues For the robots to move around the parking lot, several small studies needed to be performed: Positioning, communications and mobility.For positioning, the robots have wheel encoders built in. However, how well do these encoders work outside in the parking lot area? The wheel encoder distances were actually measured (tape measure) to ensure the movements were reasonably accurate. The same sets of studies were applied with both GPS and differential GPS systems. This allowed the ability to determine if the additional hardware would provide a considerable accuracy in positioning the robots in the outdoor environment. The GPS system demonstrated that in the original indoor environment, it was not well suited for operations. In straight-line distances, the GPS showed errors between 2-10% based on the tape measurements and the wheel encoders. However, both the wheel encoders and the GPS had errors during and after turns. The DGPS is a little better in maximum accuracy, however, it did not perform as well as the wheel encoders. During the turns, both the wheel encoders and GPS had increased errors, so the same tests were run using a digital compass. The digital compass was advertised accuracy of 2 degrees. However, during turns all of the units displayed a larger than expected errors. Once stabilized, the compass returned to a reasonable number, and the wheel encoders were able to keep within 2-5 degrees of the compass as long as the wheels did not bounce.In both the indoor as well as the outdoor environment, the robots were tested individually through the OTB for movements. This included testing the robot ability to navigate throughout the hallways and parking lot using both the OTB and onboard obstacle avoidance. This ensured that each vehicle is capable of operation without overloading the network and making sure that each unit can operate as a CGF physical entity within the OTB environment. Single robots were also tested with multiple CGF based robotic units to determine potential interactions.After the individual movements were tested, group moves were tested. This included simple move to points, and progressed through multi-step mission roles. Formation moves were tested, included wedges, columns, lines, and staggered. Wedges and lines tended to work best, since the columns had movement issues with keeping relative distance. It was possible to increase the relative distance and have the formations work better, however, with four or five robots, spaced at 1 meter distance already doesn’t leave much room in the parking lot for column formation moves. Multi-step missions were performed such as bounding overwatch (two move then the other two). This move complex task allows one group of robots to provide cover for the other robots as they move throughout the gaming area. 2.2 EngagementsThe next area of concentration in the CGF was that of tactical engagements. Virtual engagement  emitters were placed on the top of the of the Pan/Tilt camera This allowed the computer control of the pitch and elevation of the laser emitter. Most of the experimentation revolved around a human based weapons operator. Although the robotic software did contain blob detection, and some simple experiments were done to very the capability of the system to attempt to track the laser targets, it was felt that especially early in the UGV programs, the shoot capability will be retained by the human. 2.3 CommunicateInherent in the ability for the robots to be controlled by the OTB is the ability to communicate to/from the systems. Normally, this includes position, velocity vectors and Health State. However, it is possible for the robotic units to run without communications to the OTB system (silent mode). However, since we are dealing with as many as eight robots so far being controlled by the OTB, we felt that silent running is not a current option. There is no way to tell what is happening with the robot if it is not communicating with the central control.This need for communications doesn’t preclude the ability to have both a centralized control (OTB on server controls everything) as well as a distributed control (OTB on each robot communicates with each OTB to provide information about the entire scenario). This is supported by the system architecture that was designed in using a simple shared memory interface to the robots from the OTB. This enables both centralized/decentralized control as well as other system interfacing.The robots with their built in sonar and/or laser systems were able to avoid obstacles in the real world assuming the robots could see them. The best example of this was the ability to place boxes in the parking lot and we had the robots navigate through them.  However, the robots could not see things like the drainage system in the center of the parking lot.  Once the obstacle was placed in the OTB, the robots naturally moved around the obstacles without being able to directly see the obstacles.Through the laser system, the boxes, or other obstacle detection was passed back to the OTB to allow other units to also maneuver around the detected obstacle.  This provided the ability to have CGF units follow live robots, and react to some of the same real world obstacles as the robots are encountering. This extended communications and navigation capability offers a collaborative environment for group behaviors.2.4 Tele-operation and issuesTraditional military robots have been tele-operated (driven by the user). The goals of the IR&D is to move this into semi-autonomous and eventually autonomous operation. The ability for the user of the system should still be able to get involved and control any or all the robots as they desire. This can be done through the OTB. It can also be done via joystick control. It was desired to have a joystick that could drive the robot as well as control the camera and targeting system. 2.5 Technology InsertionsAs the research progressed, certain capabilities were missing from the robotic team (ad hoc networking, system controller independence and standard network capabilities). The architecture needed to be adapted to be able to handle the networking standards (at least 802.11b) as well as being generic so it can be utilized on several heterogeneous unmanned ground platforms. Fortunately, the two indoor as well as the outdoor robotic units had similar software architecture, and their control system could be made generic enough to handle being utilized on all three systems. The original embedded controllers could not be upgraded, as well as the original network controller were not capable of standard network communications. This resulted in the robotic units being redesigned to utilize standard COTS handheld controllers that could be upgraded and/or adapted to the changing standards and needs of the robotic systems, as well as the user interfaces needed to control them.3.0 Connecting a virtual simulation with the live/constructive environmentThrough the OTB testing and robot operation, we had a successful constructive and live environment setup and tested. The tele-operation of the system touched on the ability to create a virtual environment (human in the loop). There were several choices for interfacing, based on availability and general access. The M2SAF (Multi-Modal Semi-Autonomous Force) environment was selected. This transportable system consists of complete visual database, and full fidelity supporting models to allow a user to operate as a tank commander, driver, or gunner. This environment was interfaces to allow the tank driver to drive through a terrain and virtually deploy the robots for operation, and monitor their progress. This involved simulation to simulation communications and information to be passed, but quickly demonstrated the ability to interface another system into the robotic environment. The M2SAF system is shown in  REF _Ref30926210 \h Figure 3.Figure  SEQ Figure \* ARABIC 3– M2SAF system3.1 Sensor feedback from robotsOnboard the robotic units was a laser scanning capability. The laser scanner provides obstacle’s relative distance to the laser system. Since there are several robots with this laser system, the bandwidth to get the data back to the OTB would be too difficult. The data points were analyzed and some obstacle detection algorithms were developed. This was done to look for certain obstacles, such as walls, or boxes. This way, once the obstacle had been identified, the line segment endpoints, relative to the robot position were sent back to the OTB. This reduces the needed bandwidth while still keeping the necessary information available at the OTB. The OTB was modified to incorporate these data segments to be new obstacles in the simulation. This allows the robots to collaboratively understand what only one robot has found. Or, a CGF entity may react to the robots recently discovered information.3.2 Auto terrain generation in real timeThe possibility of taking real time data from the real world environment, summarizing it, and presenting it back to the simulation software offers the ability to prototype auto terrain generation in real time. This is that during normal robot operation (or manned vehicle if the sensors are placed aboard), automatic information can be transmitted back to the host system for data collection. Of course, more than just obstacle points are needed, and there is a desire to have more information, such as trees, or soil information. This can be supplemented by some image processing that is available on the robotic units. This area of synthetic natural environment generation is a potential follow on to this research, since much of the future unmanned forces will contain these navigation and obstacle avoidance systems.3.3 High Fidelity Math modelingThe original behaviors for the CGF robots were modified tank and UGV behaviors that were available at the beginning of the project. As the project progressed, the questions came in, can this math model be inserted? The answer has always been yes. Traditionally, recoding the OTB and recompiling the system did this. This required knowledge of the OTB internal structure and operations. It is possible to use the SAIC generated Composable Behavior Technologies (CBT) to insert behaviors, but this is above the level that is desired by many to determine the mobility characteristics of a new system. The process and procedure to insert a new math model was documented and automated, so that a math model could be created using the provided template. Once complete, a simple GUI was created to enter the vehicle name and file name of the math model, The OTB system was updated to reflect this math model insertions. This provided the ability to try new models, while keeping the rest of the OTB functional. The team set up a base set of interfaces that they thought would be useful for interfacing to the template.. 3.4 Interfaces with ModISE prototypesThe ability to enter physical models, or new unmanned system behaviors is an important capability that we have been able to touch on. But, there needs to be a more generic interface that might offer other capability. ModISE (Modular Interoperable Synthetic Environment) is an Army led initiative to create a web based Java/XML based interface that allows specification checking and interface checking to be performed. A prototype ModISE interface was instantiated for robotic operation. This is shown in  REF _Ref29018542 \h Figure 4. This allows the system to compose physical models, and create a physical model that can be entered in a simulation environment. This capability needs only the robotic extensions to allow the same features to be utilized within the OTB environment. The robotic specific extensions were prototyped and same XML data files were created and read by the OTB simulation system. However, the complete end to end ModISE system was not tested, since it is currently based on an Oracle database system that is not available to the team. This is combined with the inability to access additional mathematical models. Initial prototypes were created and demonstrated.Figure  SEQ Figure \* ARABIC 4 – MODIse prototype GUIFigure  SEQ Figure \* ARABIC 5 – Baseline Robot Configuration3.5 System CoordinationAlthough the system was tested through simple network protocols (TCP/IP and raw communications protocols), it became clear early on that the use of standard protocols and data transfers would assist the program. This includes adding in of new devices, as well as software features. The OTB system normally deals with TCP or DIS/HLA packets. The robotic units normally work in TCP mode, M2SAF can work with DIS/HLA packet systems. The interface to other software applications, such as ModISE and GIT’s Mission Lab software involved either custom interfaces, or XML data transfers. This meant that the cohesive environment must deal with applications at the appropriate data level. The data communications overhead in DIS/HLA protocols would increase network bandwidth beyond that of the robotic units capability. The XML data transfer between M2SAF and OTB would not be practical. For inter-application software, DIS was utilized. The tested domains were focused on ground vehicles within certain context. At a more internal layer, data transfers were done via shared memory segments. This facilitated transitions to/from XML and into TCP sockets. This flexibility in architecture allowed the insertion of Georgia Tech software into the OTB system without modification to the OTB baseline.  The final robotic configuration is shown in  REF _Ref29030096 \h Figure 5. This includes the laser navigation system (blue in front), the camera monitoring system, virtual engagement system on the camera system, and the robotic controller in the rear. 4.0 ConclusionsAs part of a complete test and training environment, the ability to interface live, virtual and constructive systems becomes more critical. There are areas of the constructive environment that cannot replicate the live environment, and the live environment cannot extend human-system interactions as far as the virtual. 5.0 References[1] Drewes, P., Rees, D.: “Semi-Autonomous Forces Integrated Robotics Environment Lessons Learned”, I/ITSEC Conference, Orlando, Fl. December 2002[2] Drewes, P.: “Lessons Learned in Group Robotic Command and Control” Unmanned Vehicle Systems Conference, Orlando, Fl, June 2002Author BiographiesDR. PETER DREWES directs research at SAIC in the intelligent agent’s area, CGF systems, composable behaviors and robotic systems. His previous experience includes system architecture, modeling and simulation, telecommunications, communication systems and graphical user interfaces. Dr. Drewes received his Ph.D. from the University of Central Florida. He has concentrated his research in the areas of performance monitoring in real time systems.DR. ROBERT W. FRANCESCHINI is a Senior Systems Engineer at SAIC in Orlando, FL.  Dr. Franceschini earned a Ph.D. in computer science from UCF.  In his 11 years of simulation experience, he has proposed and directed over $2.5M of externally funded research, leading to 40 publications concentrated in the areas of computer generated forces, distributed simulation, and multi-resolution simulation.