00F-SIW-109AVCATT-A Fair Fight and CCTT InteroperabilityEdward P. HarveyBMH Associates, Inc.5425 Robin Hood Road, Suite 201Norfolk, Virginia 23513-2441. U.S.A.(757) 857-5670 eharvey@bmh.comKeywords: AVCATT-A, CATT, VV&A, Fair Fight, InteroperabilityABSTRACT:  The Aviation Combined Arms Tactical Trainer – Aviation Reconfigurable Manned Module (AVCATT-A) system must be capable of supporting team training by U.S Army aviators in fifty three collective training tasks. The AVCATT-A synthetic battlespace consists of rotary wing aircraft simulators known as manned modules (MM) and computer generated forces (CGF). The effectiveness of AVCATT-A in supporting team training across the range of collective training tasks is highly dependent on the validity of the interactions that take place within the synthetic battlespace between MMs and CGF.  This paper describes the methodology for assessing the degree AVCATT-A supports a “fair fight” between MMs and CGF. The techniques for ensuring this type of simulation interoperability are based on the validation of MM and CGF physical system models and an assessment of model functionality that impacts the validity of MM and CGF interactions. The paper will also describe how the same techniques for addressing “fair fight” between MMs and CGF apply to the interoperability of AVCATT-A and the Close Combat Tactical Trainer (CCTT).1.	IntroductionDevelopment of AVCATT-A commenced in October 1999 upon contract award to Raytheon by STRICOM. Each AVCATT-A system is composed of six (6) reconfigurable rotary wing aircraft (RWA) simulators known as manned modules (MM) and a training environment (TE) housed in two 53’ mobile trailers. When AVCATT-A is fully developed each MM will be configurable to represent an AH-1F Cobra,    AH-64A Apache, AH-64D Longbow Apache, OH-58D Kiowa, UH-60A/L Blackhawk, UH-1H Iroquois, CH-47D Chinook, or RAH-66 Comanche aircraft. The TE consists of a synthetic battlespace that is populated by the MMs and computer generated forces (CGF); a Battle Master Control workstation for exercise management; four Role Player workstations to control ground maneuver, fire support, close air support, logistics, battle command, and engineer elements; a single CGF workstation; and an after action review system sufficient for debriefing up to twenty aviators. The AVCATT-A System Requirements Docu-ment (SRD) [1] addresses fair fight and interoperability requirements. Paragraph 1.1, Background, of the SRD states, “The AVCATT-A system will interoperate with other simulation systems through local area network (LAN) and wide area network (WAN) utilizing broadcast and multicast modes, will be Joint Technical Architecture-Army (JTA-A) compliant, will be Synthetic Environment (SE) Core compliant, and will achieve fair fight interoperability with the Close Combat Tactical Trainer (CCTT).”  Fair fight and interoperability requirements listed in paragraph D.3 of the SRD Interoperability Appendix include the following:D.3.1 Exercise Management - AVCATT-A shall contain all exercise management features and capabilities required to achieve interoperability as defined in D.3. D.3.2 Synchronization - AVCATT-A shall be capable of synchronized operations to achieve interoperability as defined in D.3.D.3.3 Fair Fight Exercise - AVCATT-A shall contain the systems and performance capabilities that support fairfight interoperability as defined in D.3.   D.3.4 Entity Awareness - The AVCATT-A shall be able to be aware of all exercise entities required to achieve interoperability as defined in D.3. during networked exercises.  D.3.5 Terrain Database Correlation - For correlated terrain databases, there shall be no miscorrelations that result in degraded system performance or adversely impact the crews’ ability to participate in a collective, fair fight, exercise.  D.3.6 Synthetic Environment - AVCATT-A synthetic environment shall be capable of interoperating with other systems in accordance with D.3.  This synthetic environment shall represent a correlated battlespace consisting of common components such as terrain, models (moving, relocatable, repositionable, animations and effects), and battlefield conditions. D.3.7 Environmental and Meteoro-logical Conditions - AVCATT-A shall have the capability of interoperating with other systems in accordance with D.3. under common environmental and meteorological conditions.  D.3.8 Communications - AVCATT-A shall be able to communicate with other systems in accordance with D.3. via applicable voice and digital radio communications systems.D.3.9 AVCATT-A Compliance with the High Level Architecture (HLA) - The AVCATT-A system shall satisfy the High Level Architecture (HLA) compliance requirements defined in the HLA: Rules, Interface Specification, and Object Model Template.  D.3.9 a. - The AVCATT-A system HLA runtime infrastructure shall support:  (1) Federation Management, (2) Declaration Management, (3) Object Management, (4) Ownership Manage-ment, (5) Time Management, and (6) Data Distribution Management.D.3.9 b. - AVCATT-A systems imple-menting Distributed Interactive Simula-tion (DIS) protocols internal to the AVCATT-A system shall require a DIS to HLA/HLA to DIS converter at the Long Haul Network interface.These requirements are the basis for develop-ment of a process to determine the degree a “fair fight” exists between AVCATT-A MMs and CGF, and between AVCATT-A and other CATT simulation systems such as CCTT. The remainder of this paper will describe the recommended approach to quantify the capability of AVCATT-A to successfully meet these “fair fight” and “interoperability” requirements.2.	CGF – MM “Fair Fight”A practical approach for determining the capability of two different simulations to support a fair fight is to compare the performance of each against a common reference to identify any differences in functionality that provide one with an unfair advantage over the other.  The actual impact on fair fight can then be assessed given the purpose for which the simulations are being employed. The recommended reference for quantifying fair fight for AVCATT-A, or for any other simulation that represents real world objects, is “the accuracy of a representation compared to the real world given intended use”. You should recognize this phrase as being similar to definitions for validation found in DoD and service VV&A policies, and in the updated DMSO VV&A Recommended Practices Guide (RPG) [2]. The information compiled during validation that describes the capabilities and limitations of a physical system or mission behavior representation can also be used to quantify fair fight.  Individual combat vehicles (aircraft, armored vehicles, logistics vehicles, etc.) are represented as entities in the AVCATT-A synthetic battlespace. An entity may either be a MM or generated by CGF. To support collective team training there should be no differences for the types of interactions supported regardless of whether an interaction is between a MM and a CGF entity, or between CGF entities. At the entity level the degree a simulation supports fair fight is directly dependent on the validity, or accuracy, of the interactions that occur between entities in the synthetic battlespace. This is the main premise on which the recommended approach for quantifying fair fight described in this paper is based.  To determine interaction validity it is first necessary to determine the validity of relevant physical system and mission behavior represen-tations for an entity that participates in the interaction. This might seem a daunting task at first thought due to the number of represen-tations that “participate” in a complex interaction; however, it is relatively easy to accomplish as long as validation documentation, or the equivalent information it contains, is available for those representations. Unfortu-nately, validation documentation is seldom available for existing, legacy simulations due to a general misunderstanding by simulation program managers regarding the cost-benefit of validation [3]. This is a potential impact on AVCATT-A fair fight assessment since AVCATT-A development is based on reuse and enhancement of existing software. L3Com is reusing software originally developed for Army schoolhouse simulators for MM development. OneSAF Test Bed (OTB) Semi-Automated Forces (SAF) is being used as the baseline CGF for AVCATT-A. Some validation documenta-tion, including design descriptions, test plans, test results, and conceptual models for OTB SAF, is available and can be used to support a fair fight assessment. What do not exist in the available documentation are criteria for the CGF that describe the required functionality for each entity physical system and mission behavior representation based on AVCATT-A system intended use. 2.1	Fair Fight Assessment ProcessThe recommended process for determining fair fight for AVCATT-A MM and CGF is shown in IDEF0 process model format in Figure 1. Fair fight assessment process tasks include System / Subsystem Specification (SSS) development; CGF Delta Analysis development; CGF knowledge acquisition/engineering (KA/E), Software Requirements Specification (SRS) development; software design, build, integrate, and verify; MM and CGF validation, and fair fight assessment. Each of these tasks, with the exception of the fair fight assessment, would be performed during a normal development process.  Products of the SSS development and the CGF Delta Analysis tasks are shown respectively as an input and constraint to the CGF KA/E task in this process depiction.  2.1.1	SSS DevelopmentThe SSS is a “refined” SRD in a database format that may include additional detail where necessary to clarify individual requirements. The SSS serves as a common frame of reference between the developer and the customer for what will be built. The AVCATT-A SSS provides a detailed fidelity analysis for each MM aircraft type that describes the required level of functionality at the aircraft physical system level for each switch, dial, control, and display. For example, the fidelity analysis in the SSS for the AH-64 aircraft shows Mode 4 for the APX-100 IFF Transponder to be functional while Modes 1, 2, 3A, and C are non-functional.CGF requirements are contained in the Training Environment (TE) portion of the SSS. CGF SSS requirements describe the types of CGF units and entities required; the minimum requirements for BLUFOR RWA mission behaviors; Forward Area Refuel Point (FARP) behaviors; and Air Defense Artillery (ADA) behaviors. CGF SSS requirements are written at a higher level than MM SSS requirements and do not contain sufficient detail at the object level necessary for design. The CGF Delta Analysis and KA/E tasks are performed to derive object level requirements with sufficient detail to serve as the basis for CGF design.2.1.2	CGF Delta AnalysisCCTT SAF and ModSAF 5.0 / OTB SAF were identified as the two candidates for the AVCATT-A CGF baseline by STRICOM in paragraph 3.1.6.3 the AVCATT SOW [14]. OTB SAF was proposed as the CGF baseline by Raytheon.  An analysis was performed by BMH to identify the capabilities of ModSAF 5.1 and OTB SAF to meet SSS requirements for CGF. The results are reported in the AVCATT-A CGF Delta Analysis [4].  Figure 2 shows the task sequence for the CGF Delta Analysis.  The intended use of the AVCATT-A training system is to serve as the primary trainer for 53 collective tasks. The CGF tasks identified are those that are required to support training conducted by aviators in the MMs.  The right leg of the Delta Analysis process identifies the CGF mission tasks required given AVCATT-A intended use. The left leg of the process identifies CGF entity physical systems required given AVCATT-A intended use. The required physical systems and mission tasks are then compared to those currently available in the CGF baseline to identify enhancements to existing physical systems and mission behaviors, and any physical systems and mission behaviors that may be missing from the baseline.  The results of the CGF Delta Analysis combined with customer-identified priorities provide the basis for development of detailed CGF requirements that are included in CGF conceptual models.CGF Knowledge Acquisition / Engineering (KA/E)[5] describes the KA/E process that was tailored for AVCATT-A. The purpose of performing the first pass through the KA/E process is to derive detailed requirements based on intended use for physical systems and mission behaviors for each required CGF entity. These detailed require-ments are at an object level and include sufficient detail to (1) serve as the basis for entity physical system and mission behavior representation design, and (2) be testable for validation purposes. The detailed requirements are contained in conceptual models similar to those developed for ModSAF [6] for STRICOM by the ADST II team. AVCATT-A CGF conceptual models will identify the types of entities to be represented, identify and describe the physical systems and mission behaviors for those entities to be represented, and list the detailed requirements based on intended use for each entity physical system and mission behavior.The KA/E process produces the level of requirements detail for CGF that is included in the aircraft fidelity analysis portion of the SSS for the MM. Once detailed designs that identify required performance data are developed a second pass through the KA/E process is made to collect performance data required for each CGF entity representation.  Software Requirements Specification (SRS)The AVCATT-A SRS lists software require-ments for each MM and TE Computer Software Component (CSC).  CSCs for the MM and CGF entities are typically at the aircraft sub-system level (sensor, avionics, dynamics, weapons, etc.). SRS MM software requirements flow directly from the SSS.  SRS CGF software requirements come from the CGF conceptual models developed during execution of the KA/E process. The SRS is the first document produced during AVCATT-A development in which software requirements for both the MM and CGF are addressed with sufficient detail to judge the planned degree of MM-CGF fair fight. In cases where the identical representations are employed for MM and CGF it will be possible to quantify the impact on fair fight. For example, if the same damage assessment model is used for both the MM and CGF there should be no adverse impact on fair fight for the assessment portion of a damage interaction. In cases where different representations are employed for similar physical systems in the MM and CGF it will be necessary to base the fair fight assessment on a comparison of physical system representation functionalities later in the development process when that type of information is available.  2.1.5	Design, Build, Integrate, and VerifyThe output of this development task is verified physical system representations for the MM and CGF, and verified mission behavior representations for CGF.  These representations are integrated to form the required MM aircraft types and CGF entity types. Ideally there will be no delta between the representation function-alities described in the SRS and implemented functionalities. If there are any deltas in functionality they will be documented in the verification test reports that describe actual representation functionality.  2.1.6	ValidationThe actual functionality for physical system and mission behavior representations described in software design documentation and tested during verification is compared to the applicable SRS software requirements to determine the accuracy of each representation given intended use.  Since there is a direct requirements trace from SSS to SRS to design for the MM, and from SSS to conceptual model to SRS to design for CGF, representation validation can be performed by identifying any deltas in representation functionality compared to the SRS requirements. The comparison of SRS requirements to imple-mented representation functionality is normally documented in a Verification and Validation (V&V) Report. The V&V Report format for AVCATT-A has not yet been defined but should include a brief description of the representation, the intended use for which the representation was developed, the representation design, the tested functionality of the representation, a comparison of the representation functionality to SRS requirements, an assessment of the impact of any differences in actual and required functionality, and a validation recommendation. The majority of this information can be presented in a requirements traceability matrix.  In practice validation of physical system representations is easily accomplished if the documentation described in this paper is developed and suitable 2-D and 3-D visuali-zation and graphical user interface (GUI) tools are available. Validation requires no additional documentation over that necessary to develop quality software suitable for a system such as AVCATT-A. Unfortunately, validation of CGF mission behavior representations is not so straightforward as validation of physical system representations. Unless there is a mechanism for directly observing CGF decision-making as it occurs, including the information that is available on which decisions are based, it is very difficult to determine if a decision was appropriate for a given situation. This is mainly due to limitations in the visualization tools that are adequate for validation of physical system representations, but only allow decision making to be viewed indirectly based on observed entity performance. For example, an entity executes a turn that appears on 2-D and 3-D displays to be in the direction of a potential adversary. The basis for the decision to execute the turn could be the entity detected the adversary and is maneuvering to achieve a firing position. It is also possible the entity has not detected the adversary and the decision to turn was due to reaching a waypoint on a pre-planned route. Both are valid behaviors. To validate this behavior the basis for the decision to turn must be known with surety. This simple example highlights the limitations of “face validation” of mission behavior representations by subject matter experts (SMEs) who are only given the means to observe physical performance and so must frequently “guess” when assessing the accuracy of a mission behavior if the observed performance is the result of an appropriate decision.  For AVCATT-A CGF sufficient visualization capability currently exists to directly compare the mission tasks an entity executes with the tasks that were defined in a mission behavior conceptual model for fixed wing aircraft (FWA). This capability will be extended to RWA and ADA as AVCATT-A CGF is fielded.Fair Fight AssessmentFair fight assessment must be performed at the physical and mission behavior levels. Fair fight at the physical level is directly observable in real-time, however, fair fight at the mission behavior level is only indirectly observable in real time for CGF through visualization applications and the CGF user interface. Fair fight at the mission behavior level for the MM is only observable after-the-fact, mainly through debriefing, since human aircrew members are not required to explain the basis for each decision they make in real time as they perform tactical operations.  2.1.7.1	Fair Fight Assessment for Physical SystemsThe first step in the fair fight assessment task is to identify the types of interactions that may occur between entities for AVCATT-A. The types of basic interactions possible during AVCATT-A training exercises include maneuver, navigation, communication, sensor, emitter, and weapon employment. An example of a basic sensor interaction is the reception of a radar emission by the radar warning receiver (RWR) on board a MM or CGF entity.  Once the basic interactions have been determined the set of physical system representations that are necessary for each interaction can be identified. Information in V&V Reports that describe representation functionality for these physical systems can be used to assess the relative capabilities of a MM and CGF to participate in the interaction without the need to conduct testing. For the basic sensor interaction described above V&V Reports, or equivalent information, for the MM and CGF RWR representations can be assessed to determine the relative capability of the two RWR representations to detect the emission.  Ideally, detection of the emission would occur simultaneously given the MM and CGF entities were co-located in the synthetic battlespace relative to the emitter. One would expect this to be the case if the same RWR representation was used for both the MM and CGF. However, if the MM and CGF RWR are different representations there may be an impact on fair fight that would result in an unfair advantage to either the MM of CGF entity for this interaction. For example, an unfair advantage for the MM would result if the MM RWR used a static range limit based on emitter type and location for determining emission detection whereas the CGF RWR used a line-of-sight model combined with a propagation-loss model. In this case the MM RWR could detect emissions the CGF RWA could not if there was intervening terrain between the locations of the emitter and the MM and the range was less than the static range limit for the MM RWR.  The result of this approach is a database of basic interaction fair fight assessments.  Fair fight assessments for complex interactions, such as the employment of the Hellfire semi-active laser (SAL) guided missile, can then be developed using the basic interaction assessments as “building blocks”. Table 1 shows how basic interactions, in this case 13 of them, combine to represent the launch of a single Hellfire missile by an AH-64 aircraft from the point in time where the decision is made to move to a battle position until the results of the engagement are reported.Maneuver – pop up to unmask sensorsSensor – identify a suitable battle position and categorize intervening terrain and cultural featuresNavigate – plan route to battle position based on intervening terrain and cultural featuresManeuver – fly route to battle position using nap-of-the-earth (NOE) flight proceduresManeuver – once in battle position pop up to unmask sensorsSensor – search for, detect, and classify targetsCommunicate – report target locationsManeuver – align aircraft for target engagementWeapon employment – select and launch SAL Hellfire missileEmit – self designate target with laser designatorSensor – determine engagement successCommunicate – report engagement results Table 1 – Basic Interactions For a Hellfire Missile EngagementOnly minimal testing should be required to determine AVCATT-A fair fight capability given the fair fight assessments for the basic interactions are based on verification testing and validation assessment. Several sample inter-actions can be tested to show the customer there is a high probability the results of a “paper” fair fight assessment accurately compare to the test results for the same fair fight assessment.  One would expect this to be the case since representation verification is based on actual test results.  This is the most practical approach for accurately quantifying fair fight capabilities for the MM and CGF at the physical system level.2.1.7.1	Fair Fight Assessment for Mission BehaviorFor the purposes of this paper a “mission behavior” is defined as “a sequence of decisions, each triggered by an event, that are made to initiate and terminate basic interactions (maneuver, navigation, communication, sensor, emitter, and weapon employment) dependent on the tactics, techniques, and procedures (TTP), standard operating procedures (SOP), rules of engagement (ROE), and the operations order or mission plan currently in effect.” Each decision in the sequence is “triggered” by an event. A trigger event is itself a basic interaction and can be as rudimentary as a preplanned time for initiating an interaction such as movement from an assembly area or FARP, or it could be the detection of an OPFOR ADA vehicle by a RWR indication, to name just 2 of hundreds of possible trigger events.The suitability of a decision by a CGF entity to initiate an interaction can be assessed by comparing the CGF entity response to a trigger event with the “typical” response of a MM aircrew to the same trigger event in the same situation. The assumption here is CGF mission behavior representation is based on the same TTP, SOP, ROE, and mission plan information as the aviators in the MM are employing.  The actual basis for comparison is documented TTP and SOP from authoritative sources, and not a specific response of by a MM aircrew due to the variability of decisions made by humans when exposed to the same situation multiple times.  If the CGF responds to a situation in accordance with the appropriate TTP, SOP, ROE, etc. then AVCATT-A fair fight requirements should be assessed as having been met.  The V&V Reports for CGF mission behavior representations contain the information neces-sary to perform a fair fight assessment of mission behavior since the V&V Reports include a description of the mission behavior, the detailed requirements based on intended use for the behavior, the manner in which the behavior is represented (the design), and the actual degree the behavior is represented based on verification test results. As with the fair fight assessment for physical systems there is no need for actual testing, other than sample testing if desired by the customer, to determine the degree of fair fight for AVCATT-A CGF mission behaviors.Fair Fight Summary The basis for determining the degree of fair fight for AVCATT-A MM and CGF physical systems and mission behaviors is results validation for MM and CGF physical system representations and CGF mission behavior representations.  V&V Reports, or the equivalent information from AVCATT-A software development docu-mentation, quantify the accuracy of each physical system and CGF mission behavior compared to the real world given AVCATT-A intended use. This information can also be used to assess the validity of basic interactions that can occur between a MM entity and a CGF entity, or between two CGF entities. A comparison of the validity of the basic interactions provides the basis for identifying functional limitations of a MM or CGF representation that could result in an unfair advantage during conduct of an AVCATT-A training exercise.  3.	CCTT InteroperabilityIn October 1997 STRICOM funded the “CCTT Interoperability Program” to study aviation manned module interoperability with CCTT and the feasibility of using CCTT system compon-ents and software in an aviation collective training system [7]. STRICOM, Reflectone, AcuSoft, and Silicon Graphics were the primary participants on this study.  Reports and products delivered as a result of this effort include an Issues and Concerns Test Matrix [8], an Interoperability Findings and Observations Report [9], CCTT Software Reuse Report [10], a Communications Enhancement Report [11], a Radar Model Emissions Enhancements Report [12], and an Initialization Enhancement report [13]. The study was completed in March 1999. A Reflectone-developed OH-58D Reconfigur-able Tactical Trainer (RTT) was used as a surrogate AVCATT-A MM. The interoperability assessments in the reports were based on reuse of CCTT system components including the CCTT SAF and initialization systems. Most of the interoperability assessment information in these reports is not applicable since a new manned simulator designed to meet CCTT interoper-ability requirements will be fielded for AVCATT-A and no reuse of CCTT system components is planned. Regardless, a thorough review of the CCTT Interoperability program documentation will be performed to insure the interoperability assessment information com-piled and the techniques employed during this effort is used to the extent practical.  The AVCATT-A SRD states in four different places, “The AVCATT-A system will interoperate with other simulation systems through local area network (LAN) and wide area network (WAN) utilizing broadcast and multicast modes, will be Joint Technical Architecture-Army (JTA-A) compliant, will be Synthetic Environment (SE) Core compliant, and will achieve fair fight interoperability with the Close Combat Tactical Trainer (CCTT).” This statement is the closest thing to a definition of CCTT interoperability in the SRD. However, the AVCATT-A SOW [14] does contain a descrip-tion for AVCATT-A and CCTT interoperability.  Para. 3.1.4 of the SOW titled “Close Combat Tactical Trainer (CCTT) Interoperability” states, “The minimum level of interoperability to be analyzed must meet two criteria. First, an agreed upon communications mechanism shall be implemented to enable the simulation systems to dynamically interchange entity, event, and exercise management information during the conduct of integrated exercises. The second criteria is that the simulations must operate in a common synthetic environment. You shall determine how to verify interoperability with CCTT without co-location of your facility and the CCTT system”. Interoperability at these two levels for AVCATT-A and CCTT is discussed in sections 3.1 and 3.2. 3.1	Interoperability Communications MechanismThere is essentially no technical risk associated with design, development, and application of an HLA-to-DIS gateway to link the AVCATT-A and CCTT networks based on previous successful efforts to federate DIS-compliant virtual simulations, constructive simulations, and C4I systems in an HLA federation. HLA-to-DIS gateways have been developed and successfully employed over the past four years for the DARPA/JFCOM STOW ACTD [15]; the USAF Coyote ’98 exercise [16]; the Navy’s Fleet Battle Experiments Foxtrot, Golf, and Hotel [17]; and for the Navy’s Battle Force Tactical Trainer (BFTT) Air Management Node (AMN) air traffic control training system [18]. For the purposes of this paper it is assumed CCTT DIS protocols and AVCATT-A HLA objects and interactions will be accurately translated bi-directionally at the gateway, and CCTT and AVCATT-A system functionalities will not be adversely impacted when the AVCATT-A and CCTT systems are linked over a long haul network and operated at their respective maximum entity counts.  The recommended technique for verifying interoperability is to employ a CCTT CGF and a CCTT data logger as a surrogate CCTT system in the AVCATT-A CGF testbed. Figure 3 depicts a similar testbed configuration that was successfully employed to develop an HLA-to-DIS gateway for the USAF Coyote ’98 exercise and to remotely test interoperability between STOW Joint Semi-automated Forces (JSAF) and USAF F-16C Distributed Mission Training (DMT) simulators located in Mesa, AZ. In this case a NAWC-TSD F-14D virtual simulator was initially employed to verify interoperability between a DIS virtual aircraft simulator and HLA CGF. The technical approach for development and integration of the HLA-to-DIS gateway and the resulting gateway performance are described in [16]. A version of the HLA-to-DIS gateway used for the Coyote ’98 exercise was successfully used to federate OTB SAF with an HLA CGF (JSAF) at the Spring 2000 SIW conference by BMH.  This testbed provides the mechanism for testing interoperability across the HLA-to-DIS gateway without the need to co-locate AVCATT-A with CCTT. Entity state and event information for CCTT SAF is generated and passed bi-directionally across the gateway to verify CCTT CGF and AVCATT-A communications mechanism interoperability. Communications mechanism interoperability between CCTT manned simulators and AVCATT-A can be verified by playing a logged CCTT exercise file through the gateway. Communications mechan-ism interoperability between AVCATT-A and CCTT manned simulators can be verified by logging an AVCATT-A exercise using the CCTT data logger then replaying the logged file at a CCTT site. The same approach can be used to verify CCTT CGF communications mechan-ism interoperability with AVCATT-A if CCTT CGF hardware and software are not available for integration in the AVCATT-A testbed due to resource or contractual constraints.The capability for two simulations to success-fully share entity state, event, and exercise management information is a first order requirement for interoperability, however, the fact the simulations share all information necessary to support interoperability does not guarantee the interactions that occur are valid or support fair fight requirements.  Common Synthetic EnvironmentPara. D.3.6, Synthetic Environment, of the AVCATT-A SRD Interoperability Appendix D: states, “The AVCATT-A synthetic environment shall represent a correlated battlespace consisting of common components such as terrain, models (moving, relocatable, repositionable, animations and effects), and battlefield conditions.”  Battlespace CorrelationIn order for a common synthetic environment to exist the entities for each simulation must (1) operate within the same region in three dimensional space, (2) be “aware” of the types of entities generated by the other simulation in order to accurately represent basic sensor interactions for those entities, and (3) represent the same battlespace attributes including weather, diurnal effects, weapon effects, and countermeasures effects. TerrainTerrain correlation for AVCATT-A is being achieved by directly converting CCTT terrain databases (TDB) to the formats used for the AVCATT-A MM image generation system and CGF. The confines of the geographic areas in which AVCATT-A and CCTT entities can interact will be identical. Several techniques will be employed to verify the terrain database attributes are comparable. Intervisibility plots from an identical location in the CCTT and AVCATT-A versions of a TDB can be compared to identify areas where inconsistencies between two terrain databases exist. When inconsistencies are identified a comparison of the “z” values at given “x/y” coordinates or a comparison of the terrain databases using a “side-by-side” visualization utility can be performed to assess the impact on interoperability.  The types of cultural features such as roads, bridges, buildings, power lines, and antennas supported and the degree to which each terrain database supports terrain such as craters, obstacles, and building damage will also be compared to determine impact on inter-operability.   Models“Model” in this context refers to entity visual representations and animation effects such as explosions or tracers that are portrayed to an aircrew member through a visual display system. First order correlation for models is achieved by ensuring the entity model types required in the AVCATT-A SRD map to the list of entity and effects types supported by CCTT. Models can be mapped by type, level of detail, and types of damage states. The capability of the models for each simulation to accurately represent articu-lated parts including turrets, launchers, fire control radar antennas, and guns must also be compared to determine impact on fair fight.There should be no impact on fair fight and interoperability as long as models are available for each entity type that can be represented; the models for each system have similar levels of detail and damage states; and the event effects that result from basic interactions are represented by special effects and animations similarly for each system. 3.2.1.3	Battlefield Conditions“Battlefield conditions” are not defined in the Interoperability Appendix of the AVCATT-A SRD. Paragraph I.3.10, Battle Master Control, Appendix I: of the SRD does define “battlefield conditions” as, ”aircraft location, configuration, and environment; SAF mix, formations, orientations, locations, lethality, speed, direction, and weapons effects; initial aircraft fuel quantity and weapons loads, both internal and external; threat conditions and postures; environmental conditions, weather, time of day/night, battlefield obscurants and electronic warfare (jamming); degraded mode operations; and rearm/refuel manned modules.” This set of conditions is fairly broad in nature and basically encompasses all that is the AVCATT-A system.  The only practical approach to judge interoperability and fair fight for all the possible battlefield conditions is to identify the types of basic interactions that may occur when AVCATT-A MM and CGF entities interact with CCTT manned simulator and SAF entities. Fortunately, the basic interactions that are possible for CCTT entities are the same as those for AVCATT-A entities. The capability of CCTT manned simulators and SAF to validly represent basic interactions can be determined by analyzing documentation that describes the functionality of CCTT physical system represen-tations. Differences in functionality of AVCATT-A and CCTT physical system representations can then be assessed for their impact on fair fight and interoperability.  For example, the CCTT fire control radar represen-tation does not currently generate radar emissions [12].  This limitation prevents AVCATT-A entities from detecting the presence of CCTT ADA from RWR indications. The result is an unfair advantage for CCTT ADA during interactions with AVCATT-A entities. Options for addressing this limitation include exclusively using AVCATT-A ADA entities that support radar emissions, or enhancing the CCTT fire control radar representation to generate the proper radar emissions. 4.	SummaryThis paper describes the recommended approach for verifying the capability of AVCATT-A to meet fair fight and CCTT interoperability requirements. It provides definitions for fair fight and CCTT interoperability, and a process model that shows how information contained in software development products is used as the basis for validation of MM and CGF physical system and mission behavior representations.  It explains the technique for identifying the basic interactions AVCATT-A entities are capable of supporting and describes the relationship between interaction validity and fair fight.  Finally, it shows how the techniques employed to verify the degree AVCATT-A supports fair fight can also be used to verify AVCATT-A and CCTT interoperability.  5.	References[1] “System Requirements Document (SRD) for the Aviation Combined Arms Tactical Trainer – Aviation Reconfigurable Manned Simulator (AVCATT-A)”, STRICOM, 10/22/99.[2] DoD Verification, Validation, and Accreditation (VV&A) Recommended Practices Guide, Version - RPG Build 1, Office of the Director of Defense Research and Engineering Defense Modeling and Simulation Office, May 2000,  HYPERLINK "http://www.msiac.dmso.mil/vva/" http://www.msiac.dmso.mil/vva/[3] Harvey, E.P., “Simulation System Verif-ication and Validation: The Program Management Perspective”, Interservice/Industry Training, Simulation, and Education Conference, 1998.[4] AVCATT-A CGF Delta Analysis, BMH Associates, Inc., 1 May 2000.[5] Petersen, C.A., D. Cavitt, “User-Oriented Systems Engineering for the Navy's Battle Force Tactical Training (BFTT) Air Management Node (AMN)”, 00S-SIW-145, Simulation Interoper-ability Workshop, March 2000.[6] “ModSAF – Threat Enhancement, Final Report, Conceptual Model”, Lockheed Martin ADST II Team, September 5, 1997.[7] “Final Report”, CCTT Interoperability Program (BAA), Reflectone, March 1, 1999[8] “Issues and Concerns Test Matrix”, CCTT Interoperability Program (BAA), Reflectone, March 1, 1999[9] “Findings and Observation Report”, CCTT Interoperability Program (BAA), Reflectone, March 1, 1999[10] “CCTT Software Reuse Report”, CCTT Interoperability Program (BAA), Reflectone, March 1, 1999[11] “Communications Enhancements – Findings and Documentation”, CCTT Interoperability Program (BAA), Reflectone, March 1, 1999[12] “CCTT Radar Model Enhancement – Findings and Documentation”, CCTT Interoperability Program (BAA), Reflectone, March 1, 1999[13] “Initialization Enhancement – Findings and Documentation”, CCTT Interoperability Pro-gram (BAA), Reflectone, March 1, 1999[14] Statement of Work for the Aviation Combined Arms Tactical Trainer – Aviation Reconfigurable Manned Module (AVCATT-A); Simulation, Training and Instrumentation Command, 26 Feb 1999.[15] “Technology Transition Plan, Version 4.1, STOW ACTD”, DARPA/JFCOM, November 24, 1999.[16] Cavitt, D.B, M.A Gibson, E.P. Harvey, “HLA/STOW Interface Development To Support Distributed Mission Training (DMT)”, 98S-SIW-204, Simulation Interoperability Work-shop, September 1998.[17] Fleet Battle Experiment Golf Exercise Plan, Navy Warfare Development Command, 23 March 2000.[18] Cavitt, D.B., M.A. Gibson, B. Dorbrydnev, D.S. Bryan, J.J. Berkeley, “Integrating STOW and the Navy’s Battle Force Tactical Training System”, 99F-SIW-191, Simulation Interoper-ability Workshop, September 1999.Author BiographyEdward P. Harvey is the President of BMH Associates, Inc., a Norfolk, VA based simulation systems engineering and software development company. He is former U.S. Navy F-14A Radar Intercept Officer with over 20 years of experience in the application and development of simulation systems. Previous experience includes the DARPA Synthetic Theater of War (STOW) ACTD; development of HLA interfaces USAF F-16 simulators for Coyote ‘98; the Joint Countermine Operational Simulation (JCOS); and V&V of the Joint Warfare System (JWARS). He is currently the Systems Engineer for the WARCON program and the BMH program manager for development of  AVCATT-A CGF. He has a Bachelor of Chemical Engineering degree from the Georgia Institute of Technology.   Raytheon’s flight simulation division was purchased by L3 Communications, Inc. in March 2000. The terms “computer generated forces (CGF)” and “semi-automated forces (SAF)” are used interchangeably in the AVCATT-A System Requirements Document.  A representation is defined as a “model or simulation” in the DMSO VV&A RPG.  For the purposes of this paper a representation is a model or simulation of some aspect of the real world. The definition of validation from DoDD 5000.59 is “the process of determining the degree to which a model is an accurate representation of the real world from the perspective of the intended uses of the model.” The OTB SAF baseline was ModSAF 5.0.  ModSAF 5.1 is the HLA (RTI 1.3) version of ModSAF 5.0. These collective training tasks are listed in SRD Appendix B: Collective Task List. Each CGF entity representation is composed of a set of “common” physical system and mission behavior representations dependent on entity type.   Verification is defined in [3] as “the process of determining that a model or simulation imple-mentation accurately represents the developer's conceptual description and specification.” This is a fictitious example for illustration purposes and does not describe the planned functionality for AVCATT-A MM or CGF RWR representations.   CCTT SAF consists of a CGF “server” and a GUI that is called a “SAF” in CCTT termi-nology.  Figure  SEQ Figure \* ARABIC 3 – STOW - DMT Interoperability Testbed Configuration EMBED PowerPoint.Slide.8  Figure  SEQ Figure \* ARABIC 2 – AVCATT-A CGF Delta Analysis ProcessFigure  SEQ Figure \* ARABIC 1 – Fair Fight Assessment Process EMBED PowerPoint.Slide.8   EMBED PowerPoint.Slide.8  