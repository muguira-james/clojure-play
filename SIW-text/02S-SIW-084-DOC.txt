Software Architecture for Integrated Test & Evaluation ofChemical/Biological Sensors	Jerome B. Soller, Ph.D.	Mike JonesSteffanie MooreCogniTech Corporation1060 East 100 South Suite, #202Salt Lake City, Utah  84102801-322-0101soller@cognitech-ut.comJoel B. DuBow, Ph.D.University of UtahDept. of Materials Science and Engineering122 South Central Campus Dr. Room 304Salt Lake City, Utah 84112801-581-8388joel.dubow@m.cc.utah.eduKeywords:Modeling, Simulation, Acquisition, VPG, Sensors, Detectors, Chemical, Uncertainty, Distributed, TestABSTRACT: Chemical and biological detection processes consist of a number of subprocesses, including the generation of a vapor cloud, atmospheric transport, large-scale meteorology, sensor hardware, sensor software, sensor fusion and decision support systems.  These processes can be represented as a system of sub-system models.  The constituent simulations are characterized by model semantics, parameters and metrics, which include domain of applicability, dynamic state evolution, simulation time scales, resolution, fidelity, uncertainty, and robustness.  The architecture incorporates these characteristics by integrating distributed software interfaces and supporting chaining of simulation outputs, errors, noise, uncertainty, and perturbation disturbances.  It securely integrates databases and process models, including a wide variety of sensor and environmental data interchange formats.  The architecture also facilitates the verification and validation of models and simulations using ground truth data.1. IntroductionThe chemical and biological detection processes consist of a number of subprocesses, including the generation of a vapor cloud, atmospheric transport, large-scale meteorology, sensor hardware, sensor software, sensor fusion and decision support systems.  These processes can be represented as a system of sub-system models to enable realistic inputs to decision support, training, procurement, and test and evaluation processes. Furthermore, the detection system itself only imperfectly reproduces or classifies this distorted signal.  The sensor fusion or decision support systems must interpret this imperfect data in a manner that provides accurate information to decision-makers.  To properly represent, model and simulate these processes, engineers must characterize the noise and uncertainty of each individual process, sensitivity of the processes themselves or the models of the processes to perturbations, and the dynamic evolution of the processes over time.Sensor and detection system performance is constrained by noise, other external disturbances, the environment, detection system dynamic range, resolution, and component variation.  While many CB sensor modeling, simulation and acquisition environments produce course-grain data appropriate for human in the loop training, they do not accurately predict CB detector performance under realistic battlespace conditions.  Some chemical and biological training systems utilize prerecorded field data; the predictive power of real field data are limited because they can only span a subset of the mission space of the detector.  In order to predict an output of a detection system under any arbitrary conditions within its mission space, a complete dynamic model is required.  There are two main categories of dynamic models: empirical and analytical.  Empirical models determine their parameters from data (e.g., scene generator data, experimental detector data, simulation data from atmospheric models) and performance measures that evaluate a system over its entire mission space.  Field test data, collected at the U.S. Army Dugway Proving Ground and other test ranges, is critical for the verification and validation of sensor models and simulations, particularly when the test data is disjoint from the data used to construct the models or simulations.  While real field data on sensor characteristics can be collected at test ranges, the results do not necessarily predict the performance of that instrument in different locations and operating conditions.  Data resulting from field tests do not cover the full range of operating values; therefore, they cannot serve as the basis for dynamic models that can predict outputs over the entire mission space.  These dynamic models are needed to predict sensor output and statistical characteristics under realistic field conditions.   The data generated by these dynamic models, in turn, are necessary for the design of effective decision support systems and the procurement of effective detection systems.These dynamic detection system simulations are characterized by the model semantics, the domain of applicability for a given model, dynamic state evolution, simulation time scales, resolution, desired and possible fidelity, uncertainty, robustness, and other parameters. Even with an ideal detection systems modeling environment, the fidelity of the resulting simulated data depends heavily on the accuracy and representations of uncertainty for data produced by environmental simulations, which in turn, receive inputs from battlefield or homeland defense scenarios.The software architecture, framework, and methodology developed by CogniTech Corporation and the University of Utah focuses on accurate prediction of sensor and detection system performance for subsequent use in decision support systems and rigorous test and evaluation processes.  The system enables accurate, high resolution, and time varying inputs to decision support systems.  To achieve these goals, it provides distributed software interfaces available to a number of different software languages; chaining of simulations; propagation of errors, noise, uncertainty, and perturbation disturbances; and support for the definition and use of syntactic, semantic and contextual constraints on simulation use, chaining and execution.  It securely integrates databases and detection system process models, with support for a wide variety of sensors (e.g., point and standoff) and associated sensor and environmental data interchange formats.  The architecture also facilitates the verification and validation of models and simulations using ground truth data.   Therefore, this framework will enhance the practices of sensor and detection system design, system procurement, system developmental and operational test, detection system deployment strategy, sensor fusion and decision support. 2. Background2.1 Variety of Sensor Technologies for Chemical and Biological DetectionChemical and biological detection systems utilize a variety of physical sensors, including long-range sensors (e.g., LIDAR, FTIR, DOAS) and short-range point detectors (e.g., Ion Mobility Spectrometers, Surface Acoustic Wave).   Each type of sensor has different input/output characteristics and operates through different physical mechanisms.  The impact and effects of environmental processes on the detection system will depend on the specific mechanisms of each detection process. However, all detection systems will be influenced by common atmospheric properties and processes, including the presence of interferents, thermodynamics and physical properties, agent transport and dispersion, and environmental turbulence characteristics.  Furthermore, in many cases, detection systems will need to fuse data from multiple types of sensors and associated interpretation algorithms to provide more robust identification and quantification of toxic agents in the environment. A chem/bio sensor is a transducer, which represents the concentration of toxic agents by transforming a physically measured property to an electrical output.  Point detectors transform in situ chemical concentrations to an output current or voltage. Point detectors take samples of the atmosphere that interacts with the sensor, sometimes after a separation technique.  Many interaction mechanisms are possible, but all of them result in either charge generation or changes in electrical potential.  Examples include ion mobility spectrometry, surface acoustic wave techniques, flame photometry, catalyst coated solid polymer electrolyte devices, and various surfaces or solutions coated with bioactive organisms or compounds.  Standoff detectors transform the complex emission, absorption, reflection and propagation of electromagnetic signals through the atmosphere into an electrical output pattern.  The two main types of standoff detectors are passive and active.  Passive standoff detectors measure the radiation incident on a detector from the atmosphere using ambient light to serve as the light source.   In these systems, the detectors capture the composite spectra of many atmospheric gases.  Both active and passive detection involves separating the spectra of benign and background gases from potentially toxic components of the atmosphere.  Active standoff detection systems generate an electromagnetic wave at the source (e.g., laser, Xe-arc lamp) and then detect the returned wave using an optical receiver (e.g., optics, beam splitting lenses and mirrors, optical detectors).  The delayed, attenuated and phase-shifted return signal is matched against the expected return signal in the presence or absence of a toxic agent.  A high fidelity atmospheric model is needed to provide baseline wave propagation predictions and enable the subsequent creation of pattern recognition algorithms to identify the constituent chemicals.  In principal, the point, active standoff, and passive standoff detection techniques can effectively detect chemical/biological agents.  In practice, the detectors do not exhibit ideal behavior and their inputs in the natural environment deviate substantially from those used in typical laboratory tests.  Point detectors are typically used for alerting and alarming personnel in the immediate area to the existence of toxic compounds. The observation point may or may not be representative of the immediate surrounding area or the larger battle area.  For this reason, point detectors are deployed in arrays or mobile platforms.  Because standoff detectors provide spatially averaged data concerning the existence and concentration of agents, they are most commonly used for identifying threat clouds and alerting field personnel to an incipient threat.  A prominent form of active standoff detector is an infrared optical radar, commonly known as LIDAR.  Chemical identification of toxic agents in clouds is enhanced by using dual wavelength, dual beam sources in a form of LIDAR known as DIAL.2.2. DIAL Active Standoff Sensor TechnologiesActive standoff detection using differential absorption lidar (DIAL) is an ongoing area of research for atmospheric chemical detection and systems using a wide number of different measurement and analysis techniques have been developed.  DIAL systems provide the ability for three-dimensional mapping, identification and quantification of chemical species’ concentration profiles within the atmosphere.  To accomplish this, laser light is transmitted into the atmosphere at two similar wavelengths.  One wavelength is chosen at which the species under investigation absorbs the light and the second is a near (off peak) wavelength.  If the two pulses are made close enough in time such that the atmosphere can be considered stationary, the off peak laser pulse is assumed to have similar atmospheric transmission characteristics to the on peak wavelength except for optical absorption by the chemical species.  Comparison of the intensities of the backscattered pulses given the concentration of the investigated species in the region of atmosphere examined.  Range is determined by resolving the arrival time of the returning pulses.Some of the processes involved in DIAL measurements are listed in Table 1 below.   A software framework incorporating these phenomena is capable of chaining together these and other simulations, and including all error sources, is needed in order to accurately assess the performance of these systems and predict their output.  For example, a recent study by Fiorani and Durieux [1] used simulated lidar signals to analyze different data analysis techniques suggested that discrepancies between concentration measurements by different DIAL systems results from the lack of statistical error propagation analysis throughout the detection process.Table 1. Processes involved in DIAL accuracy [2]Signal-to-noise limits:Signal shot noise (quantum noise)Background noiseDark-current noiseFactors related to absorption properties:Uncertainties in absorption cross sectionsOverlapping absorption profilesUncertainties in laser wavelengthsEffects due to finite laser linewidthDifferential spatial-, temporal-, and wavelength-dependent factors:Differential temporal power profilesFabry-Perot effectsWavelength-dependent scattering propertiesFactors determined by atmospheric conditions and detection system:Multiple scattering effectsTemporal noncorrelationTemporal and spatial averagingCharacteristics of photodetectors and amplifiersEffects of data acquisition2.3. Information Flow of Detection ProcessesEMBED Visio.Drawing.5Figure 1. Information Flow for the Chemical Detection ChainThe chemical and biological detection processes consist of a number of subprocesses (the detection chain), including the generation of a vapor cloud, atmospheric transport, large-scale meteorology, sensor hardware, sensor software, communication system effects, sensor fusion and decision support systems.   Each subprocess adds noise to the signal and additional uncertainty to the output estimates.  The original information from the chemical cloud may be rich at its source, but it degrades as it propagates through various stages of the atmosphere and the detection chain.  Each step in the process degrades the information on the existence, concentration, location, and direction of a toxic agent cloud.   Although information can not be added back into the system without a good ground truth reference, it is critical to understand the response of each element of the detection chain to the real degraded inputs it will receive in the field and to predict the output for this degraded input.  The decision support system must deal with this substantially altered signal and extract meaningful source information from it, leveraging realistic characterizations of the uncertainty and limitations in the data and systems used to measure the data.  Therefore, sensor fusion and decision support systems may well need to be more sophisticated and complex to extract the information needed for them to perform effectively.  Alternatively, the detector makers will need to apply modern signal processing techniques to the data based on accurate propagation and detection system component models before the data are communicated to decision support systems.  For example, in research summarized in an earlier SISO paper, the research team applied nonlinear adaptive models, Kalman filtering, and sensitivity analysis to characterize Ion Mobility Spectrometer point detectors. A generalized software environment for modeling environmental processes, detection systems, and their components is necessary for effective design, development, and deployment of chemical and biological detectors.  The stakeholders, which include acquisition, development, test and evaluation, training, deployment, and battlefield personnel, require managed access to individual models, data, and chained simulations in order to accomplish their missions.  To meet these needs, the Office of Naval Research has funded CogniTech and the University of Utah to develop a comprehensive detection systems simulation environment.  The goals of this environment are to provide decision support systems developers, testers, and planners with realistic data representing sensor and detection system outputs, output statistics, and uncertainty estimates.  In addition, these stakeholders will be able to create customized scenarios and test cases, run these tests, evaluate the performance of the systems using different metrics, and analyze the resulting databases of real and synthetic data.3.  Domain Processes Represented with a Detection Systems Simulations FrameworkFigure 2. Information Flow Within the Detection Systems Simulation EnvironmentTo effectively use a detection systems simulation environment, the software environment must contain or have access to representations of all relevant data, effects, and systems that impact the detection system outputs.   The CogniTech software framework was developed to meet the information requirements depicted in Figure 2.  The scenarios will include geographic locations and meteorological/climatological information for the projected theatre of battle.  Each environment will also have naturally-occurring or synthesized confounding or interfering agents.   In addition, the detection systems may be other exposed to other countermeasures.  The dispersal of chemical and biological agents will be accomplished through the mediation of the environment and the surface morphology of natural and human structures, prior to their deposition on the host target.  Large scale meteorology, vapor dispersion, and chemical source cloud characteristics all interact with surfaces, including urban structures, rural terrain, and bodies of water.  The sum of all effects between the source cloud and the detector need to be included to enable realistic estimates of inputs to the detection systems. The software framework for accurate models of detector behavior requires time synchronization between simulations, syntactic constraints on the parameters of simulations, and semantic constraints on the models used for simulations.  Careful time synchronization is needed because component simulations operate with different time scales and representations, and it is necessary to synchronize model time across simulations and prevent execution dead-lock.  Syntactic constraints are needed to ensure compatibility between types of data and model software requirements. Semantic constraints are required to ensure that the data and data connections are applied in their proper context.  In addition domain constraints are also needed to ensure that outputs reproduce known results are consistent with realizable scenarios.  As an example of these requirements, the constraints required by incorporating vapor cloud dispersion models into a larger detection system simulation framework are discussed below.2.3.1. Constraints on incorporating dispersion models within a detector system simulation frameworkTo effectively model a detection system’s dynamic response, a realistic characterization of the time-varying concentration of a species in the atmosphere is required.  Local concentration fluctuations greater than 35 Hz (the response time of the employed flame photometric detector) have been demonstrated in field at the U.S. Army Dugway Proving Ground [3].  Experimental tests of a detector’s response to such realistic time-varying inputs may be accomplished through field tests and chamber tests or the use of laboratory test systems such as the University of Utah’s Chemical Stimulator [4,5].  Test and evaluation of a detection system within a simulation environment often utilizes simulated data from atmospheric dispersion models.  The development of dispersion models were initially driven by the needs of Chemical Process Industries for hazard estimation and pollution characterization.  Early dispersion models were based on parameterization of chemical transport with atmospheric stability (e.g. Pasquill-Gifford Stability Classification, Monin-Obukov length) and are largely power law correlations fit to experimental data.  Many modern dispersion models have inherited from these semi-empirical models and it is important for simulators to realize the impact of this legacy.  For instance, outputs from these semi-empirical models can contain error estimates, as well as space and time-resolved species concentrations.  However, these error estimates, though expressed as a probability, are not necessarily a statistical error estimate of the local point concentration, but often a confidence measure for the hazard area that the concentration is above a given threshold. Similarly, the highly stochastic nature of micro- and mesoscale atmospheric dynamics leads to an averaging time (whether explicit or not) within vapor cloud dispersion models.  Analysis of a broad range of semi-empirical models [6] has demonstrated physically impossible behavior descriptions (such as locally increasing concentrations –a domain constraint) when used with averaging times less than 20 seconds.  This leads to a time constraint for chaining such a simulation with dynamic simulations of point detectors (e.g. IMS with sampling rates as fast as 5 Hz).Modern Lagrangian puff second order turbulence closure models such as SCIPUFF (developed by Titan’s ARAP Group) provide a direct relationship between the predicted dispersion rate and turbulent velocity statistics of the wind field, the effects of averaging time, and statistical variance of the concentration field [7].  Therefore no such implicit time constraint exists.  Even SCIPUFF, however, assumes a gaussian turbulence profile and the use of lagrangian particle techniques that can treat more complicated atmospheric dynamics would be more useful or appropriate in specific dynamic detection response investigations (e.g. the effects of signal inertia or time-averaging due to atmospheric sampling on a detector’s false alarm rate and sensitivity).An example of a semantic constraint for this scenario is that a user should not be able to use a concentration value from a dispersion model in the optical parameter fields of a standoff-detector model.The CB detection community has only recently focused upon developing truly dynamic simulation models and the University of Utah has been a pioneer for this class of models [8].  Immediate needs within the CB detection community includes the ability to integrate both static and dynamic sensor simulations, atmospheric transport models, and information sources for all subsystems throughout the detection chain, the ability to represent and propagate the uncertainty in the information flow between these processes, and the ability to provide this information to decision makers and decision support systems.In addition, these examples illustrate that a comprehensive detection simulation architecture must not only be able to chain the data flow between these simulations during execution; it must also provide the ability to represent constraints and relationships of simulation parameters, as well as semantic and contextual information about characteristics of the simulation inputs and outputs. 2.3.2 Consequences arising from fully constrained software frameworkThe detection system physical hardware, sensing mechanisms, signal conditioning and interpretation algorithms all, to some degree, impact the quality of the information contained in signals traversing the detection systems.  Realistic representations of these phenomena are needed to guide acquisition, test, training and deployment.   Each individual detector type responds differently to multiplicity of processes that degrade the chemical and biological source signal.  Therefore, each individual detector type has strengths and weaknesses for any given scenario.  Thus, multiple detection techniques and detector arrays will likely be needed for high reliability detection of toxic agents under real battlefield conditions.  The resulting data from each detector must be combined within a sensor fusion system tailored to this problem space before serving as input to a decision support system.All models and simulations included in the simulation framework need to be validated and verified individually and as a component of a larger chain of simulations.  Once this is done, it will strengthen the stakeholders listed in figure 2 and moreover, serve as a vehicle for integrating and coordinating their efforts to a degree not available at present. The availability of valid and verifiable simulations does not, by itself, guarantee meaningful use of these simulations to solve a real-world problem.  The integration and configuration of the simulations and software algorithms must make consistent assumptions on their data syntax, vocabulary, meaning, assumptions of fidelity, context, and other constraints.  Clark has described these issues for a different sensor problem domain [9].  These issues have impacted the development of this framework. Furthermore, other Department of Defense contractors have developed sophisticated high level generalized frameworks applicable to generic detection systems [10,11].    However, the architecture, framework and methodology developed by CogniTech and the University of Utah through their collaboration with the Office of Naval Research Probability and Statistics Program and the Navy Surface Warfare Center TEAMS program focuses on finer grain issues, such as the incorporation and propagation of noise, uncertainty, disturbances, and the limitations resulting from chaining these processes.  Furthermore, this system emphasizes statistical analysis techniques and engineering / statistical performance metrics to fully characterize dynamic time varying, linear, nonlinear, stochastic, and threshold effects within detection systems and their coupling with environmental effects.   4.  A Comprehensive Sensor Simulation ArchitectureCogniTech and the University of Utah share a vision of a comprehensive simulation architecture for sensors and detection systems.  This architecture will support simulation based acquisition and decision support using common data, models, and methodologies.  This architecture was developed based on common requirements of stakeholders that use sensor models, simulations, and data.                                                   Figure 3. Detection System Simulation ArchitectureFigure 3 illustrates some of the core functional components of the detection systems architecture and subset of its stakeholders.  Simulation developers would develop their simulations in a consistent format and test their simulations against standardized performance measures and public test data, which are stored in databases and generated by collecting field, test chamber, or laboratory data or by running simulations.  Upon completion of the simulation development process, the simulation developers will submit their simulations for formal verification, validation, and accreditation, which may include additional validation data sets not used to train the model parameters.  Upon accreditation or other approval process, the simulations are added to a run-time simulation repository, which contains metadata about the simulations input/output requirements, data meaning, and data context.  Test, evaluation, and acquisition staff or their system integrators would visually wire simulations and scenarios, subject to constraints on allowable inputs, outputs, data meaning, and context, to support their decision-making processes.The framework will support Java, CORBA, HLA, and web services software interfaces operating in a secure fashion.  The architecture supports the integration of databases containing data from cloud chamber and field tests, as well as from hardware devices, such as chemical stimulators (a chemical signal generator) and scene generators (a system that accurately produces the spectrum produced by the agent cloud).   The framework will eventually support tight real-time integration with the hardware devices themselves.   Likewise, future versions of the framework will support integration with computationally-intensive simulations running on high performance computing resources.The data generated by the sensor simulations will serve as input into detection algorithms and battlefield C4I decision support systems, as well as testing and simulation environments (e.g., TEAMS).  Simulation-based acquisition systems will rely on the availability of test data and models to simulate the performance of proposed detectors in their operational environment.5. ConclusionThe detection system simulation environment will enable the integration of simulation repositories of cloud generation, meteorological, and detection systems components to provide realistic inputs to decision support systems.  This end-to-end capability will permit, for the first time, rapid adaptation of detection systems to new threats in the field and unanticipated operating conditions.  It will also provide a framework for a detector acquisition methodology that will reduce the gap between operational requirements and detectors submitted for development test procedures. 6. AcknowledgmentsThis research was supported by the Office of Naval Research contract N00014-01-M-0131 to CogniTech Corporation and leveraged data resulting from the U.S. Army Dugway Proving Ground contract DAAD09-00-P-0038 to the University of Utah. The researchers acknowledge the assistance of Dr. Wendy Martinez, Program Manager for the Office of Naval Research Probability and Statistics Program; and Dr. Thomas Holland, the Director of the US Naval Surface Warfare Center Dahlgren Division Navy TEAMS facility for their collaboration throughout all phases of the development.  The US Army Dugway Proving Ground Meteorology Group (Dr. Jim Bowers and Dr. Jim Rafferty), DTRA HPAC, and NSWC VLSTRACK groups for important providing valuable insights into the contexts and constraints that detection systems will encounter during operation. We thank Doug Clark for his insights on semantic and contextual issues for integrating sensor simulations.8. ReferencesE. Duriux, L. Fiorani, “Comparison among error calculations in differential absorption lidar measurements”: Optics and Laser Technology 33 (2001) 371-377K.A. Fredriksson, “Differential Absorption Lidar For Pollution Mapping” in: Laser Remote Chemical Analysis, R.A. Measures, (Ed.): Wiley-Interscience Publications, New York, 1988. p273-332G.M. Chandler, Relative Diffusion Analysis: Final Report, Contract No. DAAD09-96-C-0009, S+J Engineering Inc., Februrary 1997.N. Arnold, J. Dubow, I. Symmach, and H. Muzelaar, ITEA: “Chemical Signal Generators for Advanced Point Detection Models”, Las Cruces, NM, June 1999J. Dubow, J. Janez, E. Kholmovski, J. Mathews, G. Bodily, T. Evans, R. Liebert: “Dynamic Systems Models of Ion Mobility Spectrometers” SPIE conference proceedings, Vol. 4036, Spring 2001D.B. Turner, Workbook of Atmospheric Dispersion Estimates 2ed.: Lewes Publishers, Boca Raton, 1994.I. Sykes, “Lagrangian Puff Dispersion Modeling and Uncertainty Estimation Using Second-Order Closure” in: Mesoscale Atmospheric Dispersion, Boybeyi, Z. (Editor), Wit Press, Boston, 2000.J. Soller, S. Moore, M. Jones, J. Dubow, J. Jeraj, ”The Role of Dynamic Modeling in Simulation-Based Acquisition” Fall Simulation Interoperability Workshop, IEEE, 2001, 01F-SIW-121.D.L. Clark, R. Howard, C. Chadbourne, C. Root, R. Esslinger, "Consistency As a First Step in Moving Toward A Common Synthetic Natural Environment Standard". 2000G.J. Rumford, M. Vuong, S.T. Bachinsky, E.T. Powell, “Foundation Initiative 2010: The Design of the Second Tena Middleware Prototype”. Fall Simulation Interoperability Workshop, 01F-SIW-110. IEEE, 2001.D. Jodeit, D.L. Jones, R. McMahon, R. Ryan, J.R. White, “Use of Environment Simulation to Support Passive Chemical Sensor Development”. 2000Author BiographiesJEROME B. SOLLER, PH.D. is the President of CogniTech Corporation.  He currently is the principal investigator of a contract to develop a web portal for the AFRL sensors directorate and a contract to develop a chemical sensor simulation environment for the Navy. He has previously held research positions at the University of Utah, the U.S. Department of Veterans Affairs, and industry.  His research focuses on statistical pattern recognition, simulations, expert systems, data mining, and software architecture. He received his Ph.D. in Computer Science from the University of Utah and his B.S. in Electrical Engineering from the Johns Hopkins University.MIKE JONES attended the University of Utah in Chemical and Fuels Engineering.  He has worked as an analytical chemist in environmental and industrial chemical analysis, a process engineer and chemist in solvent refining of precious metals, and as a software developer in B2B web development, enterprise e-marketplace / e-procurement, and messaging frameworks.  He is presently employed at CogniTech Corporation as a software developer where he works with simulations and simulation framework development.JOEL B. DUBOW, PH.D. is a pioneer in the dynamic testing and model development of chemical detectors.  He is presently a professor of materials science at the University of Utah and has over 25 years experience as a researcher in sensors, actuators and their system representations. He is currently principal investigator on a contract to model chemical detectors and test fixtures for the US Army Dugway Proving Ground. STEFFANIE MOORE is a software developer at CogniTech Corporation working with simulation framework development and tool development for distributed algorithm evaluation.  She received a bachelor's degree in physics and mathematics at the University of Utah, with thesis research involving the development of statistical models of photo-multiplier tubes and a calibration system for ultra high energy cosmic ray detectors with the High Resolution Fly's Eye Research Group.Copyright 2002, SISO, Inc. Permission is hereby granted to SISO members and sponsors to quote any of the material herein, or to make copies thereof, for personal or internal organizational purposes, as long as proper attribution is made and this copyright notice is included. All other uses, including resale and/or redistribution for commercial purposes, are prohibited without written permission from SISO, Inc. PAGE  8PAGE  8 EMBED Visio.Drawing.5   EMBED Visio.Drawing.5  