Using Modeling and simulaton throughout the entire system life cycleIncluding an Example of How the Methodology was Successfully Applied to OPNET Based Communication Architecture Models Deanna Evans, Sherie Johnson, Tom Stayonoff, Greg WolffRaytheon CompanyNWCS – Networked Communication SystemsFullerton, CaliforniaEmail:  HYPERLINK "mailto:dkevans@raytheon.com" dkevans@raytheon.com,  HYPERLINK "mailto:smjohnson@raytheon.com" smjohnson@raytheon.com,  HYPERLINK "mailto:testayonoff@raytheon.com" testayonoff@raytheon.com,  HYPERLINK "mailto:gwolff@raytheon.com" gwolff@raytheon.comKeywords:Communications, Networking, Life Cycle, Simulation Process Abstract: Communication architecture and networking protocol modeling and simulation has traditionally been focused on rapid prototyping of the objective architecture with little concern for model or software reuse.  Although this method is successful in solving the short term problem, it limits the effectiveness of the communications modeling and simulation effort in reducing time, resources, and risk associated with the entire program life cycle.  The Raytheon Communications and Networking Modeling and Simulation Center of Excellence has developed a methodology to employ communications modeling and simulation throughout all phases of a program, from requirements definition, design, to test and integration, to provide a common infrastructure for pervasive use and reuse of models and simulation tools.  This paper introduces the methodology developed by the team to use communications architecture models throughout the entire system life cycle.  In addition, an example of how this process was successfully applied to OPNET based models is presented.1. IntroductionAccurate and effective Modeling and Simulation is a cornerstone of the systems design process, particularly in the area of communications and networking.  Traditionally, during the requirements definition and design phases, individual simulations and models are identified, evaluated, selected, created and used to address major design elements and program risks.  This results in a collection of communications architecture and networking protocols models and simulations that address specific issues and are not very robust for use in future phases of the program.  The Raytheon Communications and Networking Modeling and Simulation Center of Excellence has developed a methodology for expanding the use of these models and simulations beyond the initial phases for use throughout the entire system life cycle.Building upon the foundation created during the requirements definition and design phases, communications and networking modeling and simulation continues to refine and enhance the fidelity of individual models.  Concurrently, the collection of models and simulations are evaluated and selected models of component functionality are integrated into larger simulations.  In addition, a process has been defined that provides the capability to transition modeled functions and algorithms from the simulation environment into the virtual environment, and from there, into prototype operational hardware and software.  Included in this methodology are the steps necessary to verify, validate, document and place under configuration management those modeling and simulation components that are to be placed into a repository for future use.2. Methodology OverviewThe defined methodology for modeling and simulation throughout the entire system life cycle is one of baseline, growth, iteration, and evolution in support of the design, integration and test phases of the program (Figure 1).  Figure 1.   Methodology for Using Modeling and Simulation Throughout the Entire System Life Cycle.2.1 Stand-Alone Simulations and Models DefinitionModeling and simulation development begins during the requirements definition phase when an engineer or team lead determines that one or more performance requirements or program risks requires the use of modeling and simulation.  Once a need has been identified, modeling and simulation engineers work with the appropriate engineering staff members to determine specific modeling and simulation requirements.  This includes defining the problem, i.e. areas of risk or uncertainty, determining what input data will be used by the simulation, documenting and agreeing on key assumptions made by the simulation, specifying the data and statistics collected and the format used to report key performance parameters, and selecting the appropriate simulation approach, i.e. static, dynamic, algorithmic, etc.  Once requirements have been established, actual implementation of the model or simulation can begin.  This includes collating requirements into a model or simulation description document and reviewing libraries of existing models to determine if any existing elements can be used or if completely new models must be created.  To ensure the models and simulations accurately reflect algorithmic and behavioral functionality, they are designed, coded and peer reviewed in close coordination with segment engineers.  In cases where the model will ultimately be incorporated into larger system-wide simulations, modularity and re-use is factored into the design.Once all parties agree on the implementation of the working model, three steps occur in parallel: the models or simulations are placed in the model and simulation library so that other simulation efforts may begin, verification and validation is begun, and trade studies are performed.2.1.1 Model and Simulation LibraryThe modeling and simulation library serves as the virtual repository for all models and simulations and is maintained under configuration control. Depending on overall program requirements, a given simulation may cycle through the definition, implementation, and verification steps multiple times, with each iteration incorporating additional functionality, complexity, and detail level of the simulation.  As this happens, the model description document is updated to reflect the added capabilities and the new version of the model is incorporated back into the modeling and simulation library.2.1.2 Verification and ValidationModel or simulation verification and validation (V&V) is an iterative process that must be conducted in parallel with overall system design and development, especially when the functionality being addressed is new, meaning that previously verified and validated models do not exist.  Initial verification and validation is accomplished by comparing model functionality, at the module and code level, to appropriate standards and specifications.  In cases where a function is modeled using more that one simulation, comparison of the individual results is also used as a V&V technique.  In addition, simulation test runs, using input data designed to produce a known output is also used when applicable.  As system design and development progresses, previous V&V is supplemented by comparison of simulation data against that produced by hardware/software emulators, review of results obtained from tests in the simulation driven systems integration environment and ultimately performance metrics collected from as-built system components.  2.1.3 Trade StudiesTrade studies are performed for the purpose of resolving conflicts identified during requirements analysis, decomposing functional requirements and allocating performance requirements during functional analysis, evaluating the effectiveness of alternative physical element solutions and selecting the best physical solution during synthesis, assessing system effectiveness, and managing risk factors throughout the systems engineering effort.  To perform a trade study, the requisite input data is collected and formatted and the simulation is setup and executed.  Raw data from the simulation is collected and formatted to best support evaluation and analysis.  Depending on such factors as the design element being analyzed, the quantity and complexity of the data and the objective of the study effort, simulation results are presented in a variety of methods ranging from traditional forms such as graphs and tabular data to 2- and 3-dimentional animations.  All data affecting the simulation, including scenario inputs, assumptions, formatted results, and execution metrics are collected and documented in a simulation execution report as part of analyzing the modeling and simulation results in support of the traditional trade study process.2.2 Integrated Simulations and Models, Virtual Environment Simulations and Models, and Prototype Operational Hardware and Software DefinitionThe methodology for integrating models into larger simulations, virtual environments, and prototype hardware and software is the same.  It is the target environment that is unique in the process.  An integrated simulation and model environment consists of multiple simulators connected together to provide the capability to assess operational and system performance, such as a distributed HLA simulation environment.  A virtual environment is made up of a combination of simulated and real entities, such as Hardware-in-the-Loop and Man-in-the-Loop architectures.  The prototype operational hardware and software is composed of the actual target hardware that will be used in the delivered system.The integration process begins when a model identified during the stand-alone simulation and model design phase is placed into the modeling and simulation library and placed under configuration control.  The latest version of the model is retrieved from the repository and interfaces are created that allows for direct insertion of the model into the above mentioned environments.  Once the interfaces have been tested and confirmed, a model description document is created to reflect the baseline model used and added capabilities, and the integrated model is incorporated into the modeling and simulation library.  A baseline simulation model may cycle through the definition, implementation, and verification steps multiple times, with each iteration incorporating additional functionality, complexity, and detail level of the simulation.  As this happens, the new version of the model will be retrieved from the repository and the differences in the model evaluated.  If the modifications to the model are deemed significant, the integrated model will be modified to reflect the same changes.  As this happens, the model description document is updated to reflect the added capabilities and the new version of the model is incorporated back into the modeling and simulation library.3. Example ImplementationDuring the requirements definition phase of a satellite program, the lead system engineer identified the need for modeling and simulation analysis in order to study the performance of the protocol architecture.  The following sections describe the models that were developed and will show how they were used throughout the system life cycle.  For more detailed information, please see reference [1].3.1 Stand-Alone Simulations and Models The specific problem that was defined required a model of the end-to-end performance of a voice or data thread through the system from user ->satellite->user with high fidelity representations of the underlying protocols. With the vast library of standard models available, OPNET was chosen as the development simulation environment for the model (Figure 2).  Figure 2.   End-to-End Stand-Alone Simulation Scenario and Terminal Node Model.The simulation engineers were able to use the existing application, transport, and network layers associated with a standard workstation model in OPNET, but custom created a TCP Proxy, Mil-Std-188-184 (Link-184), and UHF MAC model for insertion into the protocol stack (Figure 3).  The TCP Proxy model was designed to fit seamlessly into the existing OPNET interface definition, i.e. no OPNET code was changed.Figure 3.   Custom Created End-to-End Performance Process Models.3.2 Virtual Environment and Prototype Hardware Simulations and Models During the design of the stand-alone models, the need to study the performance of the protocol architecture with real applications and physical layer representations was identified.  In addition, the lead system engineer was interested in directly porting protocol models from the simulation environment into target hardware to minimize risk in developing Software Communications Architecture (SCA) compliant protocols.  Therefore, the simulation engineers developed the TCP Proxy and Link-184 to be reused for those applications.Once all engineers agreed on the implementation of the working OPNET models, the models were placed in the model and simulation library so that trade studies could begin to study the performance of the protocol architecture and to optimize parameter values of the custom created protocols.  In addition, the models were put into the library so that two additional efforts could begin that reused the model code.The first effort required integrating OPNET models of the TCP Proxy and Link-184 into a larger hardware-in-the-loop simulation environment that contained real representations of the application (FTP) and physical layer (Figure 4).  The End-to-End TCP Proxy model was modified to contain an interface that interacted directly with the Communications Effects Device (CED) [2] and was modified to process real IP datagrams.  The Link-184 model was modified to pass data packets via a JTT terminal.  The Simulated Communications Environment was incorporated into the middle of the simulation environment, on two separate laptops connected by JTT radios.  Two more laptops were used to host the FTP client, as well as, the respective FTP server.  IP data from the FTP session was intercepted by the CED and forwarded to the OPNET model. Once the data was processed by the OPNET model, it was directly fed into a JTT radio and broadcast to the other side.Figure 4.   TCP Proxy and Link-184 Models Directly Inserted into a Hardware-in-the-Loop Simulation.The second effort required directly porting the OPNET TCP Proxy model into operational hardware, MBMMR (AN/PSC-5) radios (Figure 5).  In this environment, the radio provided a representative Link-184 functionality. This effort turned out to be relatively straight forward since the TCP Proxy was designed to be contained within a single function.  In the OPNET model, the proxy was attached to the Link-184 process via two statistic wires that provided the proxy with flow control information. This functionality was replicated by using the radio’s predefined data flow interface, with only the addition of a handful of new code.Figure 5.   TCP Proxy Ported onto Target Hardware for Insertion into a Hardware-in-the-Loop Simulation. Due to the flexibility of the communications models, we were able to successfully verify and demonstrate the performance of the designed protocols in multiple representations of the satellite system.  In addition, since the same model was used in all three instances, we were able to gather timing parameters during the prototype hardware and Hardware-in-the-Loop testing and feed them back into the original OPNET model for further refinement of the TCP Proxy’s performance.4. ConclusionThe Raytheon Communications and Networking Modeling and Simulation Center of Excellence has developed a methodology for using modeling and simulation throughout the entire system life cycle in an efficient and effective manner.  This methodology has been successfully implemented and demonstrated on a major satellite program in order to study the performance of the protocol architecture and to minimize the risk in developing SCA compliant protocols.  With continued work and refinement of the methodology, it is our desire to apply this process to future programs as a standard for performing communications and networking modeling and simulation.5. AcknowledgementsThe authors would like to thank Dan Levis, Obie Johnson, George Vardakas, and Tom Stayonoff of Raytheon for providing us the opportunity to apply this modeling and simulation process in the capture of the satellite program.6. References[1]	G. Wolff, S. Johnson: “Closing the Gap: Transforming OPNET models into Software Communication Architecture (SCA) Compliant Protocols.”  OPNETWorks 2004, August 2004.[2]	D. Evans, T. Stayonoff: “Bridging the Gap Between Virtual Environments and Real-World Systems – Integrating OPNET Based Models of Communications Protocols and Networking Architectures Into Hardware-in-the-Loop and Man-in-the-Loop Simulations.”  OPNETWorks 2003, August 2003.Author BiographiesDEANNA EVANS is a Senior Systems Engineer with the Raytheon Communications and Networking Modeling and Simulation Center of Excellence in Fullerton, CA.  She has over 8 years experience in Software Engineering and Modeling and Simulation, including requirements analysis, virtual prototyping, 3-D visualizations, verification and validation, model development, test and evaluation, and distributed simulation.SHERIE JOHNSON is a Sr. Principal Systems Engineer at Raytheon Company, Network Centric Systems Operations, Fullerton, CA.  She has over 15 years of experience in military communications and networking systems including technical architecture design and embedded communications and networking software development for LOS and SATCOM RF systems.TOM STAYONOFF is a Principal Systems Engineer at Raytheon Company, Network Centric Systems Operations, Fullerton CA.  He has over 20 years of experience in communications and networking systems, architecture development and analysis, and operations and maintenance training on COMSEC, RADAR, SONAR and fire control systems.  He currently leads the Communications and Networking Modeling and Simulation Center of Excellence.GREG WOLFF is a Software Engineer with the Raytheon Communications and Networking Modeling and Simulation Center of Excellence in Fullerton, CA.  He has over 1 year of experience in Modeling and Simulation, including virtual prototyping, 3-D visualizations, and distributed simulation.