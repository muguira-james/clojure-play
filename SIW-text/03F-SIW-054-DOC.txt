Implementing SMART in the US Army through Simulation Support PlansMichael R. Hieb, Ph.D.Alion Science & Technology1111 Jefferson Davis Highway Suite 503-ECrystal City, VA   22202(703) 604-0261Michael.Hieb@hqda.army.milJames WallaceAlion Science & Technology1111 Jefferson Davis Highway Suite 503-ECrystal City, VA   22202 (703) 604-0262James.Wallace@hqda.army.milKeywords: Simulation and Modeling for Acquisition, Requirements and Training (SMART), SMART Planning Guidelines (SPG), Simulation Support Plan (SSP), Simulation Planning, Authoritative System Representation, Future Combat Systems (FCS)ABSTRACT: Simulation support planning is a key tenant of the Army's Simulation and Modeling for Acquisition, Requirements and Training (SMART) concept.  A Simulation Support Plan (SSP) documents the planning process and describes how models and simulations will be used throughout the lifecycle of a system.  The SSP is an appendix to an acquisition program's Capabilities Document.  Simulation planning is a continuous process and the SSP will evolve throughout the system‚Äôs acquisition and development.  The Army established a Simulation Support Tiger Team in June of 2002 to survey the current guidelines for SMART implementation and SSP development.  The Simulation Support Tiger Team produced a draft Department of the Army Pamphlet specifying instructions on how to develop an SSP.  The Simulation Support Tiger Team also revised the SMART Planning Guidelines that address implementing the SMART concept and describe the simulation planning process.There is now a body of knowledge concerning SSPs that can be shared with the Simulation Interoperability Standards Organization (SISO) community.  This is very relevant to all of the services and their acquisition processes for both simulation based acquisition and the use of models and simulations throughout a system's lifecycle.  This paper describes the current state of the art of Simulation Support Plans and reviews the revised Army guidance for SSPs developed by the Simulation Support Tiger Team.  The current SSP format is described and new concepts, such as the Authoritative System Representation, are explained and put in an SSP context.  Several new initiatives to facilitate the development and use of SSPs are a Lessons Learned project and a Contact Team. Recommendations are made regarding SISO standardization and development of best practices in this area.1.  Introduction1.1  What is SMART?Simulation and Modeling for Acquisition, Requirements and Training (SMART) is a change in Army business practices, through the exploitation of modeling and simulation (M&S) and other information age technologies, to ensure collaboration and synchronization of effort across the total Army systems lifecycle [7].SMART has its roots in Simulation Based Acquisition (SBA), a Department of Defense (DoD) initiative to revolutionize the DoD acquisition process through collaborative employment of simulation technology across acquisition phases and programs [19, 20].  SMART extends SBA beyond the acquisition of a new system, utilizing M&S tools and technologies to assess advanced concepts, interoperability, operational readiness and total lifecycle support.  SMART also places more emphasis on bridging organizational boundaries between the requirements, acquisition, test, training and operational communities.  The SMART concept applies to traditional systems developments, as well as assessment and transition of advance technologies to operational capabilities, development of tactics and doctrine, experimentation and exercises. Army Model and Simulation Office (AMSO) has sponsored five annual Conferences to publicize SMART, educate the workforce, showcase SMART enabling technologies, and share lessons learned.  A web-based tutorial, SMART 101, is available on the AMSO SMART website,  HYPERLINK "http://www.amso.army.mil/smart/tutorials/" http://www.amso.army.mil/smart/tutorials/.1.2  SMART Goals and ObjectivesThe overarching goal of SMART is to reduce the time and cost of providing improved capabilities to our warfighters.  A principal tenet of SMART is to more closely integrate the efforts of the requirements, acquisition, and training communities through the use of modeling and simulation [6]. Emerging information-age technologies are revolutionizing our capabilities to collaborate among all stakeholders using data descriptions, digital representations, and virtual prototypes to improve understanding of required capabilities, shorten procurement time, reduce procurement and sustainment costs, and ultimately, reduce total lifecycle cost.  SMART prescribes collaboration among these communities beginning with simulation support planning activities early in the system lifecycle. The SMART concept advocates the use of advanced technologies in concert with M&S to enable transformation ‚Äì through improved understanding of operational requirements, collaborative analyses of emerging technologies, and cross-domain participation in experiments and exercises.1.3  Status of SMART in the US ArmyThe Army adopted the SMART concept in 1997.  Since SMART has its genesis in SBA, it is not surprising that initial SMART efforts have focused on the Army acquisition process.  The Army‚Äôs flagship SMART program is the Future Combat System (FCS), an acquisition program that recently entered the System Development and Demonstration acquisition phase following its Milestone B review. The SMART concept is maturing and is being implemented in Army programs.  The most visible evidence that this is happening is the increasing number of Army programs submitting Simulation Support Plans (SSPs) during the requirements approval process.  The Army is also taking steps to institutionalize the SMART concept, and the underlying requirement for simulation support planning, in official Army policy [14].The Army Model and Simulation Executive Council (AMSEC) is the principal body that adjudicates issues governing all M&S activities in the Army and serves as the proponent for the SMART concept.AMSO serves as AMSEC‚Äôs executive agent for SMART and publishes the SMART Planning Guidelines (SPG) and publishes and implements the SMART Execution Plan.  AMSO participates in the Army requirements-to-solutions process, validating appropriate simulation support planning as documented in Simulation Support Plans (SSPs) [5].1.4  Paper RoadmapThe rest of this paper discusses Army efforts to institutionalize (i.e. formalize an Army process) and implement SMART.  Section 2 focuses on executing SMART at the program level and identifies the benefits that can be derived from early and continuous simulation support planning. Section 3 describes current Army simulation support planning policy and recent initiatives to update this policy.  Section 4 describes several new initiatives to facilitate the use of SMART and SSPs throughout the Army.  Section 5 concludes with recommendations to the SISO community.2.  Executing SMARTIn the broadest sense, executing SMART means applying M&S to identify and address program issues and risks.  Senior decision makers often rely on M&S results to assess real or potential capabilities.  They may also rely on M&S to decide whether or not a program will continue to be supported and funded. Requirements, Acquisition, Testing, Training and Operational communities may rely on M&S to support domain-specific planning for program acquisition activities and lifecycle support SMART involves much more than just the use of M&S.  A key SMART tenet is to link M&S capabilities with other information-age technologies in an Advanced Collaborative Environment (ACE).  Within the context of SMART, we refer to the requirements, acquisition and training M&S communities as ‚Äúdomains‚Äù.  The primary function of the ACE is to enable collaboration among these domains across all phases of the acquisition process.  Early and continuous collaboration will lead to more credible total lifecycle costing and enable shortened acquisition cycles by ‚Äúgetting it right‚Äù before hardware production begins [4].The need to incorporate simulation support in systems acquisitions is reiterated in recently updated Chairman of the Joint Chiefs of Staff (CJCS) policy, which states, ‚ÄúThe process to identify capability gaps and potential solutions must be supported by a robust analytical process which incorporates innovative practices--including best commercial practices, collaborative environments, modeling and simulation and electronic business solutions‚Äù [9]. As asserted earlier in this paper, simulation support planning must be documented so that simulation efforts will be collaboratively understood and effectively applied across the system lifecycle.  Partly because it is the product of a collaborative effort, the SSP helps to bridge the gap between the Requirements, Acquisition, Testing, Training and Operational communities.  2.1  SMART at the Program LevelInitially, a U.S. Army Training and Doctrine Command (TRADOC) Integrated Concept Team (ICT), led by the combat developer proponent, may address the application of M&S across the system lifecycle.  ‚ÄúThe ICT produces the initial plan for management of simulations in support of simulation and modeling for acquisition, requirements, and training (SMART) goals‚Äù [24].  The ICT will staff this plan through a Requirements Integration Working Group, co-chaired by TRADOC and AMSO, which will staff the initial SSP through M&S Domain Managers (for requirements, acquisition and training). When the acquisition program is approved, the ICT will provide this initial SSP to the assigned Program Manager (PM).  Ultimately, it is the PM who must determine how he or she will implement SMART within an acquisition program.  They must plan early for M&S support to achieve the maximum benefits associated with the SMART concept.  Their M&S strategy should support and be interconnected with the Acquisition and Test and Evaluation (T&E) strategies, and should support the development of system-related tactics, training and doctrine.   These strategies are documented in plans that cross reference each other and are vetted within and across the acquisition, requirements, test, training and operational communities to ensure maximum collaboration and support of the overall effort.In an SSP, the PM describes how models and simulations will be used to support the current acquisition phase and the lifecycle of the system.  The M&S strategy may evolve as the program and the related system mature and will include the history of M&S use in past phases of the program and system lifecycle.  An M&S schedule shall be included and its relationship to the acquisition program schedule will be clearly described and illustrated.  The M&S Strategy should specifically address how M&S are used to identify, analyze and mitigate program-related risks and address program needs [4].2.2  Benefits of Simulation Planning to ProgramsSimulation support planning should begin long before an acquisition program is actually established since models and simulations are almost always employed in pre-program analysis efforts.  M&S are used to explore proposed new requirements and capabilities and to support early assessments of whether a materiel solution is required, or whether changes in tactics or procedures or a modification of an existing system can provide the desired capability.If it is determined that a new capability requires a materiel solution, then implementing SMART can accelerate the fielding of that solution.  Models and simulations can support technology assessments, systems integration efforts, and analyses of interoperability and operational requirements.  Once a program is established, SMART planning means developing a simulation support strategy that is an interconnected part of the overall system acquisition strategy.Cross-domain simulation support planning will ensure that all stakeholders have thought through the benefits, costs, opportunities, and schedule considerations associated with the use of M&S over a system‚Äôs lifecycle.  Conducting SMART planning as a collaborative effort will maximize opportunities to reuse models and simulations throughout a given systems‚Äô lifecycle and across acquisition programs, with potentially significant schedule and cost savings for programs and the Army.   Where applicable, links are drawn between related developmental or current systems in the Army inventory to show how M&S can be leveraged and how M&S can be reused not only within a specific program but also among different programs [4].2.3  A Lifecycle Approach to Simulation PlanningThe use of M&S is a key element of Department of Defense (DoD) and Department of the Army (DA) acquisition strategies.  The benefits of an M&S-based acquisition process are recognized in the latest DoD acquisition instruction DoDI 5000.2, which states, ‚ÄúThe PM shall plan for M&S throughout the acquisition lifecycle‚Äù  [17].Figure 1 shows the Acquisition Lifecycle as described in DoDI 5000.2. The Program Milestones (A, B, C) are depicted in triangles at the top of the figure, along with the Initial Operational Capability (IOC) and the Full Operational Capability (FOC).  Significant program events are shown as yellow diamonds, including the Concept Decision, the Design Readiness Review and the Full Rate Production (FRP) Decision Review.  This DoD philosophy is mirrored in AR 70-1, Army Acquisition Policy, which states, ‚ÄúModeling and Simulation (M&S) planning is part of development of acquisition strategies in support of system development‚Äù [10].Figure 2:  Required Documents for Defense Acquisition LifecycleThe draft new DA Pamphlet is even more specific when it states, ‚ÄúPlanning for M&S in an interoperable environment throughout the weapon-systems‚Äô development cycle is key to successful implementation of SMART‚Äù [4].The relationship of Capabilities documents and SSPs to the Acquisition Cycle shown is illustrated in Figure 2. An initial SSP is developed after Milestone A during the Technology Development phase.  The SSP is submitted for review at Milestone B with the Capabilities Development Document (CDD) and will be revised at regularly thereafter.  The CDD replaces the Operational Requirements Document (ORD) used previously.  A revised SSP will accompany the Capabilities Production Document (CPD) at Milestone C.Figure 1:  The Defense Acquisition Lifecycle2.4 	Documenting Simulation Planning with Simulation Support PlansThe importance of documenting simulation support planning cannot be overstated.  The process of creating a SSP will help the ICT or PM to understand what cost and schedule and technological benefits can be derived from utilizing M&S in the program.  The SSP is a management tool that a PM uses to coordinate simulation support efforts among and get ‚Äúbuy-in‚Äù from program and system stakeholders.TRADOC Pam 71-9 states, ‚ÄúA SSP is a ‚Äòroadmap‚Äô that lays out how M&S tools support overall development of a concept or a system.  The SSP depicts how and when M&S tools are integrated, utilized and transitioned in the course of concept exploration and system development‚Äù [24]. Simulation support planning has to be documented to support collaboration and execution of the simulation support strategy and related activities.The SSP is a living document ‚Äì this means that its content will change as a system matures.  The initial SSP provides information about M&S used in support of the requirements determination process as well as the early simulation support concept for the proposed program.  The SSP for Milestone B and beyond provides information about ongoing program simulation support efforts as well as the roadmap for future M&S activities and how they support program capabilities.  A good SSP describes past, present and future M&S efforts, discusses the inter-relationships of these efforts, and relates them to the program‚Äôs needs.  The SSP should include a record of M&S used in development of requirements, Analysis of Alternatives (AoA), lifecycle cost estimation, and other studies.  The Combat Developer also uses the SSP to discuss and define authoritative representations of the system being acquired for use in force-on-force M&S, such as OneSAF (Semi-Automated Forces) and COMBAT XXI (Combined Arms Analysis Tool for the XXI Century).  The combat developer should coordinate with the materiel developer in transitioning the preliminary M&S concept and approach for the research, development and acquisition of a future system [4].As a planning tool, the SSP will outline the resources needed to manage and support the use of M&S across the lifecycle of the program.  The SSP accurately records M&S activities undertaken in support of materiel requirements determination and program acquisition.  The SSP must also discuss coordination with other organizations and planned future M&S activities.  Communicating and documenting the thought processes inherent in simulation support planning are critical SMART activities.  This rationale will be discussed as a part of the crosswalk that links program capabilities with planned use of specific models and simulations.  The SSP should also demonstrate the payoff of applying that M&S to the acquisition process (for example, cost avoidance, time savings, and risk reduction).A crosswalk between a Capabilities Document (CDD or CPD) and M&S applications is the foundation of a good SSP.  The crosswalk should track documented system capabilities at a level of detail sufficient to indicate that there is a workable plan, with known M&S (or with M&S that must be developed) that can be applied to address key program requirements and issues [4].  The crosswalk should address the Programs Key Performance Parameters (KPPs).  An excellent example of how a program (Aerial Common Sensor) used M&S to support analysis of their KPPs is found in [18].The purpose of the CD-M&S crosswalk is to assist all stakeholders in accomplishing the following:Identify, validate, and program M&S investments;Identify models used and upgrades needed as well as form the basis for M&S S&T investments;Ensure adherence to best practices and approved standards (or help to identify places where new standards would be of use);Assist with cross domain coordination;Encourage peer review and incorporation of lessons learned;Ensure adequate Verification, Validation, and Accreditation (VV&A); andIdentify and eliminate duplication of effort. 3.  Army Policy on Simulation Support PlansArmy policy on simulation support planning supports Army acquisition policy, which in turn supports Office of the Secretary of Defense (OSD) and CJCS acquisition policies.  The need to incorporate models and simulations into Army acquisition processes and to document simulation support planning is contained in several Army policy and guidance documents.  A recent collaborative effort led by AMSO produced recommended revisions to Army policy and guidance on SMART, simulation support planning and SSPs.3.1  Policy OverviewThe need to document simulation support planning is clearly identified in DA Pamphlet 70-3, Research, Development, and Acquisition ‚Äì Army Acquisition Procedures, which states, ‚ÄúThe PM articulates his M&S strategy via the Simulation Support Plan (SSP)‚Ä¶‚Äù [16]The current version of AR 5-11 requires that a simulation support plan be developed for major Army acquisition programs [14].  TRADOC Pamphlet 71-9, Force Development Requirements Determination, also identifies the need to document simulation planning in SSPs [24].  However, confusion still existed concerning: 1) which programs were actually required to develop SSPs; 2) what was supposed to be in an SSP; and 3) how did the SSP fit in the Army Requirements and Acquisition processes.Many practitioners in the Army Requirements and Acquisition communities desired more specific policy on SSPs and updated guidance on conducting and managing simulation support planning efforts.  The Director of AMSO responded by establishing a Simulation Support Tiger Team [21] in June 2002, to: Figure 3.  Hierarchy of Army SMART GuidanceCapture simulation support planning and SSP issues;Revise the SMART Planning Guidelines; and Develop a long-term Army strategy for simulation planning and SSP guidance and policy.The Tiger Team was chartered for one year, July 2002 - June 2003 (subsequently extended to August 2003).  Its members were a cross-section of Army M&S, requirements, acquisition, test and evaluation and training professionals.   After several months of analyzing current documented policy and guidance, the Tiger Team recommended a policy and guidance hierarchy that is illustrated in Figure 3.  The hierarchy consists of an Army Regulation (AR) that refers to an Army Pamphlet (DA Pam), which refers to an Army Guideline.3.2  AR 5-11AR 5-11 provides Army M&S policy on the management of Army models and simulations.   The Tiger Team proposed revising AR 5-11 to: introduce the SMART concept andupdate the requirement for SSPs.  Specifically, the draft revision of AR 5-11 states that, ‚ÄúSSPs will be developed for all Acquisition Category (ACAT) I, ACAT II and selected non-major programs to document the simulation support planning process that is integral to implementing the SMART concept.‚Äù  More specific guidelines are found in the draft new DA Pam 5-xx.  The other important reason for revising AR 5-11 is to introduce the proposed new DA Pamphlet on Simulation Support Planning and Plans.3.3  New DA Pamphlet 5-xxFigure 4:  SSP FormatDraft DA Pamphlet 5-xx, Simulation Support Planning and Plans, was developed to provide formal Army guidance on planning simulation support for the lifecycle of a system and documenting that planning in a SPP [4].  Generally speaking, this guidance consists of:Implementing the policy in AR 5-11 (i.e., implementing SMART for systems);Planning simulation support for a system‚Äôs lifecycle; and Documenting simulation support planning in an SSP.DA Pamphlet 5-xx contains more detailed guidance than AR 5-11 on the requirement for SSPs.  Specifically, it states that the following Army programs must have SSPs:ACAT I and ACAT II programs, andPrograms on the Director, Operational Test and Evaluation (DOT&E) Test and Evaluation Oversight List.DA Pam 5-xx identifies the following additional categories of Army programs that may require an SSP:ACAT III Training Aids, Devices, Simulators and Simulations (TADSS), M&S Systems, and Automated Information Systems;Army-led Advanced Concept Technology Demonstrations (ACTDs) that utilize M&S; andScience and Technology Objectives (STOs).Another important concept formalized in the new pamphlet is that of ‚ÄúSSP Proponent‚Äù.  The SSP Proponent is responsible for developing, maintaining, implementing and updating the SSP.¬†¬† The combat developer proponent is considered to be the SSP Proponent during the pre-systems acquisition phase of the acquisition process.¬† For new systems that require an SSP, the combat developer proponent leads the ICT that is responsible for developing the initial SSP in accordance with TRADOC Pamphlet 71-9, Force Development Requirements Determination [24].  The ICT will provide the SSP to the Program Manager (PM) when one is appointed, at which time the PM becomes the SSP Proponent.¬† The PM will ensure that the SSP is consistent with the Program Acquisition Strategy, Test and Evaluation Master Plan (TEMP) and System Training Plan (STRAP) [4].The new pamphlet prescribes a standard format, seen in Figure 4, for SSPs.  There are several good reasons for prescribing a standard SSP format.  A standard format ensures that important issues and concerns are addressed.  A standard format facilitates coordination of SSPs among all stakeholders because subject matter experts know where to focus their efforts when reviewing a given plan.  It can also be asserted that a standard format with supporting guidance eases the burden of creating the plan.Most programs will need to provide information for each section of the SSP format, although the information may be more general and incomplete in the early phases of a program.  This is understandable since the SSP is a living document that will evolve as the program matures, M&S trade-off decisions are made, and simulation support planning is updated.  3.4  Simulation Planning GuidelinesThe Simulation Support Tiger Team also collaborated on a major revision of the SMART Planning Guidelines (SPG), which provides detailed guidance on SMART and SSPs [7].  TRADOC ICTs testers and evaluators, PMs, and other stakeholders can reference the SPG to learn how to implement SMART.  The information contained in the SPG is intended to:help ICTs, PMs and other stakeholders understand SMART, describe how M&S tools support overall development of a concept or system, and offer lessons learned, insights, and suggestions for using M&S.The SPG also includes references, examples and ‚Äúlessons learned‚Äù information on planning and executing cross-domain simulation support throughout a system‚Äôs lifecycle.  Most importantly, the SPG illustrates how to implement SMART within the context of official DoD and Department of the Army acquisition guidance, and CJCS and Department of the Army capabilities validation processes.  AMSO is responsible for developing and maintaining the SPG on the AMSO website,  HYPERLINK "http://www.amso.army.mil" http://www.amso.army.mil.4.  Increasing Utilization of the Simulation Support PlanCurrently, all programs are required to have SSPs prior to Milestone B.  Program Teams spend an average of six months writing SSPs [8].  These SSPs are updated frequently and the content varies between documenting lists of models to detailed lifecycle analysis of M&S tools.While SSPs are required, there are still many areas where simulation support planning could be enhanced.  Boerjan has performed a comprehensive analysis in his PhD Thesis and lists several areas, such as Training, Lessons Learned, Help Desks and Model Repositories as key enablers [8].  Lee also identifies the need to ‚Äúcapture and inculcate best practices and lessons learned into Army SSP policy and guidance‚Äù [21].AMSO has created an initiative to acquire and disseminate Lessons Learned (LL) on how to implement SMART.  Three Army Programs have already been selected.  These programs are: Aerial Common Sensor (ACS); Advanced Threat Infrared Countermeasures/Common Missile Warning System (ATIRCMS/CMWS); and the Joint Common Missile (JCM).  In subsection 4.2 a brief summary of the ACS Lessons Learned are presented as an example of what can be developed.  The ATIRCMS/CMWS and JCM Lessons Learned, at the time this paper was written, are still in the process of being defined.AMSO is also implementing a ‚ÄúContact Team‚Äù to provide expertise on SMART to programs on an as-needed basis to help programs implement.4.1  Formulating a Lessons Learned Process Since many programs are now writing or will write SSPs there is an opportunity to start a Lessons Learned initiative that will assist programs as they execute SMART policies.  AMSO has started such an initiative to document what has worked (and has not) and publicize these lessons to the Army Program community.Figure 5 illustrates the Lessons Learned process. The process starts with the nomination of a relevant program that has been identified as a good candidate for documenting lessons learned.  The Candidate Program is contacted and asked to provide as much documentation as possible on how it has used Modeling and Simulation.  This includes its SSP, STRAP, TEMP and other program documents as well as a description of the models the program has developed.  After reviewing the documentation and conducting preliminary interviews, a meeting is arranged with the Lessons Learned Team and the Program Office.  A multi-disciplinary team led by AMSO, with the Program Executive Office for Simulation, Training, & Instrumentation (PEO STRI) and TRADOC, will discuss how the program developed its SSP and it‚Äôs experiences, both good and bad, during that effort.  After the meeting a Lessons Learned Report will be developed and coordinated with the Program Office.This process will generate a Lessons Learned ‚ÄúCase Study‚Äù that contains all relevant information about a Program‚Äôs use of SMART along with individual ‚Äúfindings‚Äù documenting particular issues. The findings will be stored in a database so trend analysis can be performed after a sufficient number of case studies have been performed. Lessons Learned Case Studies will be posted on the AMSO SMART Website and be widely distributed.  Lessons Learned Summaries will be posted on Army Knowledge Online (AKO), the Center for Army Lessons Learned (CALL) and presented at SMART/SBA forums/conferences.Figure 5:  Process for Developing Lessons LearnedLessons Learned from the ACS ProgramThe ACS program has performed innovative work in the area of SMART, including using M&S for source selection.  The program is currently in the Component Advanced Development/Technology Development phase with two competing contractor teams preparing for Milestone B in August 2003.  ACS down-selected from three contractors to two in 2002 and will make their final source selection in Jan/Feb 2004.ACS is a combination and evolution of two existing systems:  Guardrail and Airborne Reconnaissance Low.  The concept is to have a small business class jet as a platform for many different types of sensors including: Electro-Optical (EO), Infrared (IR), Communications Intelligence (COMINT), Electronic Intelligence (ELINT), Synthetic Aperture Radar (SAR), and Moving Target Indicator (MTI) [1].The following is a summary of the findings developed from the ACS program.  For a detailed description and discussion, refer to the ACS SMART Lessons Learned Case Study [3].ACS-LL-1) Use Key Performance Parameters and higher risk areas to Focus M&S Effort;ACS-LL-2) Use Incentives to Foster Collaboration during Down-select ‚Äì Industry as Partners;ACS-LL-3) Make Explicit Tradeoffs between Operational and Engineering Models;ACS-LL-4) Provide Simulation Environment to Contractors;ACS-LL-5) Develop Data Analysis Tools as Simulation Environment is Developed;ACS-LL-6) Use Calibration Scenarios to assist Model Integration; andACS-LL-7) Secure Collaborative Environments4.3  Contact TeamAlong with a SMART Lessons Learned Initiative, AMSO is setting up a ‚ÄúContact Team‚Äù to assist programs in executing SMART and developing Simulation Support Plans. The core team consists of personnel from AMSO, PEO STRI and TRADOC, with additional individuals experienced in performing Simulation Support Planning and M&S experts.  The Contact Team is oriented towards programs in the initial stages of formulating their M&S Strategy.5.  ConclusionsThe Army is in the process of ‚Äúoperationalizing SMART‚Äù through various mechanisms and procedures.  SSPs have been used as instruments of SMART and are increasingly valuable to both programs and M&S agencies.  It is now possible to identify areas that M&S has aided programs as well as point out some obstacles in the use of M&S.While the Army is still in the process of ‚Äúinstitutionalizing‚Äù SSPs as a way to do business, a similar mechanism may be of value to other Services [2, 21].  It is very challenging to go from the SMART concept to seeing effects in actual programs, but the formulation and use of SSPs has helped the Army make progress in this area.  The Army experience leads to a recommendation that SISO investigate developing standard practices for Simulation Support Planning, to enable a wider range of programs and organizations to utilize M&S.6.  AcknowledgementsThe authors would like to express their appreciation to the members of the Simulation Support Tiger Team. Much of this paper directly follows from their excellent work on the Army Pamphlet for Simulation Support Planning and Plans, and the SMART Planning Guidelines.  The members of the Tiger Team are: Charlie Abel, Cheryl Brown, Nancy Bucher, Major Troy Barnes, Kevin Burke, Scott Callender, Hugh Dempsey, Bruce Donlin, Dr. Richard Dunbar, August Fucci, John Haug, Ruth Johnson, Betty Jones, Anthony Lee, William Murphy, Laura Pegher, Colonel Steven Rust, Ken Summerford, David Thomen, Don Timian, Mike Truelove, and Angela Winter. Many other individuals assisted the Tiger Team and their contributions were both significant and appreciated. The following individuals have reviewed this paper and improved it with their comments.  The authors thank Don Timian, Joe Mills, Becky Shell, Ruth Johnson, Dr. Richard Dunbar, August Fucci, Tony Lee and Angela Winter for their insightful recommendations.Both of the authors acknowledge the support of the Army Modeling and Simulation Office.7.  References [Note: Many of these references are available from the AMSO SMART website at   HYPERLINK "http://www.amso.army.mil" http://www.amso.army.mil.][1]	Aerial Common Sensor Program: ‚ÄúAerial Common Sensor Simulation Support Plan‚Äù, 23 April 2001.[2]	Air Force: ‚ÄúModeling and Simulation Support to Acquisition‚Äù, Air Force Instruction 16-1002, 1 June 2000.[3]	AMSO: ‚ÄúAerial Common Sensor SMART Lessons Learned‚Äù, August 2003.[4]	AMSO: ‚ÄúSimulation Support Planning and Plans‚Äù, Army Pamphlet 5-xx (Draft), July 2003.[5]	AMSO: ‚ÄúPosition on the Simulation Support Plan (SSP) Requirement‚Äù, AMSO Memorandum, 18 September 2002.[6]	AMSO: ‚ÄúSMART Execution Plan‚Äù, 6 November 2000.[7]	AMSO: ‚ÄúPlanning Guidelines for SMART‚Äù, 15 September 2000.[8]	Boerjan, R.A.: ‚ÄúApplying an Information System Framework to the Army‚Äôs Simulation Support Plan Process‚Äù, PhD Thesis, University of Central Florida, Orlando Florida, 2003.[9]	Chairman of the Joint Chiefs of Staff: ‚ÄúJoint Capabilities Integration and Development System‚Äù, CJCSI 3170.01C, 24 June 2003.[10]	Department of the Army:, ‚ÄúArmy Acquisition Policy‚Äù, Army Regulation 70-1 (Draft), 11 July 2003. [10]	Department of the Army - Headquarters: ‚ÄúArmy Requirements Validation and Approval Standard Operating Procedures‚Äù, April 2002.[12]	Department of the Army: ‚ÄúApproval of Army Warfighting Requirements‚Äù, Department of the Army Memorandum, 19 March 2001. [13]	Department of the Army: ‚ÄúSimulation Based Acquisition Program, ‚Äù U.S. Army Agency Audit, 8 November 2000.[14]	Department of the Army: ‚ÄúManagement of Army Models and Simulations‚Äù, Army Regulation 5-11, 1997.[15]	Department of the Army ‚Äì ASA(RDA): ‚ÄúModeling and Simulation in Support of the Army Acquisition Process,‚Äù Department of the Army Memorandum, 20 September, 1996. [16]	Department of the Army: ‚ÄúResearch, Development, and Acquisition ‚Äì Army Acquisition Procedures‚Äù, DA Pamphlet 70-3.[17]	Department of Defense: DoDI 5000.2, ‚ÄúOperation of the Defense Acquisition System‚Äù, May 12, 2003.[18]	Eiserman, G.: ‚ÄúThe Use of Analysis Requirements in the Development of the ACS Concept Exploration Federation‚Äù 01F-SIW-064, Simulation Interoperability Workshop, Orlando Florida, September 2001.[19]	Frost, R. and Thomen, D.:  ‚ÄúSimulation Based Acquisition, The Road Map,‚Äù 99S-SIW-147, Simulation Interoperability Workshop, Orlando Florida, 1999. [20]	Johnson, M.V., McKeon, M.F.,  Szanto, T.R.,  ‚ÄúExpanding the SBA Envelope,‚Äù Simulation Based Acquisition:  A New Approach, Defense Systems Management College Press, December 1998.[21]	Lee, T.: ‚ÄúSimulation Support Plans in the US Army:  Increasing the utility of SSP's in support of SMART‚Äù, 02F-SIW-066, Simulation Interoperability Workshop, Orlando Florida, September 2002.[22]	Perry, R.B., Kissell, A.H., Bates, C.F.: ‚ÄúImplementing SMART within PEO Tactical Missiles,‚Äù Army AL&T Magazine, HQDA PB-10-01-03, May-June 2001.[23]	TRADOC Headquarters: ‚ÄúDevelopment and Approval of Warfighting Requirements‚Äù, Headquarters Memorandum, 31 May 2002.[24]	TRADOC: ‚ÄúForce Development Requirements‚Äù (Draft), TRADOC Pamphlet 71-9, November 2001.Author BiographiesMICHAEL HIEB is an Assistant Vice President of Alion Science and Technology, as well as a core architect of the Army Simulation to C4I Interoperability Overarching Integrated Product Team (SIMCI OIPT) and was the technical supervisor of the Defense Modeling and Simulation Office (DMSO) Modular Reconfigurable C4I Interface (MRCI) project while at SAIC.  He received his PhD in Information Technology at George Mason University (GMU) in 1996 and performed his doctoral research at the Center for Excellence in Command, Control, Communications and Intelligence at GMU.  He has published over 50 papers in the areas of learning agents, knowledge acquisition, interface technology and multistrategy learning.  Previously, he worked as a Nuclear Engineer for General Electric. Dr. Hieb received his Bachelor of Science degree in Nuclear Engineering from the University of California in Santa Barbara and received his Masters of Science degree in Engineering Management from George Washington University.JAMES WALLACE is a Senior Military Analyst with Alion Science and Technology. His active duty military career included 6 years as a U.S. Navy electronics technician on ballistic missile submarines and 14 years as a computer systems acquisition officer in the U.S. Air Force.  While in the Air Force he worked with weather data processing, space defense and joint surveillance systems.  For the past two-and-a-half years he has worked as a defense contractor, supporting the Office of the Director, Operational Test and Evaluation and the Army Model and Simulation Office. He received his Bachelor of Arts degree in Computer Science from of The University of Texas at Austin and his Master of Science degree in Computer Systems from the Air Force Institute of Technology.Presented at the Fall Simulation Interoperability Workshop, Orlando Florida, September 16, 2003Page  PAGE 1 of  NUMPAGES 11 