OPFOR Perception of the Battlespace (OPB):Challenges for Intelligence Community Support to Military Training SimulationsBrian J. DubasGary L. WaagBooz•Allen and HamiltonAllen Building8283 Greensboro DriveMcLean, VA  22102703-902-6717, 703-902-7166 HYPERLINK mailto:dubas_brian@bah.com dubas_brian@bah.com HYPERLINK mailto:waag_gary@bah.com waag_gary@bah.comChristopher C. WertmanBooz•Allen and Hamilton3190 Fairview Park, Ste. 890Falls Church, VA  22042703-289-5132wertman_chris@bah.comPeter N. StarrModeling and Simulation DivisionDefense Intelligence AgencyWashington, DC  20340-5100202-231-4334AFstapn@dia.osis.govKeywords:FISR, OPFOR, Training, Exercise, Simulation, Intelligence, Surveillance, ReconnaissanceABSTRACT:  With new concepts, such as Dominant Battlespace Awareness and Information Operations, providing challenges to the way we traditionally view warfare, our training tools must adapt.  In terms of computer-assisted exercises, our current approaches severely restrict our ability to respond to these challenges.An example of these challenges is the means by which Opposing Force (OPFOR) role-players in training simulation-based exercises currently perceive the battlespace.  It is common today for such participants to base command decisions, in whole or part, on Ground Truth.  They then take into account the respective training objectives for that exercise, and given their understanding of the particular enemy being represented, act to ensure that the training audience is afforded opportunities to achieve those objectives.  This approach to providing an OPFOR perception of the battlespace will severely restrict, if not prevent, future training simulations, such as the Joint Simulation System (JSIMS), from realistically and accurately training our forces.  Without some representation of the OPFOR assets of intelligence sensors, communications links and communications nodes, and the processes that unite them, it becomes difficult for the training audience to receive realistic feedback from attempts to detect, deceive and disrupt those assets.  Furthermore and much more importantly, with OPFOR maneuver forces fighting from an artificial picture of the battlespace, lessons learned by the training audience can be negative or meaningless. This paper identifies some of the issues related to the OPFOR perception of the battlespace in the context of simulation-based training, presents a high-level conceptual approach for how such a capability might be developed and concludes with a description of related activity to recognize and embrace these issues within training environments, such as the JSIMS Alliance.IntroductionWith the need to train Joint Task Force Commanders, component commanders, and their staffs to perform effectively within the constructs of Joint Vision 2010 (JV2010), simulation centers, their sponsoring organizations and especially the command elements seeking the training experience must rethink the way their Opposing Force (OPFOR) role-players perceive the battlespace.  It is common today for such participants to base command decisions, in whole or part, on Ground Truth.  They then take into account the respective training objectives for that exercise, and given their understanding of the particular enemy being represented, act to ensure that the training audience is afforded opportunities to achieve those objectives.The principles of JV2010 mandate that attrition-based warfare be replaced by Full Spectrum Dominance of which all elements, Dominant Maneuver, Precision Engagement, Focused Logistics and Full-dimensional Protection, will be reliant on the need for Information Superiority.1  The training audience of the future will therefore be heavily involved in the manipulation of the OPFOR information environment, needing to detect its status, deceive it, and/or disrupt it, perhaps simultaneously.  Consequently, training tools must enable the training audience to perceive a realistic response to their actions.The premise of this paper is that the current approach to providing an OPFOR perception of the battlespace will severely restrict, if not prevent, future training simulations, such as the Joint Simulation System (JSIMS), from satisfying this requirement, and therefore will not realistically and accurately train our forces.  Without some representation of the OPFOR assets of intelligence sensors, communications links and nodes, and the processes that unite them, it becomes difficult for the training audience to receive realistic feedback from attempts to detect, deceive and disrupt those assets.  Furthermore, with OPFOR maneuver forces fighting from an artificial picture of the battlespace, lessons learned by the training audience can be negative or meaningless.What this paper will explore is the concern that little attention has historically been given to providing a robust and realistic OPFOR perception of the battlespace, and that for a variety of reasons, this will no longer suffice.  It will also present an approach for rectifying the situation and some initial work conducted by the Defense Intelligence Agency (DIA) to address these issues.Methods of OPFOR ParticipationIn both the current mainstream suite of interacting models, as represented by the Joint Training Confederation (JTC), and in plans for the future JSIMS suite of simulations, significant emphasis has been placed on the level of fidelity and degree of realism with which the training audience's forces and capabilities are represented.  Little attention, however, has been paid to these same issues regarding the OPFOR.  Recognizing that a credible threat must exist against which to fight, typical approaches to addressing OPFOR functionality in these simulations is to use a version of some of the same software that was built for Blue forces, but to "color it Red," by providing data parameter values that reflect the capabilities of the respective OPFOR adversary's systems and processes to an extent agreed upon between the training audience headquarters and the simulation center staffs.  This action may then be supplemented during the actual training event by a variety of techniques that might be referred to as "tempered cheating," which we will discuss in a little more detail below.  These techniques work well enough to provide a gaming atmosphere in which staffs can be stressed in their combat administrative operations, but often fail to provide a credible threat and threat reaction.Overview of Simulation Support to OPFOR OperationsA discussion of OPFOR conduct should contain the caveat that no two simulation centers conduct their opposing force operations in the same way.  Despite the JTC being the standard configuration for staff training at the major training sites, or perhaps because of it, quite a bit of individuality has crept into each center's operations.  The JTC itself is used in a variety of configurations, in great part due to the needs and/or capabilities of the particular theater represented or the training requirements of a given user.  Even the suite of models bound together as the de jure baseline differs from application to application.  During a given exercise at any center, one may find "strap-hangers" or additional simulations tethered to the Aggregate Level Simulation Protocol (ALSP) suite to fit a specific exercise design.  These baselines, primarily in place to directly support the training audience, vary greatly.  It is then easy to assert that if such variance occurs on the Blue side, the OPFOR cannot possibly be in a more stable state.  The concept of "non-standard OPFOR" will appear again in this paper.Prior to the emergence of the ALSP and its implementation within the JTC, training models operated within their unique combat domains and had little or no interaction.  Intelligence, with little exception, was played outside the bounds of the combat models and relied on manual intervention to provide linkages between those models.  The exception, created almost as an afterthought in the 1980s, was collection operations with a heavy land flavor, performed by a module attached to a ground game, collecting ground force information.  Such pairings, the ICM (Intelligence Collection Model) drawing from the GRWSIM (Ground Warfare Simulation) or the BICM (Battlefield Intelligence Collection Model) or JIM (Joint Intelligence Model) reading CBS (Corps Battle Simulation) were originally designed to support army elements, particularly from the Blue perspective.  The latter two intelligence models are in use today working within and around the JTC, and in many cases, providing a large portion of ground intelligence to OPFOR.  (More realistic attempts at the representation of intelligence capabilities have been included in the JTC with TACSIM (Tactical Simulation) and NWARS (National Warfare Simulation), but these have been almost exclusively tools of the friendly forces.)  As has become evident over the years, painting the location, direction and speed, and sometimes the identification of ground combat and combat support units is not a big enough piece of what intelligence is.  Intelligence gathers much more than just identification and positional data on units.  These battlefield observables, which our national, theater and tactical intelligence sensors are built to detect, are a far more rich and robust set than simply position and velocity vectors.  For example, pulse repetition frequencies of radars, thermal signatures of maneuver units and message content of communications are among the many detailed observables in the real world that our intelligence assets are attempting to detect.  Intelligence must also address segments of the battlespace other than just land.  It must incorporate the demanding elements of Information Operations, including among other things, Command & Control Warfare (C2W).  It must account for fusion and analysis.  In order for our training environment to provide a realistic representation of the operational world, our training simulations, to some extent, must account for such factors.  Given the limitations of the current attrition-based simulations, as well as restrictions due to security concerns, the portrayal of such functionality is typically accomplished via supplemental measures."Supplemental" OPFOR OperationsGround TruthGround Truth, or what the computer knows, forms the basis of almost all supplementation efforts for OPFOR intelligence functions.  Really, the other techniques listed below are a subset of Ground Truth.  The theory that powers this technique is that a well-trained intelligence analyst or two can decrement a God's eye view of the battlespace with what they know about an enemy's intelligence capability.  In cases where Ground Truth is available to the OPFOR, the enemy knows all, and must be trusted to disseminate to operational leadership what it is "reasonable" for that leadership to know.  As an example, an OPFOR Intelligence Officer with Ground Truth would know where all of the Blue Force aircraft are located.  Because he is an expert on the intelligence capabilities of the particular force being represented by OPFOR in the particular training activity, and he knows the approximate quality of individual intelligence disciplines and/or the relative ability of that force to successfully fuse information into an accurate picture, he may tell his boss where 30% of the aircraft are located.  In many respects, it would not matter how the OPFOR were to obtain its information because that OPFOR is simply one of the tools used to support a training audience.  Their actions, for the most part, would be guided by an exercise DISTAFF (directing staff) who would ensure training objectives were met.  There would be little sense or need for the OPFOR to receive and act upon real or realistic data.  Figure 2.1 helps show the role of Ground Truth in most major Computer Assisted Exercises (CAXs) today.  As this figure highlights, there is a significant difference between how the Blue training audience and OPFOR separately perceive the battlespace.  The Blue perception is derived largely from a suite of simulations, representing Blue intelligence sensors that have access to Ground Truth.  Next, resulting Blue intelligence products may be modulated by a simulated representation of the Blue intelligence cycle's (described in section 3) impact of lowering quantity, quality and product delivery timeliness.  On the other hand, as described earlier, there is rarely any attempt to represent the OPFOR intelligence sensors and cycle; rather, the OPFOR perception of the battlespace is largely derived from human role player access to Ground Truth. EMBED PowerPoint.Show.8  Figure 2.1Subject Matter ExpertsSubject Matter Experts (SMEs) in OPFOR cells work with Ground Truth to make up reasonable reports about Blue Force activities.  In the paragraph above, the SME is the well-trained intelligence analyst.  He may be an expert on the forces of Botswana or in fact on all of Sub-Saharan Africa.  He is asked to fabricate realistic intelligence capabilities by tempering Ground Truth with his knowledge.  An example of a specific permanent party of SMEs is the World Class OPFOR, an on-site cadre supporting training events at the US Army’s NTC (National Training Center) at Fort Leavenworth, Kansas."White Cell" MeetingsThe White Cell Meeting may be scheduled or ad hoc.  The scheduled version may occur once or twice a day, more or less depending on training objectives and timelines of the training event.  Unscheduled meetings may be necessary to accommodate actions that are deemed critical to drive a particular training objective or sub-objective that is eluding execution during the normal course of the training event.  In either case, the chief of the White Cell will hold a meeting with White Cell participants to gauge how their activities are or are not supporting training objectives or new requirements.  A member of the OPFOR intelligence staff will be present at this meeting.  He is, in fact, a Trusted Agent and will take away what is needed for his commanders to accommodate training objectives.Limitations of Current MethodsTraining for JV2010 Information Operations DemandsThe current methods of providing an OPFOR perception of the battlespace in CAXs are, at best, restrictive in terms of the realism of OPFOR actions and interactions provided to the training audience.  At worst, the methods are flawed.  But they will seem even more flawed in the future when JV2010 demands so much in dimensions we are just beginning to understand.  With the current methods of OPFOR conduct, the enemy's knowledge level is artificial and arbitrary.  It stands to reason that in the real world, while we are trying to gain an "…interactive 'picture' [that] will yield much more accurate assessments of friendly and enemy operations within the area of interest," which we call Dominant Battlespace Awareness, the adversary will be trying to do the same thing.2  How can we train for this if we do not represent an adversary's capabilities in some accurate and meaningful way?  Accordingly, a major assertion of this paper is that in the absence of OPFOR representation, our officer corps cannot be educated in the fundamental tenets of JV2010, which, in turn, underscore the importance of Information Operations (IO).  Combat Development Commands cannot experiment with various tactics and techniques of IO.  Command Staffs cannot be trained in established IO doctrine.  Additionally, without this representation, the Department of Defense (DoD) Intelligence Community will be unable to grow as a full warfare component in joint warfighting doctrine and DoD policy, and will be unable to train the next generation of analysts to fulfill the demands of dynamic JV2010 operational support.Lacking Feedback from Detection, Deception and Disruption of OPFOR Intelligence AssetsAs a subset of the previous section, in order for Blue Forces to succeed in the activities of Detection and especially Deception and Disruption of OPFOR's intelligence assets and capability, some manner of intelligence capability must exist or be represented to the extent that the effects of Detection, Deception and Disruption can be measured.  The OPFOR commander cannot be deceived if Blue Forces do not manipulate his perceptual and cognitive (command decision-making) functions.  Manipulation and deceit or disruption of adversary intelligence collection, communications and data processing include a wide array of specific activities, to include:Communications Deception, Computer Network Intrusion, Decoys & Feints, Signature Suppression and Hard Kill and/or Suppression of Sensors, Nodes and Links.  Failure to accommodate activities in these areas is common today but will be more noticeable when JV2010 stresses the importance of Information Superiority.  Currently, there may be OPFOR units associated with an intelligence function against which Blue Forces can collect, and once collected against, those units could be deceived or disrupted.  But if the results, or lack of results, of disruption can be offset by OPFOR's access to Ground Truth, what is the point of that disruption?  If there are no units, which is more likely the case, how does one disrupt or deceive a trusted agent short of locking him out of the exercise facility?  Even that would bear no relation to realism, which we will explore in succeeding sections.Manpower Intensity of Human-in-the-Loop (HITL)Thus far, we have referred to an OPFOR intelligence staff as one or more intelligence analysts with the tools of ground model output and some form or forms of supplementation.  One thing that is missing is scope—this OPFOR intelligence staff may be fifty or more intelligence analysts and administrative assistants.  It may only be one analyst.  There is great variance in the number of staff from center to center, and typically, the number of staff is fixed.  The center that uses one OPFOR intelligence member might need him to perform his job with a significantly higher economy and with a toolkit that is entirely aggregate in its output.  A much larger staff might be able to afford to work with more detail.  Any staff in between would then need information on a continuum, from aggregate to detailed.  Those are the staffs of today.  Tomorrow, leadership is demanding that a reduction be realized in the numbers of support personnel for the conduct of training exercises.  Yet JV2010 requires that much more be taken into account in achieving Information Superiority.  Perhaps a simulation center will have an expert on Sub-Saharan Africa.  Will that center also have an expert on Southwest Asia or Central Europe?  Will that center have to augment its staff for every different adversary?  This quandary can only be solved by more automation, automation that has typically been reserved for Blue Forces, but becoming necessary to support the OPFOR to keep staff requirements from skyrocketing.Negative or Meaningless LessonsOPFOR actions, dependent almost solely upon the unique talents and expertise of the available OPFOR staff, are unique and non-repeatable.  SMEs provide varying OPFOR representation from center to center and event to event.  Lessons that will have no bearing on real life could easily be drawn from a simulation event .  These lessons can put soldiers at risk, and this is considering just the simulation aspects of an event.  Add to that personal bias, experience, interpretation and human error, and the risk of sending a battlestaff out to a real fray with faulty expectations based upon invalid training increases tremendously.Difficulty of ValidationEvery limitation we have brought up so far points to a validation challenge.  Validation in Modeling and Simulation is determining that a model is an accurate representation of the real world for the intended use of that model.3  Certainly one would expect an attached module such as a BICM or JIM, mentioned previously, to oblige validation.  Because the number of scenarios a center could support would be directly related to the amount of available database storage, the issue of determining accurate representation for an enormous set of intended uses, read many potential adversaries, could be achievable.  We mentioned in the last paragraph that current OPFOR actions are not repeatable.  But even though common sense and scientific reasoning suggest that being able to repeat an operation might be fairly important to validation, nowhere in the DoD recommended Verification, Validation and Accreditation Practices Guide is repeatability even mentioned.  Similarly, the guide includes the use of SMEs for validation4—if there is so much leeway, what then is the challenge?Before we address the challenge, a few words may be necessary to describe the intelligence cycle.  The intelligence cycle is the iterative chain of events shown in Figure 3.1.  Joint Publications define the overall cycle as "[t]he steps by which information is converted into intelligence and made available to users."  Planning and Direction includes determining requirements, building a plan to meet those requirements, ordering or requesting collection agencies to conduct collection operations, and then checking up on satisfaction.  Collection, which is the element most people relate to intelligence, is the actual information acquisition and provision of the information to processing or production elements.  Processing is conversion of collected information into something fit for production.  Production is the "[c]onversion of information into intelligence products in support of known or anticipated user requirements."  This is also typically where any analysis and fusion would take place.  Fusion is the combining of multiple intelligence disciplines to form an assessment or opinion.  Finally, Dissemination is getting the finished intelligence product to users.5  It may be helpful to note that the intelligence cycle is not a single, all-inclusive entity.  There can be cycles within cycles, and not all intelligence operations strictly follow the elements of the cycle as they are laid out in this figure.  In fact, some intelligence disciplines, such as Imagery Intelligence, have their own cycles that vary from The intelligence cycle. EMBED PowerPoint.Show.8  Figure 3.16Using our knowledge of the intelligence cycle, we can now go back to the validation challenge.  First, as stated before, these attached modules are reading a land combat model; perhaps later versions are reading a sea combat model or an aircraft database or even an interactive air picture.  That covers collection.  What about the other substantive steps of the cycle:  processing, production with analysis and fusion, and dissemination?  These are all being performed by HITL on the OPFOR side.  As suggested in section 3.3, perhaps a simulation center has an expert on one region; will that center have experts on all regions within its command's AoR (Area of Responsibility)?  And if not, how will different people, even if you could still call them SMEs, be able to perform in similar fashion at different centers supporting different exercises, maybe in the same theater, and maintain any semblance of consistency and standardization?  A possible response to this might be that OPFOR practices during a given exercise are captured and debriefed following a training event.  Because these practices are captured, they can be shared from exercise to exercise and center to center—but is that enough to accommodate validation?A High-Level Approach for ImprovementThe preceding discussion has presented our contention that OPFOR behavior in today's CAX environment lacks validity, and more importantly, will result in our current and future CAX simulation environments failing to provide training in the fundamental tenets of JV2010.   With the hope of rectifying this situation at some time in the near future, we have begun to lay the groundwork for identifying key issues and requirements, and describing a high-level conceptual approach for implementing such a capability.  Our approach may best be introduced with a general discussion of the requirements for OPFOR battlespace perception.Principally, there is a need to represent OPFOR intelligence assets (sensors, links, nodes, and communications) at tailorable levels of fidelity and detail.  This must include the detail necessary, if required for a particular exercise, to represent individual ISR sensors and their attributes.  This need derives from Blue Forces requiring something to detect and disrupt.  In addition, a battlespace perception at a separately tailorable level of detail must be provided to OPFOR.  In contrast, this perception may have to be at the opposite extreme, highly aggregate in nature.The different demands of the above make aggregation and fusion algorithms, which will translate detailed sensor data into aggregate reports, perhaps the most difficult challenge of implementing an OPFOR capability.  But this is necessary in order to present an aggregate view of the battlespace to OPFOR, critical due to typical staff size limitations, while making detailed assets available for Blue operations.Description of DIA-Booz•Allen & Hamilton Conceptual Approach—OverviewThere are then two separate issues that drive the OPFOR conceptual approach.  The first is the need to provide something for Blue to see.  The second is to provide some levels of aggregate battlespace view to OPFOR, supplemented by detailed views in specified AoIs.Issue 1:  Targets for Blue Information OperationsThis approach requires that targets for Blue Information Operations, or specifically C2W, are available.  It will therefore be necessary to provide objects for Blue Force interactions in terms of detection, deception, disruption and destruction.  These objects would be representations of sensors, nodes and links as individual platforms/objects, but they would really be avatars with skeletal internal attributes, embodying only what is necessary for their interactions.  Communications assets and fusion functions would also have to be represented as objects with attributes to serve as targets for the same Blue Force interactions.  This would include the links and nodes of the adversary intelligence networks.  Depending on the exercise objectives, this requirements may vary.  If IO is not being exercised in a particular training event, there would be no need for all of these elements to be represented at a high level of detail.  In such a situation, the overall capability could be turned off, driving the need to make this a tailorable feature.Issue 2:  Aggregate Processing for OPFOR Exercise CellThe second issue or requirement would be for a need to present an aggregate perception of the battlespace to the OPFOR Role Players.  This would be accomplished by representing aggregate intelligence capabilities of adversaries within each individual intelligence discipline or perhaps inclusively across all disciplines.  This should provide a satisfactory solution to support OPFOR operational decision-making.  But it need not be accomplished in a high-resolution manner, which would be expensive and require large amounts of code and large-scale and sustained increases in resources.  For many applications, OPFOR does not need that kind of detail, but the function would, nevertheless, have to be a tailorable feature to support unique exercise objectives.  In a training event in which the OPFOR staff is very large, a greater level of detail might be afforded and preferred.  Conversely, OPFOR intelligence cells can be very small, as small as one person; one person cannot handle a large volume of detailed reports.  In that instance, highly aggregate reporting must be dialed in.Regardless of the level of aggregation, the capability would need to be augmented with an enhanced functionality to include tailoring of collection emphases to accommodate detailed intelligence reporting in selected Areas of Interest (AoIs).  These AoIs would be high-priority areas in very specific regions of the battlespace that OPFOR would name and define.  By enabling OPFOR the ability to perform detailed intelligence operations in these areas, concentrated Blue actions (e.g., deception and disruption) could actually have an impact upon OPFOR when perceived via tailorable AoI reports.  Major JV2010 training requirements can then be satisfied.  An additional challenge is levied when we insist that the tailorable AoIs must accommodate dynamic and responsive selection or change by Exercise Control, not just by OPFOR.  Additionally, OPFOR networks must be included in an aggregate sense in order to be able to modulate factors such as report quantity, quality and timeliness.  If necessary, the Exercise Control Group would be able to augment or degrade the quality, quantity and/or timeliness in order to dynamically meet certain exercise training objectives.Benefits of Providing an Automated CapabilityGains with this approach would be achieved in realism; Blue forces could experience the impacts of IO missions realistically.  An environment for the effective use of metrics would also be realized in that measures of effectiveness for the profitability of selected IO actions and the measures of the training audience’s proficiency in planning and tactics would both be available.  Finally the task of validation might be more easily accommodated; an OPFOR intelligence perception-based view of the battlespace reflects actual adversary capabilities, and algorithmic control of such processes is amenable to rigorous validation.Current and/or Planned Activity in this AreaFor over a year, DIA has been leading an effort to improve OPFOR participation in simulation-based training events.  Figure 5.1 depicts the path this effort has taken.  While activity started with merely knowledge acquisition, it was soon clear that there was very little in the way of a coordinated plan for improving OPFOR perception within the JSIMS program.  The path was pursued in two directions, one for work on acceptance by the JSIMS community, and the other towards building the conceptual approach and the further development of requirements.  Gradually the requirements and conceptual approach paths merged concentration on JSIMS acceptance and how to update the JSIMS requirements structure with a more detailed breakout of OPFOR requirements. EMBED PowerPoint.Show.8  Figure 5.1These paths were deemed critical, as JSIMS is intended to replace the current JTC of ALSP and provide the basis for Joint Task Force training for the next century, and success has been obtained in these endeavors.  As currently endorsed by representatives from the offices of the Commanders in Chief; the Uniformed Services; the JSIMS Joint Program Office and its Development and Executive Agents; the JTASC (Joint Training, Analysis and Simulation Center)/JWFC (Joint Warfighting Center), which are the United States Atlantic Command's agencies for joint training and exercises, and JSIMS DoD-wide user advocacy; and the DoD Intelligence Community, OPFOR role players' actions must be supported by a simulation-driven perception of the battlespace in order for JSIMS to satisfy many of its fundamental training requirements.  The JSIMS Requirements Control Board, consisting of representatives from many of these same offices, has unanimously accepted and endorsed the requirement for such a capability in the JSIMS program.  DIA is currently engaged in the detailed definition and breakdown of these requirements for inclusion in the appropriate JSIMS requirements documents.ConclusionsThe need for improvements in OPFOR perception of the battlespace support a fundamental exercise precept:  "The training audience must be rewarded for good behavior and punished for bad."  Actions taken by the Blue training audience must be perceived by OPFOR and have appropriate impacts upon OPFOR behaviors.  Whatever the future tools for joint battlestaff training happen to be, they must train U.S. command staffs in JV2010 operational doctrine.  They must therefore present scenarios and adversary actions that challenge the intelligence collection and assessment capabilities of Blue battle staffs and portray valid adversary reactions to Blue operations.  This must occur particularly in the context of Blue actions in the battle for information superiority.  We feel it is important to present our conceptual work at this stage, although we recognize that there is much work remaining to bring such capabilities to fruition.  Our goal is to help improve the art of wargaming so as to provide a more realistic, valid threat representation that can stress the Blue training audience in all facets of JV2010 Doctrine.ReferencesJV 2010 Doctrine.Ibid., p. 13.DoD Instruction 5000.61, DoD Modeling and Simulation (M&S) Verification, Validation, and Accreditation (VV&A), April 29, 1996.Office of the Director of Defense Research and Engineering, Defense Modeling and Simulation Office, DoD Verification, Validation, and Accreditation (VV&A), Recommended Practices Guide, November, 199, p. 1-8.Joint Pub 1-02, Department of Defense Dictionary of Military and Associated Terms, Joint Terminology Master Database, 10 June 1998, pp. 224-5.Central Intelligence Agency, Factbook on Intelligence, 15 October 1997.Author BiographiesBRIAN  J. DUBAS is an Associate with the National Security Technology Group of Booz•Allen and Hamilton's National Security Team.  He is currently supporting DIA's endeavors to enhance OPFOR participation.  Mr. Dubas has over fourteen years of military intelligence and consulting experience, including time in joint contingency and combat operations directing all-source intelligence fusion and analysis while serving in the US Air Force.  At one point during the years preceding the incorporation of ALSP, he was responsible for the organization and operation of Blue Forces intelligence at the Warrior Preparation Center in Einsiedlerhof, Germany.GARY L. WAAG is a Senior Associate at Booz•Allen & Hamilton, Inc., in McLean, VA.  He is Program Manager of the contractor team supporting DIA's endeavors to enhance OPFOR perception of the battlespace for JSIMS, and has been instrumental in the development of the high-level approach presented here.  He has over twenty years of engineering experience supporting diverse DoD and NATO M&S activities, including design, development, employment and management of constructive and virtual simulations used for analysis, acquisition and training support.  Mr. Waag leverages this experience to help coordinate his firm’s modeling and simulation support to customers who span the U.S. national intelligence as well as defense communities.  He is also a Co-Vice Chair of the SISO C4ISR Planning and Review Panel.CHRISTOPHER C. WERTMAN is an Associate with Booz•Allen and Hamilton's Defense Team.  He is the lead engineer supporting DIA's endeavors to enhance the benefits of OPFOR participation.  Mr. Wertman holds a B.S. in Aerospace Engineering from the University of Oklahoma and an M.S. in Computer Information Systems from Boston University.  He has held numerous positions during a period of more than 15 years, developing, implementing and using modeling & simulation in support of major theater level exercises.  He has supported the design and implementation of major simulation events and simulation centers.  He has also supported the Defense Modeling & Simulations Office in a number of functional areas including their MSOSA (Modeling & Simulation Operational Support Activity) Implementation, High-Level Architecture (HLA) Help Desk operations and HLA testing.PETER N. STARR is the acting Senior Intelligence Officer and former Chief of Model Development and Fielding for DIA's Modeling and Simulation Division (DI-FSM).  A career Program Manager, Mr. Starr is the catalyst behind much of DIA's current activity in supporting realistic OPFOR representation.  Mr. Starr has been involved with various large-scale information technology management programs, and has performed a range of tasks relative to the analysis, design, modification, development and implementation of the technical aspects of information systems.  Currently, he serves at the expert level performing the full range of analytical tasks pertaining to planning, programming and budgeting matters, technical studies, automation projects, and acquisition planning and management.  Mr. Starr has an M.S. in Systems Management from the University of Southern California and is a graduate of the Program Manager Course, Defense Systems Management College.