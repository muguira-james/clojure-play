Synthesizing Distributed Simulations Using Multiple Simulation ProtocolsJames NutaroRaytheon Missile Systemsnutaro@ece.arizona.eduHessam SarjoughianUniversity of Arizonahessam@ece.arizona.eduKeywords:multi-protocol distributed simulation, HLAABSTRACT:  The most common model of a distributed discrete event simulation is a collection of logical processes that communicate via time stamped messages. This approach fails to recognize fundamental properties of the system that the distributed simulator means to simulate. For example, systems exhibiting instantaneous input responses (i.e. zero time events) are particularly difficult to handle using the logical process model. Consequently, simulation algorithms developed around this model are at risk for being inadequate to simulate the types of systems envisioned by the designer. This paper presents a systems theory-based model to address time management in distributed simulation systems. An event-stepped algorithm derived from the model is presented, and it is shown how the RTI can be used to implement that algorithm.1. IntroductionDespite differences in implementations and simulation paradigms, distributed simulation systems seem to share a common set of functional requirements.  While some work has been done to describe the generic aspects of a simulation system in abstract terms [2], the most common approach to describing new simulation systems is a description of that system’s implementation.  This is unfortunate since it obscures important aspects of the system (e.g. time management schemes, data distribution schemes, and modeling paradigm) behind a screen of implementation details.  This paper presents, at a high level, a model enabling integration of popular alternative simulation protocols.  Two implementations of the model are then discussed.  The first is developed using MPI [6] for message passing, connection management, and federation startup.  The second implementation redevelops the time management, message passing, and connectivity functions using the HLA/RTI [1]. 2. Components of a distributed simulation systemA distributed simulation system has four components that are essential to its operation.  These are a set of network services that support communication amongst distributed software components, a global time management mechanism, one or more local time management mechanisms, and simulators that compute the state and output trajectories of simulated entities.  Figure 1 shows the organization of these components.The global and local control mechanisms are frequently compacted into a single layer, especially when only one time management scheme is being considered within a simulation execution (e.g. SPEEDES and DEVS-C++)[7, 8].  Systems intended to support multiple, simultaneously executing simulation protocols separate the notion of local and global time management (e.g. ADAPT and HLA) [2, 1].The simulator is a simulation program executing on a single node.  The simulators are not necessarily capable of supporting conservative or optimistic simulation.  For example, a simulator might not support lookahead or rollbacks.  The only requirements are that a simulator can accept external inputs, has accessible output, provides accurate information concerning next internal event and output times, and the progress of the simulator can be controlled.  Physically, the simulator could execute on a single computer, a shared memory multiprocessor, or even on a computer cluster or parallel machine.The local control mechanisms control the progress of their attached simulators.  They ensure that the attached simulator adheres to the local causality constraint.  Local control mechanisms can be optimistic or conservative, depending on what features are supported by the attached simulator.The global control mechanism is responsible for providing valid earliest input time (EIT) estimates to the local control mechanisms.  The EIT is the smallest timestamp that will be attached to any future input received by the local control mechanism.  A valid estimate of the EIT is less than or equal to the actual EIT for that local controller.  The global control mechanism is also responsible for providing I/O services to the local control mechanisms.  This could take the form of publish/subscribe services, coupling between input and output ports, or any other suitable representation.The network services provide connection management and message passing services necessary to implement the distributed simulation algorithm.  The network services might be provided by a package like MPI, PVM, or CORBA, or some lower level message passing toolkit (e.g. sockets or remote procedure calls).3. Simulating DEVS and DEVS-like systemsThe model described above can be formalized.  Via that formalization, it can be shown that the model can represent DEVS models described at the I/O functional level [4].  Consequently, the model can represent, at the I/O functional level [11], any system that has a DEVS representation.  It is perhaps more useful to notice that simulation algorithms can themselves be represented as discrete event systems using the concept of a DEVS bus [11].  It follows that general-purpose simulation engines can be incorporated as simulators within the simulation framework – namely the Distributed Simulation Environment (DSE).  Such an approach has the advantage of allowing simulators constructed on these simulation engines to be reused within the distributed simulation environment.  4. DSE, the Distributed Simulation EnvironmentDSE, the Distributed Simulation Environment, is a realization of the distributed simulation model described in the previous section.  DSE is implemented in C++ and uses MPI to provide network services.  The implementation includes a global control mechanism and risk-free optimistic, conservative, and event stepped local control mechanisms.  The adevs discrete event simulation library has been integrated with DSE in order to support distributed simulation of DEVS models [5].  The following sections discuss the high level design of DSE.DSE provides interfaces for the simulator and local controller.  The user implements the interfaces in order to integrate a simulator into the distributed simulation environment.  The steps required to build and run a distributed simulation using DSE are as follows:1. Write the simulation model program using simulation software that supports the DSE simulator interface (e.g., adevs). If desired, write state management and/or lookahead computing code to support optimistic and/or conservative local controllers.2.  Assign simulators to local controllers and local controllers to processors.3.  Use mpirun to start the simulator.  The mpirun script comes with most MPI implementations.4.1 Connection and data managementMPI requires that the user specify the number of federates and their locations prior to executing the distributed program.  The mpirun script can then be used to start the federation.  MPI assigns a unique name to each federate and provides message passing services that can be used to transport simulation data.MPI supports transport of primitive types (e.g. double, int, byte, etc).  The user is required to pack complex data types into contiguous buffers prior to sending a message across the network.  Similarly, the user needs to unpack messages received from the network.4.2 The EIT algorithmEarliest input time estimates are computed via a hierarchical global virtual time algorithm.  Since only one EIT is computed for all of the simulators, the EIT is referred to as GVT (global virtual time) from here on.  The global controller is organized as shown in the figure 2.  Each node in the distributed system has a simulator, local controller, and is part of the global controller.The leaves are responsible for initiating a round of computation.  Each node computes the minimum of is own local controller’s next event time and the next event times provided by is siblings.  This pattern is continued until the top of the tree is reached and a global minimum has been obtained.  The results are then propagated back down the tree.  4.3 Inter-process I/O and transition computationThe global controller consists of many identical parts, one of which resides on each processor.  Each part has complete information about coupling at the inter-federate level.  This allows each part of the global controller (hereafter referred to as global controllers) to send and receive output directly to and from its neighbors.  Once each of the global controllers has sent and received all of its output and input, the local controllers can be provided with the global time of next event and any input whose timestamp is equal to that time.  The complete global control algorithm is shown as algorithm 1.  Algorithm 1: Global control algorithmvariables:	N, pid, and tN – number of federates, ID of this federate, and time of next event, respectively.input – a list of messages with timestamps equal to tNlcm_output – the local controller’s output.adj – the adjacency matrix.  If federate m sends data to federate n, adj[m][n] is true.  Otherwise, adj[m][n] is false.e – a time stamped input   while (true)input := remove_all (input)tN := global time of next event/* Send outputs to any processors adjacent to this one.  If there is no data to be sent, send ( to indicate this fact. */for (i = 1; i ≤ N; i := i + 1)if (adj[pid][i] = true and lcm_output has timestamp equal to tN)send_msg_to (i, lcm_output)else if (adj[pid][i] = true)send_msg_to (i, ()endifendfor/* Wait for input from each federate that has this federate as a neighbor.  ( values are discarded. */for (i = 1; i ≤ N; i := i + 1)if (adj[i][pid] = true)e := recv_msg_from (i)if (e ( () input := insert (input, e, 0)endifendfor/* compute local controller’s next state */if (tN = local controller’s tN or length?(input) ( 0)apply tN and input to the local controllerendifendwhileThe list used in algorithm 1 is an object with the specification presented in [9, pp 27-31).  For convenience, the following, additional, method is defined:list’ remove_all (list) where length?(remove_all(list)) = 04.4 Local controllersFour types of local controllers were implemented; an event stepped, a conservative, and two risk-free optimistic.  Algorithm 2 shows the implementation of the event stepped local controller.  While this local controller is simplistic, it provides a sample of the local controller and simulator interfaces.Algorithm 2: Event stepped local controllervariables:sim – The interface to the user’s simulator(t, v) – an input v with timestamp tbegin compute_output ()return sim outputendbegin compute_tN ()return sim tNendbegin apply_input ((t, v))deliver (t, v) to sim and compute state of sim at time tendRisk-free optimistic and conservative local controllers can, in many cases, can reduce the execution time of the distributed simulation.  The conservative local controller accomplishes this by using user-supplied information about the output behavior of the simulator in the form of a lookahead value.  Risk-free optimistic local controllers allow the simulator to advance time beyond the global time of next event in order to discover opportunities for parallelism that would otherwise go undetected.  For a detailed treatment of the conservative and risk-free optimistic local controllers see [4].4.5 Integrating adevs with DSEThe local controllers and global controller expect the global time of next event to be strictly increasing.  DEVS in general, and adevs in particular, allow for zero-time events and, hence, can not meet the requirement for a strictly increasing time of next event.  To overcome this difficulty, the simulator interface for adevs augments the timestamps produced by adevs in such a way that they are strictly increasing.  The augmentation preserves the interpretation of zero-time events (i.e. zero time advance) within DEVS.  A detailed treatment can be found in [4].5 A multi-protocol simulation using DSETo exercise DSE, a DEVS model was simulated using a variety of local controllers and the resulting speedup observed.  The model consists of a multiple processor server attached to a generator and transducer.  The generator produces jobs that need to be processed by the multiprocessor.  The transducer collects finished jobs from the multiprocessor and compiles throughput and turn around time statistics.  The multiprocessor consists of eight processors who maintain a job queue and assign time to each job in a round robin fashion.  A load balancing process tries to equalize the lengths of the processor queue lengths.  Figure 3 shows the partitioning of the model for distributed simulation.A job is a structure with the following fields:processing time – the time required to finish the job.  This is a random variable uniformly distributed in [0, 40]job ID – the job’s unique ID number.processor ID – the ID of the processor assigned to this job by the load balancer.The generator (genr) produces a job every r units of time, where r is a random variable uniformly distributed in [0, 10].  When input is received on the stop port, the generator passivates (i.e. time of next event is ().  The generator is initialized with tN = r.  In the case of optimistic simulation, the state of the random number generator is saved along with the genr state.  Consequently, the random number stream is fixed relative to the initial seed.The load balancer (lb) tries to do load balancing for eight processors.  The lb maintains a load measurement for each processor.  The load measurements are initially zero.  When the lb receives a job on its in port, it looks for the least loaded processor, adds one to its load measurement, and then sends that job to the target processor.  When a completed job is received on the load port, the load measure for the processor who sent the job is decremented by one.  The lb requires zero units of time to process a job. The transducer (transd) computes average turn around time and throughput over an observation interval.  At the end of the observation interval, it produces an output on its stop port.A processor (proc) maintains a list of jobs, and processes the jobs in a round robin fashion, giving 0.01 units of time to each job in turn.  When a job is completed, it is removed from the list and sent to the output port.  When a job is received on the processor’s in port, the job is added to the back of the list.  If the list was empty, the processor immediately starts processing the job.  Otherwise, the processor finishes up the time slice for the current job.  The processor’s lookahead value is the run time of the smallest job in the list.The model was run in six different configurations, each over four different transd observation intervals, and the execution time for each configuration was observed.  Note that since each run is begun with the same seed for the random number generator, the state, input, and output trajectories for each configuration will be fixed relative to the observation interval.The configuration and observation intervals for each experiment were as follows.  Each configuration was run with four different observation intervals: 500, 3500, 6500, 9500.  The configuration for each run is show in table 1.Table 1: Assignment of local controllers to computerscomputer 0odd computerseven computersevent steppedconservativeconservativeevent steppedrisk-free optimisticrisk-free optimisticevent steppedrisk-free optimisticconservativerisk-free optimisticconservativeconservativerisk-free optimisticrisk-free optimisticrisk-free optimisticrisk-free optimisticrisk-free optimisticconservative5.1 ResultsThe experiments were performed using nine Sun SPARC Ultra 5/10 Workstations connected by a 100 Mbps local area network.  Each workstation has 64 MB of memory and is running SunOS 5.7Figures 4 and 5 show execution times and speedup for each simulation.  The one-sided 95% confidence interval for the execution time is less than 15 seconds in all cases.  The format for the legend is <even computer type>.<odd computer type>.<computer zero type>.  Conservative simulators are denoted by con, risk-free optimistic by rfo, and event stepped by es.6 An HLA/RTI implementation of the global controllerThe HLA/RTI can be used to implement a global controller.  This global controller can then drive local controllers as before.  The HLA/RTI based global controller is shown in algorithm 3.  This algorithm was originally developed to simulate DEVS models using the services of the HLA/RTI [3].  Its contribution to this implementation is the ability to handle preempted outputs without requiring the use of the HLA/RTI retraction service.  Preempted outputs can occur when input arrives with a timestamp less than the timestamp of the next output.  In this case, applying the input could cause the output trajectory to change, thereby modifying or canceling the originally anticipated output value [10].Algorithm 3: A time constrained/time regulating global control algorithmJoin the federationPublish/subscribe to classes and interactionscreate an event stepped local controller (lcm) to drive the DEVS simulatortgrant := 0x := (while (more to do)x := (if (lcm.out () = () nextEventRequest (lcm.compute_tN())fill the bag x with incoming interactions and updateswait for a time advance grant to tgrant// Advance the simulator to the grant timelcm.apply_input (tgrant, x)else      // advance the clock to ε time units before lcm.tN()       nextEventRequest (lcm.compute_tN() - ε)fill the bag x with incoming interactions and updateswait for a time advance grant to tgrant// if no input was received, send the lcm output and // advance the RTI clockif (x = ()send lcm.compute_output()nextEventRequest (lcm.compute_tN())fill the bag x with incoming interactions and updateswait for a time advance grant to tgrantendiflcm.apply_input (tgrant, x)endifendwhileThe value of ε is chosen to be the lookahead of the system being simulated.6.1 Simulating a queuing model using the HLA/RTIAlgorithm 3 was used to simulate a simple queuing model using adevs and an event stepped local controller.  The queuing model consisted of three components, each of which comprised a federate.  A generator produced jobs every T units of time.  A processor required P units of time to finish a job, with jobs waiting for service being queued up within the processor.  Finally, a transducer collected statistics about the performance of the system (i.e. throughput and turnaround time).  In both cases, P and T are greater than zero.  Figure 6 depicts the model components and their coupling.  The simulation was run using the standalone DEVS simulation engine and as a collection of federates.  In both cases, the results of the simulation were identical.7 ConclusionsThe distributed simulation system model presented in this paper can serve as a starting point for developing distributed simulations.  The global controller algorithm presented in section 6 provides a common solution to HLA based time management for DEVS simulations and simulation of systems that have a DEVS representation.  The DEVS bus concept can be used to extend this solution to encompass other, non-DEVS, simulation protocols.The modular nature of the distributed simulation system model allows for a remarkable amount of flexibility in selecting the technology to be used to implement the global control mechanism.  As a result of the well-defined local controller interface, local controller implementations can be insulated from changes in the global controller implementation.  This can allow a simulator to participate in an HLA federation, and the same simulator can be seamlessly integrated into an alternative simulation environment as the need arises (e.g. when zero-time events need to be supported).     Works Cited[1] Defense Modeling and Simulation Office, IEEE Standard for Modeling and Simulation (M&S) High Level Architecture, IEEE standard 1516-2000, IEEE, 2000[2] Vikas Jha, Rajive Bagrodia, “A Unified Framework for Conservative and Optimistic Distributed Simulation”, 8th Workshop on Parallel and Distributed Simulation, pp. 12-19, 1994[3] Thomas W. Lake, Bernard P. Zeigler, Hessam S. Sarjoughian, James J. Nutaro, “DEVS Simulation and HLA Lookahead”, SIW 2000, Orlando, Florida, 2000[4] James Nutaro, “Time Management and Interoperability in Distributed Discrete Event Simulation”, Master’s Thesis, University of Arizona, Department Electrical and Compute Engineering, 2000[5] James Nutaro, “adevs”, http://www.ece.arizona.edu/~nutaro, 2000[6] Marc Snir, Steve Otto, Steven Huss-Lederman, David Walker, Jack Dongarra, MPI – The Complete Reference: Volume 1, The MPI Core, second edition, MIT Press, Cambridge, Mass., 1998[7] Jeff S. Steinman, “SPEEDES: A multiple-synchronization environment for parallel discrete event simulation”, The International Journal for Computer Simulation, Vol. 2, No. 3, pp. 251-286, 1992[8] Bernard P. Zeigler, Yoonkeon Moon, Doohwan Kim, George Ball, “The DEVS Environment for High-Performance Modeling and Simulation”, IEEE Computational Science & Engineering, July-September, 1997[9] Bernard P. Zeigler, Objects and Systems, Springer-Verlag, New York, 1997[10] Bernard P. Zeigler, George Ball, Hyup Cho, J.S. Lee, Hessam Sarjoughian, “Implementation of the DEVS Formalism over the HLA/RTI: Problems and Solutions”, Simulation Interoperability Workshop, March 1999[11] Bernard P. Zeigler, Herbert Praehofer, Tag Gon Kim, Theory of Modeling and Simulation, 2nd edition, Academic Press, New York, 2000Author BiographiesJAMES NUTARO is a systems engineer at Raytheon Missile Systems in Tucson, Arizona and a graduate student in Electrical and Computer Engineering at the University of Arizona.HESSAM SARJOUGHIAN is Assistant Research Professor of Electrical and Computer Engineering at the University of Arizona. His current research interests are in the theory, methodology, and practice of collaborative/distributed Modeling & simulation.  Internal events cause local state changes w.r.t. its simulator without necessarily being mapped into output events. New (user-defined) local control mechanisms/simulators may be incorporated into DSE. For example, to support simulation of cellular automata, appropriate simulators/local controller can be added to DSE.PAGE  1Figure 4: Simulator execution timeFigure 5: Simulator speedupFigure 3: The model partitioned for simulation on 9 computersComputers 2 ... 7out 8out 2 … 7Figure 1: Modular view of a distributed simulation frameworkGlobal control mechanismSimulatorSimulatorSimulatorLocal control mechanismLocal control mechanismLocal control mechanismNetwork servicesComputer 8inoutprocComputer 1inoutprocComputer 0loadout 1inlbstoparrivesolvedtransdstoppoutgenrFigure 2: A 6-node simulation program654321Figure 6: Simple queuing modeljobjobTransducerProcessorGenerator