PSF: A Portable Scenario Format for CCTTDarren R.. LawJim MoerkScience Applications International Corporation (SAIC)12901 Science DriveOrlando, FL 32826darren.r.law@saic.com, jim.d.moerk@saic.comThe Close Combat Tactical Trainer (CCTT) system is a distributed, human-in-the-loop virtual system designed primarily for training tank or mechanized infantry units at the company and platoon level.  CCTT is widely used by the U.S. Army at fixed and mobile sites in the U.S. and abroad. The United Kingdom Combined Arms Tactical Trainer (UKCATT) and several other products derived from CCTT use similar system architectures and exercise file structures.  Each of these programs has made substantial investments in the development of exercise files for their particular training needs.The original CCTT exercise file format was a binary representation of the system data model.  The use of this representation and the requirement for backwards compatibility with existing exercise files limits the system's extensibility, complicates software maintenance, and precludes reuse of CCTT exercise files even among CCTT-derived products.The Portable Scenario Format (PSF) project replaced the CCTT binary scenario files with W3C-compliant XML documents.  The resulting exercise files are platform independent and promote a more data-driven interoperation with other systems.  Tools developed as part of the PSF project automatically maintain consistency between the CCTT source code and the W3C-compliant schema representation of the data model, thus reducing software maintenance costs and enhancing extensibility.  The use of open-source tools permits non-CCTT customers to leverage the investment in CCTT exercise files.IntroductionThe Close Combat Tactical Trainer (CCTT) system is a distributed, human-in-the-loop virtual system designed primarily for training tank or mechanized infantry units at the company and platoon level.  CCTT is widely used by the U.S. Army at fixed and mobile sites in the U.S. and abroad.  CCTT is implemented primarily in Ada and was originally fielded on collections of single- and dual-processor PowerPC machines using the AIX operating system.The United Kingdom Combined Arms Tactical Trainer (UKCATT) and several other products derived from CCTT use similar system architectures and exercise file structures.  Almost all of these programs have added entity types, unit types, and new unit orders to the system to support the tactical doctrine requirements of their program.  Each of these programs has also made a substantial investment in the development of exercise files for their particular training needs.  CCTT Exercise FilesA CCTT scenario specifies the initial environmental conditions, order of battle, and planned orders for a CCTT exercise.  The order of battle includes tactical units, orders for those units, and initial positional and status information for the entities (vehicles or soldiers) within that unit.  The unit orders are parameterized generic orders (e.g. move in formation, occupy position) derived from Combat Instruction Sets (CIS) which are part of the CCTT requirements.  Parameters for these orders may be as simple as a desired speed or target location or as complex as a conditional trigger to start execution when some other unit crosses an overlay symbol on the Plan View Display (PVD).  All of this information is saved in a “.data” file for each force in a CCTT scenario.A technically-challenging requirement for any system is the ability to gracefully “undo” actions previously taken.  Despite its real-time, human-in-the-loop nature (or perhaps because of it), CCTT is required to checkpoint its exercise state at intervals specified by the user prior to system initialization.  The checkpointed exercise state information must be sufficient to restart the system at a recent point in time so that some alternative course of action can be pursued (e.g. “let’s take fifteen minutes to discuss target recognition, then reset to right before someone shot the platoon leader’s tank”).  The information which must be checkpointed by CCTT is nearly identical to the scenario information and must be copied to secondary storage during real-time execution.  In addition, this same information must be loaded quickly from secondary storage back to primary storage to make system restarts as fast as possible. In order to meet these stringent performance requirements, checkpoint data is saved in a direct binary representation of the way it is stored in the SAF Entity Object Database (SEOD)   At some point during CCTT’s initial development, the decision was made to use the binary checkpoint format as the format for the initial exercise conditions.  This decision certainly resulted in faster exercise initialization times and a reduction in development cost, but had a number of undesirable consequences. As these consequences began to impede extensions to  CCTT functionality STRICOM (now PEO-STRI) contracted SAIC to eliminate these barriers by developing a Portable Scenario Format.Overview of PSFThe original CCTT exercise file format was a binary representation of the system data model.  The use of this representation complicated CCTT system maintenance in a number of ways which made changing the CCTT data model unnecessarily difficult.Limitations of the Binary FormatThe requirements for CCTT continue to evolve as CCTT is extended to include new elements of tactical doctrine, new equipment types, and even new theaters of potential conflict. Changes to CCTT requirements frequently require modification or extension of the data model.  The objects in the binary representation of that data model may need to change in size in response to this modification to reflect the addition of parameters or attributes to an object.Data model changes present a great problem to CCTT because of the large investment in scenario files.  Because of this investment, CCTT is required to provide the ability to reuse pre-existing scenario files that may not be based upon the same data model.  The limitations described above greatly hamper the ability to make significant updates to the data model without either invalidating the older scenario files or requiring convoluted code to map from one data model to another.The CCTT binary scenario files are loaded into memory by copying a fixed size block (size determined by largest object type) from the file and typecasting it as an object of the appropriate type.  This works well for checkpoint files, as they only remain valid for the life of an exercise. The data model version represented in the file and in memory will remain consistent throughout an exercise.  This is not necessarily the case for scenario files.  For backwards compatibility, this technique requires the size of a particular object’s binary representation to remain constant throughout all versions of the runtime data model.  This limitation means objects are unable to grow as needed.  Some effort was made initially to allow for future CCTT data model updates.  Padding was inserted into the data models for various object types to allow for the expansion of data types.  This is only a temporary solution to the problem.  Only a limited amount of padding is present in various places within the data model.  When new items are added to an object, it replaces the padding that was previously in place.  Once the padding has been completely replaced with new items, no more additions can be made to an object.A second constraint imposed by the use of binary scenario files is dependency on position within type enumerations.  Enumerations are actually represented internally as the numeric position of the enumeration value within the enumeration type.  This poses a problem when the enumeration values are saved in a binary scenario format.  Because the position of the enumeration value is saved, all updates to the enumeration must be made to the end of the enumeration range.  If any values that are added prior to existing enumeration values, each enumeration value that follows will be offset.  This causes a problem when loading scenario files created prior to the enumeration addition.  Enumerations values will no longer be consistent between the saved scenario version and the current internal memory representation.A coding practice in the early versions of CCTT code exploited the fact that similar objects were given consecutive positions in CCTT enumerated types.  The various types of friendly (NATO) tanks, for example, form a continuous subrange of the entity type enumeration.  Much of the original CCTT code exploits this original ordering, so that tests for membership in the set of friendly tanks might be written as “x is in M1A1 .. Leopard” rather than by writing and then calling a set membership function (e.g. Is_A(Friendly_Tank, x)”). The vast amount of CCTT source code (several million SLOC) would make identification and replacement of all such order-dependent membership tests nontrivial.  CCTT used dummy enumeration values in much the same way that padding was used to allow for future expansion of the data model.  An enumeration range typically  included several temporary placeholder values (e.g. Spare_Tank_1, …etc.) at the end to allow additional values to be placed within the range.  The placeholder value is simply replaced with the new enumeration value when the new type is added.  As long as there are still placeholder values vailable, no additional changes are necessary to maintain the consistency of the enumeration range.  This solution  has the same limitation the padding solution has: once the placeholder values are exhausted, so is the possibility for expansion.A workaround was introduced into CCTT to allow developers to add entity types and other enumerations into subranges when there were no remaining “dummy” or spare entries.  New enumerations could be added at the end of a subrange in the code, but a remapping of each enumeration was performed during load/save so that subrange testing in the CCTT code would still work correctly.  This mapping extension was implemented prior to the PSF project to allow the creation of new vehicle types after spare slots for certain subtype ranges had been exhausted. The enumeration remapping allowed subrange testing to operate correctly, but greatly complicated the addition of new enumerated types and did not address the limitations on data model object size.The PSF Solution ApproachThe objective of the PSF project was to solve all of the problems introduced by using a binary scenario file format. Specifically, the desired solution had to permit changes in data model object sizes, eliminate the positional dependencies which hampered system extensibility, and permit backwards compatibility with all previously-developed exercise files.  In order to meet these goals, PSF had to find a suitable format to replace the CCTT binary files, modify CCTT to use the new file format, and make changes to the system so that the use of a new format would reduce future software maintenance costs.Selecting the New Scenario File FormatThe PSF team decided to use XML to replace the CCTT binary scenario files.  XML was chosen as a replacement language for several key reasons:XML is extensible.XML allows for updates to the data model that are required of CCTT.  XML has none of the positional dependencies or size limitations associated with binaryfiles.XML is platform independent.  –Since  XML is a text based format, it does not have the traditional platform dependencies of the binary representation.  This allows access to the CCTT data model on platforms not yet supported by CCTT.XML provides a query capability. XML has standards for extracting information from a file.  By using a standard method to extract information from the scenario file, it is more interoperable.  Other applications do not need access to CCTT code to operate on the scenario files.XML is widely used.  The use of tandards-compliant XML schema allows us to use open source tools for parsing and validating. Non-CCTT applications will also be able to use these same open-source tools, facilitating interoperability.XML facilitates reuse.  OneSAF was planning to use XML for their scenario applications.  Our use of XML would allow OneSAF to reuse our scenarios with much less effort.There were several potential disadvantages to selecting XML as a replacement for CCTT binary scenario files:XML would almost certainly be slower to load than binary memory images because it would have to be parsed.XML files seemed very likely to require more disk space than binary memory images.In practice, it was discovered that the widespread use of large fixed-size arrays in the data model made CCTT binary files unnecessarily large (since these arrays were extremely sparse). The PSF project took steps to promote more efficient storage of sparse arrays, thus eliminating much of this waste and offsetting the potential increase in file size.One of the chief limitations of the binary scenario file format was the inability to increase the size of existing data model objects once any predefined internal padding was exhausted.  In the PSF scenario files, each object is defined as an element in the XML file and is defined by a start and end tag.  The use of these embedded object boundary markers eliminates the need for fixed object sizes as the data model for the system evolves.  By referring to descriptive schema for the scenario file, each object and component thereof can be loaded by name as an element or attribute from the scenario file.The second major limitation of binary scenario files was the dependency on positions within an enumeration in the scenario loading process.  The PSF representation of enumerated information converts the internal representation to a named string value of the enumeration when the scenario file is saved.  When the file is loaded, the string value is then converted back into its internal representation.  If updates have been made to the enumeration, the string value still represents the value it was meant to represent.  The internal representation may be different than it was when the file was originally saved, but the intention and correct system operation will be preserved.The solutions to the problems of fixed object size and positional dependency both incur a performance cost.  It is clearly slower to parse the start and end tags of an object from text in secondary storage than it is to load a fixed-size block of memory.  It also substantially slower to load and decode a string description of an enumerated value than the binary representation of an enumeration index.  Performance risks were identified in the early phases of PSF and experiments were conducted during various stages of development so that the team and customer could make informed design decisions.Using the New Scenario File FormatInitially PSF was going to develop an XML schema to define the CCTT data model external to the CCTT Ada code.  This schema was to be W3C-compliant (World Wide Web Consortium) to allow standard validation using existing open-source tools and to maximize the potential reuse of the schema by other simulation systems.  As development of the W3C-compliant schema continued, it became increasing complex to allow the flexibility desired for interoperability while providing some of the necessary elements to allow a completely data-driven read/write of the scenario files.Because of this is it was decided to separate the information that was only required within the confines of CCTT into its own set of schema.  This schema is used specifically by the Ada application to effectively map from the internal data representation to the new portable scenario format and vice versa.   A decision was made to maintain both the W3C-compliant and CCTT-specific schema to realize the benefits of both. Reducing Software Maintenance CostsThe use of the CCTT-specific schema to load and save exercise files allowed the code for those functions to be replaced with much more general, data-driven code.  The replacement of  object-type-specific code with more general purpose code resulted in the elimination of several thousand lines of Ada code.  A tool was created that will create the mapping schema from the CCTT Ada code directly.  The use of this tool greatly reduces the amount of programmer maintenance required for data model updates.  The tool is run, and a new set of schema is generated that matches the new internal data model.  Currently all loading and saving is data-driven via the schema generated by this tool.  Updates to the data model do not require any code to be written to load or save the data to the scenario files.  The only possible maintenance which is required to update schema when the data model changes is updating the atox configuration file.  This configuration file defines default values for large data structures (e.g., the large sparse arrays that were so space-inefficient in the binary representation.) This is a vast improvement over the maintenance that would be necessary using the old binary scenario format.  The code required to map from the storage view to the run-time view was extremely convoluted and complex.  PSF completely eliminated the need for any such code to maintain the consistency of the data models after additions are made.  It is all handled by the regeneration of the schema file after the updates are made.PSF ImplementationThe PSF program addressed the problems associated with binary exercise files in three distinct phases:Replaced CCTT binary exercise files with equivalent XML files.  Modified CCTT to use XML exercise files rather than binary exercise files wherever the binary files are an impairment to system extensibility or maintenanceDeveloped tools to make certain that modifications to the CCTT system do not increase maintenance costsReplacing Exercise Files with XMLOnce XML was chosen as the new CCTT exercise file format, it was necessary to provide utilities to translate existing binary files into XML and save them.The main goal of PSF was to facilitate the ability to update the CCTT data model without invalidating older scenario files.  To achieve this goal, it was necessary to provide the ability to allow the use of old binary exercise files as well as files saved in the new XML format.  This presented the PSF team with two options: translate all existing binary scenario files to the new XML format or to maintain the capability to load both the binary and XML formats, but save only the new XML format.The customer (PEO-STRI) directed the PSF team to develop an offline translation tool to convert all existing exercise files to XML exercise files and remove the capability for binary exercise load and save from the system.  The PSF team developed an offline translation utility that loaded existing binary files and then stored them into the new PSF file.  This tool was designed to be run as a script that would recursively search for all “.data” files and run the conversion application on them. A configuration file allows the user to specify whether or not to back up the binary files being translated, and the location to back them up to if necessary.The file conversion tool extensively reused existing code. The old code used to load binary scenario files was modified slightly and frozen so future data model changes would not have any impact on the utility.  The decision to freeze the embedded data model was made because the conversion tool was only designed to load binary files based on the data model at the time PSF was introduced.  This was possible because, with the addition of PSF, no binary files would exist with a later version of the data model.  The freezing of the binary version is necessary so that the impacts PSF is correcting do not get propagated into the binary conversion tool.Once the binary file is loaded into memory, the PSF save code is then used to write the information out in the new XML format based upon the schema described in section  REF _Ref31017132 \w \h  \* MERGEFORMAT 4.3.  The XML file will also be based upon the initial data model when PSF was first created. Because CCTT will be able to load all data model versions of the PSF, there will be no issues using the older data model.  The use of the initial data model throughout both the loading and saving process of the conversion means that no maintenance associated with data model updates is ever required for the conversion tool.  After this process was implemented, the customer directed the PSF team to maintain the ability to load binary exercise files at run-time without user intervention.  The above solution was modified to allow the CCTT application to directly call the conversion application at exercise load.  The CCTT application searches for a PSF XML scenario file when loading an  exercise.  If one is not found, the CCTT application invokes the conversion tool to translate the binary version into XML.  The user is not notified that the translation is occurring.  This process also uses the backup capability if it is enabled.Runtime Use of XML in CCTTThe PSF team identified several system functions which might be able to make use of the data-driven nature of the PSF code changes.  Certainly exercise loading and saving were preeminent among these changes, but there was also the potential to use these modifications in the system’s checkpointing and even to reduce the system’s code footprint and maintenance costs substantially by using the PSF data-driven representation in the network code which maintains the coherence of the SEOD.Loading and Saving XML Exercise FilesPSF uses two sets of schema.  The first is designed strictly as the “mapper” from the binary to XML.  This schema is specifically written for the Ada application to use to load the XML files into the memory representation.  This schema is loaded by the application during initialization as shown in  REF _Ref31010931 \h  \* MERGEFORMAT Figure 1.  This schema contains the name-value required for storage in the XML file.  This includes the name of every element of every object that can be stored, and its corresponding data type.  The data types that can be used range from atomic value types such as 32-bit integer to complicated variant records.  This schema also includes the offset of each element within the object that contains it.  Code was written to use the information contained within this schema to perform a data-driven load and save of the scenario files. The PSF Interface code loads the schema information and stores it in memory.  The schema is saved as multiple XML Documents, so the same parser that is used to load the scenario files can be used here to load the schema.  The use of this schema is key in the ability to provide the data-driven read/write capabilities of PSF. EMBED MSDraw.1.01  Figure  SEQ Figure \* ARABIC 1: CCTT Application InitializationWhile the first schema was designed with the data-driven implementation within the CCTT code, the second schema was created in order to promote CCTT interoperability with other simulations and tools.  The second schema is a W3C-compliant XML Schema.  This decision was made so that tools having absolutely no association with CCTT (or any other simulation for that matter) can validate  scenario files against CCTT data models.  This opens the door to a wide array of open-source and proprietary tools that can be used to operate on the new CCTT Portable Scenario Format.  The CCTT application also uses the W3C-compliant  schema during the scenario loading process.  The schema is used by the XML parser upon scenario load to validate the file.  This also plays a key role in the ability to reduce the size of the file.  Any values within an object that are the same as the default value described in the schema are left out of the scenario file.  The W3C-compliant schema validating parser automatically inserts the default values for these attributes upon scenario load.   EMBED MSDraw.1.01  Figure  SEQ Figure \* ARABIC 2: CCTT Exercise Load/SaveThe PSF Interface uses the schema information loaded at application initialization to convert the name-value scenario file representation into the run-time memory format by copying the loaded information into memory at the offsets defined in the first schema  This process is illustrated above in  REF _Ref31011161 \h  \* MERGEFORMAT Figure 2.Other Potential Uses of PSFThe possibility of using PSF loading/saving to replace the runtime exercise state checkpointing was investigated as an opportunity for further code reduction.  The runtime exercise checkpoint methods used much of the same implementation as the binary scenario file implementation.  Several experiments were conducted to estimate the cost of making this change and indicated (as expected) that the binary saving/loading is several times faster than the portable version.  The checkpoint files do not share the same requirement to be compatible between data model versions that the scenario files do (since the checkpoint files are only used during an exercise execution, the data model encoded in the executables is guaranteed not to change during checkpoint load/save).   Since the only benefit of replacing checkpointing code with PSF code was code reduction, checkpointing was left in place.A second area investigated for possible PSF modification was the runtime use of name-value pairs to communicate SEOD data.  The CCTT SEOD contains numerous variant record types; since Ada allocates memory for these types based on the size of the largest variant, many objects distributed by the SEOD are larger than they need to be (due to variant records and padding).  The use of  name-value pairs based on the CCTT-specific schema offered the potential for a significant reduction in network utilization during initialization and execution.  The conversion of large amounts of object-specific code to more general, data-driven code would also have permitted the elimination of several thousand lines of Ada code that would no longer have to be built or maintained.A prototype was written that performed several of the commonly used functions in this data-driven manner. The functions implemented in the prototype were anywhere from 4 to 22 times slower than the original method.  The performance issue may not significantly impact some off-line applications, but the slowdown would probably have pushed the CCTT CGF application outside of acceptable runtime performance limits. The real-time, human-in-the-loop nature of CCTT precluded extension of PSF name-value pairs into the run-time SEOD.Automatic Schema MaintenanceSection  REF _Ref30954391 \r \h  \* MERGEFORMAT 4.2 described how the replacement of CCTT exercise files with XML permits extension of the CCTT data model by allowing increases in object size, by eliminating positional dependencies, and by allowing easier addition of new object types to the data model. While these changes permit CCTT to be extended, they do so in part by adding a requirement to maintain not only source code, but a set of schema describing the data model which that source code embeds.  In order to avoid increasing software maintenance cost, the PSF project developed tools and modifications to the CCTT build process to automatically maintain consistency between the source code data model and the schema used to load and save exercise files.An application was written based on the Ada Semantics Interface Specification (ASIS) standard to convert the CCTT data model from Ada compiled source code to an XML format.  The Ada-to-XML (atox) application has the ability to pull nearly all of the information required for the CCTT specific schema directly out of the Ada code.  Anything that could or should not be generated automatically (array value defaults, items to be excluded from schema) must be defined in the atox configuration file.  This file is read in by the atox application and applied during the conversion to XML.  This application was absolutely critical to the low-maintenance PSF approach.  Upon implementation, approximately 35,000 schema lines were required to define the CCTT data model.  With the atox tool, the entire schema is generated in a few minutes.  Copying the name-value and memory offset values by hand is extremely tedious and error-prone.  The accuracy of the name, value type and memory offsets is required for PSF to work.  The use of the atox nearly eliminates the possibility of errors in the process.The process to generate the W3C compliant XML Schema is just as simple.  An XSL transformation was written to convert the CCTT-Specific Schema into the format required for the W3C compliant XML Schema.  An open-source XSL transformation utility is then used to apply that transformation to generate the W3C compliant XML Schema.  There is no other information or code required at all to generate this schema.  All data is derived from the first schema. EMBED MSDraw.1.01  Figure  SEQ Figure \* ARABIC 3: Schema Generation ProcessThe automatic generation of both of these schema was instrumental to the substantial maintenance benefit achieved by PSF.  PSF achieved all of the maintenance reduction goals associated with fixed sized objects and positional dependencies.  The effort invested to automate the schema maintenance process will prevent PSF changes from adding any maintenance issues of its own. ConclusionsThe Portable Scenario Format represents a great leap forward in extensibility and interoperability for CCTT.  The tools developed as part of the PSF project to maintain data model consistency and backward compatibility will result in long-term software maintenance savings to the CCTT program.  There are several areas of CCTT which can still benefit from  extending the use of PSF when customer funding and programmatic considerations permit.The use of PSF technology and tools by other simulation programs will improve their ability to  interoperate with CCTT and will allow those programs to leverage CCTT’s substantial investment in doctrinally correct and tactically-relevant exercises at a relatively modest cost.Author BiographiesDarren R. Law is a Senior Scientist at Science Applications International Corporation.  Mr. Law has Bachelor’s degrees in Computer Science and in Mathematics from the University of Florida and Master’s degrees in Computer Science and in Simulation Modeling and Analysis from the University of Central Florida.  He is a doctoral candidate in Computer Science at UCF and has 15 years experience in modeling and simulation.  His research interests include systems performance, distributed simulation, and graph theory.  Mr. Law is currently working on the CCTT, OneSAF, and UKCATT programs and provided technical guidance for the PSF project.Jim Moerk is a Software Engineer at Science Applications International Corporation.  Mr. Moerk has a Bachelor’s degree in Computer Science from the University of Florida.  He has 5 years experience in modeling and simulation.  Mr. Moerk is currently working on the OneSAF Testbed (OTB) and was the Technical Lead for the PSF project.