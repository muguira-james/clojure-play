An Investigation of Fidelity Metrics by theValidation of a Safeguards Monitoring System SimulationVaughn STANDLEY and Helmuth BOECKAtominstitut Vienna, Austriae9727248@student.tuwien.ac.atReinhard VIERTLVienna University of Technology, Austriaviertl@ws5.statistik.tuwien.ac.atKeywords:Simulation, Validation, Fidelity, SafeguardsAbstract:  Design and validation of a distributed safeguards monitoring system (SMS) simulation is conducted as a means of investigating fidelity metrics.  The research goal is to create a simulation of an SMS where the data can be compared with that of a laboratory referent.  In this, the first phase of study, agreement between simulation and referent data is analyzed in the context of the simulation objective using rigorous statistical methods and expressed in terms of a fitness metric. Fitness defines the validity of the simulation.  The referent, under construction at the Atominstitut in Vienna Austria, is comprised of a digital camera and two neutron detectors.  A benefit of the process of computing simulation fitness is automation of the SMS data review.  Preliminary results suggest that routine and anomalous events in a nuclear facility could be discriminated using a system based on simulation data.  Phase-two research will deal with how the fitness metric can be used to rationally order changes in the simulation in terms of fidelity metrics, which are measures of the simulation's realism.  1.0 IntroductionThe purpose of a safeguards monitoring system (SMS) is to make undetected diversion of special nuclear material (SNM) difficult.  A modern SMS may include devices such as video cameras, radiation detectors, and electronic seals, among others.  Moreover, there is a trend to network electronic monitoring devices and to make their data remotely accessible to authorized clients.  For the most part, analysis of SMS data is done manually.  For this reason, it can be expensive and prone to error.  Some technologies have emerged to reduce cost and errors.  Scene-change detection systems, for example, can reduce literally days of video review to a few minutes, but they only work for facilities where there is little activity and not for busy facilities where the false alarm rate is high.  It is widely believed that simulation technology can improve acquisition, design, and analysis in most technical fields.  Simulators can be used to train operations and maintenance staff.  The process of creating a simulation also increases understanding about a system and its underlying phenomena.  However, simulation-based technology has yet to be widely used in many fields, including safeguards.  Some activities are routinely assisted by simulation, such as with electronic circuit design and troubleshooting of SMS components, but are not applied beyond the boundaries of the devices.  For example, circuit analysis software can predict how a pulse from a neutron in detector is processed by the circuit.  How neutrons are emitted from a source, scattered, absorbed, and arrive at the detector is not routinely simulated, either for designing a safeguards device or for operating it.  The reason simulation is not more widely used is twofold.  The benefits of using simulation are not clear and, even if they were, there is no general theory about the validity of simulations to help judge which simulation is best, if any.Research on software validity has been ongoing in many technical areas for many years.  Nevertheless, there is no standardized, systematic, and quantitative methodology for determining validity.  More recently, the importance of computing and publishing simulation fidelity and fitness metrics has been emphasized [] to advance validation technology.  Fidelity is the realism of a simulation and is thought to be a key to developing and standardizing validation methodologies.  Unfortunately, there is no systematic methodology for computing fidelity either.  Even the units of fidelity are not agreed to within the simulation community.  The same is true for simulation fitness, which is the suitability of a simulation for its intended purpose and is said to define a simulation's validity.The work described herein is the beginning of a new attempt to deal with a lack of validation technology and demonstrate the benefits of simulation to safeguards by practical application.  A methodology for systematically accomplishing both tasks is described.2.0 BackgroundFielding an SMS requires the determination of SMS objectives and specific component requirements, design, fabrication, test, and evaluation of system hardware and software.  Historically, the steps were accomplished distinctly, often in numerous iterations.  Modern thinking is that the steps should be integrated to the greatest extent possible.  The use of simulation helps in this effort and government acquisition agencies nowadays tout this approach and call it Simulation Based Acquisition.Requirements definition is the act of setting the minimum performance levels of a system.  The requirements should derive from the objective of the system.  For an SMS, the objective is to detect improper movements of SNM within predefined confidence levels or tolerances.  Specific requirements for an SMS typically include parameters such as size, weight, temperature, humidity, and vibration that depend on conditions in the facility where the device must operate.  Other requirements are specific to devices.  A short list of the requirements for a camera also includes frame rate, light sensitivity, and view angle.  Requirements for a neutron detector will include such specifications as its sensitivity to neutrons of particular energies.  In practice, device specific requirements are not derived from the confidence levels because the only systematic way to do so is to simulate the system and adjust the requirements until the system objective is met within the allowed confidence levels.  The obvious drawback is the need to create a simulation of the system before the system is designed.Design and fabrication of an SMS is the creation of hardware and software to realize the objectives.  The process normally requires some level of modeling, but it is usually limited to components.  A few applications exist to help evaluate the general architecture of a proposed SMS or physical protection system [].  The best way, however, to evaluate how components work together is to implement a detailed simulation of the entire system.  A proper simulation assigns behavior to individual objects in the system being modeled.  Different objects interact with one another via environmental variables such as space, time, force, etc.  Objects and environmental conditions are most likely going to be stochastic and, therefore, be based on an appropriate probability distribution.  The simulation begins after the various objects and environmental variables are initialized with a random seed.  This type of simulation is termed Monte-Carlo.  A good simulation should possess some tools for observing each simulation as it unfolds and for acquiring statistics about many simulations where the outcomes are different only because of the initial randomization.  The statistics acquired from many simulations is generally what is of interest.  The trick of making a good simulation is choosing the relevant objects and environmental variables and ensuring that their underlying phenomena are well represented, which means finding and correctly coding the right phenomenological equations and probability distributions.  Fidelity would describe how well this is done.  Which objects and environmental considerations are important depends on the objective of the simulation study.  For an SMS watching over a busy store of plutonium, where that system is based on video and neutron detection data, the simulation must at least be able to create images and count-rate data like that acquired by the real devices.  This means that objects having an effect on this data must be included.  There must be, therefore, visual and neutronic models of the plutonium containers and objects that manipulate them or shield them from view of the camera or radiation detector.  Realistically then, there should be models in the simulation of walls, doors, containers, cranes, even people.Rigorous test and evaluation are performed with a prototype SMS under field conditions before larger scale production and deployment is considered.  Validation is a set of tests to prove that software meets its requirements.  Validation may also apply to simulation software.  Fitness would be a quantitative measure of the degree a simulation is valid.Before metrics of simulation fidelity can be rigorously studied, there must be a quantitative system for evaluating the operation of a simulation.  A concrete use-case is called for [] involving the validation of a simulation.  It is also proposed to use the same simulation in the operational system.  The usefulness of fidelity and fitness metrics should be measured by the success of its application to the real software validation exercise.  3.0 ObjectiveThe objective of this study is to design and validate an SMS simulation.  The final simulation should be able to quantify, for arbitrarily configured SMS, the probability of detecting a diversion and the false alarm rate.4.0 MethodFundamental to determining fidelity and fitness is comparing real data to simulated data.  Comparison takes the form of a function with two arguments.  It may be written as comp[arg1, arg2] and it returns one or more numbers describing how the arguments compare.  The order of the arguments is important.  We choose arg1 to correspond to real data and arg2 to simulated data.The comparison should be made to data after it has been subject to an objective.  For example, the possible outcomes of a review of surveillance may be “conclusive”, “inconclusive”, “conclusive-positive”, or “conclusive-negative”.  The objective function obj[arg1, arg2, … fit] may have few or many arguments depending on the application.  If the objective is known to rely on simulated data, then fitness may also be an argument.Several indices are required to evaluate fitness based on comparison of objective function information.  Because fitness will be computed in iterations, index i is chosen to represent the state of fitness for a given simulation.  Raw data must be indexed.  The index j specifies one of N possible cases.  Index m specifies which simulation information corresponds to the real information.  Finding which simulation data should be compared with real data is, generally, nontrivial.  Raw data from a real measurement is rj.  Raw data from a simulated measurement is si,j,m.Fitness F may be quantified by applying statistics to many comparisons between real and simulated objective outcomes.  The function stat[arg1,arg2, …] is a general way of saying that a statistical function is applied to many arguments.  The arguments in this case are the comparison of outcomes 1 to N so that fitness may be written as Equation 1.Fi+1 = statj=1 to N[comp( obj(rj), obj(si,j,m , Fi))](1)Although one argument is shown in each of the objective functions, there can be several.  The first argument can be replaced with a function.  The compare function can be used as this function if its first argument corresponds to the argument in its respective objective function.  The substitutions are made in Equation 2.  In it, rj must be the first argument of the comparison in the left most objective function, while si,j,m is the first argument of the rightmost objective function.  The second argument in both comparisons of both objective functions must be identical so that the total calculation is unaffected.  This second argument is the reference data.  Note that it can be any data that can be compared to the first argument (i.e., same data type).  Real or simulated data could be used.  The most useful choice for this argument, however, is one that best helps to achieve the objective function.  As simulated data will be easier to create, the argument will be another simulation datum, si,j,m2, where the m index for this simulated data must be differentiated from simulation data in the rightmost objective function's first argument because they may be different.Fi+1 = statj=1 to N[comp(obj(comp(rj,si,j,m2),obj(comp(si,j,m1,si,j,m2),Fi)))] (2)Equation 2 should be implemented from the inside out.  Raw data comes from either a real source or a simulated source and in different types.  Images are often bitmaps, two-dimensional arrays of pixels, where the color of each pixel is described by the red-green-blue (RGB) standard that is represented by 24 bits (i.e., 224 colors).  Radiation data normally is in a vector of time versus counts-per-second (CPS).It is possible to use raw data in Equation 2 but it is more productive to first process the raw data.  There are many different ways to process the images and vectors, but those used in this study are based on gradient information.  The gradient is the change in value of one data point to the next.  One can compute an absolute gradient, relative gradient, the absolute change in gradient, and the relative change in gradient.  An upper and lower threshold is set and, if the gradient between any two points is within these limits, they will be identified.  In the case of an image, the gradient operation generates another image of the equal area having only "YES" or "NO" pixels (i.e., black or white points).  In the case of a vector from neutron data, the gradient operation generates a vector of equal length having only "YES" or "NO" values.  The statistical operation is performed on real and simulated data and is the basis for comparisons used by the objective function.For comparing two images or vectors, n represent the total number of pixels in a bitmap or length of the vector.  The number of items selected from n in the first image or vector is r.  Points selected from the reference image are k.  The second image or vector will have j pixels or points that coincide with those comprising r or will be in the set not selected by the first image or vector, which has n-r points.  This method of comparing two data sets, irrespective of whether one is real or simulated, is a matching problem.  Other ways of comparing two data sets are possible.  For example, rather than determining if one point exactly overlaps another, the result being "YES" or "NO", on could compute and evaluate the distances between points.  This is why in Equation 2 the compare function is not specified.Choosing the indexes m1 or m2 requires that the offset and scale of the images or vectors should be adjusted positively or negatively to optimize the comparison.  This process has considerable value because small differences in images or vectors can be tolerated.  Small differences between data may be unavoidable due to stochastic processes, such as camera vibration or minor clock discrepancies between instruments.The objective function is the crux of the fitness equation.  It uses its arguments in the context of the problem being solved to synthesize a decision.  For an SMS, the “objective” is to use video images and radiation data to detect diversion of SNM.  The basis of detection is the reference data.  Without knowledge to the contrary, it is random chance that the real or simulated data will match the reference data.  An objective criterion can be based on the probability of matching the reference data to the real or simulated data.  If, for example, a reference image matches very well to a real image, then it is likely that the images are of the same object.The probability distribution obtained when drawing from a dichotomous population from n items, r of type 1 and n-r of type 2, without replacement is the hypergeometric.  If the number of items is large and r/n is moderate, then it may be approximated by the binomial distribution.  The ratio r/n is given the symbol (.  The binomial can be approximated [] to circumvent computer overflow errors caused by attempting factorial calculations with large n values (e.g., 100!).  From a binomial distribution approximation, one can compute the probability of matching random points.  As with the compare function, other functions than binomial may be used for the objective function and that is why it is not specified in Equation 2.  The probability of matching random points is given by Equation 3, where ( is the standard normal cumulative distribution function. EMBED Equation.3  (3)As an example, a 320 by 240 bitmap has 76800 pixels.  Using a hypothetical image of that size obtained with a real camera, the gradient operation generates 768 points.  The gradient operating on an equal size image generated from a simulation returns 500 points.  Of these points, 75 coincide with the real points.  For this example, n=76800, r=7680, (=0.10, and k=500.  The probability of obtaining 75 matches or better accidentally is P(Y(75)= 6.8E-5, using the normal approximation.  An objective criterion would be to set the maximum value of P.  If the requirement were that P<.001 then, for this hypothetical example, the real and simulated images would be identified as that appearing in the reference image.  The same process would apply to neutron data except that P would be obtained from the directly from the hypergeometric.The first fitness calculation F1 is estimated by comp(obj (comp(rj,si,j,m2), obj(comp(si,j,m1,si,j,m2))).  Subsequently, fitness is a direct comparison of the objective outcomes.  For the case where both real and simulated objective outcomes are determined to be "Conclusive-Positive", F2 is numerically one, provided it is true that the number one represents perfect agreement.  Additional calculations may produce a variety of ones and zeros such that F lies somewhere between one and zero.5.0 ApproachPhase-I will be to demonstrate the processes illustrated in Figure 1.  It is comprised of two parts.  One is data acquisition through the construction and operation of a laboratory referent and its simulation.  The second is to implement the process of fitness evaluation.  Phase-II will be to improve the SMS simulation by its fitness according to Equation 2.  The ultimate goal is to show that the process can be a basis for rationally ordering fidelity metrics.The referent is under construction at the Atominstitut in Vienna, Austria.  There will be a digital video camera and two neutron detectors connected to the Institute’s network.  A simulation of the referent will be developed, but not from scratch.  Rather, two existing “high fidelity” codes will be integrated.  The existing applications are a 3D engine and nuclear transport model.  The 3D engine will be from ID Software Incorporated.  The transport code used will be MCNP version 4b from Los Alamos Laboratories.  MCNP will run via the network on a separate machine for speed, making the simulation truly distributed.6.0 ResultsThe real situation tested is of a plutonium-beryllium source in a polyethylene drum that normally is kept inside a closed store.  The events simulated are those of the source and container being moved out of the store, inspected, and returned to the store multiple times.  A camera is fixed to the top of the reactor gantry looking down at the door of the store.  A neutron monitor is beside the door.  A visual/mechanical model of the reactor hall, store, and plutonium container, was created.  The plutonium source, radiation transport, and neutron detection was modeled assuming simple isotropic attenuation.  A new program written for this research, named SimFit, implements Equation 2.  Real and simulated data, the objective data, and tolerances are input for SimFit.Illustrative results for video and neutron data are shown in Figures 2 and 3, respectively.  The figures are screen captures from the SimFit program.  Addressing the images left to right, top to bottom, the first image in Figure 2 is that of the real SNM store and the next image is a simulation of it.  The third image is the reference image to which the first two are compared.  Adjacent sets of pixels in each of the first three images that are different by more than 10% are identified using the gradient algorithm.  The first image in the second row is a superposition of the gradient pixels from the real image and the reference image.  The image to its right is a superposition of the gradient pixels from the simulated image and the reference image.  For clarity of explanation, the data in the lower middle frame are not superimposed for the best comparison.  That is, they are superimposed so that the reader can see two distinct sets of data.  It would be normal, anyway, to run an algorithm to optimize the comparison because it is unlikely they would overlay well without such adjustment.  The two windows in the last frame summarize the objective outcomes for real and simulated data, respectively.  To compute fitness, many such outcomes would be compared in a statistical function, according to Equation 2.Similar comments apply to Figure 3 for neutron detector data, except that the movement of the SNM container is included in the data.  Also note that processed CPS data are one-dimensional.Figure 2.  Screen capture of SimFit during analysis of a real (top left) and simulated (top middle) video images against a reference image (top right).  Results of an absolute gradient operation on the real and reference images are superimposed for optimum comparison (lower left).  Gradient data for a simulated image and the reference are superimposed with an offset so that the two sets of data are clear (lower middle).  The objective function for real and simulated data are shown in the lower rightmost frames.  The images are only of the doorway.  The objective operation, therefore, confirms the presence and position of it.  Once this is done, perturbations of the view caused by vibration can be corrected and new objects appearing in subsequent images is more easily detected with the same technique.Figure 3.  Screen capture of SimFit during analysis of a real (top left) and simulated (top middle) neutron detector data against a reference set (top right). Performing an absolute gradient operation with the real and reference vectors returns two sets of one-dimensional data.  The data are presented as short vertical lines indicating the x-coordinate selected.  The reference points selected are below the real points for comparison (lower left).  The next window (lower middle) shows the reference points below the simulated points.  In both comparisons, points selected occur from the jump in the graph caused by movement of the plutonium source close to the detector.  The objective function for real and simulated data are shown in the lower rightmost frames.The real image of the SNM store doorway is identified within the objective function tolerance of 10-3.  For the real image shown in Figure 2, the probability that the real image and reference image match as they do by accident is very close to zero, and the objective function returns a decision of “Conclusive-Positive”.  Because the simulated image is artificially offset from the reference image in the comparison window, the objective function returns “Inconclusive”.  Therefore, the first estimate of fitness is reported in the objective window to be zero. The appearance of SNM containers in subsequent images (not shown) is easily detected.  Subtracting consecutive images, where the container is first absent and then appears, facilitates identification of the containers. Movement of the plutonium source container is identified within a probability of 10-3 using neutron detector data.  For the data shown in Figure 3, both real and simulated outcomes are “conclusive-positive” and so the first estimate of fitness is 1.  7.0 ConclusionsThe results demonstrate that, for the cases under scrutiny, real objects and events can be identified using a methodology based on simulation.  Success is measured by the objective function.  More significant is that results of the objective function for real and simulated data can be compared directly in order to compute the simulation fitness.  Given that results were possible even for the extremely low fidelity models used in the simulation, there is promise for calculating the fitness of increasingly higher fidelity simulations in order to define their validity.The Software Interoperability Standards Organization (SISO) is the body most openly active in the area of validation technology at present.  It sketches a modeling and simulation (M&S) process where fitness is the convergence of application requirements expressed in terms of tolerances with M&S capabilities expressed in terms of fidelity [], what Equation 2 does quantitatively.  Equation 2, however, does not compare application tolerances directly with fidelity metrics to arrive at fitness.  Rather, fitness is a direct function of application requirements and an indirect function of fidelity, via the operation of the simulation.  Fidelity metrics do not directly matter to the fitness calculation.This research has not yet produced fidelity metrics.  However, an important step in deriving the metrics is having a method for evaluating them.  Equation 2 is such a method and relies on rigorous quantitative procedures.  It also links the phases of objective and requirements definition to design, operation, and validation of an SMS.  Because the approach is based on simulation, it is very scaleable to the needs of the simulation or operational software.  The technique doesn't change, only the simulation is improved.8.0 References[]	Meier, Harvey A. et al., “Derivation and Publication of Simulation Fidelity Metrics” Simulation Interoperability Workshop, 97F-SIW-059, Orlando Florida, March 3-7, 1997.[]	Williams, James, “Physical Protection System Design and Evaluation” Extended Synopses, International Conference on Physical Protection of Nuclear Materials: Experience in Regulation, Implementation and Operations” IAEA-CN-68/29, pp 53-54, 1998.[]	Roza, Manfred, “Experience in (Ab) Using the FDM-ISG Fidelity Framework” Fall Software Interoperability Workshop, Orlando Florida, September 12-17, March 14-19, 1999.[]	Blake, Ian F., “Introduction to Applied Probability” Robert E. Krieger Publishing Company Inc., p 259, 1987.[]	Gross, David C., "Report from the Fidelity Implementation Study Group Redacted" Spring Interoperability Workshop, 99S-SIW-167, September 12-17, 1999.9.0 Author BiographiesVAUGHN STANDLEY is a doctoral student at the Atominstitut and a Safeguards Inspector with the International Atomic Energy Agency (IAEA) in Vienna, Austria.HELMUTH BOECK is an associate professor of nuclear engineering and manager of the 250 kW TRIGA reactor facility at the Atominstitut. He is a consulting expert to the IAEA in the field of safety, management, and utilization of research reactors, is president of the Austrian Nuclear Society, and is a member of the American Nuclear Society.REINHARD VIERTL is a full professor of applied statistics at the Vienna University of Technology.  He is a Fellow of the Royal Statistical Society of London and is the founder of the Austrian Bayesian Society. EMBED MSDraw.Drawing.8.1   EMBED Word.Picture.8  