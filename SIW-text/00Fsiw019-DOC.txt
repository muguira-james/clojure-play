Simulation Conceptual Model Development Issues and Implications for Reuse of Simulation Components*Dale K. PaceThe Johns Hopkins University Applied Physics Laboratory11100 Johns Hopkins RoadLaurel, Maryland 20723-6099(240) 228-5650; (240) 228-5910 (FAX)dale.pace@jhuapl.eduKeywords:  conceptual model, validation, fidelity, simulation reuseABSTRACT:  A simulation conceptual model is a simulation developer’s way of translating modeling requirements into a detailed design framework, from which the software, hardware, networks, and systems/equipment that will make up the simulation can be built.  Recommended methods for developing and documenting a simulation conceptual model have been presented at previous Simulation Interoperability Workshops (SIWs), at Summer Computer Simulation Conferences (SCSCs), and in DoD’s updated Recommended Practices Guide (RPG) for simulation verification, validation, and accreditation (VV&A) .  This paper examines issues that have been raised about suggested methods for conceptual model development and documentation.  Simulation conceptual model development methods have significant implications for simulation reuse.  They are explored  in relation  to current High Level Architecture (HLA) guidelines.IntroductionSimulation applications vary widely.  They include legacy simulations, their modifications, and new simulations.  They may involve live and virtual forces as well as constructive ones. Previously published ideas and recommendations about simulation conceptual models were more general and less prescriptive than some desire. This occurred because these ideas and recommendations were intended to provide guidance for the full spectrum of simulation applications.The conceptual model is a simulation developer’s way of translating modeling requirements into a detailed design framework, from which the software, hardware, networks, and systems/equipment that will make up the simulation can be built, modified, or assembled.  This paper provides a brief summary of previously published ideas about simulation conceptual model development and documentation [1]-[6]. The paper discusses issues raised about these ideas and recommendations, then addresses implications about simulation reuse resulting from ideas about conceptual model development and documentation.Conceptual Model DevelopmentA simulation conceptual model has three components:  1) the simulation context which provides authoritative information about the domain which the simulation is to address; 2) the simulation concept with its mission space and its simulation space aspects; and 3) the simulation elements.  Figure 1 (located at the end of the paper) illustrates the relationship of the three components.A simulation element consists of the information describing concepts for an entity, a composite or collection of entities, or process which is represented within a simulation.  A simulation element includes assumptions, algorithms, characteristics, relationships (especially interactions with other things within the simulation), data, etc. that identify and describe that item’s possible states, tasks, events, behavior and performance, parameters and attributes, etc.  A simulation element can address a complete system, a subsystem, an element within a subsystem, or even a fundamental item (such as an atom).  It can also address composites of systems (such as a ship with its collection of sensors, weapons, etc.).  It should be noted that a person, part of a person (such as a hand), or a group of people can likewise be addressed by a simulation element.  A simulation element can also address a process such as environmental effects on sensor performance.The simulation concept describes the simulation developer’s concept for the entire simulation application (all the federates and other pieces in a distributed simulation, everything that comprises the simulation) and explains how the simulation developer expects to build a simulation that can fully satisfy user defined requirements.  The simulation concept has to address both simulation space (simulation operational and functional capability) and mission space (representational capability of the simulation, which is described mainly by simulation elements).  Simulation space characteristics can range from identification of specific kinds of computing systems (hardware and operating systems that the simulation must run upon) and timing constraints so that real systems can be part of the simulation to simulation control capabilities that allow the simulation to be stopped, backed-up in time, and restarted, or that allow parameter values to be changed by controller fiat during simulation execution.The simulation context provides “authoritative” information about the domain which the simulation is to address.  Often this part of the conceptual model is merely a collection of pointers and references to sources that define behaviors and processes for things that will be represented within the simulation.  Special care, especially for distributed simulations, must be used when algorithms are taken from more than one source to ensure that sources do not employ contradictory assumptions or factors (such as different models for the shape of the earth, differences in characterizing the environment, etc.).  The information contained in the simulation context establishes boundaries on how the simulation developer can properly build the simulation.Conceptual model decomposition determines what simulation elements are in the conceptual model.  This determines the scope of representation in the simulation and the discernible levels of the simulation.  These six items discussed below can be used as a checklist in conceptual model decomposition as the conceptual model is being developed.  Using this rationale will help a conceptual model to be complete and coherent.There should be a specific simulation element (parameter, entity, etc.) for every item (parameter, entity, etc.) specified for representation in the simulation by simulation requirements.There should be a specific simulation element (parameter, entity, etc.) for every item (entity, task, parameter, state, etc.) of potential assessment interest related to the purpose of the simulation.There should be “real world” counterparts (objects, parameters for which data exist or could exist, etc.) for every simulation element as far as possible.  The potential impact of data, and metadata structures, on simulation elements and the simulation conceptual model should not be underestimated.Wherever possible, the simulation elements should correspond to “standard” and widely-accepted decomposition paradigms to facilitate acceptance of the conceptual model and effective interaction (including reuse of algorithms and other simulation components) with other simulation endeavors.Simulation elements required for computational considerations (such as an approximation used as a surrogate for a more desirable parameter which is not computationally viable) that fail to meet any of the previously stated rationale should be used only when absolutely essential.There should not be extraneous simulation elements.  Elements not directly related to specific items in the simulation requirements, not implied directly by potential assessment issues, and without a specific counterpart in the real world or in standard decomposition paradigms should not be included in the simulation conceptual model.  Every extraneous simulation element is an unnecessary source of potential simulation problem.Conceptual Model DocumentationA simulation conceptual model documentation should employ the scientific paper approach.  Nine items are suggested for description of a portion of the conceptual model (such as a simulation element) or of the entire conceptual model in the scientific paper approach to documenting a simulation conceptual model:  Conceptual Model Portion Identification; Principal Simulation Developer Point(s) of Contact (POCs) for the Conceptual Model (or part of it); Requirements and Purpose; Overview; General Assumptions; Identification of Possible States, Tasks, Actions, and Behaviors, Relationships and Interactions, Events, and Parameters and Factors for Entities and Processes being described; Identification of Algorithms; Simulation Development Plans; and Summary and Synopsis.  This list of items is functionally equivalent to the ten items in the generic content guidelines from IEEE/EIA 12207 for describing a planned or actual function, design, performance or process: -- the ten items are:  date of issue and status, scope, issuing organization, references, context, notation for description, body, summary, glossary, and change history [7].IssuesCMMS RelationshipThe Defense Modeling and Simulation Office (DMSO) is leading a DoD-wide effort to provide an integrated framework and toolset for developing Conceptual Models of the Mission Space (CMMS), which are viewed as “the first abstraction of the real world and a frame of reference for simulation development.” [8]  CMMS is expected to provide simulation-independent warfighters’ description of real world processes, entities, environments, interactions, and relationships.  Common semantics and syntax, data interchange formats, and model libraries  to enhance simulation interoperability and reuse, to ensure use of authoritative information sources, and to manage knowledge acquisition and repositories.  CMMS, HLA, and Data Standards are the three components of the DoD Modeling and Simulation (M&S) Common Technical Framework.Relative to the simulation conceptual model ideas presented in this paper, CMMS materials can provide much of the simulation context and may provide models which can be used in part or totally for some simulation elements.  Experience to date indicates that the general kind of models likely to be found in a repository may need to be supplemented with additional information for use in the specific application of a simulation [9].  Certainly any models in a repository will need to be adapted for the particular requirements of a specific simulation.Simulation Development ParadigmMany modern simulation developments employ iterative development paradigms, such as spiral, rapid prototyping, etc.  How does the idea of an explicit conceptual model work in that kind of development?In iterative software development, one repetitively cycles through specification and design (and sometimes code) until mature products evolve.  Similar cycling through versions of the conceptual model is also possible – as it evolves to more completely capture how the developer intends to satisfy simulation requirements so that improved specifications for the simulation may be written.  The main challenge is a configuration management one so that there will be explicit linkage between the conceptual model version and the specifications, design, and implementation (code) related to it.  Without an explicit tie of requirements through the evolving conceptual model to the evolving specifications and related design, it will be difficult to have a high degree of assurance that the iteratively developed design fully satisfies simulation requirements.Cost of an Explicit Conceptual ModelA number of questions have been raised about the cost of developing an explicit conceptual model for a simulation and maintaining documentation for it, particularly by those developing simulations for which an explicit conceptual model is not identified specifically as a deliverable.Modern software development ideas place significant emphasis upon processes that facilitate quality design and implementation, understanding that it is far better to prevent faults or detect and correct them earlier instead of later.  Development of an explicit conceptual model for a simulation, and maintaining its documentation, is an important factor in removing requirements-induced faults and in minimizing design-induced faults.  The author believes that savings from such more than outweigh the cost of conceptual model development.  However, the limited amount of empirical information related to this subject that has been reported in the simulation literature prevents solid conclusions in this area.One Conceptual Model or Many?The ideas presented in this paper have a single conceptual model for a simulation.  However, the same development processes and kind of documentation should be done for simulation elements (parts of a conceptual model) as for the entire conceptual model.  It has little functional impact whether one calls the part of a simulation conceptual model that describes a simulation element a separate conceptual model or merely part of the simulation conceptual model, but it can cause confusion in the community.  It is better to use the terminology of this paper (one conceptual  model for a simulation) since that is the terminology of the updated DoD Recommended Practices Guide for VV&A.  There is an additional reason for adopting this terminology.  By connecting the conceptual model part (description of a simulation element) to the entire conceptual model of the simulation, it is more likely that the intended application for the simulation will be understood when that conceptual model part is evaluated than might be the case if the conceptual model for the part did not have such an explicit tie to the expected application.Conceptual Model Reuse ImplicationsSoftware reuse has been a promising approach since the 1960s, but as of the mid-1990s that promise was still mainly postulated and had not been proven by empirical studies [10] in spite of substantial efforts to facilitate software reuse.  Those substantial efforts included the DoD Software Technology for Adaptable, Reliable Systems (STARS) and Software Reuse Initiatives, NASA’s Software Engineering Laboratory (SEL) and Repository Based Software Engineering (RBSE) program, Europe’s Eureka Software Factory and the European Programme for Research in Information Technology (Esprit)’s Software Evolution and Reuse (SER) project, and Japan’s software factories and Fifth Generation Computing Project [11]-[14].  And in spite of some success, such as reported in the Software Reuse Executive Primer [15], “systematic reuse of software has not universally delivered significant improvements in quality or productivity” [16].  This applies to reuse of simulations as much as it applies to reuse of other kinds of software.Reuse involves use of knowledge or artifacts from existing systems to build new ones.    “For models and simulation, reuse applies to a range of potential products from knowledge bases/data sources to architectures/designs through actual software code/components” [17].  Even “requirements and conceptual model specification” qualify as “reusable objects” [18].  A mid-1990s GAO report to Congress listed eight items as examples of reusable software components:  1) knowledge and experience, 2) software tools, 3) executable programs, 4) code, 5) documentation, 6) software requirements, 7) designs and architectures, and 8)test data and test plans [19].A number of principles for effective reuse of software seem to be widely recognized.  These are summarized here, and the relationship of a quality, explicit simulation conceptual mode to them is discussed.Reuse Requires More Than Technical CapabilitiesEffective reuse of software typically requires a number of organizational changes and modifications to business culture as well as significant up front investment, with the payoff usually coming several years downstream.  Often the extra cost associated with reuse cannot be recouped within a single project, but must be spread across a number of projects.  The impediments to reuse of Defense software and simulations arising from these facts is widely recognized.  Resources must be allocated to acquire, build, maintain, and upgrade domain knowledge, architectures, and support tools [15].  Rewards for software engineers have to be established for designing and developing software for reuse.  Legal issues about rights to use different resources have to be faced [14].Reuse of simulations and simulation components faces the same non-technical challenges as general software reuse.  The explicit tie of a conceptual model part to specific simulation requirements creates a potential for reuse of such simulation components whenever the requirement applies.  This creates a potential market incentive for conceptual model parts, and for articulation of requirements associated with them, that is an important consideration in simulation reuse.Technical Aspects of ReuseTechnical issues include standards for representation and interfaces, tools, integration of formal and informal modeling and representational methodologies, documentation (content and currency), and all aspects of configuration management.It has been observed that software engineering, as compared to other engineering disciplines, “is disproportionately design engineering.  Thus, the tooling, manufacturing and materials costs which provide economic incentives for reuse in physical engineering disciplines are not as easily quantifiable . . . . in software engineering.” [20]  This is, perhaps, one reason “the literature indicates that a higher level of abstraction gives greater potential for reuse” [14].  It also places great importance on a quality, explicit conceptual model because it is the highest level of abstraction for the simulation other than the requirements.  In this context, use of “formal methods can support the reuse of knowledge which is created within a software development process” [21].Reuse can tie a product or process to past constructs, and may inhibit adoption of newer and better capabilities.  This is, in part, what happen to Japanese software factories, which fell from the “most productive and highest quality software industry in the 1980s”  to a position that is “not competitive in today’s world marketplace” [22].  By focusing simulation reuse at the conceptual model level, one is not tied to past approaches to implementation (hardware or software) and can adapt the reusable component to contemporary capabilities.  Explicit and properly documented conceptual models would facilitate the software renovation factory approach toward automatic modification (updating) of legacy simulations [23].  Unfortunately, there are few tools yet available to facilitate and automate reuse of components from early in the development lifecycle [24], although there are contemporary efforts to develop such capabilities [25].Potential Reuse ProblemsMany believe that the biggest obstacle to software (and simulation) reuse has been, and may continue to be, the “not invented here” syndrome [15].  The importance of very restricted domains for successful reuse of software is a common theme in the reuse literature [27].  These two points provide an important context and perspective needed when addressing potential reuse problems.Potential for inappropriate reuse is a major concern expressed by many writers.  Potential inappropriate reuse ranges from modifying user requirements in order to accommodate limitations of reused components to Ariane 5-like disasters, in which a satellite-launch costing more than half-a-billion dollars failed because of software reused from Ariane 4 [26].  The potential for inappropriate reuse applies as much to HLA distributed simulations (where the reused components are simulations, or federates in HLA parlance) as it does to reuse of simulation components (such as a requirement or specification, algorithm, or module) in building or modifying a stand-alone simulation.As indicated earlier, reuse can stifle innovation in improvement [17].  It is also possible that reuse will fail to reduce cost of the software or simulation project, will not result in a workable product sooner, and may have more defects than would be expected if one developed the product from scratch.[16]  The quantitative benefits reported for reuse come from reuse successes, and even then may not give the whole cost, schedule, and quality story for the endeavor.  The “losses” associated with failed reuse attempts are seldom reported.  This is why knowledgeable authorities, such as the chair of the IEEE Technical Council on Software Engineering, Committee on Software Reuse, claim that empirical evidence about the real overall “benefit” of software reuse is, at best,  scanty [10].It can be argued that reuse of simulation conceptual models or parts of conceptual models, and the requirements related to them, is less subject to these potential abuses than may be the case for other kinds of software development artifacts.  It can also be argued that developing and documenting a conceptual model, or part of one, in the manner recommended [1 & 5] will produce a simulation component that facilitates reuse without requiring expenditure of additional resources beyond that required for quality development apart from reuse considerations.  As of yet, there are no case studies to support or refute these contentions.  It is hoped that the literature will begin to contain evidence that would allow these points to be evaluated on the basis of documented simulation development experience.ConclusionSimulation conceptual model development and documentation has been reviewed and associated issues have been discussed.  The impact of an explicit, quality simulation conceptual model on simulation reuse has been explored.  It is suggested that reuse of a simulation conceptual model or its parts, and associated requirements, has high potential reuse value and is less vulnerable to potential reuse abuses than may be the case with other simulation artifacts.  The need for more empirical date about this has been stressed.References[1]  Special Topic:  Conceptual Model, in the updated DoD Recommended Practices Guide for VV&A [available at the DMSO website:   HYPERLINK http://www.dmso.mil] http://www.dmso.mil].[2]  Dale K. Pace, “Development and Documentation of a Simulation Conceptual Model,” Proceedings of the Fall 1999 Simulation Interoperability Workshop, March 15-19,1999.[3]  Dale K. Pace, “Conceptual Model Descriptions,” Proceedings of 1999 Summer Computer Simulation Conference, July 12-14, 199, Chicago, IL.[4]  Dale K. Pace, “Development and Documentation of a Simulation Conceptual Model,” 99 Fall Simulation Interoperability Workshop Papers, September 1999.[5]  Dale K. Pace, “Simulation Conceptual Model Development,” Proceedings of the Spring 2000 Simulation Interoperability Workshop, March 26-31, 2000, Orlando, FL.[6]  Dale K. Pace, “Simulation Conceptual Model Issues:  Development Methods (Part 1), Interaction with Simulation Requirements (Part 2), and Simulation Development Costs and V&V Costs (Part 3),” Proceedings of the 2000 Summer Computer Simulation Conference, July 16-20, 20000, Vancouver, British Columbia, Canada.[7] 	Reed Sorensen, “Software Standards:  Their Evolution and Current State,” CrossTalk:  The Journal of Defense Software Engineering, Vol. 12 No. 12 (December 1999), pp. 21-25.[8] 	Conceptual Model of the Mission Space (CMMS) [materials available at the DMSO website:.  HYPERLINK http://www.dmso.mil] http://www.dmso.mil ].[9]  Thomas H. Johnson, “Mission Space Model Development, Reuse and the Conceptual Models of the Mission Space Toolset” 98 Spring Simulation Interoperability Workshop Papers, March 1998, Vol. 2, pp. 893-900.[10]  William B. Frakes, “Software Reuse Empirical Studies,” Ch. 6 in Software Reusability (Wilhelm Schafer, Ruben Prieto-Diaz, and Masao Matsumoto, eds.), New York:  Ellis Horwood, 1994, pp. 153-160.[11]  Ruben Prieto-Diaz, “Historical Overview,” Ch. 1 in Software Reusability (Wilhelm Schafer, Ruben Prieto-Diaz, and Masao Matsumoto, eds.), New York:  Ellis Horwood, 1994, pp. 1-16.[12]  Michael A. Cusumano, Japan’s Software Factories,  New York:  Oxford University Press, 1991.[13]  Ivan Aaen, Peter Bottcher, and Lars Mathiassen, The Software Factory, Information Systems Research Seminar in Scandinavia (IRIS), June 1997  [available at:  HYPERLINK http://iris.adb.gu.se/conference/iris20/39.htm] http://iris.adb.gu.se/conference/iris20/39.htm].[14]  Urban Nulden, The Why, What, and How of Reuse in Software Development, Information Systems Research Seminar in Scandinavia (IRIS), June 1997   [available at:  HYPERLINK "http://iris.adb.gu.se/conference/iris20/3.htm#E12E27" http://iris.adb.gu.se/conference/iris20/3.htm#E12E27].[15]  Software Reuse Executive Primer, DoD Software Reuse Initiative Program Management Office, April 15, 1996 [available at  HYPERLINK "http://dii-sw.ncr.disa.mil/reuseic/pol-hist/primer/" http://dii-sw.ncr.disa.mil/reuseic/pol-hist/primer/ ].[16]  Douglas C. Schmidt, “Why Software Reuse has Failed and How to Make It Work for You,” C++ Report, January 1999 [available at:  HYPERLINK http://www.cs.wustl.edu/~schmidt/reuse-lessons.html http://www.cs.wustl.edu/~schmidt/reuse-lessons.html ].[17]  DDR&E Technical Advisory Team on Reuse Report, May 1996.[18]  Masao Matusumoto, “The SEA/I Environment,” Section 4 of Ch. 5 (Tools and Environments) in Software Reusability (Wilhelm Schafer, Ruben Prieto-Diaz, and Masao Matsumoto, eds.), New York:  Ellis Horwood, 1994, pp. 1-16.[19]  GAO/IMTEC-93-16, Issues Facing Software Reuse, January 28, 1993.  [accessible at  HYPERLINK http://dii-sw.ncr.disa.mil/reuseic/pol-hist/history/gao_rep.htm] http://dii-sw.ncr.disa.mil/reuseic/pol-hist/history/gao_rep.htm].[20]  Results from IEEE Reuse Steering Committee Principles of Software Reuse Study Group, Reuse ’97, July 22nd-24th, 1997 [available at:   HYPERLINK http://www.nplace.wvhf.org/reuse97/Dkane/index.htm] http://www.nplace.wvhf.org/reuse97/Dkane/index.htm].[21]  Joachim Cramer, Ernst-Erich Doberkat, and Michael Goedicke, “Formal Methods,” Ch. 4 in Software Reusability (Wilhelm Schafer, Ruben Prieto-Diaz, and Masao Matsumoto, eds.), New York:  Ellis Horwood, 1994, pp. 79-111.[22]  Mitsuru Ohba and Hironobu Nagano, “Section 1:  Fall and Decline of Japanese Software Factory,” A Global Software Marketplace:  Virtual or Real [accessible at  HYPERLINK http://www.sel.cs.hiroshima-cu.ac.jp/~ohba/scals.htm] http://www.sel.cs.hiroshima-cu.ac.jp/~ohba/scals.htm].[23]  Alex Sellink and Chris Verhoef, Toward Automated Modification of Legacy Assets [accessible at  HYPERLINK http://adam.wins.uva.nl/~x/aml/aml.htm] http://adam.wins.uva.nl/~x/aml/aml.htm].[24]  Jacob Cybulski, Ralph Neal, Anthony Kram, and Jeffrey Allen, “Reuse of Early Life-cycle Artifacts:  Workproducts, Methods, and Tools,” Annuals of Software Engineering, 5 (1998), pp. 227-251.[25]  W. Lam, “A Case Study of Requirements Reuse Through Product Families,” Annuals of Software Engineering, 5 (1998), pp. 253-277.[26]  John Doyle, “Virtual Engineering:  Toward a Theory for Modeling and Simulation of Complex Systems,” Appendix B of Volume 9 Modeling and Simulation, Technology for the United States Navy and Marine Corps 2000-2035:  Becoming a 21st-Century Force, Panel on Modeling and Simulation, Committee on Technology for Future Naval Forces, Naval Studies Board, Commission on Physical Sciences, Mathematics, and Applications, National Research Council – published by National Academy Press, Washington, D. C., 1997., pp. 158-159.[27]  Michael Scheinholtz, Manufacturing and Quality [draft paper, available at  HYPERLINK http://www.lb.cs.cmu-edu/~koopman/des_s99/manufacturing_quality/index.htm/] http://www.lb.cs.cmu-edu/~koopman/des_s99/manufacturing_quality/index.htm/].About the AuthorDale K. Pace, a member of the Principal Professional Staff of The Johns Hopkins University Applied Physics Laboratory, is a specialist in operations research, modeling and simulation, analysis, and wargaming.  Dr. Pace is a member of the Defense Modeling and Simulation Office (DMSO) Verification, Validation, and Accreditation (VV&A) Technical Working Group and its VV&A Technical Support Team, with particular responsibilities in the area of conceptual model development.  He was the initial lead for validation in the independent verification and validation (IV&V) team for Wargame 2000 and is Simulation’s Associate Editor for Validation. EMBED PowerPoint.Show.8  * The work reported in this paper was performed under sponsorship of the Defense Modeling and Simulation Office (DMSO), but its views are those of the author and should not be construed to represent views of DMSO or of any other organization or agency, public or private.