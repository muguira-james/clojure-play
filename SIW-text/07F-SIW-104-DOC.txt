Clarifying Validation for Agent Based SimulationsLisa Jean MoyaWernerAnderson, Inc.6596 Main Street, Gloucester, VA 23061804-694-3173 HYPERLINK "mailto:lmoya@werneranderson.com" lmoya@werneranderson.comSimone YoungbloodModeling and Simulation Coordination Office703-824-3436 HYPERLINK "mailto:simone.youngblood@jhuapl.edu" simone.youngblood@jhuapl.eduKeywords:agent-based simulation, validation, validation methodology, verification, V&V, VV&AABSTRACT:  Validation has long been recognized as critical to the credible use of any model and simulation.  The U.S. Department of Defense, Department of Energy, American Institute of Aeronautics and Astronautics, American Society of Mechanical Engineers, and the U.K. Ministry of Defence among others, all have a definition for validation.  While these definitions differ slightly in language and application, each has three main components:  the thing to be simulated, the simulation model, and a bounding principle.  However, even with these common concepts within the definitions, these terms are not widely understood.  In a recent workshop on the validation requirements for agent based simulations in military applications, it became clear that elaboration of validation terms was required before the definition could be applied to develop an agent based simulation validation framework.  This paper discusses validation in terms of the prevailing definitions and suggests ways to interpret the validation definition for agent based simulations.IntroductionAlthough discrete event and time-stepped models dominate military simulations, multi-agent models providing human behavior representations are of growing interest to the military community (c.f.  ADDIN REFMGR.CITE <Refman><Cite><Author>Cares</Author><Year>2002</Year><RecNum>66</RecNum><IDText>The use of agent-based models in military concept development</IDText><MDL Ref_Type="Conference Proceeding"><Ref_Type>Conference Proceeding</Ref_Type><Ref_ID>66</Ref_ID><Title_Primary>The use of agent-based models in military concept development</Title_Primary><Authors_Primary>Cares,J.R.</Authors_Primary><Date_Primary>2002</Date_Primary><Keywords>models</Keywords><Keywords>simulation</Keywords><Reprint>In File</Reprint><Start_Page>935</Start_Page><End_Page>939</End_Page><Periodical>Proceedings of the 2002 Winter Simulation Conference</Periodical><Title_Secondary>The 2002 Winter Simulation Conference</Title_Secondary><ZZ_JournalFull><f name="System">Proceedings of the 2002 Winter Simulation Conference</f></ZZ_JournalFull><ZZ_WorkformID>12</ZZ_WorkformID></MDL></Cite><Cite><Author>Marine Corps Warfighting Laboratory</Author><Year>2006</Year><RecNum>86</RecNum><IDText>Project Albert</IDText><MDL Ref_Type="Electronic Citation"><Ref_Type>Electronic Citation</Ref_Type><Ref_ID>86</Ref_ID><Title_Primary>Project Albert</Title_Primary><Authors_Primary>=Marine Corps Warfighting Laboratory</Authors_Primary><Date_Primary>2006/7/18</Date_Primary><Reprint>In File</Reprint><Periodical>http://projectalbert.org</Periodical><Date_Secondary>2007/1/17</Date_Secondary><ZZ_JournalStdAbbrev><f name="System">http://projectalbert.org</f></ZZ_JournalStdAbbrev><ZZ_WorkformID>34</ZZ_WorkformID></MDL></Cite></Refman>[1,2]).  The hope is that the simple rule structures of agent based simulations (ABSs) will exhibit emergent behavior that can capture the complexities of the battle space environment.  Complex systems, emergent behavior, and rapid update cycles make validation simulations in this environment particularly challenging.  Standard approaches to validation fall short of achieving the desired results for the complex behaviors generated human behavior models and ABSs.  While results validation and face validation are often used methods, the difficulties with this approach for simulations having sensitivity to initial conditions, or chaotic/emergent effects, and the difficulties with validating human based representation models is well known (c.f.  ADDIN REFMGR.CITE <Refman><Cite><Author>Harmon</Author><Year>2002</Year><RecNum>178</RecNum><IDText>Validation of Human Behavior Representations</IDText><MDL Ref_Type="Conference Proceeding"><Ref_Type>Conference Proceeding</Ref_Type><Ref_ID>178</Ref_ID><Title_Primary>Validation of Human Behavior Representations</Title_Primary><Authors_Primary>Harmon,S.Y.</Authors_Primary><Authors_Primary>Hoffman,C.W.D.</Authors_Primary><Authors_Primary>Gonzalez,A.J.</Authors_Primary><Authors_Primary>Knauf,R.</Authors_Primary><Authors_Primary>Barr,V.B.</Authors_Primary><Date_Primary>2002</Date_Primary><Keywords>BEHAVIOR</Keywords><Keywords>validation</Keywords><Reprint>In File</Reprint><Start_Page>B3-1</Start_Page><End_Page>B3-34</End_Page><Periodical>Proceedings of Foundations for V&amp;V in the 21st Century Workshop (Foundations &apos;02)</Periodical><Title_Secondary>Foundations for V&amp;V in the 21st Century Workshop (Foundations &apos;02)</Title_Secondary><Date_Secondary>2002/10/22</Date_Secondary><Misc_2>The Johns Hopkins University Applied Physics Laboratory, Laurel, Maryland (USA)</Misc_2><ZZ_JournalFull><f name="System">Proceedings of Foundations for V&amp;V in the 21st Century Workshop (Foundations &apos;02)</f></ZZ_JournalFull><ZZ_WorkformID>12</ZZ_WorkformID></MDL></Cite><Cite><Author>Defense Modeling and Simulation Office</Author><Year>2004</Year><RecNum>59</RecNum><IDText>The Verification, Validation, and Accreditation Recommended Practices Guide</IDText><MDL Ref_Type="Book, Whole"><Ref_Type>Book, Whole</Ref_Type><Ref_ID>59</Ref_ID><Title_Primary>The Verification, Validation, and Accreditation Recommended Practices Guide</Title_Primary><Authors_Primary>=Defense Modeling and Simulation Office</Authors_Primary><Date_Primary>2004</Date_Primary><Keywords>verification</Keywords><Keywords>validation</Keywords><Keywords>accreditation</Keywords><Reprint>In File</Reprint><ZZ_WorkformID>2</ZZ_WorkformID></MDL></Cite><Cite><Author>Akst</Author><Year>2006</Year><RecNum>65</RecNum><IDText>Musings on verification, validation, and accreditation (VV&amp;A) of analytical combat simulations</IDText><MDL Ref_Type="Journal"><Ref_Type>Journal</Ref_Type><Ref_ID>65</Ref_ID><Title_Primary>Musings on verification, validation, and accreditation (VV&amp;A) of analytical combat simulations</Title_Primary><Authors_Primary>Akst,George</Authors_Primary><Date_Primary>2006</Date_Primary><Keywords>accreditation</Keywords><Keywords>simulation</Keywords><Keywords>validation</Keywords><Keywords>verification</Keywords><Reprint>In File</Reprint><Start_Page>9</Start_Page><End_Page>11</End_Page><Periodical>Phalanx</Periodical><Volume>39</Volume><Issue>3</Issue><Pub_Place>Alexandria, VA</Pub_Place><Publisher>Military Operations Research Society</Publisher><ISSN_ISBN>0195-1920</ISSN_ISBN><ZZ_JournalFull><f name="System">Phalanx</f></ZZ_JournalFull><ZZ_WorkformID>1</ZZ_WorkformID></MDL></Cite><Cite><Author>Moya</Author><Year>2007</Year><RecNum>67</RecNum><IDText>A Visualization Technique to Support Human Behavior Representation Model Rule Validation</IDText><MDL Ref_Type="Journal"><Ref_Type>Journal</Ref_Type><Ref_ID>67</Ref_ID><Title_Primary>A Visualization Technique to Support Human Behavior Representation Model Rule Validation</Title_Primary><Authors_Primary>Moya,Lisa Jean</Authors_Primary><Authors_Primary>McKenzie,Frederick D.</Authors_Primary><Authors_Primary>Nguyen,Quynh-Anh H.</Authors_Primary><Date_Primary>2007</Date_Primary><Keywords>BEHAVIOR</Keywords><Keywords>model</Keywords><Keywords>simulation</Keywords><Keywords>validation</Keywords><Reprint>In File</Reprint><Periodical>Simulation &amp; Gaming: An Interdisciplinary Journal of Theory, Practice, and Research</Periodical><Volume>A symposium issue, submitted October 2006, revised February 2007, accepted March 2007</Volume><Issue>Artificial Intelligence, Intelligent Agents, and Simulation Gaming, a special issue</Issue><ZZ_JournalFull><f name="System">Simulation &amp; Gaming: An Interdisciplinary Journal of Theory, Practice, and Research</f></ZZ_JournalFull><ZZ_WorkformID>1</ZZ_WorkformID></MDL></Cite></Refman>[3-6]).  A methodology is needed that will provide effective validation for these complex behavior models.  The Marine Corps Combat Development Center (MCCDC) Operations Analysis Division (OAD) commissioned an Agent Based Verification, Validation, & Accreditation Framework Study to develop general, institutionally acceptable processes and criteria for assessing the validity of agent-based simulations used as part of DoD analyses.  Toward this effort a workshop was held to obtain inputs and active participation from the wider analytical community.  The purpose of the workshop was to obtain from leading validation and agent based simulation practitioners and academics their thoughts on validation techniques applicable to agent based simulations.  The focus was to improve the vernacular of validation as it applies to agent based simulations in support of analytical applications, in particular irregular warfare, focusing on validation principles and the practical rather than process using analytical applications, test cases, and the DoD to bound the problem.  At the workshop and in subsequent work, it was clear that clarity in how to apply and interpret the definition of validation was required.  Other papers identify some of the requirements for a validation framework of agent based simulations  ADDIN REFMGR.CITE <Refman><Cite><Author>Moya</Author><Year>2007</Year><RecNum>234</RecNum><IDText>Towards a methodology for validating emergent behavior simulations</IDText><MDL Ref_Type="Conference Proceeding"><Ref_Type>Conference Proceeding</Ref_Type><Ref_ID>234</Ref_ID><Title_Primary>Towards a methodology for validating emergent behavior simulations</Title_Primary><Authors_Primary>Moya,Lisa Jean</Authors_Primary><Authors_Primary>Weisel,Eric W.</Authors_Primary><Date_Primary>2007</Date_Primary><Keywords>agent-based simulation</Keywords><Keywords>BEHAVIOR</Keywords><Keywords>simulation</Keywords><Keywords>validation</Keywords><Keywords>validation methology</Keywords><Keywords>verification</Keywords><Reprint>In File</Reprint><Periodical>European Simulation Interoperability Workshop</Periodical><Volume>07E-SIW-055</Volume><ZZ_JournalFull><f name="System">European Simulation Interoperability Workshop</f></ZZ_JournalFull><ZZ_WorkformID>12</ZZ_WorkformID></MDL></Cite></Refman>[7], the theoretical foundations for an architecture supporting validity assessments  ADDIN REFMGR.CITE <Refman><Cite><Author>Weisel</Author><Year>2007</Year><RecNum>235</RecNum><IDText>Towards an Architecture for Distributed Component-Based Simulation</IDText><MDL Ref_Type="Conference Proceeding"><Ref_Type>Conference Proceeding</Ref_Type><Ref_ID>235</Ref_ID><Title_Primary>Towards an Architecture for Distributed Component-Based Simulation</Title_Primary><Authors_Primary>Weisel,Eric W.</Authors_Primary><Authors_Primary>Moya,Lisa Jean</Authors_Primary><Date_Primary>2007</Date_Primary><Keywords>agent-based simulation</Keywords><Keywords>BEHAVIOR</Keywords><Keywords>simulation</Keywords><Keywords>validation</Keywords><Keywords>validation methology</Keywords><Keywords>verification</Keywords><Keywords>architecture</Keywords><Reprint>In File</Reprint><Periodical>European Simulation Interoperability Workshop</Periodical><Volume>07E-SIW-057</Volume><ZZ_JournalFull><f name="System">European Simulation Interoperability Workshop</f></ZZ_JournalFull><ZZ_WorkformID>12</ZZ_WorkformID></MDL></Cite></Refman>[8], and the beginnings of a taxonomy of agent simulations  ADDIN REFMGR.CITE <Refman><Cite><Author>Moya</Author><Year>2007</Year><RecNum>192</RecNum><IDText>Towards a Taxonomy of Agents and Multi-Agent Systems</IDText><MDL Ref_Type="Conference Proceeding"><Ref_Type>Conference Proceeding</Ref_Type><Ref_ID>192</Ref_ID><Title_Primary>Towards a Taxonomy of Agents and Multi-Agent Systems</Title_Primary><Authors_Primary>Moya,Lisa Jean</Authors_Primary><Authors_Primary>Tolk,Andreas</Authors_Primary><Date_Primary>2007</Date_Primary><Keywords>agent</Keywords><Keywords>agents</Keywords><Keywords>multi-agent systems</Keywords><Keywords>SYSTEMS</Keywords><Keywords>taxonomy</Keywords><Keywords>distributed simulation</Keywords><Keywords>simulation</Keywords><Keywords>MECHANISM</Keywords><Reprint>In File</Reprint><Periodical>Proceedings of the 2007 Spring Simulation Conference: Agent Directed Simulation</Periodical><Title_Secondary>Agent Directed Simulation &apos;07</Title_Secondary><Issue>ADS-10</Issue><Date_Secondary>2007/3/26</Date_Secondary><Misc_2>Norfolk, VA</Misc_2><ZZ_JournalFull><f name="System">Proceedings of the 2007 Spring Simulation Conference: Agent Directed Simulation</f></ZZ_JournalFull><ZZ_WorkformID>12</ZZ_WorkformID></MDL></Cite></Refman>[9].  This paper suggests ways to interpret the validation definition for agent-based simulations. Figure  SEQ Figure \* ARABIC 1.  Representation of a typical agent (left figure adapted from  ADDIN REFMGR.CITE <Refman><Cite><Author>Defense Modeling and Simulation Office</Author><Year>2004</Year><RecNum>59</RecNum><IDText>The Verification, Validation, and Accreditation Recommended Practices Guide</IDText><MDL Ref_Type="Book, Whole"><Ref_Type>Book, Whole</Ref_Type><Ref_ID>59</Ref_ID><Title_Primary>The Verification, Validation, and Accreditation Recommended Practices Guide</Title_Primary><Authors_Primary>=Defense Modeling and Simulation Office</Authors_Primary><Date_Primary>2004</Date_Primary><Keywords>verification</Keywords><Keywords>validation</Keywords><Keywords>accreditation</Keywords><Reprint>In File</Reprint><ZZ_WorkformID>2</ZZ_WorkformID></MDL></Cite></Refman>[4], right figure from  ADDIN REFMGR.CITE <Refman><Cite><Author>Moya</Author><Year>2007</Year><RecNum>192</RecNum><IDText>Towards a Taxonomy of Agents and Multi-Agent Systems</IDText><MDL Ref_Type="Conference Proceeding"><Ref_Type>Conference Proceeding</Ref_Type><Ref_ID>192</Ref_ID><Title_Primary>Towards a Taxonomy of Agents and Multi-Agent Systems</Title_Primary><Authors_Primary>Moya,Lisa Jean</Authors_Primary><Authors_Primary>Tolk,Andreas</Authors_Primary><Date_Primary>2007</Date_Primary><Keywords>agent</Keywords><Keywords>agents</Keywords><Keywords>multi-agent systems</Keywords><Keywords>SYSTEMS</Keywords><Keywords>taxonomy</Keywords><Keywords>distributed simulation</Keywords><Keywords>simulation</Keywords><Keywords>MECHANISM</Keywords><Reprint>In File</Reprint><Periodical>Proceedings of the 2007 Spring Simulation Conference: Agent Directed Simulation</Periodical><Title_Secondary>Agent Directed Simulation &apos;07</Title_Secondary><Issue>ADS-10</Issue><Date_Secondary>2007/3/26</Date_Secondary><Misc_2>Norfolk, VA</Misc_2><ZZ_JournalFull><f name="System">Proceedings of the 2007 Spring Simulation Conference: Agent Directed Simulation</f></ZZ_JournalFull><ZZ_WorkformID>12</ZZ_WorkformID></MDL></Cite></Refman>[9])ABS of InterestABSs are primarily being applied to systems with referents lying in theory (perhaps multiple, conflicting theories) but having little empirical data.  The data available for building the models are frequently qualitative in nature and without an analytic foundation.  The models are built from the bottom-up on local descriptions of behavior.  That is, micro-level modeling leads to macro-level effects through interactions that occur and are governed at the local level.  Thus, the behavior emerges rather than being scripted and top-down determined.  This paradigm lends itself well to modeling environments where the physical, analytic, mathematical representation is unknown at the macro-level such as found in social systems or when the interactions between local elements is of primary interest.  While this aggregation can lead to predictable results in some domains (e.g., predator-prey models, traffic models, and economic models), the mechanism leading to these results are unknown.  Further these models often have hidden, unobservable behaviors.  Every agent within an agent system includes an internal state representation, a knowledge base including a representation of the simulated environment, and a behavior engine which takes in any inputs and chooses behaviors based on the agent’s state and information found in the knowledge base, shown in  REF _Ref170746346 \h  \* MERGEFORMAT Figure 1.  The reasoning / decision-making architecture found in the behavior engine includes the agent’s capabilities for reacting to changes in its environment and memory capabilities as well as beliefs and goals.  An ABS is the result of the interaction of many agents within the simulation environment  ADDIN REFMGR.CITE <Refman><Cite><Author>Moya</Author><Year>2007</Year><RecNum>192</RecNum><IDText>Towards a Taxonomy of Agents and Multi-Agent Systems</IDText><MDL Ref_Type="Conference Proceeding"><Ref_Type>Conference Proceeding</Ref_Type><Ref_ID>192</Ref_ID><Title_Primary>Towards a Taxonomy of Agents and Multi-Agent Systems</Title_Primary><Authors_Primary>Moya,Lisa Jean</Authors_Primary><Authors_Primary>Tolk,Andreas</Authors_Primary><Date_Primary>2007</Date_Primary><Keywords>agent</Keywords><Keywords>agents</Keywords><Keywords>multi-agent systems</Keywords><Keywords>SYSTEMS</Keywords><Keywords>taxonomy</Keywords><Keywords>distributed simulation</Keywords><Keywords>simulation</Keywords><Keywords>MECHANISM</Keywords><Reprint>In File</Reprint><Periodical>Proceedings of the 2007 Spring Simulation Conference: Agent Directed Simulation</Periodical><Title_Secondary>Agent Directed Simulation &apos;07</Title_Secondary><Issue>ADS-10</Issue><Date_Secondary>2007/3/26</Date_Secondary><Misc_2>Norfolk, VA</Misc_2><ZZ_JournalFull><f name="System">Proceedings of the 2007 Spring Simulation Conference: Agent Directed Simulation</f></ZZ_JournalFull><ZZ_WorkformID>12</ZZ_WorkformID></MDL></Cite></Refman>[9], shown in  REF _Ref170747463 \h  \* MERGEFORMAT Figure 2.  Validation definitionsThe U.S. Department of Defense (DoD) requires verification and validation (V&V) of military simulations by way of DODD 5000.1  ADDIN REFMGR.CITE <Refman><Cite><Author>Department of Defense</Author><Year>2003</Year><RecNum>5</RecNum><IDText>Department of Defense Directive (DoDD) 5000.1:  The Defense Acquisition System</IDText><MDL Ref_Type="Book, Whole"><Ref_Type>Book, Whole</Ref_Type><Ref_ID>5</Ref_ID><Title_Primary>Department of Defense Directive (DoDD) 5000.1:  The Defense Acquisition System</Title_Primary><Authors_Primary>=Department of Defense</Authors_Primary><Date_Primary>2003/11/24</Date_Primary><Keywords>acquisition</Keywords><Keywords>DODD</Keywords><Keywords>policy</Keywords><Reprint>In File</Reprint><Publisher>USD(AT&amp;L)</Publisher><ZZ_WorkformID>2</ZZ_WorkformID></MDL></Cite></Refman>[10] and DODI 5000.61  ADDIN REFMGR.CITE <Refman><Cite><Author>Department of Defense</Author><Year>2003</Year><RecNum>21</RecNum><IDText>Department of Defense Instruction (DoDI) 5000.61:  DoD Modeling and Simulation (M&amp;S) Verification, Validation, and Accreditation (VV&amp;A)</IDText><MDL Ref_Type="Book, Whole"><Ref_Type>Book, Whole</Ref_Type><Ref_ID>21</Ref_ID><Title_Primary>Department of Defense Instruction (DoDI) 5000.61:  DoD Modeling and Simulation (M&amp;S) Verification, Validation, and Accreditation (VV&amp;A)</Title_Primary><Authors_Primary>=Department of Defense</Authors_Primary><Date_Primary>2003/5/13</Date_Primary><Keywords>DODI</Keywords><Keywords>DOD</Keywords><Keywords>modeling</Keywords><Keywords>simulation</Keywords><Keywords>policy</Keywords><Keywords>models</Keywords><Keywords>DODD</Keywords><Reprint>In File</Reprint><Publisher>USD(AT&amp;L)</Publisher><ZZ_WorkformID>2</ZZ_WorkformID></MDL></Cite></Refman>[11] and defines validation as follows:Validation is the process of determining the degree to which a model and its associated data are an accurate representation of the real world from the perspective of the intended uses of the model.This is not the only definition of validation available though.  The U.K. Ministry of Defence’s definition for validation with respect to cost models focuses on the fitness of a model or process for a given purpose:Validation – To establish that the model / process is fit for purpose  ADDIN REFMGR.CITE <Refman><Cite><Author>Burridge</Author><Year>2007</Year><RecNum>236</RecNum><IDText>UK Ministry of Defence Guidelines for the Verification and Validation of Cost Modelling for Forecasts of Future Cost</IDText><MDL Ref_Type="Report"><Ref_Type>Report</Ref_Type><Ref_ID>236</Ref_ID><Title_Primary>UK Ministry of Defence Guidelines for the Verification and Validation of Cost Modelling for Forecasts of Future Cost</Title_Primary><Authors_Primary>Burridge,J.</Authors_Primary><Date_Primary>2007/1/26</Date_Primary><Keywords>validation</Keywords><Keywords>verification</Keywords><Reprint>In File</Reprint><Volume>Vers 2 Final - U</Volume><Publisher>UK Ministry of Defence</Publisher><ZZ_WorkformID>24</ZZ_WorkformID></MDL></Cite></Refman>[12]Similar to the intended use requirement in the DoD definition, the U.K. definition highlights the need to relate validity to a specific purpose of a model.  While the U.K. definition neglects the concepts of real world, accuracy, and data and does not bound model fitness, or validity, to an accuracy assessment or a real world comparison,  ADDIN REFMGR.CITE <Refman><Cite><Author>Burridge</Author><Year>2007</Year><RecNum>236</RecNum><IDText>UK Ministry of Defence Guidelines for the Verification and Validation of Cost Modelling for Forecasts of Future Cost</IDText><MDL Ref_Type="Report"><Ref_Type>Report</Ref_Type><Ref_ID>236</Ref_ID><Title_Primary>UK Ministry of Defence Guidelines for the Verification and Validation of Cost Modelling for Forecasts of Future Cost</Title_Primary><Authors_Primary>Burridge,J.</Authors_Primary><Date_Primary>2007/1/26</Date_Primary><Keywords>validation</Keywords><Keywords>verification</Keywords><Reprint>In File</Reprint><Volume>Vers 2 Final - U</Volume><Publisher>UK Ministry of Defence</Publisher><ZZ_WorkformID>24</ZZ_WorkformID></MDL></Cite></Refman>[12] provides elaboration on the definition and its application.  As stated in  ADDIN REFMGR.CITE <Refman><Cite><Author>Burridge</Author><Year>2007</Year><RecNum>236</RecNum><IDText>UK Ministry of Defence Guidelines for the Verification and Validation of Cost Modelling for Forecasts of Future Cost</IDText><MDL Ref_Type="Report"><Ref_Type>Report</Ref_Type><Ref_ID>236</Ref_ID><Title_Primary>UK Ministry of Defence Guidelines for the Verification and Validation of Cost Modelling for Forecasts of Future Cost</Title_Primary><Authors_Primary>Burridge,J.</Authors_Primary><Date_Primary>2007/1/26</Date_Primary><Keywords>validation</Keywords><Keywords>verification</Keywords><Reprint>In File</Reprint><Volume>Vers 2 Final - U</Volume><Publisher>UK Ministry of Defence</Publisher><ZZ_WorkformID>24</ZZ_WorkformID></MDL></Cite></Refman>[12], validation seeks to determine “the extent to which a model represents the real world situation” to ensure that there is “objective and auditable” evidence to support the assessed model capabilities as well as its supporting data.  Figure  SEQ Figure \* ARABIC 2.  Typical multi-agent system (found in  ADDIN REFMGR.CITE <Refman><Cite><Author>Moya</Author><Year>2007</Year><RecNum>192</RecNum><IDText>Towards a Taxonomy of Agents and Multi-Agent Systems</IDText><MDL Ref_Type="Conference Proceeding"><Ref_Type>Conference Proceeding</Ref_Type><Ref_ID>192</Ref_ID><Title_Primary>Towards a Taxonomy of Agents and Multi-Agent Systems</Title_Primary><Authors_Primary>Moya,Lisa Jean</Authors_Primary><Authors_Primary>Tolk,Andreas</Authors_Primary><Date_Primary>2007</Date_Primary><Keywords>agent</Keywords><Keywords>agents</Keywords><Keywords>multi-agent systems</Keywords><Keywords>SYSTEMS</Keywords><Keywords>taxonomy</Keywords><Keywords>distributed simulation</Keywords><Keywords>simulation</Keywords><Keywords>MECHANISM</Keywords><Reprint>In File</Reprint><Periodical>Proceedings of the 2007 Spring Simulation Conference: Agent Directed Simulation</Periodical><Title_Secondary>Agent Directed Simulation &apos;07</Title_Secondary><Issue>ADS-10</Issue><Date_Secondary>2007/3/26</Date_Secondary><Misc_2>Norfolk, VA</Misc_2><ZZ_JournalFull><f name="System">Proceedings of the 2007 Spring Simulation Conference: Agent Directed Simulation</f></ZZ_JournalFull><ZZ_WorkformID>12</ZZ_WorkformID></MDL></Cite></Refman>[9], adapted from  ADDIN REFMGR.CITE <Refman><Cite><Author>Wooldridge</Author><Year>2002</Year><RecNum>9</RecNum><IDText>An Introduction to MultiAgent Systems</IDText><MDL Ref_Type="Book, Whole"><Ref_Type>Book, Whole</Ref_Type><Ref_ID>9</Ref_ID><Title_Primary>An Introduction to MultiAgent Systems</Title_Primary><Authors_Primary>Wooldridge,Michael J.</Authors_Primary><Date_Primary>2002</Date_Primary><Reprint>In File</Reprint><Pub_Place>West Sussex, England</Pub_Place><Publisher>John Wiley and Sons</Publisher><ISSN_ISBN>0-471-49691-X</ISSN_ISBN><ZZ_WorkformID>2</ZZ_WorkformID></MDL></Cite></Refman>[13])The American Society of Mechanical Engineers (ASME) has a definition of validation similar to that of the DoD, merely leaving out the importance of the model’s associated data:The process of determining the degree to which a model is an accurate representation of the real world from the perspective of the intended use of the model  ADDIN REFMGR.CITE <Refman><Cite><Author>Schwer</Author><Year>2006</Year><RecNum>238</RecNum><IDText>An overview of the ASME guide for verification and validation in computational solid mechanics</IDText><MDL Ref_Type="Conference Proceeding"><Ref_Type>Conference Proceeding</Ref_Type><Ref_ID>238</Ref_ID><Title_Primary>An overview of the ASME guide for verification and validation in computational solid mechanics</Title_Primary><Authors_Primary>Schwer,L.E.</Authors_Primary><Date_Primary>2006</Date_Primary><Keywords>verification</Keywords><Keywords>validation</Keywords><Reprint>In File</Reprint><Start_Page>A - II - 111</Start_Page><End_Page>A - II - 122</End_Page><Periodical>LS-DYNA</Periodical><Volume>Keynote - Vortr&#xE4;ge II</Volume><Publisher>The American Society of Mechanical Engineers</Publisher><Misc_2>Anwenderforum, Ulm</Misc_2><ZZ_JournalFull><f name="System">LS-DYNA</f></ZZ_JournalFull><ZZ_WorkformID>12</ZZ_WorkformID></MDL></Cite></Refman>[14]AMSE gives clarification to the definition of validation in  ADDIN REFMGR.CITE <Refman><Cite><Author>Schwer</Author><Year>2006</Year><RecNum>238</RecNum><IDText>An overview of the ASME guide for verification and validation in computational solid mechanics</IDText><MDL Ref_Type="Conference Proceeding"><Ref_Type>Conference Proceeding</Ref_Type><Ref_ID>238</Ref_ID><Title_Primary>An overview of the ASME guide for verification and validation in computational solid mechanics</Title_Primary><Authors_Primary>Schwer,L.E.</Authors_Primary><Date_Primary>2006</Date_Primary><Keywords>verification</Keywords><Keywords>validation</Keywords><Reprint>In File</Reprint><Start_Page>A - II - 111</Start_Page><End_Page>A - II - 122</End_Page><Periodical>LS-DYNA</Periodical><Volume>Keynote - Vortr&#xE4;ge II</Volume><Publisher>The American Society of Mechanical Engineers</Publisher><Misc_2>Anwenderforum, Ulm</Misc_2><ZZ_JournalFull><f name="System">LS-DYNA</f></ZZ_JournalFull><ZZ_WorkformID>12</ZZ_WorkformID></MDL></Cite></Refman>[14] by viewing it as determining the “physics” of the model, or the appropriate real world representation.  This includes the determination of the adequacy of selected conceptual and mathematical models.  In contrast, verification includes the determination that the code that solves the mathematics is working correctly at the desired level of accuracy.  Physical testing and real world experimental data are viewed as critical by ASME in order to assess the adequacy of chosen conceptual and mathematical models.  Finally, the stated goal of the validation process, as given in  ADDIN REFMGR.CITE <Refman><Cite><Author>Schwer</Author><Year>2006</Year><RecNum>238</RecNum><IDText>An overview of the ASME guide for verification and validation in computational solid mechanics</IDText><MDL Ref_Type="Conference Proceeding"><Ref_Type>Conference Proceeding</Ref_Type><Ref_ID>238</Ref_ID><Title_Primary>An overview of the ASME guide for verification and validation in computational solid mechanics</Title_Primary><Authors_Primary>Schwer,L.E.</Authors_Primary><Date_Primary>2006</Date_Primary><Keywords>verification</Keywords><Keywords>validation</Keywords><Reprint>In File</Reprint><Start_Page>A - II - 111</Start_Page><End_Page>A - II - 122</End_Page><Periodical>LS-DYNA</Periodical><Volume>Keynote - Vortr&#xE4;ge II</Volume><Publisher>The American Society of Mechanical Engineers</Publisher><Misc_2>Anwenderforum, Ulm</Misc_2><ZZ_JournalFull><f name="System">LS-DYNA</f></ZZ_JournalFull><ZZ_WorkformID>12</ZZ_WorkformID></MDL></Cite></Refman>[14], is to assess the predictive capability of a model with the intended use of making certain, specified predictions.  Other organizations have similar definitions for validation.  For instance, the American Institute of Aeronautics and Astronautics uses the ASME definition ( ADDIN REFMGR.CITE <Refman><Cite><Author>American Institute of Aeronautics and Astronautics</Author><Year>1999</Year><RecNum>243</RecNum><IDText>Guide for the verification and validation of computation fluid dynamics simulations</IDText><MDL Ref_Type="Report"><Ref_Type>Report</Ref_Type><Ref_ID>243</Ref_ID><Title_Primary>Guide for the verification and validation of computation fluid dynamics simulations</Title_Primary><Authors_Primary>=American Institute of Aeronautics and Astronautics</Authors_Primary><Date_Primary>1999</Date_Primary><Keywords>simulation</Keywords><Keywords>validation</Keywords><Keywords>verification</Keywords><Reprint>In File</Reprint><Volume>AIAA-F-077-1998</Volume><Pub_Place>Reston, VA</Pub_Place><Publisher>American Institute of Aeronautics and Astronautics</Publisher><ZZ_WorkformID>24</ZZ_WorkformID></MDL></Cite></Refman>[15] as cited in  ADDIN REFMGR.CITE <Refman><Cite><Author>Oberkampf</Author><Year>2002</Year><RecNum>241</RecNum><IDText>Verification and validation in computational fluid dynamics</IDText><MDL Ref_Type="Report"><Ref_Type>Report</Ref_Type><Ref_ID>241</Ref_ID><Title_Primary>Verification and validation in computational fluid dynamics</Title_Primary><Authors_Primary>Oberkampf,William L.</Authors_Primary><Authors_Primary>Trucano,Timothy</Authors_Primary><Date_Primary>2002/3</Date_Primary><Keywords>validation</Keywords><Keywords>verification</Keywords><Reprint>In File</Reprint><Volume>SAND2002-0529</Volume><Pub_Place>Albuquerque, NM</Pub_Place><Publisher>Sandia National Laboratories</Publisher><ZZ_WorkformID>24</ZZ_WorkformID></MDL></Cite></Refman>[16]).  Specifically, it deals with between a sufficiently accurate computational model, determined through verification, and experimental data, where the experimental data serves as the best proxy available for the real world.  Validation quantifies error and uncertainty within the conceptual and computational models as implemented in code  ADDIN REFMGR.CITE <Refman><Cite><Author>Oberkampf</Author><Year>2002</Year><RecNum>241</RecNum><IDText>Verification and validation in computational fluid dynamics</IDText><MDL Ref_Type="Report"><Ref_Type>Report</Ref_Type><Ref_ID>241</Ref_ID><Title_Primary>Verification and validation in computational fluid dynamics</Title_Primary><Authors_Primary>Oberkampf,William L.</Authors_Primary><Authors_Primary>Trucano,Timothy</Authors_Primary><Date_Primary>2002/3</Date_Primary><Keywords>validation</Keywords><Keywords>verification</Keywords><Reprint>In File</Reprint><Volume>SAND2002-0529</Volume><Pub_Place>Albuquerque, NM</Pub_Place><Publisher>Sandia National Laboratories</Publisher><ZZ_WorkformID>24</ZZ_WorkformID></MDL></Cite></Refman>[16].  The Department of Energy focuses on validation in terms of software engineering and the ability of a specific computer model to support predictive physical modeling as compared to some experimental observations, perhaps with some acceptable stated error  ADDIN REFMGR.CITE <Refman><Cite><Author>Hills</Author><Year>2001</Year><RecNum>244</RecNum><IDText>Statistical validation of engineering and scientific models with application to CTH</IDText><MDL Ref_Type="Report"><Ref_Type>Report</Ref_Type><Ref_ID>244</Ref_ID><Title_Primary>Statistical validation of engineering and scientific models with application to CTH</Title_Primary><Authors_Primary>Hills,Richard G.</Authors_Primary><Authors_Primary>Trucano,Timothy</Authors_Primary><Date_Primary>2001/5</Date_Primary><Keywords>model</Keywords><Keywords>models</Keywords><Keywords>validation</Keywords><Reprint>In File</Reprint><Volume>SAND2001-0312</Volume><Publisher>Sandia National Laboratories</Publisher><ZZ_WorkformID>24</ZZ_WorkformID></MDL></Cite><Cite><Author>Thacker</Author><Year>2004</Year><RecNum>245</RecNum><IDText>Concepts of model verification and validation</IDText><MDL Ref_Type="Report"><Ref_Type>Report</Ref_Type><Ref_ID>245</Ref_ID><Title_Primary>Concepts of model verification and validation</Title_Primary><Authors_Primary>Thacker,Ben H.</Authors_Primary><Authors_Primary>Doebling,Scott W.</Authors_Primary><Authors_Primary>Hemez,Francois M.</Authors_Primary><Authors_Primary>Anderson,Mark C.</Authors_Primary><Authors_Primary>Pepin,Jason E.</Authors_Primary><Authors_Primary>Rodriguez,Edward A.</Authors_Primary><Date_Primary>2004/10</Date_Primary><Keywords>model</Keywords><Keywords>validation</Keywords><Keywords>verification</Keywords><Reprint>In File</Reprint><Volume>LA-14167-MS</Volume><Publisher>Los Alamos National Laboratory</Publisher><ZZ_WorkformID>24</ZZ_WorkformID></MDL></Cite></Refman>[17,18].  It defines validation similarly to the ASME:  The process of determining the degree to which a computer model is an accurate representation of the real world from the perspective of the intended model applications ( ADDIN REFMGR.CITE <Refman><Cite><Author>U.S. Department of Energy Defense Programs</Author><Year>2000</Year><RecNum>239</RecNum><IDText>Accelerated Strategic Computing Initiative (ASCI) Program Plan</IDText><MDL Ref_Type="Report"><Ref_Type>Report</Ref_Type><Ref_ID>239</Ref_ID><Title_Primary>Accelerated Strategic Computing Initiative (ASCI) Program Plan</Title_Primary><Authors_Primary>=U.S. Department of Energy Defense Programs</Authors_Primary><Date_Primary>2000</Date_Primary><Keywords>validation</Keywords><Reprint>In File</Reprint><Volume>DOE/Dp-00-000010592</Volume><ZZ_WorkformID>24</ZZ_WorkformID></MDL></Cite></Refman>[19] as cited in  ADDIN REFMGR.CITE <Refman><Cite><Author>Oberkampf</Author><Year>2002</Year><RecNum>241</RecNum><IDText>Verification and validation in computational fluid dynamics</IDText><MDL Ref_Type="Report"><Ref_Type>Report</Ref_Type><Ref_ID>241</Ref_ID><Title_Primary>Verification and validation in computational fluid dynamics</Title_Primary><Authors_Primary>Oberkampf,William L.</Authors_Primary><Authors_Primary>Trucano,Timothy</Authors_Primary><Date_Primary>2002/3</Date_Primary><Keywords>validation</Keywords><Keywords>verification</Keywords><Reprint>In File</Reprint><Volume>SAND2002-0529</Volume><Pub_Place>Albuquerque, NM</Pub_Place><Publisher>Sandia National Laboratories</Publisher><ZZ_WorkformID>24</ZZ_WorkformID></MDL></Cite></Refman>[16] )The focus for the DOE is the solving of numerical equations, and at the heart of predictability assessment is the need for experimental results against which to compare model outputs.  Another, less formal, view of validation is that of the “process of determining that the equations are correct.”  In contrast, the process of determining that the equations are solved correctly is verification  ADDIN REFMGR.CITE <Refman><Cite><Author>Pilch</Author><Year>2000</Year><RecNum>240</RecNum><IDText>Guidelines for Sandia ASCI verification and validation plans - content and format: version 2.0</IDText><MDL Ref_Type="Report"><Ref_Type>Report</Ref_Type><Ref_ID>240</Ref_ID><Title_Primary>Guidelines for Sandia ASCI verification and validation plans - content and format: version 2.0</Title_Primary><Authors_Primary>Pilch,Martin</Authors_Primary><Authors_Primary>Trucano,Timothy</Authors_Primary><Authors_Primary>Moya,Jaime L.</Authors_Primary><Authors_Primary>Froehlich,Gary</Authors_Primary><Authors_Primary>Hodges,Ann</Authors_Primary><Authors_Primary>Peercy,David</Authors_Primary><Date_Primary>2000</Date_Primary><Keywords>validation</Keywords><Keywords>verification</Keywords><Reprint>In File</Reprint><Volume>SAND2000-3101</Volume><ZZ_WorkformID>24</ZZ_WorkformID></MDL></Cite></Refman>[20].  The Institute of Electrical and Electronics Engineers (IEEE) definition of validation differs significantly from the other definitionsThe process of evaluating a system or component during or at the end of the development process to determine whether it satisfies specified requirements ( ADDIN REFMGR.CITE <Refman><Cite><Author>Institute of Electrical and Electronics Engineers</Author><Year>1991</Year><RecNum>242</RecNum><IDText>IEEE Standard Glossary of software engineering terminology</IDText><MDL Ref_Type="Report"><Ref_Type>Report</Ref_Type><Ref_ID>242</Ref_ID><Title_Primary>IEEE Standard Glossary of software engineering terminology</Title_Primary><Authors_Primary>=Institute of Electrical and Electronics Engineers</Authors_Primary><Date_Primary>1991</Date_Primary><Reprint>In File</Reprint><Volume>IEEE Std 610.12-1990</Volume><Pub_Place>New York</Pub_Place><Publisher>IEEE</Publisher><ZZ_WorkformID>24</ZZ_WorkformID></MDL></Cite></Refman>[21] as cited in  ADDIN REFMGR.CITE <Refman><Cite><Author>Oberkampf</Author><Year>2002</Year><RecNum>241</RecNum><IDText>Verification and validation in computational fluid dynamics</IDText><MDL Ref_Type="Report"><Ref_Type>Report</Ref_Type><Ref_ID>241</Ref_ID><Title_Primary>Verification and validation in computational fluid dynamics</Title_Primary><Authors_Primary>Oberkampf,William L.</Authors_Primary><Authors_Primary>Trucano,Timothy</Authors_Primary><Date_Primary>2002/3</Date_Primary><Keywords>validation</Keywords><Keywords>verification</Keywords><Reprint>In File</Reprint><Volume>SAND2002-0529</Volume><Pub_Place>Albuquerque, NM</Pub_Place><Publisher>Sandia National Laboratories</Publisher><ZZ_WorkformID>24</ZZ_WorkformID></MDL></Cite></Refman>[16]).This definition neglects the intended use of the model; perhaps assuming the requirements will explicitly capture the needs of the intended use and will embed the real world physical mathematical descriptions and accuracy representations needed for model development.  Figure  SEQ Figure \* ARABIC 3.  General validation process (adapted from  ADDIN REFMGR.CITE <Refman><Cite><Author>Defense Modeling and Simulation Office</Author><Year>2004</Year><RecNum>59</RecNum><IDText>The Verification, Validation, and Accreditation Recommended Practices Guide</IDText><MDL Ref_Type="Book, Whole"><Ref_Type>Book, Whole</Ref_Type><Ref_ID>59</Ref_ID><Title_Primary>The Verification, Validation, and Accreditation Recommended Practices Guide</Title_Primary><Authors_Primary>=Defense Modeling and Simulation Office</Authors_Primary><Date_Primary>2004</Date_Primary><Keywords>verification</Keywords><Keywords>validation</Keywords><Keywords>accreditation</Keywords><Reprint>In File</Reprint><ZZ_WorkformID>2</ZZ_WorkformID></MDL></Cite></Refman>[4])Validation versus VerificationValidation is commonly thought of in terms of answering the question, “Was the right thing coded?” Whereas, verification answers the question, “Was it coded right?”  ADDIN REFMGR.CITE <Refman><Cite><Author>Defense Modeling and Simulation Office</Author><Year>2004</Year><RecNum>59</RecNum><IDText>The Verification, Validation, and Accreditation Recommended Practices Guide</IDText><MDL Ref_Type="Book, Whole"><Ref_Type>Book, Whole</Ref_Type><Ref_ID>59</Ref_ID><Title_Primary>The Verification, Validation, and Accreditation Recommended Practices Guide</Title_Primary><Authors_Primary>=Defense Modeling and Simulation Office</Authors_Primary><Date_Primary>2004</Date_Primary><Keywords>verification</Keywords><Keywords>validation</Keywords><Keywords>accreditation</Keywords><Reprint>In File</Reprint><ZZ_WorkformID>2</ZZ_WorkformID></MDL></Cite></Refman>[4].  There are subtle distinctions between the two activities with areas of gray, or overlap, between the two, especially when spiral development and iterative verification and validation are used.  The distinctions can be seen when considering fine tuned physics modeling.  This modeling construct uses differential (difference) equations, and the solution estimation technique used is important for the accuracy level which can be achieved (e.g., Runge-Kutte, Eulers method, et al).  The conceptual model includes the mathematical equations and data along with initial and boundary conditions for the system being modeled.  The computational model is the code that implements this model.  Validation consists of ensuring that the conceptual model is correct for the purpose to which the simulation model will be put; i.e., the mathematical equations and physical models are correct (Conceptual Model Validation).  This includes ensuring that the chosen iterative strategies generate the desired level of accuracy.  In contrast, verification ensures that the algorithm was programmed correctly.  In models of this type, the verification process assesses the correctness of the computational model against a subset of known simple, test problems, where the validation process compares the computational solutions of the verified model to experimental results (Results Validation).   REF _Ref170748679 \h Figure 3 shows how these processes are related.Thus, validation is in part ensuring that the model being used fits the needs of the modeling construct.  For example, is a flat or round earth required, are frictional or other modifiers required, etc.  Similarly, when designing an ABS, it is important to validate the rule sets that generate and select between agent behaviors.  That is, in ABS systems, it is important to validate that the mathematical equations that represent the rules in the model meet the intent of the system conceptualization.  This is equivalent to validating the choice of appropriate physical model but is made more difficult since the systems that ABSs are generally applied to do not have a codified analytic theory governing them.  Further, these systems often do not have large amounts of data to support their development and experimentation with these systems is often difficult to impossible.  Ensuring that the chosen rules are programmed correctly is verification.  While matching the chosen rule to the basic theoretical requirements and ensuring that the rule acts as expected and as needed is validation.  This includes making sure that the model conceptualization is traceable to some source.  In physics based modeling and data based modeling this source traceability is straightforward as to be obvious, in these other modeling constructs the sourcing needs to be more concrete.  When evaluating the purpose of validation, in part, it can be seen as a communication activity that gives the << Insert cycle / iterative validation graphic here>>Figure  SEQ Figure \* ARABIC 4.  Cycle of validation elementsability of an M&S to meet user requirements in support of a specific intended use application and provides information to the decision-makers so that they can make effective decisions about the use of a model.  Thus, validity is a qualitative and not an absolute assessment.  That is, a model is not valid in all cases for all pursuits; a model may be valid in some instances, but not in others.  In contrast, verification checks to ensure that the coded is correct within the areas, bounds, and parameters of interest.Applying the Validation DefinitionIntuitively, the validity of the model is based upon how closely the behaviors in simulation match the real world.  This concept is captured in each of these definitions using three main components:  the thing to be simulated, the simulation model; and a bounding principle.  The thing to be simulated is captured by the term “real world” in most of the discussed definitions.  The simulation model includes the “model and its associated data” in the DoD definition, the model / process in the U.K. definition, and the system or component in the IEEE definition.  The bounding principle is the concept of “fit for purpose” in the U.K. definition and is determined by the accuracy required for the intended use of the model in the DoD definition, and satisfying the specified requirements in the IEEE definition.  Understanding and applying this definition, sticking with the DoD definition as the baseline, it is important to understand what is meant by the “real world,” the model, and the bounding principle.  Real world or referentThe real world is captured in physics based modeling by empirical data.  This is the referent against which simulation results are compared.  Empirical data is sufficient for results validation, but when assessing the choice of conceptual model other referents are used.  Physics based modeling has the analytic, mathematical model as the referent in the (axiomatic) conceptual model validation.  In other types of modeling, the referent for an M&S is the system conceptualization against which the conceptual or mathematical model is compared when assessing whether it contains all of the right elements at the desired level of fidelity, hopefully resulting in the needed accuracy for a stated intended use.  For simulations of social systems, this may be the underlying theory that serves as the basis for the model development.Because the assessment can be made against multiple model elements, single model may be multiple referents depending on what aspects of the M&S are being validated.  For example, the conceptual model for an M&S may have a referent which is based on SMEs, theory, data, and other sources.  Each of these could be a referent for the system of interest.  This material, compiled together into a coherent form, gives another referent for the model.  This is a conceptualization of the system of interest and given the basis against which the conceptual model is compared.The conceptual model, containing all of the agent behaviors (in an ABS), relationships, expected outcomes, etc. then forms the referent for the mathematical instantiation of the model used to capture the desired system model behaviors.  The mathematical description forms the referent for the computational, algorithmic instantiation of the model.  Each of these relationships is one to many; that is, there are many mathematical descriptions for a given conceptual model and there are many algorithms to capture a mathematical description.  Whether the chosen capture method is appropriate depends on the required parameters and the level of accuracy desired.  Lastly, expected model results and behaviors found in the conceptual model as well as expected results from real world data, other models, direct calculation, or other sources form the referent against which results from simulation runs are compared.   REF _Ref171941388 \h Figure 4 shows this progression.Simulation modelThe progression in  REF _Ref171941388 \h Figure 4 demonstrates that there is a model to be validated at each step.  Three of the main models are the conceptual model, the mathematical model, and the instantiated or coded model.  The conceptual model is a description of the basic theory used to substantiate the description of the system under consideration.  The validation process in this domain requires the determination that the conceptualization of the system matches available data and theory for the system containing all of the relevant aspects of that system necessary to support the intended use.  When data or theory (possibly multiple theories) is in conflict, then the choices made and their justifications are documented to ensure traceability throughout the process.  The conceptual model, when built, needs to drive to a sufficiently detailed description of the system to enable the building of a mathematical description of the system.  The mathematical model is the way in which the system is describes so that it can be captured in code.  In physics based modeling, this is the analytic model.  In the ABS construct, this is the specifics choices of how rules are implemented within the system model.  For instance, the conceptual model may say have a state value increasing with certain stimuli.  The mathematical model is the formulae used to calculate the state value increase as a function of the relevant stimuli.  More than one formulation could be possible.  The coded model is the algorithm instantiated in the computer used to calculate the mathematical formulation of the conceptual model of the system.  Bounding principleThe bounding principle for assessing validity is encompassed by the dual concepts of intended use and accuracy.  Intended use drives the level, degree, and type of accuracy required for a given simulation.  Accuracy is a description of the match between a simulation and some comparative set.  Some uses may allow a subject matter expert opinion assessment that the model “looks about right,” while other uses could require a measurement that empirical data and simulation results are within some tolerance of each other.  For instance, predictive uses could require a high level of simulation accuracy between the system and its model with a low level of error, while training or gaming uses may only require some level of equivalence between the system and its model.  Trend assessments or analysis applications may require low level of accuracy on a state by state basis but high equivalence match, while test and evaluation or design applications could require a higher state by state match.  Other accuracy assessments are possible such as a confidence interval about the mean end state of the simulation, a comparison of end states, or a probability of achieving certain trends.Validation for ABSIn the areas to which ABS is applied, unlike with physics based models, the theory underlying the system in unknown.  Further, the data supporting model development is sparse.  Therefore, there is little data available against which simulationists and model builders can use to build and test their models.  This means that the referent against the simulation model is compared may be difficult to obtain and, perhaps, may have to be built during the model development process.  Documentation of the assumptions, references, and justifications for the choices made in the development of the conceptual model can support validation as well as support model use through providing a communication mechanism between developers, users, and decision-makers.  An ABS is built from the composition of multiple agents embedded in a simulation environment.  This implies that the validity of the simulation depends not only on the validity of the individual agents of which the simulation is comprised but also on the composition and interaction between these agents (so called micro-macro effects  ADDIN REFMGR.CITE <Refman><Cite><Author>Bankes</Author><Year>2002</Year><RecNum>232</RecNum><IDText>Agent-based modeling: A revolution?</IDText><MDL Ref_Type="Conference Proceeding"><Ref_Type>Conference Proceeding</Ref_Type><Ref_ID>232</Ref_ID><Title_Primary>Agent-based modeling: A revolution?</Title_Primary><Authors_Primary>Bankes,Steven C.</Authors_Primary><Date_Primary>2002</Date_Primary><Keywords>agent based</Keywords><Keywords>modeling</Keywords><Reprint>In File</Reprint><Start_Page>7199</Start_Page><End_Page>7200</End_Page><Periodical>Proceedings of the National Academy of Sciences of the United States of America</Periodical><Volume>PNAS 2002</Volume><Issue>99</Issue><Web_URL><u>www.pnas.org/cgi/doi/10.1073/pnas/072081299</u></Web_URL><ZZ_JournalFull><f name="System">Proceedings of the National Academy of Sciences of the United States of America</f></ZZ_JournalFull><ZZ_WorkformID>12</ZZ_WorkformID></MDL></Cite></Refman>[22]).  This creates layers for validation.  First, the individual agents or the micro-level representation need to be validated.  This includes the agents’ conceptual models, knowledge bases, mathematical instantiations, and coded implementations.  Second, the interactions between agents within the simulation environment or the macro-level representation need to be validated.  This includes the conceptual model of the agents’ interactions as well as the simulation results.  In assessing validity of these elements, various bounding principles could be used.  In the conceptual model validation, a binary assessment of included/not included could be made.  Mathematical model validation could be an assessment that the correct (broad) relationships are in place.  Results validation could run the gambit from a state by state match with some theoretical expectation to an assessment that the overall trends occurring in the model match the theory.SummaryValidation is critical to the credible use of any model and simulation.  While there are many definitions for validation which differ slightly in language and application, each has three main components:  the thing to be simulated, the simulation model, and a bounding principle.  In physics based models, the meaning and application of these terms is straightforward.  However, for ABS in military applications, further elaboration of these terms is required in order to develop an ABS validation framework.  The concepts of intended use and accuracy together form the bounding principle for a simulation.  In physics based models this is frequently cast in terms of an error tolerance, confidence interval, or some other easily measurable, quantitative assessment which relies on the accessibility of empirical data, which is used as a proxy for the real world system being modeled.  Since ABS are used for systems lacking in empirical data and frequently have little theoretical support for model development and experimentation with the system is impractical or impossible, the determination of the referent representing the real world can be problematical.  The simulationist may need to reconcile multiple, conflicting theories.  Thus, the determination and validation of the conceptual model is a necessary element of the overall validation approach.  The validation of the conceptual model and knowledge base reflect the need to have a valid micro-level representation on which these models are predicated.  Results validation ensures that the interactions that occur at the local levels create an appropriately accurate macro-level representation of the system being modeled (for the intended use).  Therefore, in validating an agent system, the validation agent needs to evaluate the conceptual model design, the knowledge base, the behavior engine and knowledge base implementation, and the overall integration with simulation environment.AcknowledgementsElements of this work were completed under the MCDCC ABS Verification and Validation (V&V) Framework Study.  We gratefully acknowledge the support and input the MCCDC ABS V&V Framework Study Workshop participants, the MCDCC ABS V&V Study team members, and the MCDCC.  References ADDIN REFMGR.REFLIST [1]	J.R. Cares: "The use of agent-based models in military concept development" Proceedings of the 2002 Winter Simulation Conference, pp. 935-939, 2002. [2]	Marine Corps Warfighting Laboratory: "Project Albert"  HYPERLINK "http://projectalbert.org," http://projectalbert.org, 7-18-2006. [3]	S.Y. Harmon, C.W.D. Hoffman, A.J. Gonzalez, R. Knauf, and V.B. Barr: "Validation of Human Behavior Representations" Proceedings of Foundations for V&V in the 21st Century Workshop (Foundations '02), pp. B3-1-B3-34, 2002. [4]	Defense Modeling and Simulation Office: The Verification, Validation, and Accreditation Recommended Practices Guide. 2004[5]	G. Akst: "Musings on verification, validation, and accreditation (VV&A) of analytical combat simulations" Phalanx, Vol. 39, 3, pp. 9-11, 2006[6]	L. J. Moya, F. D. McKenzie, Q.-A. H. Nguyen: "A Visualization Technique to Support Human Behavior Representation Model Rule Validation" Simulation & Gaming: An Interdisciplinary Journal of Theory, Practice, and Research, Vol. A symposium issue, submitted October 2006, revised February 2007, accepted March 2007, Artificial Intelligence, Intelligent Agents, and Simulation Gaming, a special issue, 2007[7]	L.J. Moya and E.W. Weisel: "Towards a methodology for validating emergent behavior simulations" European Simulation Interoperability Workshop 07E-SIW-055, 2007. [8]	E.W. Weisel and L.J. Moya: "Towards an Architecture for Distributed Component-Based Simulation" European Simulation Interoperability Workshop 07E-SIW-057, 2007. [9]	L.J. Moya and A. Tolk: "Towards a Taxonomy of Agents and Multi-Agent Systems" Proceedings of the 2007 Spring Simulation Conference: Agent Directed Simulation, ADS-10, 2007. [10]	Department of Defense: Department of Defense Directive (DoDD) 5000.1:  The Defense Acquisition System. USD(AT&L), 2003[11]	Department of Defense: Department of Defense Instruction (DoDI) 5000.61:  DoD Modeling and Simulation (M&S) Verification, Validation, and Accreditation (VV&A). USD(AT&L), 2003[12]	J. Burridge: "UK Ministry of Defence Guidelines for the Verification and Validation of Cost Modelling for Forecasts of Future Cost" Vers 2 Final - U,  UK Ministry of Defence. 1-26-2007. [13]	M.J. Wooldridge: An Introduction to MultiAgent Systems. West Sussex, England, John Wiley and Sons, 2002[14]	L.E. Schwer: "An overview of the ASME guide for verification and validation in computational solid mechanics" LS-DYNA Keynote - Vorträge II, p. A - II - 111-A - II - 122,  The American Society of Mechanical Engineers. 2006. [15]	American Institute of Aeronautics and Astronautics: "Guide for the verification and validation of computation fluid dynamics simulations" AIAA-F-077-1998, Reston, VA, American Institute of Aeronautics and Astronautics. 1999. [16]	W.L. Oberkampf and T. Trucano: "Verification and validation in computational fluid dynamics" SAND2002-0529, Albuquerque, NM, Sandia National Laboratories. 2002. [17]	R.G. Hills and T. Trucano: "Statistical validation of engineering and scientific models with application to CTH" SAND2001-0312,  Sandia National Laboratories. 2001. [18]	B.H. Thacker, S.W. Doebling, F.M. Hemez, M.C. Anderson, J.E. Pepin, and E.A. Rodriguez: "Concepts of model verification and validation" LA-14167-MS,  Los Alamos National Laboratory. 2004. [19]	U.S. Department of Energy Defense Programs: "Accelerated Strategic Computing Initiative (ASCI) Program Plan" DOE/Dp-00-000010592, 2000. [20]	M. Pilch, T. Trucano, J.L. Moya, G. Froehlich, A. Hodges, and D. Peercy: "Guidelines for Sandia ASCI verification and validation plans - content and format: version 2.0" SAND2000-3101, 2000. [21]	Institute of Electrical and Electronics Engineers: "IEEE Standard Glossary of software engineering terminology" IEEE Std 610.12-1990, New York, IEEE. 1991. [22]	S.C. Bankes: "Agent-based modeling: A revolution?" Proceedings of the National Academy of Sciences of the United States of America PNAS 2002, 99, pp. 7199-7200, 2002. Author BiographiesLISA JEAN MOYA, as Chief Scientist, leads WernerAnderson’s modeling and simulation (M&S) research and development effort.  She is co-chair of the M&S Caucus Standing Committee in support of M&S Professional Development and Education.  She received an M.S. in Operations Research from The College of William and Mary and a B.S. in Applied Mathematics from Old Dominion University.  Ms. Moya’s areas of expertise include Multiple Objective Decision Analysis (MODA), Multi-Attribute Utility Theory (MAUT), Modeling and Simulation, simulation validation, and the development and application of analysis.  Her research interests include agent based simulation, simulation theory and formalisms, and validation.SIMONE YOUNGBLOOD is 